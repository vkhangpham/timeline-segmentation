id,title,content,year,cited_by_count,keywords,children
https://openalex.org/W2068737686,Automatic acquisition of hyponyms from large text corpora,"Automatic acquisition of hyponyms from large text corpora

We describe a method for the automatic acquisition of hyponymy lexical relation from unrestricted text. Two goals motivate approach: (i) avoidance need pre-encoded knowledge and (ii) applicability across wide range identify set lexico-syntactic patterns that are easily recognizable, occur frequently text genre boundaries, indisputably indicate interest. discovering these suggest other relations will also be acquirable in this way. A subset algorithm is implemented results used to augment critique structure large hand-built thesaurus. Extensions applications areas such as information retrieval suggested.

pattern recognition, computer science, linguistics, computational linguistics, automatic classification, information fusion, semantic evaluation, terminology extraction, data science, machine translation, keyword extraction, large text corpora, machine learning research, terminology management, text mining, natural language processing, information extraction, automatic acquisition, knowledge discovery, corpus linguistics",1992,3274,pattern recognition|computer science|linguistics|computational linguistics|automatic classification|information fusion|semantic evaluation|terminology extraction|data science|machine translation|keyword extraction|large text corpora|machine learning research|terminology management|text mining|natural language processing|information extraction|automatic acquisition|knowledge discovery|corpus linguistics,
https://openalex.org/W2117331532,In Other Words: A Coursebook on Translation,"In Other Words: A Coursebook on Translation

In Other Words is the definitive coursebook for students studying translation. Assuming knowledge of foreign languages, it offers practical and theoretical guidance translation studies, provides an important foundation training professional translators.

speech translation, specialized translation, multimodal translation, comparative literature, machine translation, translation studies",1992,889,speech translation|specialized translation|multimodal translation|comparative literature|machine translation|translation studies,https://openalex.org/W1481560182|https://openalex.org/W2167645056
https://openalex.org/W1644866298,An Introduction to Machine Translation,"An Introduction to Machine Translation

General introduction and brief history linguistic background computational aspects basic strategies analysis problems of transfer interlingua generation the practical use MT systems evaluation Systran SUSY Meteo (TAUM) Ariane (GETA) Eurotra METAL Rosetta DLT some other directions research.

computer science, natural language processing, neural machine translation, computational linguistics, multimodal translation, machine translation, translation studies",1992,759,computer science|natural language processing|neural machine translation|computational linguistics|multimodal translation|machine translation|translation studies,https://openalex.org/W2203653769|https://openalex.org/W1615927100|https://openalex.org/W1481560182|https://openalex.org/W2057235967|https://openalex.org/W3082760180
https://openalex.org/W2060498389,The CLP( ℛ ) language and system,"The CLP( ℛ ) language and system

The CLP( ℛ ) programming language is defined, its underlying philosophy and methodology are discussed, important implementation issues explored in detail, finally, a prototype interpreter described. designed to be an instance of the Constraint Logic Programming Scheme, family rule-based constraint languages defined by Jaffar Lassez. domain computation this particular algebraic structure consisting uninterpreted functors over real numbers. An property )is that constraints treated uniformly sense they used specify input parameters program, only primitives execution describe output program. Implementation CLP language, particular, raises new problems design constraint-solver. For example, solver must incremental solving additional not entail resolving old constraints. In our system, filtered through inference engine, engine/solver interface, equation inequality solver. This sequence modules reflects classification prioritization classes Modules higher priority isolated from complexities lower multiple-phase constraints, together with set associated algorithms, gives rise practical system.

applied linguistics, computer science, linguistics, structural linguistics, natural language processing, language, general linguistics, syntax, abstract interpretation, extensible language, programming language implementation, programming language theory, computational linguistics, programming language, specification language, machine translation, logic in computer science, context (linguistics)",1992,530,applied linguistics|computer science|linguistics|structural linguistics|natural language processing|language|general linguistics|syntax|abstract interpretation|extensible language|programming language implementation|programming language theory|computational linguistics|programming language|specification language|machine translation|logic in computer science|context (linguistics),
https://openalex.org/W1923492477,Translation as Text,"Translation as Text

Getting Started There and Then Versus Here Now Resistances Defences Establishing the Therapeutic Relationship Themes Links Roles Problem Behaviours Conflicts Expressive Techniques Some Tried True Exercises.

linguistics, text normalization, machine translation, language, translation studies",1992,203,linguistics|text normalization|machine translation|language|translation studies,
https://openalex.org/W2058335193,Learning translation templates from bilingual text,"Learning translation templates from bilingual text

This paper proposes a two-phase example-based machine translation methodology which develops templates from examples and then translates using template matching. method improves quality facilitates customization of systems. focuses on the automatic learning templates. A is bilingual pair sentences in corresponding units (words pharases) are coupled replaced with variables. Correspondence between determined by suing dictionary analyzing syntactic structure sentences. Syntactic ambiguity correspondence simultaneously resolved. All generated corpus grouped their source language part, further refined to resolved conflicts among whose parts same but target different. By proposed method, not only transfer rules also knowledge for lexical selection effectively extracted corpus.

bilingual text, language, machine translation, translation studies, translation templates",1992,167,bilingual text|language|machine translation|translation studies|translation templates,
https://openalex.org/W1578472035,Machine Translation: A Knowledge-Based Approach,"Machine Translation: A Knowledge-Based Approach

From the Publisher:
This is first book devoted exclusively to knowledge-based machine translation. While most approaches translation for natural languages seek ways translate source language texts into target without full understanding of text, based on extracting and representing meaning text. It scientifically challenging approach task translation, significant progress has been achieved within it in recent years.

The authors introduce general paradigm MT, survey major developments, compare with other present a paradigmatic view its component processes-natural analysis, generation, text representation, ontological modeling, etc. Special chapters are machine-aided speech challenges solutions knowledge representation. Based these analyses, as well review trends discuss interesting directions future research development.

This will be interest researchers advanced students processing, computational linguistics, artificial intelligence, even some philosophers theoretical linguists.

artificial intelligence, knowledge representation and reasoning, information technology, knowledge-based system, natural language processing, language model, language, knowledge modeling, knowledge-based reasoning, neural machine translation, knowledge integration, knowledge discovery, knowledge extraction, machine translation, translation studies, knowledge management",1992,130,artificial intelligence|knowledge representation and reasoning|information technology|knowledge-based system|natural language processing|language model|language|knowledge modeling|knowledge-based reasoning|neural machine translation|knowledge integration|knowledge discovery|knowledge extraction|machine translation|translation studies|knowledge management,https://openalex.org/W2203653769
https://openalex.org/W2088135026,What can machines know?,"What can machines know?

article Free Access Share on What can machines know?: On the properties of knowledge in distributed systems Authors: Ronald Fagin View Profile , Joseph Y. Halpern Moshe Vardi Authors Info & Claims Journal ACMVolume 39Issue 2April 1992 pp 328–376https://doi.org/10.1145/128749.150945Published:01 April 1992Publication History 88citation764DownloadsMetricsTotal Citations88Total Downloads764Last 12 Months47Last 6 weeks9 Get Citation AlertsNew Alert added!This alert has been successfully added and will be sent to:You notified whenever a record that you have chosen cited.To manage your preferences, click button below.Manage my Alerts New Alert!Please log to account Save BinderSave BinderCreate BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF

computer science, artificial intelligence, machine vision, machine to machine, machine learning, automated reasoning, computational intelligence, deep learning, machine learning research, machine translation, neural network (machine learning), machine intelligence, physic aware machine learning, machine perception",1992,128,computer science|artificial intelligence|machine vision|machine to machine|machine learning|automated reasoning|computational intelligence|deep learning|machine learning research|machine translation|neural network (machine learning)|machine intelligence|physic aware machine learning|machine perception,
https://openalex.org/W1856106381,Translation of an Instrument,"Translation of an Instrument

ABSTRACT. Translation of a research instrument questionnaire from English to another language is analyzed in relation principles involved, procedures followed, and problems confronted by nurse researchers the US–Nordic Family Dynamics Nursing Research Project. Of paramount importance translation are equivalency, congruent value orientation, careful use colloquialisms. It important recognize that copyright guidelines apply an instrument. Approaches solving discussed.

specialized translation, speech translation, machine translation, music, translation studies, instrumentation",1992,109,specialized translation|speech translation|machine translation|music|translation studies|instrumentation,https://openalex.org/W1926644249
https://openalex.org/W2007972469,A fast algorithm for the generation of referring expressions,"A fast algorithm for the generation of referring expressions

We simplify previous work in the development of algorithms for generation referring expressions while at same time taking account psycholinguistic findings and transcript data. The result is a straightforward algorithm that computationally tractable, sensitive to preferences human users, reasonably domain-independent. provide specification resources host system must order make use algorithm, describe an implementation used IDAS system.

text mining, linguistics, semantics, language model, computational linguistics, adaptive algorithm, fast algorithm, natural language processing, machine learning research, machine translation, algorithmic development, computer science, treebanks, terminology extraction, sequential algorithm, applied mathematics, natural language generation",1992,100,text mining|linguistics|semantics|language model|computational linguistics|adaptive algorithm|fast algorithm|natural language processing|machine learning research|machine translation|algorithmic development|computer science|treebanks|terminology extraction|sequential algorithm|applied mathematics|natural language generation,https://openalex.org/W2125447031
https://openalex.org/W2104858828,A new quantitative quality measure for machine translation systems,"A new quantitative quality measure for machine translation systems

In this paper, an objective quantitative quality measure is proposed to evaluate the performance of machine translation systems. The method compare raw output MT system with final revised version for customers, and then compute editing efforts required convert version. contrast other proposals, evaluation process can be done quickly automatically. Hence, it provide a quick response on any change. A designer thus find advantages or faults particular dynamically. Application such improve on-line parameterized feedback-controlled will demonstrated. Furthermore, because used directly as reference, reflect real gap between customer expectation. concentrate practically important topics rather than theoretically interesting issues.

quality metric, machine translation, computer-assisted translation, statistics, machine translation systems",1992,80,quality metric|machine translation|computer-assisted translation|statistics|machine translation systems,
https://openalex.org/W2148321974,The <i>Pan</i> language-based editing system,"The <i>Pan</i> language-based editing system

Powerful editing systems for developing complex software documents are difficult to engineer. Besides requiring efficient incremental algorithms and data structures, such editors must accommodate flexible styles, provide a consistent, coherent, powerful user interface, support individual variations projectwide configurations, maintain sharable database of information concerning the being edited, integrate smoothly with other tools in environment. Pan is language-based browsing system that exhibits these characteristics. This paper surveys design engineering , paying particular attention number issues pervade system: checking analysis, retention presence change, tolerance errors anomalies, extension facilities.

linguistics, language technology, computational linguistics, machine translation, language",1992,72,linguistics|language technology|computational linguistics|machine translation|language,
https://openalex.org/W127035525,Proceedings of the 30th annual meeting on Association for Computational Linguistics,"Proceedings of the 30th annual meeting on Association for Computational Linguistics

This volume contains the papers prepared for 30th Annual Meeting of Association Computational Linguistics, held 28 June-2 July in Newark, Delaware. Following on from last year's innovation, presented at separate student session are also to be found, gathered a section end this Proceedings.In keeping with prestigious nature meeting, and despite number alternative conferences our area, programme committee was once again confronted With large very high quality submissions around world. Balancing desire accept as many possible those which merited inclusion need present conference ordinary mortals could reasonably expected benefit proved, always, difficult challenge. We hope results, represented by itself collected here, will stand fair representative cross-section best work field today.

corpus linguistics, linguistics, computational semantics, computational linguistics, natural language processing, machine translation",1992,68,corpus linguistics|linguistics|computational semantics|computational linguistics|natural language processing|machine translation,
https://openalex.org/W278872335,An On-Line Computational Model of Human Sentence Interpretation: A Theory of the Representation and Use of Linguistic Knowledge,"An On-Line Computational Model of Human Sentence Interpretation: A Theory of the Representation and Use of Linguistic Knowledge

This dissertation presents a model of the human sentence interpretation process, which attempts to meet criteria adequacy imposed by different paradigms interpretation. These include need produce high-level interpretation, embed linguistically motivated grammar, and be compatible with psycholinguistic results on processing.
The includes theory grammar called Construction-Based Interpretive Grammar (CIG) an interpreter uses build for single sentences. An implementation has been built Sal.
Sal is on-line interpreter, reading words one at time updating partial after each constituent. constituent-by-constituent more fine-grained hence than most previous models. Sal strongly interactionist in using both bottom-up top-down knowledge evidential manner access set constructions interpretations. It coherence-based selection mechanism choose among these candidate interpretations, allows temporary limited parallelism handle local ambiguities. Sal's architecture consistent large number results.
The embodies strong claims about processing. One claim uniformity, respect representation process. In kind structure, grammatical construction, used represent lexical, syntactic, idiomatic, semantic knowledge. CIG thus does not distinguish between lexicon, idiom dictionary, syntactic rule base, base. Uniformity processing means that there no distinction lexical analyzer, parser, interpreter. Because kinds are represented uniformly, they can accessed, integrated, disambiguated mechanism.
A second fundamentally knowledge-intensive expectation-based. The integration many diverse types linguistic Similarly, sensitive bottom-up, knowledge, based coherence

psycholinguistics, cognitive science, linguistics, knowledge discovery, human sentence interpretation, spoken language technology, machine translation, computational model, interpretation, computational linguistics, semantic analysis (linguistics), natural language processing, linguistic knowledge, computer science, knowledge representation and reasoning, computational semantics, linguistic theory, language science, on-line computational model",1992,64,psycholinguistics|cognitive science|linguistics|knowledge discovery|human sentence interpretation|spoken language technology|machine translation|computational model|interpretation|computational linguistics|semantic analysis (linguistics)|natural language processing|linguistic knowledge|computer science|knowledge representation and reasoning|computational semantics|linguistic theory|language science|on-line computational model,
https://openalex.org/W2203653769,Anaphora Resolution in Machine Translation,"Anaphora Resolution in Machine Translation

In this paper we give an overview of approach to anaphora resolution that takes a whole variety different factors into account. These concern on the one hand structural information like agreement, proximity, binding principles, subject preference, topic negative preference for free adjuncts and other about contents text conceptual consistency. This led twofold representation: representation referential representation. The are implemented as rules with weights express influence each has in process resolution. For factor linguistic motivation well formal it works is given. We show how integrated component existing experimental MT system.

speech translation, anaphora resolution, natural language processing, language, machine translation, translation studies",1992,38,speech translation|anaphora resolution|natural language processing|language|machine translation|translation studies,
https://openalex.org/W2141383378,Shake-and-bake machine translation,"Shake-and-bake machine translation

Article Free Access Share on Shake-and-bake machine translation Author: John L. Beaven Universidad de Cambridge CambridgeView Profile Authors Info & Claims COLING '92: Proceedings of the 14th conference Computational linguistics - Volume 2August 1992Pages 602–609https://doi.org/10.3115/992133.992164Published:23 August 1992Publication History 9citation296DownloadsMetricsTotal Citations9Total Downloads296Last 12 Months14Last 6 weeks6 Get Citation AlertsNew Alert added!This alert has been successfully added and will be sent to:You notified whenever a record that you have chosen cited.To manage your preferences, click button below.Manage my Alert!Please log in to account Save BinderSave BinderCreate New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF

language, neural machine translation, multimodal translation, machine translation, translation studies, shake-and-bake machine translation, computer-assisted translation",1992,34,language|neural machine translation|multimodal translation|machine translation|translation studies|shake-and-bake machine translation|computer-assisted translation,
https://openalex.org/W2006969979,The mathematics of statistical machine translation: parameter estimation,"The mathematics of statistical machine translation: parameter estimation

We describe a series of five statistical models the translation process and give algorithms for estimating parameters these given set pairs sentences that are translations one another. define concept word-by-word alignment between such sentences. For any pair each our assigns probability to possible alignments. an algorithm seeking most probable Although is suboptimal, thus obtained accounts well relationships in have great deal data French English from proceedings Canadian Parliament. Accordingly, we restricted work two languages; but feel because minimal linguistic content they would on other languages. also feel, again algorithms, it reasonable argue alignments inherent sufficiently large bilingual corpus.

statistical inference, statistical machine translation, applied mathematics, parameter estimation, statistics, machine translation",1993,4149,statistical inference|statistical machine translation|applied mathematics|parameter estimation|statistics|machine translation,https://openalex.org/W2154124206|https://openalex.org/W2116316001|https://openalex.org/W2139403546|https://openalex.org/W2150028966|https://openalex.org/W2091889711|https://openalex.org/W1994919150|https://openalex.org/W204945112|https://openalex.org/W2161792612|https://openalex.org/W2160382364|https://openalex.org/W2032175749|https://openalex.org/W1916559533|https://openalex.org/W2155607551|https://openalex.org/W2137698233|https://openalex.org/W1753482797|https://openalex.org/W2170738476|https://openalex.org/W2963260202|https://openalex.org/W2963463964|https://openalex.org/W3082760180
https://openalex.org/W2138584836,Text-translation alignment,"Text-translation alignment

We present an algorithm for aligning texts with their translations that is based only on internal evidence. The relaxation process rests a notion of which word in one text corresponds to the other essentially similarity distributions. It exploits partial alignment level induce maximum likelihood sentence level, turn used, next iteration, refine estimate. appears converge correct few iterations.

machine translation, text-translation alignment, language, translation studies",1993,302,machine translation|text-translation alignment|language|translation studies,https://openalex.org/W2006969979
https://openalex.org/W2998215494,The mathematics of statistical machine translation,"The mathematics of statistical machine translation

We describe a series of five statistical models the translation process and give algorithms for estimating parameters these given set pairs sentences that are translations ...

machine learning research, natural language processing, statistics, machine translation, computer science, statistical machine translation, neural machine translation, applied mathematics",1993,292,machine learning research|natural language processing|statistics|machine translation|computer science|statistical machine translation|neural machine translation|applied mathematics,https://openalex.org/W2091889711|https://openalex.org/W2032175749|https://openalex.org/W3082760180
https://openalex.org/W1615927100,Machine translation : a view from the lexicon,"Machine translation : a view from the lexicon

This book describes a novel, cross-linguistic approach to machine translation that solves certain classes of syntactic and lexical divergences by means conceptual structure can be composed decomposed in language-specific ways. allows the translator operate uniformly across many languages, while still accounting for knowledge is specific each language.The model used map source-language sentence target-language principled fashion. It built on basis parametric approach, making it easy change from one language another (by setting switches providing descriptions language) without having write whole new processor language.Dorr's advances field number important ways: provides uniform which same lexical-semantic processing modules are language; interlingual, able derive an underlying language-independent form source any three target languages - Spanish, English, or German produced this form; systematic mapping between level appropriate words selected realized, despite potential divergences. Bonnie Jean Dorr Assistant Professor Computer Science Department at University Maryland.

linguistics, computational linguistics, natural language processing, machine translation, language, neural machine translation, translation studies",1993,197,linguistics|computational linguistics|natural language processing|machine translation|language|neural machine translation|translation studies,
https://openalex.org/W4235233489,The Language Builder,"The Language Builder

Linguistics, as a social science, should have something to teach us about humans beings. However, modern grammatical theories regard languages autonomous systems, so these are little concerned with speakers and hearers, their interactions, relationship the world around them. Further, tend toward excessive concern methodology properties of linguistic neglecting, in fact, themselves those who use them everyday life. Even shift cognitive approaches, promising for new insights into brain, still misses an equally important aspect language, namely framework which would account activity by build structures order meet requirements communication. Based on wide range languages, Hagège's work sheds light human language building activity. He argues that conscious unconscious 'signatures' nature written everywhere language. The study signatures gives insight basic characteristics beings, tends re-humanize linguistics, stresses importance dynamic opposed self-contained system.

linguistics, natural language interface, natural language processing, language engineering, language, computational linguistics, machine translation, computer-assisted language learning, spoken language technology, language builder",1993,121,linguistics|natural language interface|natural language processing|language engineering|language|computational linguistics|machine translation|computer-assisted language learning|spoken language technology|language builder,
https://openalex.org/W1982228897,Language and Computers,"Language and Computers

Language and Computers, Markus Dickinson, Chris Brew, Detmar Meurers, Wiley-Blackwell, 2013

linguistics, language technology, computational semantics, spoken language processing, speech recognition, computational linguistics, speech processing, natural language processing, machine translation, computer science, educational technology, language, programming language, language recognition, speech technology, computing education, spoken language technology, human-computer interaction",1993,113,linguistics|language technology|computational semantics|spoken language processing|speech recognition|computational linguistics|speech processing|natural language processing|machine translation|computer science|educational technology|language|programming language|language recognition|speech technology|computing education|spoken language technology|human-computer interaction,
https://openalex.org/W2085904853,Similarity between words computed by spreading activation on an English dictionary,"Similarity between words computed by spreading activation on an English dictionary

This paper proposes a method for measuring semantic similarity between words as new tool text analysis. The is measured on network constructed systematically from subset of the English dictionary, LDOCE (Longman Dictionary Contemporary English). Spreading activation can directly compute any two in Longman Defining Vocabulary, and indirectly all other LDOCE. represents strength lexical cohesion or relation, also provides valuable information about coherence texts.

english, linguistics, content similarity detection, similarity search, knowledge discovery, computational lexicology, pattern recognition, machine learning research, terminology extraction, semantics, semantic similarity, machine translation, semantic evaluation, text mining, computational linguistics, natural language processing, english dictionary, language, information fusion",1993,113,english|linguistics|content similarity detection|similarity search|knowledge discovery|computational lexicology|pattern recognition|machine learning research|terminology extraction|semantics|semantic similarity|machine translation|semantic evaluation|text mining|computational linguistics|natural language processing|english dictionary|language|information fusion,
https://openalex.org/W89279510,Proceedings of the 31st annual meeting on Association for Computational Linguistics,"Proceedings of the 31st annual meeting on Association for Computational Linguistics

This volume contains the papers prepared for 31 st Annual Meeting of Association Computational Linguistics, held 22-26 June 1993 at The Ohio State University in Columbus, Ohio. cluster final section stems from student session, featured meeting 3rd successive year and testifying to vigor this emerging tradition.The number quality submitted was again gratifying, all authors deserve our collective plaudits efforts they invested despite well-known risks submitting a highly selective conference. It their that once ensured (and Proceedings) reflecting highest standards computational linguistics, offering tour some most significant recent advances lively research frontiers.In an effort increase fairness reviewing, we opted blind reviewing year. Also, reduce load upon program committee members more humanly manageable level, curtail frantic last-minute searches specialist reviewers, allow methodical, uniform, interactive submissions, size expanded include 22 besides chair. still heavy, but performed duties exemplary fashion; five-week period which culminated one-day meeting, spared no arrive detailed, accurate principled assessments, best possible Meeting.

corpus linguistics, linguistics, computational semantics, computational linguistics, natural language processing, machine translation",1993,106,corpus linguistics|linguistics|computational semantics|computational linguistics|natural language processing|machine translation,
https://openalex.org/W1557431580,Translation analysis and translation automation,"Translation analysis and translation automation

We argue that the concept of translation analysis provides a suitable foundation for new generation support tools. show pre-existing translations can be analyzed into structured memory and describe our TransSearch bilingual concordancing system, which allows translators to harness such memory. claim analyzers help detect errors in draft we present results an experiment on detection deceptive cognates conducted as part TransCheck project. Finally, facilitate speech-to-text transcription dictated introduce TransTalk

translation automation, translation analysis, computer-assisted translation, machine translation, translation studies",1993,78,translation automation|translation analysis|computer-assisted translation|machine translation|translation studies,
https://openalex.org/W1542847127,Statistically-driven computer grammars of English : the IBM/LANCASTER approach,"Statistically-driven computer grammars of English : the IBM/LANCASTER approach

This book is about building computer programs that parse (analyze, or diagram) sentences of a real-world English. The English we are concerned with might be corpus everyday, naturally-occurring prose, such as the entire text this morning's newspaper. Most now exist for purpose not very successful at finding correct analysis everyday sentences. In contrast, described here make use more statistically-driven approach. Our is, first, record five-year research collaboration between IBM and Lancaster University. Large numbers were fed into memory program grammatical (including detailed grammar English) processed by statistical methods. idea to single out parse, among all those offered grammar, on basis probabilities. Second, how-to book, showing how build implement broad-coverage We even supply our own necessary algorithms, knowledge needed prepare large set (or corpus) so it can used guide processing grammar's rules.

english, linguistics, language model, grammatical formalism, syntactic structure, grammar, general linguistics, english language, grammar induction, machine translation, semantic evaluation, text mining, computational linguistics, natural language processing, language, statistically-driven computer grammars, applied linguistics, computational semantics, syntactic parsing",1993,77,english|linguistics|language model|grammatical formalism|syntactic structure|grammar|general linguistics|english language|grammar induction|machine translation|semantic evaluation|text mining|computational linguistics|natural language processing|language|statistically-driven computer grammars|applied linguistics|computational semantics|syntactic parsing,
https://openalex.org/W2997195443,Text-translation alignment,"Text-translation alignment

We present an algorithm for aligning texts with their translations that is based only on internal evidence. The relaxation process rests a notion of which word in one text corresponds to w...

language, translation studies, machine translation, text-translation alignment",1993,65,language|translation studies|machine translation|text-translation alignment,
https://openalex.org/W1999453928,The CNN is universal as the Turing machine,"The CNN is universal as the Turing machine

It is shown that the game of life algorithm, which equivalent to a Turing machine, can be realized by cellular neural network (CNN). Thus CNN also universal.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>

knowledge representation and reasoning, convolutional neural network, turing machine, artificial intelligence, machine learning research, machine translation, neural network (machine learning), machine vision, computer science, machine learning, recurrent neural network, large language model, computer engineering, computational intelligence, systems engineering, image representation, large ai model, deep learning",1993,63,knowledge representation and reasoning|convolutional neural network|turing machine|artificial intelligence|machine learning research|machine translation|neural network (machine learning)|machine vision|computer science|machine learning|recurrent neural network|large language model|computer engineering|computational intelligence|systems engineering|image representation|large ai model|deep learning,
https://openalex.org/W2154124206,Discriminative training and maximum entropy models for statistical machine translation,"Discriminative training and maximum entropy models for statistical machine translation

We present a framework for statistical machine translation of natural languages based on direct maximum entropy models, which contains the widely used source-channel approach as special case. All knowledge sources are treated feature functions, depend source language sentence, target sentence and possible hidden variables. This allows baseline system to be extended easily by adding new functions. show that is significantly improved using this approach.

computer science, discriminative training, machine learning, statistical machine translation, machine learning research, machine translation, maximum entropy models",2001,1055,computer science|discriminative training|machine learning|statistical machine translation|machine learning research|machine translation|maximum entropy models,https://openalex.org/W2116316001|https://openalex.org/W2032175749|https://openalex.org/W2157435188|https://openalex.org/W2101096097|https://openalex.org/W2159755860|https://openalex.org/W12732426
https://openalex.org/W2116316001,A syntax-based statistical translation model,"A syntax-based statistical translation model

We present a syntax-based statistical translation model.Our model transforms source-language parse tree into target-language string by applying stochastic operations at each node.These capture linguistic differences such as word order and case marking.Model parameters are estimated in polynomial time using an EM algorithm.The produces alignments that better than those produced IBM Model 5.

applied linguistics, linguistics, language model, language, syntax, computational linguistics, machine translation, translation studies, syntactic parsing",2001,756,applied linguistics|linguistics|language model|language|syntax|computational linguistics|machine translation|translation studies|syntactic parsing,https://openalex.org/W2161792612|https://openalex.org/W2160382364|https://openalex.org/W2032175749|https://openalex.org/W1916559533|https://openalex.org/W2109802560|https://openalex.org/W2156422881|https://openalex.org/W1829822087|https://openalex.org/W2118090838
https://openalex.org/W2157963512,Scaling to very very large corpora for natural language disambiguation,"Scaling to very very large corpora for natural language disambiguation

The amount of readily available on-line text has reached hundreds billions words and continues to grow. Yet for most core natural language tasks, algorithms continue be optimized, tested compared after training on corpora consisting only one million or less. In this paper, we evaluate the performance different learning methods a prototypical disambiguation task, confusion set disambiguation, when trained orders magnitude more labeled data than previously been used. We are fortunate that particular application, correctly is free. Since will often not case, examine effectively exploiting very large comes at cost.

computer science, link analysis, computational linguistics, information fusion, natural language disambiguation, language, semantic evaluation, data science, large corpora, machine translation, language model, distributional semantics, language corpus, text mining, natural language processing, large language model, knowledge discovery, coreference resolution, corpus linguistics",2001,654,computer science|link analysis|computational linguistics|information fusion|natural language disambiguation|language|semantic evaluation|data science|large corpora|machine translation|language model|distributional semantics|language corpus|text mining|natural language processing|large language model|knowledge discovery|coreference resolution|corpus linguistics,
https://openalex.org/W652095014,Repairing Texts: Empirical Investigations of Machine Translation Post-Editing Processes,"Repairing Texts: Empirical Investigations of Machine Translation Post-Editing Processes

Machine translation has long been studied and analyzed in an attempt to better understand enhance the process. What neglected, however, is study of post-editing mental processes involved. In Repairing Texts, Hans P. Krings challenges idea that, given effectiveness machine translation, major costs could be reduced by using monolingual staff post -- edit translations. With goal discovering underlying trends potential hypotheses for further research, he sets different groups translators work texts both with without benefit source text. He offers up studies systems their uses, current state process methodology, data collection, analysis. All who are involved this expanding important field will find book contribution ongoing research translation.

text mining, empirical investigations, machine translation, computer-assisted translation, computer science, text processing",2001,286,text mining|empirical investigations|machine translation|computer-assisted translation|computer science|text processing,https://openalex.org/W2057235967
https://openalex.org/W2139403546,Fast decoding and optimal decoding for machine translation,"Fast decoding and optimal decoding for machine translation

A good decoding algorithm is critical to the success of any statistical machine translation system. The decoder's job find that most likely according set previously learned parameters (and a formula for combining them). Since space possible translations extremely large, typical algorithms are only able examine portion it, thus risking miss solutions. In this paper, we compare speed and output quality traditional stack-based with two new decoders: fast greedy decoder slow but optimal treats as an integer-programming optimization problem.

machine translation, computer science, optimal decoding",2001,233,machine translation|computer science|optimal decoding,https://openalex.org/W2116316001|https://openalex.org/W2161792612|https://openalex.org/W2032175749|https://openalex.org/W1916559533
https://openalex.org/W2150028966,Translating named entities using monolingual and bilingual resources,"Translating named entities using monolingual and bilingual resources

Named entity phrases are some of the most difficult to translate because new can appear from nowhere, and many domain specific, not be found in bilingual dictionaries. We present a novel algorithm for translating named using easily obtainable monolingual resources. report on application evaluation this Arabic entities English. also compare our results with obtained human translations commercial system same task.

multilingualism, named-entity recognition, linguistic diversity, entity disambiguation, machine translation, bilingual resources, language",2001,211,multilingualism|named-entity recognition|linguistic diversity|entity disambiguation|machine translation|bilingual resources|language,https://openalex.org/W2116316001
https://openalex.org/W4244061366,Machine Dreams,"Machine Dreams

This was the first cross-over book into history of science written by an historian economics. It shows how 'history technology' can be integrated with economic ideas. The analysis combines Cold War postwar economics in America and later elsewhere, revealing that Pax Americana had much to do abstruse formal doctrines such as linear programming game theory. links literature on 'cyborg' economics, element missing date. treatment further calls question idea has been immune postmodern currents, arguing neoclassical participated deconstruction integral 'self'. Finally, it argues for alliance computational institutional themes, challenges widespread impression there is nothing else besides American theory left standing after demise Marxism.

mechanical engineering, computer science, machine vision, machine dreams, machine learning, abstract machine, machine translation, machine intelligence, machine perception",2001,183,mechanical engineering|computer science|machine vision|machine dreams|machine learning|abstract machine|machine translation|machine intelligence|machine perception,
https://openalex.org/W2119880425,Semi‐automatic grammar recovery,"Semi‐automatic grammar recovery

Abstract We propose an approach to the construction of grammars for existing languages. The main characteristic is that are not constructed from scratch but they rather recovered by extracting them language references, compilers and other artifacts. provide a structured process recover including adaptation raw extracted derivation parsers. applicable possibly all languages which business critical applications exist. illustrate with non‐trivial case study. Using our some basic tools, we in few weeks complete correct VS COBOL II grammar specification IBM mainframes. In addition, parser II, were first publish (Web‐enabled) so others can use this result construct their own grammar‐based tools or derivatives. Copyright © 2001 John Wiley &amp; Sons, Ltd.

linguistics, semi-automatic grammar recovery, natural language processing, grammar, computational linguistics, computational semantics, machine translation",2001,151,linguistics|semi-automatic grammar recovery|natural language processing|grammar|computational linguistics|computational semantics|machine translation,
https://openalex.org/W2091889711,Multipath translation lexicon induction via bridge languages,"Multipath translation lexicon induction via bridge languages

This paper presents a method for inducing translation lexicons based on transduction models of cognate pairs via bridge languages. Bilingual within languages families are induced using probabilistic string edit distance models. Translation arbitrary distant language then generated by combination these intra-family and one or more cross-family on-line dictionaries. Up to 95% exact match accuracy is achieved the target vocabulary (30-68% inter-family test pairs). Thus substantial portions can be accurately where no bilingual dictionary parallel corpora may exist.

language, translation studies, lexicon, machine translation, bridge languages",2001,147,language|translation studies|lexicon|machine translation|bridge languages,https://openalex.org/W2116316001
https://openalex.org/W2150678312,Translation: In retrospect and prospect,"Translation: In retrospect and prospect

This review is occasioned by the fact that problem of translation, which has simmered on biological sidelines for last 40 years, about to erupt center stage—thanks recent spectacular advances in ribosome structure. most complex, beautiful, and fascinating cellular mechanisms, translation apparatus, also important. Translation not only defines gene expression, but it sine qua non without modern (protein-based) cells would have come into existence. Yet from start, been misunderstood—a reflection molecular perspective dominated Biology century. In our conception will play a significant role creating structure 21st century Biology, critical current (and fundamentally flawed) view be understood what reformulated become an all-embracing can develop. Therefore, present both retrospective plea biologists establish new evolutionary, RNA-World-centered concept translation. What needed evolutionarily oriented that, first foremost, focuses nature origin) primitive apparatus transformed ancient evolutionary era nucleic acid life, RNA World, world cells.

specialized translation, multimodal translation, machine translation, comparative literature, translation studies",2001,122,specialized translation|multimodal translation|machine translation|comparative literature|translation studies,
https://openalex.org/W2125256409,Text Representation,"Text Representation

This book brings together linguistics and psycholinguistics. Text representation is considered a cognitive entity: mental construct that plays crucial role in both text production understanding.&lt;br /&gt;The focus on referential relational coherence the of linguistic characteristics as processing instructions from discourse psychology point view. Consequently, this presents various research methodologies: analysis, corpus linguistics, computational argumentation experimental psycholinguistic study processing. The authors compare, test, evaluate theories representation.&lt;br /&gt;A state art volume an emerging field interest, located at very heart our communicative behavior: /&gt;

corpus linguistics, text mining, linguistics, text normalization, textual practice, computational linguistics, natural language, natural language processing, machine translation, text segmentation, text representation, text recognition, language, literature, text processing, representation theory, natural language generation",2001,119,corpus linguistics|text mining|linguistics|text normalization|textual practice|computational linguistics|natural language|natural language processing|machine translation|text segmentation|text representation|text recognition|language|literature|text processing|representation theory|natural language generation,
https://openalex.org/W1994919150,An efficient A* search algorithm for statistical machine translation,"An efficient A* search algorithm for statistical machine translation

In this paper, we describe an efficient A* search algorithm for statistical machine translation. contrary to beam-search or greedy approaches it is possible guarantee the avoidance of errors with A*. We develop various so-phisticated admissible and almost heuristic functions. Especially our newly developped method perform a multi-pass iteratively improved function allows us translate even long sentences. compare approach on Hansards task.

statistical software, data science, natural language processing, information retrieval, statistics, machine translation, computer science, statistical machine translation",2001,97,statistical software|data science|natural language processing|information retrieval|statistics|machine translation|computer science|statistical machine translation,https://openalex.org/W2032175749
https://openalex.org/W204945112,Statistical multi-source translation,"Statistical multi-source translation

We describe methods for translating a text given in multiple source languages into single target language. The goal is to improve translation quality applications where the ultimate translate same document many languages. statistical approach and two specific models deal with this problem. Our method generally applicable as it independent of models, or application domains. evaluate on multilingual corpus covering all eleven official European Union that was collected automatically from Internet. In various tests we show these can significantly quality. As side effect, also compare machine systems domain.

linguistics, statistical multi-source translation, machine translation, computer-assisted translation, translation studies, multi-source",2001,95,linguistics|statistical multi-source translation|machine translation|computer-assisted translation|translation studies|multi-source,https://openalex.org/W2032175749
https://openalex.org/W2078861931,Automatic evaluation of machine translation quality using n-gram co-occurrence statistics,"Automatic evaluation of machine translation quality using n-gram co-occurrence statistics

Evaluation is recognized as an extremely helpful forcing function in Human Language Technology R&D. Unfortunately, evaluation has not been a very powerful tool machine translation (MT) research because it requires human judgments and thus expensive time-consuming easily factored into the MT agenda. However, at July 2001 TIDES PI meeting Philadelphia, IBM described automatic technique that can provide immediate feedback guidance research. Their idea, which they call ""evaluation understudy"", compares output with expert reference translations terms of statistics short sequences words (word N-grams). The more these N-grams shares translations, better judged to be. idea elegant its simplicity. But far important, showed strong correlation between automatically generated scores quality. As result, DARPA commissioned NIST develop facility based on work. This utility now available from serves primary measure for

machine translation quality, computer science, linguistics, language model, natural language processing, machine learning, n-gram co-occurrence statistics, computational linguistics, data science, machine translation, automatic classification, computer-assisted translation, automatic evaluation",2002,1601,machine translation quality|computer science|linguistics|language model|natural language processing|machine learning|n-gram co-occurrence statistics|computational linguistics|data science|machine translation|automatic classification|computer-assisted translation|automatic evaluation,https://openalex.org/W2032175749|https://openalex.org/W2057235967|https://openalex.org/W2125447031|https://openalex.org/W2156422881|https://openalex.org/W1493309689|https://openalex.org/W2963463964
https://openalex.org/W1934041838,Improved backing-off for M-gram language modeling,"Improved backing-off for M-gram language modeling

In stochastic language modeling, backing-off is a widely used method to cope with the sparse data problem. case of unseen events this backs off less specific distribution. paper we propose use distributions which are especially optimized for task backing-off. Two different theoretical derivations lead quite from probability that usually Experiments show an improvement about 10% in terms perplexity and 5% word error rate.

computer science, large language model, language model, natural language processing, language, m-gram language modeling, machine learning, computational linguistics, computational semantics, deep learning, machine translation",2002,1470,computer science|large language model|language model|natural language processing|language|m-gram language modeling|machine learning|computational linguistics|computational semantics|deep learning|machine translation,https://openalex.org/W2157435188|https://openalex.org/W1848260265|https://openalex.org/W2251682575|https://openalex.org/W1985258458|https://openalex.org/W2567070169
https://openalex.org/W1593271688,Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,"Proceedings of the 40th Annual Meeting on Association for Computational Linguistics

This year's meeting is special. First, it the first ACL to be hosted jointly with our North-American chapter, NAACL. Second, also ACL's 40th anniversary meeting: association was created 13 June 1962, and its took place 25-26 August 1963 in Denver.Our field has expanded quite a bit since then, so have meetings. year, main conference program includes some 65 different refereed papers, covering most active research areas computational linguistics. And extended complementing that 19 system demonstrations, 4 tutorials, 12 Student Research no less than 11 pre- post-conference workshops presenting total of about 150 papers.

linguistics, natural language processing, natural language generation, computational linguistics, computational semantics, machine translation, corpus linguistics",2002,1206,linguistics|natural language processing|natural language generation|computational linguistics|computational semantics|machine translation|corpus linguistics,
https://openalex.org/W2161792612,"A phrase-based, joint probability model for statistical machine translation","A phrase-based, joint probability model for statistical machine translation

We present a joint probability model for statistical machine translation, which automatically learns word and phrase equivalents from bilingual corpora. Translations produced with parameters estimated using the are more accurate than translations IBM Model 4.

linguistics, natural language processing, statistical machine translation, machine translation, joint probability model",2002,488,linguistics|natural language processing|statistical machine translation|machine translation|joint probability model,https://openalex.org/W2116316001|https://openalex.org/W2032175749|https://openalex.org/W2057235967|https://openalex.org/W2157331557|https://openalex.org/W2950635152
https://openalex.org/W4241926506,Writing Machines,"Writing Machines

A pseudo-autobiographical exploration of the artistic and cultural impact transformation print book to its electronic incarnations.Tracing a journey from 1950s through 1990s, N. Katherine Hayles uses autobiographical persona Kaye explore how literature has transformed itself inscriptions rendered as flat durable marks dynamic images CRT screens, verbal texts diverse sensory modalities multimedia works, books technotexts.Weaving together Kaye's narrative with theorization contemporary in media-specific terms, examines ways which literary every genre period mutate they are reconceived rewritten for formats. As documents become more pervasive, appears not sea we swim, transparent because so accustomed conventions, but rather medium own assumptions, specificities, inscription practices. explores works that focus on very technologies produce them, examining three writing machines depth: Talan Memmott's groundbreaking work Lexia Perplexia, Mark Z. Danielewski's cult postprint novel House Leaves, Tom Phillips's artist's Humument. concludes by speculating technotexts affect development subjectivity.Writing Machines is second volume Mediawork Pamphlets series.

technology, computer engineering, machine intelligence, natural language processing, digital medium, machine translation, text processing, natural language generation, computational intelligence, computer science, machine-readable dictionary, machine-readable representation, automation, machine learning, machine learning research, text mining, turing machine, writing instruction",2002,461,technology|computer engineering|machine intelligence|natural language processing|digital medium|machine translation|text processing|natural language generation|computational intelligence|computer science|machine-readable dictionary|machine-readable representation|automation|machine learning|machine learning research|text mining|turing machine|writing instruction,
https://openalex.org/W2130722890,WSJCAMO: a British English speech corpus for large vocabulary continuous speech recognition,"WSJCAMO: a British English speech corpus for large vocabulary continuous speech recognition

A significant new speech corpus of British English has been recorded at Cambridge University. Derived from the Wall Street Journal text corpus, WSJCAMO constitutes one largest corpora spoken currently in existence. It specifically designed for construction and evaluation speaker-independent recognition systems. The database consists 140 speakers each speaking about 110 utterances. This paper describes motivation processes undertaken its utilities needed as support tools. All utterance transcriptions have verified a phonetic dictionary developed to cover training data tasks. Two tasks defined using standard 5000 word bigram 20000 trigram language models. concludes with comparative results on these American English.

english, corpus linguistics, language model, speech recognition, computational linguistics, english language, speech processing, speech translation, natural language processing, machine translation, distant speech recognition, computer science, language corpus, language, speech communication, speech corpus, spoken language technology",2002,326,english|corpus linguistics|language model|speech recognition|computational linguistics|english language|speech processing|speech translation|natural language processing|machine translation|distant speech recognition|computer science|language corpus|language|speech communication|speech corpus|spoken language technology,
https://openalex.org/W2339065664,Writing Machines,"Writing Machines

From the Publisher:
Tracing a journey from 1950s through 1990s, N. Katherine Hayles uses autobiographical persona of Kaye to explore how literature has transformed itself inscriptions rendered as flat durable marks print dynamic images CRT screens, verbal texts diverse sensory modalities multimedia works, books technotexts.
Weaving together Kaye's pseudo-autobiographical narrative with theorization contemporary in media-specific terms, examines ways which literary every genre and period mutate they are reconceived rewritten for electronic formats. As documents become more pervasive, appears not sea we swim, transparent because so accustomed its conventions, but rather medium own assumptions, specificities, inscription practices. explores works that focus on very technologies produce them, examining three writing machines depth: Talan Memmott's groundbreaking work Lexia Perplexia, Mark Z. Danielewski's cult postprint novel House Leaves, Tom Phillips's artist's book A Humument. concludes by speculating technotexts affect development subjectivity.
Writing Machines is second volume Mediawork Pamphlets series.

turing machine, computer science, automation, machine intelligence, machine learning, computational intelligence, natural language generation, machine-readable representation, machine translation, writing instruction, technology, computer engineering, machine learning research, natural language processing, text mining, digital medium, text processing, machine-readable dictionary",2002,321,turing machine|computer science|automation|machine intelligence|machine learning|computational intelligence|natural language generation|machine-readable representation|machine translation|writing instruction|technology|computer engineering|machine learning research|natural language processing|text mining|digital medium|text processing|machine-readable dictionary,
https://openalex.org/W1481560182,Computer-Aided Translation Technology: A Practical Introduction,"Computer-Aided Translation Technology: A Practical Introduction

Lynne Bowker introduces the world of technology to translation in this unique book, first its kind. reveals role and how use ever developing tool.

technology, machine translation, computer-assisted translation, computer-aided translation technology, translation studies, practical introduction",2002,285,technology|machine translation|computer-assisted translation|computer-aided translation technology|translation studies|practical introduction,
https://openalex.org/W2167645056,Translation Quality Assessment: Linguistic Description versus Social Evaluation,"Translation Quality Assessment: Linguistic Description versus Social Evaluation

The paper first reports on three different approaches to translation evaluation which emanate from concepts of “meaning” and its role in translation. Secondly, a functional-pragmatic model is described, features distinction between types translations versions, stresses the importance using “cultural filter” one particular type Thirdly, influence English as worldwide lingua franca processes discussed, finally important linguistic analysis social judgement introduced, conclusions for practice assessing quality are drawn.

linguistics, quality evaluation, communication, content analysis, language assessment, general linguistics, machine translation, semantic evaluation, nlp task, linguistic description, sociolinguistics, computational linguistics, natural language processing, language, translation studies, language testing, translation quality assessment, abstract interpretation, cross-cultural assessment, semantic interpretation, social evaluation",2002,213,linguistics|quality evaluation|communication|content analysis|language assessment|general linguistics|machine translation|semantic evaluation|nlp task|linguistic description|sociolinguistics|computational linguistics|natural language processing|language|translation studies|language testing|translation quality assessment|abstract interpretation|cross-cultural assessment|semantic interpretation|social evaluation,
https://openalex.org/W2156518033,"Use of Natural Language Processing to Translate Clinical Information from a Database of 889,921 Chest Radiographic Reports","Use of Natural Language Processing to Translate Clinical Information from a Database of 889,921 Chest Radiographic Reports

PURPOSE: To evaluate translation of chest radiographic reports by using natural language processing and to compare the findings with those in literature. MATERIALS AND METHODS: A processor coded 10 years narrative from an urban academic medical center. Coding for 150 was compared manual coding. Frequencies co-occurrences 24 clinical conditions (diseases, abnormalities, states) were estimated. The ratio right left lung mass, association pleural effusion other conditions, frequency bullet stab wounds independent observations. sensitivity specificity system’s pneumothorax coding financial RESULTS: system 889,921 on 251,186 patients. On basis reports, processor’s (0.81) (0.99) comparable previously reported expert coders. frequencies selected ranged 0.22 0.0004 tension pneumothorax. database confirmed earlier observations that cancer occurs a 3:2 right-to-left ratio. mirrored Bullet decreased during at rate consistent crime statistics. review cases showed (sensitivity, 1.00; specificity, 0.996) more accurate than discharge 0.17; P = .002; 0.996; not significant). CONCLUSION: Internal external validation this study accuracy translating into large information. © RSNA, 2002

clinical translation, clinical data, natural language processing, machine translation, clinical database, radiology, clinical information, health data, health informatics, biomedical informatics",2002,196,clinical translation|clinical data|natural language processing|machine translation|clinical database|radiology|clinical information|health data|health informatics|biomedical informatics,
https://openalex.org/W1560329227,Maps of Meaning,"Maps of Meaning

Preface: Descensus ad Inferos 1. Maps of Experience: Object and Meaning 2. Meaning: Three Levels Analysis Normal Revolutionary Life: Two Prosaic Stories Neuropsychological Function: The Nature the Mind Mythological Representation:The Constitutent Elements Experience 3. Apprenticeship Enculturation: Adoption a Shared Map 4. Appearance Anomaly: Challenge to Introduction: Paradigmatic Structure Known Particular Forms Anomaly Rise Self-Reference, Permanent Contamination with Death 5. Hostile Brothers: Archetypes Response Unknown Hero Adversary Adversary: Emergence, Development Representation Heroic Adaptation: Voluntary Reconstruction Conclusion: Divinity Interest

general linguistics, linguistics, semantic interpretation, interpretation, semantic representation, lexical semantics, structural linguistics, machine translation, symbolic linguistic representation, language, semantic evaluation, semantics, distributional semantics, context (linguistics), art, morphology, narrative, social semiotics",2002,174,general linguistics|linguistics|semantic interpretation|interpretation|semantic representation|lexical semantics|structural linguistics|machine translation|symbolic linguistic representation|language|semantic evaluation|semantics|distributional semantics|context (linguistics)|art|morphology|narrative|social semiotics,
https://openalex.org/W2160382364,Phrasal cohesion and statistical machine translation,"Phrasal cohesion and statistical machine translation

There has been much interest in using phrasal movement to improve statistical machine translation.We explore how well phrases cohere across two languages, specifically English and French, examine the particular conditions under which they do not.We demonstrate that while there are cases where coherence is poor, many regularities can be exploited by a translation system.We also compare three variant syntactic representations determine one best properties with respect cohesion.

linguistics, natural language processing, statistical machine translation, phrasal cohesion, machine translation",2002,173,linguistics|natural language processing|statistical machine translation|phrasal cohesion|machine translation,https://openalex.org/W2116316001|https://openalex.org/W2032175749|https://openalex.org/W2166905217
https://openalex.org/W2090362702,Machine transliteration of names in Arabic text,"Machine transliteration of names in Arabic text

We present a transliteration algorithm based on sound and spelling mappings using finite state machines. The models can be trained relatively small lists of names. introduce new spelling-based model that is much more accurate than state-of-the-art phonetic-based easier-to-obtain training data. apply our to the names from Arabic into English. report accuracy exact-matching criterion human-subjective evaluation. also compare system human translators.

arabic text, computer science, linguistics, text mining, natural language processing, language, neural machine translation, computational linguistics, machine transliteration, machine translation",2002,166,arabic text|computer science|linguistics|text mining|natural language processing|language|neural machine translation|computational linguistics|machine transliteration|machine translation,https://openalex.org/W2150028966
https://openalex.org/W560582116,Translation and Power,"Translation and Power

The contributors to this volume see translation as an activity that takes place not in ideal neutral site but real social and political situations, with parties who have vested interests the production reception of texts across linguistic cultural boundaries. Translation is simply a process faithful reproduction invariably involves deliberate acts selection, construction, omission. It inextricably linked issues dominance, assertion, resistance - short, power. Although governments, churches, publishing firms, other powerful institutions may influence process, many translators found ways resist used introduce new ideas modes expression. Exploring nexus power, essays offer wide variety examples, multiple languages societies. They range from case studies historical episodes which has played role assertion military such 1840 treaty between British Maori continues be source conflict present-day New Zealand, analyses work specific translators, Germaine de Stael Gayatri Spivak. Along examining how contributes ideological negotiations struggles, reveal dimensions power inherent itself relationship translator author, text, translated text. In addition editors, include Rosemary Arrojo, Michael Cronin, Sabine Fenton, Camino Gutierrez Lanza, Christopher Larkosh, Alexandra Lianeri, Lin Kenan, Carol Maier, Paul Moon, Adriana S. Pagano, Sherry Simon.

speech translation, specialized translation, power relation, language, multimodal translation, machine translation, translation studies, computer-assisted translation",2002,164,speech translation|specialized translation|power relation|language|multimodal translation|machine translation|translation studies|computer-assisted translation,
https://openalex.org/W1974967573,Toward a unified approach to statistical language modeling for Chinese,"Toward a unified approach to statistical language modeling for Chinese

This article presents a unified approach to Chinese statistical language modeling (SLM). Applying SLM techniques like trigram models is challenging because (1) there no standard definition of words in Chinese; (2) word boundaries are not marked by spaces; and (3) dearth training data. Our automatically consistently gathers high-quality data set from the Web, creates lexicon, segments using this compresses model, all maximum likelihood principle, which consistent with model training. We show that each methods leads improvements over SLM, combined method yields best pinyin conversion result reported.

linguistics, language engineering, machine translation, language, statistics, natural language processing, computational linguistics, statistical language, language model",2002,147,linguistics|language engineering|machine translation|language|statistics|natural language processing|computational linguistics|statistical language|language model,
https://openalex.org/W2117130368,A unified architecture for natural language processing,"A unified architecture for natural language processing

We describe a single convolutional neural network architecture that, given sentence, outputs host of language processing predictions: part-of-speech tags, chunks, named entity semantic roles, semantically similar words and the likelihood that sentence makes sense (grammatically semantically) using model. The entire is trained jointly on all these tasks weight-sharing, an instance multitask learning. All use labeled data except model which learnt from unlabeled text represents novel form semi-supervised learning for shared tasks. show how both improve generalization tasks, resulting in state-of-the-art-performance.

computer science, artificial intelligence, natural language interface, language model, natural language processing, language engineering, unified architecture, computational linguistics, deep learning, nlp task, machine translation, knowledge architecture",2008,5021,computer science|artificial intelligence|natural language interface|language model|natural language processing|language engineering|unified architecture|computational linguistics|deep learning|nlp task|machine translation|knowledge architecture,https://openalex.org/W2126725946|https://openalex.org/W1753482797|https://openalex.org/W2118090838|https://openalex.org/W2250539671|https://openalex.org/W2283196293|https://openalex.org/W2120615054|https://openalex.org/W2896457183|https://openalex.org/W3019166713
https://openalex.org/W2131472136,<b>yaImpute</b>: An<i>R</i>Package for<i>k</i>NN Imputation,"<b>yaImpute</b>: An<i>R</i>Package for<i>k</i>NN Imputation

This article introduces yaImpute, an R package for nearest neighbor search and imputation. Although imputation is used in a host of disciplines, the methods implemented yaImpute are tailored to imputation-based forest attribute estimation mapping. The impetus writing growing interest spatially explicit inventory, need within this research community software that facilitates comparison among different algorithms subsequent techniques. provides directives defining space, distance calculation, rules given number neighbors. Further, offers suite diagnostics results generated from analyses set functions mapping results.

computer science, knowledge representation and reasoning, information fusion, knowledge compilation, natural language processing, missing data, neural machine translation, automated reasoning, data-centric ai, data science, computational intelligence, deep learning, statistics, machine translation, scientific computing, bioinformatics",2008,377,computer science|knowledge representation and reasoning|information fusion|knowledge compilation|natural language processing|missing data|neural machine translation|automated reasoning|data-centric ai|data science|computational intelligence|deep learning|statistics|machine translation|scientific computing|bioinformatics,
https://openalex.org/W2032175749,Statistical machine translation,"Statistical machine translation

Statistical machine translation (SMT) treats the of natural language as a learning problem. By examining many samples human-produced translation, SMT algorithms automatically learn how to translate. has made tremendous strides in less than two decades, and new ideas are constantly introduced. This survey presents tutorial overview state art. We describe context current research then move formal problem description an main subproblems: modeling, parameter estimation, decoding. Along way, we present taxonomy some different approaches within these areas. conclude with evaluation discussion future directions.

natural language processing, neural machine translation, statistical machine translation, statistics, machine translation, translation studies",2008,375,natural language processing|neural machine translation|statistical machine translation|statistics|machine translation|translation studies,https://openalex.org/W1916559533|https://openalex.org/W2155607551|https://openalex.org/W2070789508
https://openalex.org/W2105891181,Lattice-based minimum error rate training for statistical machine translation,"Lattice-based minimum error rate training for statistical machine translation

Minimum Error Rate Training (MERT) is an effective means to estimate the feature function weights of a linear model such that automated evaluation criterion for measuring system performance can directly be optimized in training. To accomplish this, training procedure determines each its exact error surface on given set candidate translations. The are then adjusted by traversing combined over all sentences and picking those values which resulting count reaches minimum. Typically, candidates MERT represented as N-best lists contain N most probable translation hypotheses produced decoder. In this paper, we present novel algorithm allows efficiently constructing representing translations encoded phrase lattice. Compared MERT, number thus taken into account increases several orders magnitudes. proposed method used train phrase-based statistical machine system. Experiments conducted NIST 2008 tasks show significant runtime improvements moderate BLEU score gains MERT.

lattice (order), data science, natural language processing, machine translation, statistical machine translation",2008,366,lattice (order)|data science|natural language processing|machine translation|statistical machine translation,https://openalex.org/W2131988669|https://openalex.org/W2166905217|https://openalex.org/W2169279899|https://openalex.org/W2100238596|https://openalex.org/W2117642127|https://openalex.org/W1848260265|https://openalex.org/W2101096097|https://openalex.org/W2159755860|https://openalex.org/W2250489405|https://openalex.org/W12732426
https://openalex.org/W2131988669,Optimizing Chinese word segmentation for machine translation performance,"Optimizing Chinese word segmentation for machine translation performance

Previous work has shown that Chinese word segmentation is useful for machine translation to English, yet the way different strategies affect MT still poorly understood.In this paper, we demonstrate optimizing an existing standard does not always yield better performance.We find other factors such as consistency and granularity of ""words"" can be more important translation.Based on these findings, implement methods inside a conditional random field segmenter directly optimize with respect task, providing improvement 0.73 BLEU.We also show improving using external lexicon proper noun features yields 0.32 BLEU increase.

computational linguistics, natural language processing, machine translation, computer-assisted translation, machine translation performance, machine learning, chinese word segmentation, language, text processing",2008,313,computational linguistics|natural language processing|machine translation|computer-assisted translation|machine translation performance|machine learning|chinese word segmentation|language|text processing,
https://openalex.org/W2081795963,Multilingual subjectivity analysis using machine translation,"Multilingual subjectivity analysis using machine translation

Although research in other languages is increasing, much of the work subjectivity analysis has been applied to English data, mainly due large body electronic resources and tools that are available for this language. In paper, we propose evaluate methods can be employed transfer a repository across languages. Specifically, attempt leverage on and, by employing machine translation, generate Through comparative evaluations two different (Romanian Spanish), show automatic translation viable alternative construction new target

multilingual subjectivity analysis, language, natural language processing, machine translation",2008,287,multilingual subjectivity analysis|language|natural language processing|machine translation,
https://openalex.org/W2166905217,A New String-to-Dependency Machine Translation Algorithm with a Target Dependency Language Model,"A New String-to-Dependency Machine Translation Algorithm with a Target Dependency Language Model

In this paper, we propose a novel string-todependency algorithm for statistical machine translation. With new framework, employ target dependency language model during decoding to exploit long distance word relations, which are unavailable with traditional n-gram model. Our experiments show that the string-to-dependency decoder achieves 1.48 point improvement in BLEU and 2.53 TER compared standard hierarchical string-tostring system on NIST 04 Chinese-English evaluation set.

language model, natural language processing, machine translation, computer science, dependency linguistics",2008,260,language model|natural language processing|machine translation|computer science|dependency linguistics,https://openalex.org/W137989762
https://openalex.org/W2169279899,Further meta-evaluation of machine translation,"Further meta-evaluation of machine translation

This paper analyzes the translation quality of machine systems for 10 language pairs translating between Czech, English, French, German, Hungarian, and Spanish. We report over 30 diverse based on a large-scale manual evaluation involving hundreds hours effort. use human judgments to analyze automatic metrics quality, we strength correlation with at both system-level sentence-level. validate our methodology by measuring intra- inter-annotator agreement, collecting timing information.

meta-analysis, natural language processing, machine translation, computer-assisted translation, computer science, further meta-evaluation, translation studies",2008,260,meta-analysis|natural language processing|machine translation|computer-assisted translation|computer science|further meta-evaluation|translation studies,https://openalex.org/W2159107349|https://openalex.org/W2087735403|https://openalex.org/W2270190199|https://openalex.org/W2252166243|https://openalex.org/W2257408573|https://openalex.org/W2251994258|https://openalex.org/W2512924740|https://openalex.org/W2903193068
https://openalex.org/W2125945136,Working with Transcripts and Translated Data,"Working with Transcripts and Translated Data

Transcribing talk originating from various interactional contexts into a written form is an integral part qualitative research practice. Transcripts are produced for particular analytic purposes and therefore range in detail, broad verbatim transcripts more content-oriented analysis to extremely refined detailed transcriptions on interaction-oriented of naturally occurring data. Learning master transcription skills, solving the practical, technical theoretical considerations decisions that go process producing good quality something both students, teachers methods researchers within field equally struggle with. Discussion practice all important given sees as central means securing validity guaranteeing publicly verifiable, transparent cumulative nature its claims findings (e.g., Hutchby & Wooffitt, 1998 Hutchby, I. R. 1998. Conversation analysis: principles, practices applications, Cambridge, , UK: Polity Press. [Google Scholar]; Peräkylä, 1997 A. 1997. ""Reliability based tapes transcripts"". In Qualitative research: Theory, method practice, Edited by: Silverman, D. London: Sage. Seale, 1999 C. 1999. The research, [Crossref] Scholar]). This paper offers concise review working with 'good transcripts.' addition perhaps importantly, it discusses often-neglected question translating data another language (typically) English speaking academic audience looks at choices scholars make when presenting their work. Opening art translation wider discussion crucial increasingly conducted international environment. Students, scholars, travel across national boundaries new areas join in. guidelines how translated accessible yet precise fashion, should ideally be presented reading audience, transparency secured increasing demand.

language corpus, language, transcriptomics technology, machine translation, translation studies, transcriptome",2008,171,language corpus|language|transcriptomics technology|machine translation|translation studies|transcriptome,
https://openalex.org/W2157435188,Generalizing Word Lattice Translation,"Generalizing Word Lattice Translation

The Department of Defense (DoD) and civilian relief agencies (non-governmental organizations--

word embeddings, linguistics, language, general linguistics, word lattice translation, machine translation, translation studies",2008,167,word embeddings|linguistics|language|general linguistics|word lattice translation|machine translation|translation studies,https://openalex.org/W2155607551
https://openalex.org/W2103098030,Pattern-Based Translation of BPMN Process Models to BPEL Web Services,"Pattern-Based Translation of BPMN Process Models to BPEL Web Services

The business process modeling notation (BPMN) is a graph-oriented language primarily targeted at domain analysts and supported by many tools. execution for Web services (BPEL) on the other hand mainly block-structured software developers several platforms. Translating BPMN models into BPEL code necessary step towards standards-based development environments. This translation challenging since represent two fundamentally different classes of languages. Existing BPMN-to-BPEL translations rely identification patterns in that are mapped onto structured constructs. article advances state art defining methods identifying not only perfectly fragments models, but quasi-structured can be turned ones flow-based acyclic combination constructs control links. Beyond its direct relevance context BPEL, this addresses issues arise generally when translating between flow definition

computer science, business process modeling, systems modeling, process modelling, data modeling, web service modeling, process engineering, pattern-based translation, process safety, machine translation, supply chain management, information technology, bpmn process models, modeling and simulation, systems engineering, process control, model reuse, web service, chemical engineering",2008,157,computer science|business process modeling|systems modeling|process modelling|data modeling|web service modeling|process engineering|pattern-based translation|process safety|machine translation|supply chain management|information technology|bpmn process models|modeling and simulation|systems engineering|process control|model reuse|web service|chemical engineering,
https://openalex.org/W2001006503,Translating Structured English to Robot Controllers,"Translating Structured English to Robot Controllers

Recently, Linear Temporal Logic (LTL) has been successfully applied to high-level task and motion planning problems for mobile robots. One of the main attributes LTL is its close relationship with fragments natural language. In this paper, we take first steps toward building a language interface methods robots as application domain. For purpose, built structured English which maps directly fragment LTL.

robotics, english, machine translation",2008,142,robotics|english|machine translation,
https://openalex.org/W2100238596,Lattice Minimum Bayes-Risk decoding for statistical machine translation,"Lattice Minimum Bayes-Risk decoding for statistical machine translation

We present Minimum Bayes-Risk (MBR) decoding over translation lattices that compactly encode a huge number of hypotheses. describe conditions on the loss function will enable efficient implementation MBR decoders lattices. introduce an approximation to BLEU score (Papineni et al., 2001) satisfies these conditions. The under this approximate is realized using Weighted Finite State Automata. Our experiments show Lattice decoder yields moderate, consistent gains in performance N-best Arabic-to-English, Chinese-to-English and English-to-Chinese tasks. conduct range understand why improves upon study impact various parameters performance.

computer science, statistical machine translation, machine translation",2008,132,computer science|statistical machine translation|machine translation,https://openalex.org/W2105891181|https://openalex.org/W2057235967
https://openalex.org/W2117642127,Applying Morphology Generation Models to Machine Translation,"Applying Morphology Generation Models to Machine Translation

We improve the quality of statistical machine translation (SMT) by applying models that predict word forms from their stems using extensive morphological and syntactic information both source target languages. Our inflection generation are trained independently SMT system. investigate different ways combining prediction component with system training base MT on fully inflected or stems. applied our in translating English into two morphologically complex languages, Russian Arabic, show model improves over phrasal syntax-based systems according to BLEU human judgements.

computer science, morphology generation models, natural language processing, machine translation, language generation",2008,130,computer science|morphology generation models|natural language processing|machine translation|language generation,
https://openalex.org/W2126610017,A Discriminative Latent Variable Model for Statistical Machine Translation,"A Discriminative Latent Variable Model for Statistical Machine Translation

Large-scale discriminative machine translation promises to further the state-of-the-art, but has failed deliver convincing gains over current heuristic frequency count systems. We argue that a principle reason for this failure is not dealing with multiple, equivalent translations. present model which models derivations as latent variable, in both training and decoding, fully globally optimised. Results show accounting multiple does indeed improve performance. Additionally, we regularisation essential maximum conditional likelihood order avoid degenerate solutions.

machine translation, machine learning, statistical machine translation, statistics, latent variable model",2008,116,machine translation|machine learning|statistical machine translation|statistics|latent variable model,https://openalex.org/W2155607551
https://openalex.org/W1979495315,Forest-based translation rule extraction,"Forest-based translation rule extraction

Translation rule extraction is a fundamental problem in machine translation, especially for linguistically syntax-based systems that need parse trees from either or both sides of the bi-text. The current dominant practice only uses 1-best trees, which adversely affects set quality due to parsing errors. So we propose novel approach extracts rules packed forest compactly encodes exponentially many parses. Experiments show this method improves translation by over 1 BLEU point on state-of-the-art tree-to-string system, and 0.5 points better than (and twice as fast as) extracting 30-best When combined with our previous work forest-based decoding, it achieves 2.5 improvement base-line, even outperforms hierarchical system Hiero 0.7 points.

data science, computer-assisted translation, machine translation",2008,116,data science|computer-assisted translation|machine translation,https://openalex.org/W2100238596
https://openalex.org/W179875071,Recurrent neural network based language model,"Recurrent neural network based language model

A new recurrent neural network based language model (RNN LM) with applications to speech recognition is presented. Results indicate that it possible obtain around 50% reduction of perplexity by using mixture several RNN LMs, compared a state the art backoff model. Speech experiments show 18% word error rate on Wall Street Journal task when comparing models trained same amount data, and 5% much harder NIST RT05 task, even more data than LM. We provide ample empirical evidence suggest connectionist are superior standard n-gram techniques, except their high computational (training) complexity. Index Terms: modeling, networks,

computer science, linguistics, large language model, language model, natural language processing, language, neural machine translation, machine learning, recurrent neural network, sequential learning, computational intelligence, deep learning, machine learning research, machine translation, neural network (machine learning), language learning",2010,5099,computer science|linguistics|large language model|language model|natural language processing|language|neural machine translation|machine learning|recurrent neural network|sequential learning|computational intelligence|deep learning|machine learning research|machine translation|neural network (machine learning)|language learning,https://openalex.org/W1753482797|https://openalex.org/W2118090838|https://openalex.org/W2250489405|https://openalex.org/W2251682575|https://openalex.org/W2170738476|https://openalex.org/W1985258458|https://openalex.org/W2567070169|https://openalex.org/W2546938941|https://openalex.org/W3019166713
https://openalex.org/W1916559533,Statistical machine translation,"Statistical machine translation

This introductory text to statistical machine translation (SMT) provides all of the theories and methods needed build a translator, such as Google Language Tools Babelfish. In general, techniques allow automatic systems be built quickly for any language-pair using only translated texts generic software. With increasing globalization, will central communication commerce. Based on courses tutorials, classroom-tested globally, it is ideal instruction or self-study, advanced undergraduates graduate students in computer science and/or computational linguistics, researchers natural language processing. The companion website open-source corpora tool-kits.

machine translation, statistical machine translation, natural language processing, statistics, neural machine translation, translation studies",2010,1282,machine translation|statistical machine translation|natural language processing|statistics|neural machine translation|translation studies,https://openalex.org/W2116316001|https://openalex.org/W2032175749|https://openalex.org/W2157435188|https://openalex.org/W1972141422|https://openalex.org/W2133564696|https://openalex.org/W2964308564|https://openalex.org/W2100664567|https://openalex.org/W2964241990|https://openalex.org/W1915251500|https://openalex.org/W2251994258|https://openalex.org/W2889326796
https://openalex.org/W2613000335,Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,"Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics

It is with great pleasure that I welcome you to the 2010 Human Language Technologies conference of North American chapter Association for Computational Linguistics. An enormous amount effort has gone into organizing conference, and result rich set intellectual social experiences will enjoy this week.

The NAACL HLT an orchestrated production many events. The centerpiece collection carefully chosen papers, posters, demonstrations be presented during three days main conference. This includes papers posters Student Research Workshop, a setting gives encouragement opportunity new members our community present their work. preceded by day tutorials on topics current interest in field, it followed very full program specialized workshops.

linguistics, language technology, computational linguistics, natural language processing, machine translation, human language technologies",2010,332,linguistics|language technology|computational linguistics|natural language processing|machine translation|human language technologies,
https://openalex.org/W2109802560,A Monolingual Tree-based Translation Model for Sentence Simplification,"A Monolingual Tree-based Translation Model for Sentence Simplification

In this paper, we consider sentence simplification as a special form of translation with the complex source and simple target. We propose Tree-based Simplification Model (TSM), which, to our knowledge, is first statistical model covering splitting, dropping, reordering substitution integrally. also describe an efficient method train large-scale parallel dataset obtained from Wikipedia Simple Wikipedia. The evaluation shows that achieves better readability scores than set baseline systems.

sentence simplification, linguistics, language model, natural language processing, machine translation, language",2010,322,sentence simplification|linguistics|language model|natural language processing|machine translation|language,https://openalex.org/W2156422881|https://openalex.org/W2534253848
https://openalex.org/W2127849236,Creating Speech and Language Data With Amazon's Mechanical Turk,"Creating Speech and Language Data With Amazon's Mechanical Turk

In this paper we give an introduction to using Amazon's Mechanical Turk crowdsourcing platform for the purpose of collecting data human language technologies. We survey papers published in NAACL-2010 Workshop. 24 researchers participated workshop's shared task create speech and applications with $100.

mechanical turk, language model, speech recognition, speech processing, language monitoring, data science, natural language processing, machine translation, language data, computer science, language, spoken language technology, speech corpus, deep learning",2010,299,mechanical turk|language model|speech recognition|speech processing|language monitoring|data science|natural language processing|machine translation|language data|computer science|language|spoken language technology|speech corpus|deep learning,https://openalex.org/W2159107349|https://openalex.org/W137989762
https://openalex.org/W1926644249,Understanding the Processes of Translation and Transliteration in Qualitative Research,"Understanding the Processes of Translation and Transliteration in Qualitative Research

There has been growing interest in the use of qualitative methods health research amongst and social care professionals. Good cross-cultural analysis is not an easy task as it involves knowledge different approaches, techniques command appropriate languages. This article aims to discuss explore some key processes concepts involved conducting translation transliteration research.

linguistics, clinical translation, sociolinguistics, applied linguistics, specialized translation, multimodal translation, translational research, qualitative analysis, qualitative research, machine translation, language, translation studies, qualitative interpretation",2010,271,linguistics|clinical translation|sociolinguistics|applied linguistics|specialized translation|multimodal translation|translational research|qualitative analysis|qualitative research|machine translation|language|translation studies|qualitative interpretation,
https://openalex.org/W2155607551,"cdec: A Decoder, Alignment, and Learning Framework for Finite-State and Context-Free Translation Models","cdec: A Decoder, Alignment, and Learning Framework for Finite-State and Context-Free Translation Models

We present cdec, an open source framework for decoding, aligning with, and training a number of statistical machine translation models, including word-based phrase-based models based on synchronous context-free grammars. Using single unified internal representation forests, the decoder strictly separates model-specific logic from general rescoring, pruning, inference algorithms. From this representation, can extract not only 1- or k-best translations, but also alignments to reference, quantities necessary drive discriminative using gradient-based gradient-free optimization techniques. Its efficient C++ implementation means that memory use runtime performance are significantly better than comparable decoders.

context-free translation models, data science, natural language processing, machine learning research, machine translation, nlp task, computer science, machine learning, sequence alignment, deep learning",2010,238,context-free translation models|data science|natural language processing|machine learning research|machine translation|nlp task|computer science|machine learning|sequence alignment|deep learning,https://openalex.org/W1829822087|https://openalex.org/W1753482797|https://openalex.org/W2118434577|https://openalex.org/W2251994258
https://openalex.org/W2057235967,A Productivity Test of Statistical Machine Translation Post-Editing in a Typical Localisation Context,"A Productivity Test of Statistical Machine Translation Post-Editing in a Typical Localisation Context

We evaluated the productivity increase of statistical MT post-editing as compared to traditional translation in a two-day test involving twelve participants translating from English French, Italian, German, and Spanish.The setup followed an empirical methodology.A random subset entire new content produced our company during given year was translated with engines trained on data previous year.The environment recorded times for each sentence.The results show participant, significant variance across inviduals.

typical localisation context, localization, productivity test, machine translation, computer science, machine learning, language localisation",2010,233,typical localisation context|localization|productivity test|machine translation|computer science|machine learning|language localisation,
https://openalex.org/W2165403123,"Writing from Sources, Writing from Sentences","Writing from Sources, Writing from Sentences

Instead of focusing on students’ citation sources, educators should attend to the more fundamental question how well students understand their sources and whether they are able write about them without appropriating language from source. Of 18 student research texts we studied, none included summary a source, raising questions critical reading practices. summary, which is highly valued in academic writing promoted composition textbooks, paraphrased, copied from, or patchwrote individual sentences sources. Writing places writers constant jeopardy working too closely with source thus inadvertently plagiarizing; it also does not compel writer

context (linguistics), linguistics, creative writing, second language writing, applied linguistics, language documentation, narrative, textual practice, narrative extraction, writing instruction, natural language processing, machine translation, composition approach, grammar, syntactic structure, language, literature, principle of compositionality",2010,230,context (linguistics)|linguistics|creative writing|second language writing|applied linguistics|language documentation|narrative|textual practice|narrative extraction|writing instruction|natural language processing|machine translation|composition approach|grammar|syntactic structure|language|literature|principle of compositionality,
https://openalex.org/W1848260265,Discriminative Instance Weighting for Domain Adaptation in Statistical Machine Translation,"Discriminative Instance Weighting for Domain Adaptation in Statistical Machine Translation

We describe a new approach to SMT adaptation that weights out-of-domain phrase pairs according their relevance the target domain, determined by both how similar it they appear be, and whether belong general language or not. This extends previous work on discriminative weighting using finer granularity, focusing properties of instances rather than corpus components, simpler training procedure. incorporate instance into mixture-model framework, find yields consistent improvements over wide range baselines.

machine translation, computer science, discriminative instance, machine learning, statistical machine translation, domain adaptation",2010,213,machine translation|computer science|discriminative instance|machine learning|statistical machine translation|domain adaptation,https://openalex.org/W2137698233|https://openalex.org/W2147262247
https://openalex.org/W2159107349,Findings of the 2010 Joint Workshop on Statistical Machine Translation and Metrics for Machine Translation,"Findings of the 2010 Joint Workshop on Statistical Machine Translation and Metrics for Machine Translation

This paper presents the results of WMT10 and MetricsMATR10 shared tasks, which included a translation task, system combination an evaluation task. We conducted large-scale manual 104 machine systems 41 entries. used ranking these to measure how strongly automatic metrics correlate with human judgments quality for 26 metrics. year we also investigated increasing number by hiring non-expert annotators through Amazon's Mechanical Turk.

computer science, statistical machine translation, natural language processing, machine translation",2010,190,computer science|statistical machine translation|natural language processing|machine translation,https://openalex.org/W2087735403|https://openalex.org/W2270190199|https://openalex.org/W2252166243|https://openalex.org/W2257408573|https://openalex.org/W2251994258|https://openalex.org/W2512924740|https://openalex.org/W2903193068
https://openalex.org/W1664049007,"Speech Recognition by Machine, A Review","Speech Recognition by Machine, A Review

This paper presents a brief survey on Automatic Speech Recognition and discusses the major themes advances made in past 60 years of research, so as to provide technological perspective an appreciation fundamental progress that has been accomplished this important area speech communication. After research development accuracy automatic recognition remains one challenges (e.g., variations context, speakers, environment).The design system requires careful attentions following issues: Definition various types classes, representation, feature extraction techniques, classifiers, database performance evaluation. The problems are existing ASR techniques solve these constructed by workers have presented chronological order. Hence authors hope work shall be contribution recognition. objective review is summarize compare some well known methods used stages identify topic applications which at forefront exciting challenging field.

pattern recognition, computer science, linguistics, speech recognition, voice recognition, language model, speech processing, speech perception, spoken language processing, machine learning, speech technology, language recognition, speaker recognition, machine learning research, machine translation, speech communication, spoken language technology, computer engineering",2010,168,pattern recognition|computer science|linguistics|speech recognition|voice recognition|language model|speech processing|speech perception|spoken language processing|machine learning|speech technology|language recognition|speaker recognition|machine learning research|machine translation|speech communication|spoken language technology|computer engineering,
https://openalex.org/W2101096097,Large Scale Parallel Document Mining for Machine Translation,"Large Scale Parallel Document Mining for Machine Translation

A distributed system is described that reliably mines parallel text from large corpora. The approach can be regarded as cross-language near-duplicate detection, enabled by an initial, low-quality batch translation. In contrast to other approaches which require specialized metadata, the uses only textual content of documents. Results are presented for a corpus over two billion web pages and collection digitized public-domain books.

machine translation, computer science, text mining, natural language processing, large language model, data science, knowledge discovery, parallel computing",2010,149,machine translation|computer science|text mining|natural language processing|large language model|data science|knowledge discovery|parallel computing,https://openalex.org/W3038033387
https://openalex.org/W2070789508,Following directions using statistical machine translation,"Following directions using statistical machine translation

Mobile robots that interact with humans in an intuitive way must be able to follow directions provided by unconstrained natural language. In this work we investigate how statistical machine translation techniques can used bridge the gap between language route instructions and a map of environment built robot. Our approach uses training data learn translate from automatically-labeled map. The complexity process is controlled taking advantage physical constraints imposed As result, our technique efficiently handle uncertainty both labeling parsing. experiments demonstrate promising capabilities achieved approach.

statistical machine translation, natural language processing, statistics, machine translation, neural machine translation, machine learning research",2010,133,statistical machine translation|natural language processing|statistics|machine translation|neural machine translation|machine learning research,
https://openalex.org/W1599046146,The Translator's Invisibility,"The Translator's Invisibility

Since publication over ten years ago, The Translator's Invisibility has provoked debate and controversy within the field of translation become a classic text. Providing fascinating account history from seventeenth century to present day, Venuti shows how fluency prevailed other strategies shape canon foreign literatures in English investigates cultural consequences receptor values which were simultaneously inscribed masked texts during this period. author locates alternative theories practices British, American European cultures aim communicate linguistic differences instead removing them. In second edition his work, Venuti: clarifies further develops key terms arguments responds critical commentary on argument incorporates new case studies that include: an eighteenth French novel by working class woman; Richard Burton's controversial Arabian Nights; modernist poetry translation; translations Dostoevsky bestselling translators Pevear Larissa Volokhonsky; translated crime fiction updates data current state translation, including publishing statistics translators' rates. will be essential reading for students at all levels. Lawrence is Professor Temple University, Philadelphia. He theorist historian as well translator recent publications Scandals Translation: Towards Ethics Difference Translation Studies Reader, both published Routledge.

applied linguistics, linguistics, speech translation, specialized translation, language, communication, multimodal translation, machine translation, translation studies",2012,609,applied linguistics|linguistics|speech translation|specialized translation|language|communication|multimodal translation|machine translation|translation studies,https://openalex.org/W2167645056
https://openalex.org/W2159755860,Batch Tuning Strategies for Statistical Machine Translation,"Batch Tuning Strategies for Statistical Machine Translation

There has been a proliferation of recent work on SMT tuning algorithms capable handling larger feature sets than the traditional MERT approach. We analyze number these in terms their sentence-level loss functions, which motivates several new approaches, including Structured SVM. perform empirical comparisons eight different strategies, MERT, variety settings. Among other results, we find that simple and efficient batch version MIRA performs at least as well training online, consistently outperforms options.

statistical machine translation, data science, natural language processing, machine translation",2012,350,statistical machine translation|data science|natural language processing|machine translation,https://openalex.org/W2794365787
https://openalex.org/W2087735403,Findings of the 2012 Workshop on Statistical Machine Translation,"Findings of the 2012 Workshop on Statistical Machine Translation

This paper presents the results of WMT12 shared tasks, which included a translation task, task for machine evaluation metrics, and run-time estimation quality. We conducted large-scale manual 103 systems submitted by 34 teams. used ranking these to measure how strongly automatic metrics correlate with human judgments quality 12 metrics. introduced new this year, evaluated submissions from 11

computer science, statistical machine translation, natural language processing, machine translation",2012,338,computer science|statistical machine translation|natural language processing|machine translation,https://openalex.org/W2270190199|https://openalex.org/W2252166243|https://openalex.org/W2257408573|https://openalex.org/W2251994258|https://openalex.org/W2512924740|https://openalex.org/W2903193068
https://openalex.org/W2125447031,Computational Generation of Referring Expressions: A Survey,"Computational Generation of Referring Expressions: A Survey

This article offers a survey of computational research on referring expression generation (REG). It introduces the REG problem and describes early work in this area, discussing what basic assumptions lie behind it, showing how its remit has widened recent years. We discuss frameworks underlying REG, demonstrate trend that seeks to link algorithms with well-established Knowledge Representation techniques. Considerable attention is given efforts at evaluating lessons they allow us learn. The concludes discussion way forward focusing references larger more realistic settings.

linguistics, computational generation, language model, computational lexicology, terminology extraction, natural language generation, spoken language technology, semantics, procedural generation, machine translation, computational intelligence, text mining, computational linguistics, natural language processing, computer science, language, applied linguistics, computational semantics, language generation",2012,327,linguistics|computational generation|language model|computational lexicology|terminology extraction|natural language generation|spoken language technology|semantics|procedural generation|machine translation|computational intelligence|text mining|computational linguistics|natural language processing|computer science|language|applied linguistics|computational semantics|language generation,
https://openalex.org/W2126900439,The Processing of Formulaic Language,"The Processing of Formulaic Language

It is generally accepted that we store representations of individual words in our mental lexicon. There growing agreement the lexicon also contains formulaic language ( How are you? kick bucket ). In fact, there compelling reasons to think brain represents sequences long-term memory, bypassing need compose them online through word selection and grammatical sequencing capacity-limited working memory. The research surveyed this chapter strongly supports position an advantage way native speakers process compared nonformulaic language. This extends access use different types language, including idioms, binomials, collocations, lexical bundles. However, evidence mixed for nonnative speakers. While very proficient nonnatives sometimes exhibit processing advantages similar natives, less learners often have been shown a word-by-word manner Furthermore, if idiomatic (where meaning cannot be understood from component words), figurative meanings can much more difficult than nonidiomatic,

linguistics, formal semantics, grammatical formalism, grammar, formulaic language, semantics, general linguistics, machine translation, syntax, formal language, computational linguistics, natural language processing, computer science, language, logic in computer science, applied linguistics, computational semantics, theoretical linguistics, social semiotics",2012,246,linguistics|formal semantics|grammatical formalism|grammar|formulaic language|semantics|general linguistics|machine translation|syntax|formal language|computational linguistics|natural language processing|computer science|language|logic in computer science|applied linguistics|computational semantics|theoretical linguistics|social semiotics,
https://openalex.org/W2062299199,Before It Gets Started: Regulating Translation at the 5′ UTR,"Before It Gets Started: Regulating Translation at the 5′ UTR

Translation regulation plays important roles in both normal physiological conditions and diseases states. This requires cis-regulatory elements located mostly 5′ 3′ UTRs trans-regulatory factors (e.g., RNA binding proteins (RBPs)) which recognize specific features interact with the translation machinery to modulate its activity. In this paper, we discuss aspects of UTR-mediated by providing an overview characteristics function main present region, like uORF (upstream open reading frame), secondary structures, RBPs motifs different mechanisms impact they have on gene expression human health when deregulated.

regulating translation, language policy, molecular regulation, regulation, machine translation, language, translation studies",2012,232,regulating translation|language policy|molecular regulation|regulation|machine translation|language|translation studies,
https://openalex.org/W2156422881,Sentence Simplification by Monolingual Machine Translation,"Sentence Simplification by Monolingual Machine Translation

In this paper we describe a method for simplifying sentences using Phrase Based Machine Translation, augmented with re-ranking heuristic based on dissimilarity, and trained monolingual parallel corpus. We compare our system to word-substitution baseline two state-of-the-art systems, all tested paired from the English part of Wikipedia Simple Wikipedia. Human test subjects judge output different systems. Analysing judgements shows that by relatively careful phrase-based paraphrasing model achieves similar simplification results while generating better formed output. also argue text readability metrics such as Flesch-Kincaid grade level should be used caution when evaluating

sentence simplification, linguistics, computational linguistics, natural language processing, machine translation, computer-assisted translation, language, monolingual machine translation",2012,231,sentence simplification|linguistics|computational linguistics|natural language processing|machine translation|computer-assisted translation|language|monolingual machine translation,https://openalex.org/W2534253848
https://openalex.org/W2134410571,Mechanisms and implications of programmed translational frameshifting,"Mechanisms and implications of programmed translational frameshifting

Abstract While ribosomes must maintain translational reading frame in order to translate primary genetic information into polypeptides, cis ‐acting signals located mRNAs represent higher content that can be used fine‐tune gene expression. Classes of have been identified direct a fraction elongating shift by one base the 5′ (−1) or 3′ (+1) direction. This is called programmed ribosomal frameshifting (PRF). Although mechanisms PRF differ, common feature induction ribosome pausing, which alters kinetic partitioning rates between in‐frame and out‐of‐frame codons at specific ‘slippery’ sequences. Many viruses use ensure synthesis correct ratios virus‐encoded proteins required for proper viral particle assembly maturation, thus identifying as an attractive target antiviral therapeutics. In contrast, recent studies indicate may primarily function mRNA destabilizing elements cellular mRNAs. These suggest expression through decay pathways. The possible regulation noncoding RNAs also discussed. WIREs RNA 2012 doi: 10.1002/wrna.1126 article categorized under: Structure Dynamics &gt; Influence Biological Systems Evolution Genomics Computational Analyses Translation Regulation

computer animation, translational research, machine translation, computer science, programmed translational frameshifting, human-computer interaction",2012,198,computer animation|translational research|machine translation|computer science|programmed translational frameshifting|human-computer interaction,
https://openalex.org/W2035023916,Not Lost in Translation: Neural Responses Shared Across Languages,"Not Lost in Translation: Neural Responses Shared Across Languages

How similar are the brains of listeners who hear same content expressed in different languages? We directly compared fMRI response time courses English speakers and Russian listened to a real-life narrative its translation. In translation, we tried preserve while reducing structural similarities across languages. The story evoked brain responses, invariant changes languages, beginning just outside early auditory areas extending through temporal, parietal, frontal cerebral cortices. similarity responses languages was nearly equal within each language group. present results demonstrate that human processes information manner is largely insensitive which conveyed. methods introduced here can potentially be used quantify transmission meaning cultural linguistic boundaries.

linguistics, cross-language perspective, natural language processing, machine translation, neural responses, language, language processing in the brain, translation studies",2012,195,linguistics|cross-language perspective|natural language processing|machine translation|neural responses|language|language processing in the brain|translation studies,
https://openalex.org/W1998582365,Transfer learning for Latin and Chinese characters with Deep Neural Networks,"Transfer learning for Latin and Chinese characters with Deep Neural Networks

We analyze transfer learning with Deep Neural Networks (DNN) on various character recognition tasks. DNN trained digits are perfectly capable of recognizing uppercase letters minimal retraining. They par fully letters, but train much faster. Chinese characters easily recognize Latin letters. Learning is accelerated by first pretraining a small subset all classes and then continuing to classes. Furthermore, pretrained nets consistently outperform randomly initialized new tasks few labeled data.

computer science, specialized translation, character recognition, machine learning, chinese characters, language, cross-language retrieval, multilingual pretraining, cognitive science, machine translation, cross-lingual representation, transfer learning, language model, latin, deep learning, machine learning research, language learning, natural language processing, deep neural networks",2012,192,computer science|specialized translation|character recognition|machine learning|chinese characters|language|cross-language retrieval|multilingual pretraining|cognitive science|machine translation|cross-lingual representation|transfer learning|language model|latin|deep learning|machine learning research|language learning|natural language processing|deep neural networks,https://openalex.org/W1978660892|https://openalex.org/W2963088995
https://openalex.org/W1493309689,Re-examining Machine Translation Metrics for Paraphrase Identification,"Re-examining Machine Translation Metrics for Paraphrase Identification

We propose to re-examine the hypothesis that automated metrics developed for MT evaluation can prove useful paraphrase identification in light of significant work on development new over last 4 years. show a meta-classifier trained using nothing but recent outperforms all previous approaches Microsoft Research Paraphrase corpus. In addition, we apply our system second corpus task plagiarism detection and obtain extremely positive results. Finally, conduct extensive error analysis uncover top systematic sources approach relying solely metrics. release both dataset annotations use by community.

computer science, paraphrase, natural language processing, paraphrase identification, machine translation",2012,176,computer science|paraphrase|natural language processing|paraphrase identification|machine translation,
https://openalex.org/W137989762,Machine Translation of Arabic Dialects,"Machine Translation of Arabic Dialects

Arabic Dialects present many challenges for machine translation, not least of which is the lack data resources. We use crowdsourcing to cheaply and quickly build Levantine-English Egyptian-English parallel corpora, consisting 1.1M words 380k words, respectively. The dialectal sentences are selected from a large corpus web text, translated using Amazon's Mechanical Turk. this Dialectal MT systems, find that small amounts have dramatic impact on translation quality. When translating Egyptian Levantine test sets, our system performs 6.3 7.0 BLEU points higher than Modern Standard trained 150M-word Arabic-English corpus.

arabic dialects, linguistics, machine translation, translation studies, computer-assisted translation",2012,162,arabic dialects|linguistics|machine translation|translation studies|computer-assisted translation,
https://openalex.org/W1976732479,Translation as human–computer interaction,"Translation as human–computer interaction

This paper seeks to characterise translation as a form of human–computer interaction. The evolution translator–computer interaction is explored, and the challenges benefits are enunciated. concept cognitive ergonomics drawn on argue for more caring inclusive approach towards translator by developers technology. A case also made wider acceptance community technology at their disposal humanistic research impact translator, profession, process.

computer science, human-computer interaction, machine translation, translation studies, computer-assisted translation",2012,157,computer science|human-computer interaction|machine translation|translation studies|computer-assisted translation,
https://openalex.org/W2000828950,Non-professionals Translating and Interpreting,"Non-professionals Translating and Interpreting

Translation studies finds itself today at a stage where its traditional focus on translator and interpreter training the advancement of status translators interpreters as professionals is no longer sufficient to address complexity real-life situations translating interpreting. As increasing numbers non-professionals translate interpret in wider range contexts more diversified forms, their work emerges not only an alternative established professional practice, but also distinctive phenomenon, which discipline has yet recognize noteworthy area study. This article looks into relatively uncharted territory non-professional translation interpreting, drawing mainly Arjun Appadurai's conceptualization global transactions, offers number insights what these new developments might mean for large.

medium interpretation, specialized translation, language, multimodal translation, interpretation technique, machine translation, translation studies, multilingualism, interpretation",2012,137,medium interpretation|specialized translation|language|multimodal translation|interpretation technique|machine translation|translation studies|multilingualism|interpretation,
https://openalex.org/W2137698233,Perplexity Minimization for Translation Model Domain Adaptation in Statistical Machine Translation,"Perplexity Minimization for Translation Model Domain Adaptation in Statistical Machine Translation

We investigate the problem of domain adaptation for parallel data in Statistical Machine Translation (SMT). While techniques monolingual can be borrowed data, we explore conceptual differences between translation model and language their effect on performance, such as fact that models typically consist several features have different characteristics optimized separately. also adapting multiple (4-10) sets with no a priori distinction in-domain out-of-domain except an development set.

computer science, domain adaptation, machine learning, statistical machine translation, perplexity minimization, machine translation",2012,135,computer science|domain adaptation|machine learning|statistical machine translation|perplexity minimization|machine translation,
https://openalex.org/W1829822087,Semantics-Based Machine Translation with Hyperedge Replacement Grammars,"Semantics-Based Machine Translation with Hyperedge Replacement Grammars

We present an approach to semantics-based statistical machine translation that uses synchronous hyperedge replacement grammars translate into and from graph-shaped intermediate meaning representations, our knowledge the first work in NLP make use of context free graph grammars. algorithms for each step pipeline, including a novel graph-to-word alignment algorithm two grammar rule extraction. investigate influence syntactic annotations on by presenting alternative extraction algorithms, one requires only semantic another additionally relies annotations, explore effect syntax language bias representation structures running experiments with different biased toward English syntax-like structure is neutral. While preliminary work, these show promise semantically-informed translation.

hyperedge replacement grammars, linguistics, natural language processing, semantics, computational linguistics, computational semantics, semantics-based machine translation, machine translation, semantic parsing",2012,131,hyperedge replacement grammars|linguistics|natural language processing|semantics|computational linguistics|computational semantics|semantics-based machine translation|machine translation|semantic parsing,
https://openalex.org/W2126725946,Exploiting Similarities among Languages for Machine Translation,"Exploiting Similarities among Languages for Machine Translation

Dictionaries and phrase tables are the basis of modern statistical machine translation systems. This paper develops a method that can automate process generating extending dictionaries tables. Our translate missing word entries by learning language structures based on large monolingual data mapping between languages from small bilingual data. It uses distributed representation words learns linear vector spaces languages. Despite its simplicity, our is surprisingly effective: we achieve almost 90% precision@5 for English Spanish. makes little assumption about languages, so it be used to extend refine any pairs.

language, machine translation, natural language processing, translation studies",2013,1414,language|machine translation|natural language processing|translation studies,https://openalex.org/W2294774419|https://openalex.org/W1828724394|https://openalex.org/W3035390927|https://openalex.org/W3107826490|https://openalex.org/W3001434439|https://openalex.org/W3101498587
https://openalex.org/W1753482797,Recurrent Continuous Translation Models,"Recurrent Continuous Translation Models

We introduce a class of probabilistic continuous translation models called Recurrent Continuous Translation Models that are purely based on representations for words, phrases and sentences do not rely alignments or phrasal units. The have generation conditioning aspect. the is modelled with target Language Model, whereas source sentence Convolutional Sentence Model. Through various experiments, we show first our obtain perplexity respect to gold translations > 43% lower than stateof-the-art alignment-based models. Secondly, they remarkably sensitive word order, syntax, meaning despite lacking alignments. Finally match state-of-the-art system when rescoring n-best lists translations.

language, machine translation, translation studies",2013,1288,language|machine translation|translation studies,https://openalex.org/W2157331557|https://openalex.org/W2950635152|https://openalex.org/W2964199361|https://openalex.org/W2133564696|https://openalex.org/W2120615054|https://openalex.org/W2172140247|https://openalex.org/W2251682575|https://openalex.org/W2964308564|https://openalex.org/W1902237438|https://openalex.org/W1514535095|https://openalex.org/W2100664567|https://openalex.org/W2118434577|https://openalex.org/W2949335953|https://openalex.org/W2251743902|https://openalex.org/W1915251500|https://openalex.org/W2962784628|https://openalex.org/W2963463964|https://openalex.org/W2963206679|https://openalex.org/W2799020610|https://openalex.org/W3019166713
https://openalex.org/W2118090838,Bilingual Word Embeddings for Phrase-Based Machine Translation,"Bilingual Word Embeddings for Phrase-Based Machine Translation

We introduce bilingual word embeddings: semantic embeddings associated across two languages in the context of neural language models. propose a method to learn from large unlabeled corpus, while utilizing MT alignments constrain translational equivalence. The new significantly out-perform baselines similarity. A single similarity feature induced with adds near half BLEU point results NIST08 Chinese-English machine translation task.

word embeddings, linguistics, natural language processing, machine translation, bilingual word embeddings, phrase-based machine translation",2013,529,word embeddings|linguistics|natural language processing|machine translation|bilingual word embeddings|phrase-based machine translation,https://openalex.org/W2157331557|https://openalex.org/W2950635152|https://openalex.org/W2251682575|https://openalex.org/W2294774419|https://openalex.org/W1828724394
https://openalex.org/W2025478229,Sentiment analysis in twitter using machine learning techniques,"Sentiment analysis in twitter using machine learning techniques

Sentiment analysis deals with identifying and classifying opinions or sentiments expressed in source text. Social media is generating a vast amount of sentiment rich data the form tweets, status updates, blog posts etc. this user generated very useful knowing opinion crowd. Twitter difficult compared to general due presence slang words misspellings. The maximum limit characters that are allowed 140. Knowledge base approach Machine learning two strategies used for analyzing from In paper, we try analyze twitter about electronic products like mobiles, laptops etc using Learning approach. By doing specific domain, it possible identify effect domain information classification. We present new feature vector tweets as positive, negative extract peoples' products.

computer science, opinion aggregation, social medium mining, machine learning, content analysis, communication, semantic evaluation, data science, machine translation, online information, social medium intelligence, multimodal sentiment analysis, text mining, natural language processing, affective computing, social medium monitoring, machine learning techniques, knowledge discovery, social media, sentiment analysis",2013,393,computer science|opinion aggregation|social medium mining|machine learning|content analysis|communication|semantic evaluation|data science|machine translation|online information|social medium intelligence|multimodal sentiment analysis|text mining|natural language processing|affective computing|social medium monitoring|machine learning techniques|knowledge discovery|social media|sentiment analysis,
https://openalex.org/W2889754959,The BIA Model and Bilingual Word Recognition,"The BIA Model and Bilingual Word Recognition

One controversial issue is the way bilingual speakers match an input 
string to a word from one of their two languages. There are competing 
viewpoints about this issue. The language-selective access hypothesis holds 
that bilinguals possess independent lexica that selectively accessed, 
depending on language set information (Gerard & Scarborough, 1989; Kolers, 
1963, 1966; Macnamara Kushnir, 1971; Gerard, Cortese, 
1984; Soares Grosjean, 1984). In contrast, nonselective 
holds integrated lexicon in which lexical representations both languages simultaneously activated during processing (Altenberg Cairns, 1983; Beauvillain Grainger, 
1987; Bijeljac-Babic, Biardeau, 1997; Caramazza Brones, 1979; 
Grainger Beauvillain, 1987; Grainger Dijkstra, 1992).

linguistics, bia model, multilingualism, speech recognition, computational linguistics, speech processing, cross-language retrieval, natural language processing, machine translation, computer science, cross-lingual representation, language, language recognition, bilingual word recognition, language processing in the brain, spoken language technology",2013,332,linguistics|bia model|multilingualism|speech recognition|computational linguistics|speech processing|cross-language retrieval|natural language processing|machine translation|computer science|cross-lingual representation|language|language recognition|bilingual word recognition|language processing in the brain|spoken language technology,
https://openalex.org/W1978660892,Multilingual acoustic models using distributed deep neural networks,"Multilingual acoustic models using distributed deep neural networks

Today's speech recognition technology is mature enough to be useful for many practical applications. In this context, it of paramount importance train accurate acoustic models languages within given resource constraints such as data, processing power, and time. Multilingual training has the potential solve data issue close performance gap between resource-rich resource-scarce languages. Neural networks lend themselves naturally parameter sharing across languages, distributed implementations have made feasible large networks. paper, we present experimental results cross- multi-lingual network eleven Romance on 10k hours in total. The average relative gains over monolingual baselines are 4%/2% (data-scarce/data-rich languages) 7%/2% training. However, additional gain from jointly all comes at an increased time roughly four weeks, compared two weeks (monolingual) one week (crosslingual).

cognitive science, multilingualism, acoustic modeling, language model, multilingual pretraining, data science, natural language processing, machine translation, nlp task, computer science, machine learning, language learning, cross-lingual representation, multilingual acoustic models, spoken language technology, deep learning",2013,291,cognitive science|multilingualism|acoustic modeling|language model|multilingual pretraining|data science|natural language processing|machine translation|nlp task|computer science|machine learning|language learning|cross-lingual representation|multilingual acoustic models|spoken language technology|deep learning,
https://openalex.org/W2251811146,Deep Learning for Chinese Word Segmentation and POS Tagging,"Deep Learning for Chinese Word Segmentation and POS Tagging

This study explores the feasibility of performing Chinese word segmentation (CWS) and POS tagging by deep learning. We try to avoid task-specific feature engineering, use layers neural networks discover relevant features tasks. leverage large-scale unlabeled data improve internal representation characters, these improved representations enhance supervised models. Our achieved close state-of-theart performance with minimal computational cost. also describe a perceptron-style algorithm for training networks, as an alternative maximum-likelihood method, speed up process make learning easier be implemented.

po tagging, text mining, east asian languages, linguistics, knowledge discovery, computational linguistics, contemporary china, natural language processing, machine translation, document classification, text segmentation, machine learning, language engineering, language, chinese word segmentation, text processing, deep learning",2013,270,po tagging|text mining|east asian languages|linguistics|knowledge discovery|computational linguistics|contemporary china|natural language processing|machine translation|document classification|text segmentation|machine learning|language engineering|language|chinese word segmentation|text processing|deep learning,
https://openalex.org/W2270190199,Findings of the 2013 Workshop on Statistical Machine Translation,"Findings of the 2013 Workshop on Statistical Machine Translation

We present the results of WMT13 shared tasks, which included a translation task, task for run-time estimation machine quality, and an unofficial metrics task. This year, 143 systems were submitted to ten tasks from 23 institutions. An additional 6 anonymized included, then evaluated both automatically manually, in our largest manual evaluation date. The quality had four subtasks, with total 14 teams, submitting 55 entries.

computer science, statistical machine translation, natural language processing, machine translation",2013,263,computer science|statistical machine translation|natural language processing|machine translation,https://openalex.org/W2257408573|https://openalex.org/W2512924740|https://openalex.org/W2903193068
https://openalex.org/W2250489405,Joint Language and Translation Modeling with Recurrent Neural Networks,"Joint Language and Translation Modeling with Recurrent Neural Networks

We present a joint language and translation model based on recurrent neural network which predicts target words an unbounded history of both source words. The weaker independence assumptions this result in vastly larger search space compared to related feedforward-based or models. tackle issue with new lattice rescoring algorithm demonstrate its effectiveness empirically. Our builds well known (Mikolov, 2012) augmented by layer additional inputs from the language. show competitive accuracy traditional channel features. best results improve output system trained WMT 2012 French-English data up 1.5 BLEU, 1.1 BLEU average across several test sets.

linguistics, language model, computational linguistics, natural language processing, machine translation, recurrent neural network, computer science, machine learning, language, neural machine translation, translation modeling, computational intelligence, joint language, deep learning",2013,247,linguistics|language model|computational linguistics|natural language processing|machine translation|recurrent neural network|computer science|machine learning|language|neural machine translation|translation modeling|computational intelligence|joint language|deep learning,https://openalex.org/W2157331557|https://openalex.org/W2950635152|https://openalex.org/W2251682575|https://openalex.org/W1985258458
https://openalex.org/W932413789,Decoding with Large-Scale Neural Language Models Improves Translation,"Decoding with Large-Scale Neural Language Models Improves Translation

We explore the application of neural language models to machine translation. develop a new model that combines probabilistic Bengio et al., rectified linear units, and noise-contrastive estimation, we incorporate it into translation system both by reranking k-best lists direct integration decoder. Our large-scale, large-vocabulary experiments across four pairs show our improves quality up 1.1 Bleu.

language model, natural language processing, machine translation, language, neural machine translation, large language model",2013,219,language model|natural language processing|machine translation|language|neural machine translation|large language model,https://openalex.org/W2157331557|https://openalex.org/W2950635152|https://openalex.org/W2251682575|https://openalex.org/W2963088995
https://openalex.org/W1996372440,Translation Changes Everything: Theory and Practice,"Translation Changes Everything: Theory and Practice

Click to increase image sizeClick decrease size Wei LiuSchool of Foreign Languages, Beihang University, Beijing, ChinaEmail: liuweipipi@yahoo.cn© 2013, Liu

speech translation, abstract interpretation, specialized translation, natural language processing, machine translation, computer-assisted translation, multimodal translation, translation changes everything, linguistics, language, translation studies",2013,174,speech translation|abstract interpretation|specialized translation|natural language processing|machine translation|computer-assisted translation|multimodal translation|translation changes everything|linguistics|language|translation studies,
https://openalex.org/W2057636328,Linguistic Computational Model Based on 2-Tuples and Intervals,"Linguistic Computational Model Based on 2-Tuples and Intervals

Herrera and Martínez initiated a 2-tuple fuzzy linguistic representation model for computing with words. Moreover, Wang Hao further developed new to deal the term sets that are not uniformly symmetrically distributed. This study proposes another computational based on 2-tuples intervals, which we call an interval version of model. The proposed possesses three steps: 1) numerical scale; 2) computation numbers; 3) generalized inverse operation scale. first step transforms terms into numbers, second is executed output as number. Finally, this number then mapped by operation. also generalizes scale approach, presented in model, set scale, considering context where semantics defined type-2 (IT2 FSs). In order compare existing IT2 FSs, have conducted extensive simulations. simulations demonstrate results obtained our proposal consistent FSs (in some sense) vast majority cases.

applied linguistics, computer science, linguistics, language model, natural language processing, language, syntax, semantic evaluation, interval computation, computational linguistics, semantics, computational semantics, mathematical linguistics, linguistic computational model, machine translation, linguistic theory, combinatorics on word",2013,165,applied linguistics|computer science|linguistics|language model|natural language processing|language|syntax|semantic evaluation|interval computation|computational linguistics|semantics|computational semantics|mathematical linguistics|linguistic computational model|machine translation|linguistic theory|combinatorics on word,
https://openalex.org/W2252166243,Continuous Measurement Scales in Human Evaluation of Machine Translation,"Continuous Measurement Scales in Human Evaluation of Machine Translation

We explore the use of continuous rating scales for human evaluation in context machine translation evaluation, comparing two assessor-intrinsic qualitycontrol techniques that do not rely on agreement with expert judgments. Experiments employing Amazon’s Mechanical Turk service show quality-control made possible by scale dramatic improvements to intra-annotator up +0.101 kappa coefficient, inter-annotator increasing to+0.144 when additional standardization scores is applied.

human evaluation, measurement, continuous measurement scales, machine translation",2013,155,human evaluation|measurement|continuous measurement scales|machine translation,https://openalex.org/W2512924740|https://openalex.org/W2903193068|https://openalex.org/W3159892921
https://openalex.org/W2123660869,Labeling the Languages of Words in Mixed-Language Documents using Weakly Supervised Methods,"Labeling the Languages of Words in Mixed-Language Documents using Weakly Supervised Methods

In this paper we consider the problem of labeling languages words in mixed-language documents. This is approached a weakly supervised fashion, as sequence with monolingual text samples for training data. Among approaches evaluated, conditional random field model trained generalized expectation criteria was most accurate and performed consistently amount data varied.

linguistics, mixed-language documents, text mining, natural language processing, language, machine learning, computational linguistics, document classification, nlp task, machine translation, document analysis, text normalization",2013,155,linguistics|mixed-language documents|text mining|natural language processing|language|machine learning|computational linguistics|document classification|nlp task|machine translation|document analysis|text normalization,
https://openalex.org/W2006832571,On the features of translationese,"On the features of translationese

Journal Article On the features of translationese Get access Vered Volansky, Volansky Department Computer Science, University Haifa, Israel Search for other works by this author on: Oxford Academic Google Scholar Noam Ordan, Ordan Institut für Angewandte Sprachwissenschaft sowie Übersetzen und Dolmetschen, Universität des Saarlandes, Saarbrücken, Germany Shuly Wintner Digital Scholarship in Humanities, Volume 30, Issue 1, April 2015, Pages 98–118, https://doi.org/10.1093/llc/fqt031 Published: 03 July 2013

linguistics, speech translation, specialized translation, language, general linguistics, translation studies, literature, machine translation, english language, language adaptation",2013,145,linguistics|speech translation|specialized translation|language|general linguistics|translation studies|literature|machine translation|english language|language adaptation,
https://openalex.org/W2251986002,Sentence Level Dialect Identification in Arabic,"Sentence Level Dialect Identification in Arabic

This paper introduces a supervised approach for performing sentence level dialect identification between Modern Standard Arabic and Egyptian Dialectal Arabic. We use token labels to derive sentence-level features. These features are then used with other core meta train generative classifier that predicts the correct label each in given input text. The system achieves an accuracy of 85.5% on online-commentary dataset outperforming previously proposed achieving 80.9% reflecting significant gain over majority baseline 51.9% two strong systems 78.5% 80.4%, respectively.

applied linguistics, computer science, linguistics, speech recognition, natural language processing, speech processing, language, computational linguistics, language recognition, machine translation, spoken language technology",2013,125,applied linguistics|computer science|linguistics|speech recognition|natural language processing|speech processing|language|computational linguistics|language recognition|machine translation|spoken language technology,
https://openalex.org/W2147262247,Adaptation Data Selection using Neural Language Models: Experiments in Machine Translation,"Adaptation Data Selection using Neural Language Models: Experiments in Machine Translation

Data selection is an effective approach to domain adaptation in statistical machine translation. The idea use language models trained on small in-domain text select similar sentences from large general-domain corpora, which are then incorporated into the training data. Substantial gains have been demonstrated previous works, employ standard ngram models. Here, we explore of neural for data selection. We hypothesize that continuous vector representation words makes them more than n-grams modeling unknown word contexts, prevalent text. In a comprehensive evaluation 4 pairs (English German, French, Russian, Spanish), found indeed viable tools selection: while improvements varied (i.e. 0.1 1.7 BLEU), they fast train and can sometimes substantially outperform conventional n-grams.

language adaptation, natural language processing, language, neural language models, adaptation data selection, machine learning, machine translation, adaptation, language learning",2013,121,language adaptation|natural language processing|language|neural language models|adaptation data selection|machine learning|machine translation|adaptation|language learning,
https://openalex.org/W1972141422,Lexical statistical machine translation for language migration,"Lexical statistical machine translation for language migration

Prior research has shown that source code also exhibits naturalness, i.e. it is written by humans and likely to be repetitive. The researchers showed the n-gram language model useful in predicting next token a file given large corpus of existing code. In this paper, we investigate how well statistical machine translation (SMT) models for natural languages could help migrating from one programming another. We treat as sequence lexical tokens apply phrase-based SMT on lexemes those tokens. Our empirical evaluation two Java projects into C# lexical, achieve high accuracy (BLEU 81.3-82.6%). Users would have manually edit only 11.9-15.8% total number resulting correct it. However, percentage methods (49.5-58.6%) syntactically incorrect. Therefore, our result calls more program-oriented capable better integrating syntactic semantic information program support migration.

linguistics, neural machine translation, machine translation, translation studies, language migration",2013,114,linguistics|neural machine translation|machine translation|translation studies|language migration,
https://openalex.org/W2250539671,Glove: Global Vectors for Word Representation,"Glove: Global Vectors for Word Representation

Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using arithmetic, but the origin these has remained opaque. We analyze make explicit model properties needed such to emerge word vectors. The result is a new global logbilinear regression that combines advantages two major families literature: matrix factorization local context window methods. Our efficiently leverages statistical information by training only on nonzero elements word-word cooccurrence matrix, rather than entire sparse or individual windows large corpus. produces with meaningful substructure, as evidenced its performance 75% recent analogy task. It also outperforms related models similarity tasks named entity recognition.

word embeddings, language resource, computer science, linguistics, computational linguistics, semantic representation, information fusion, language, semantic evaluation, vector space model, word representation, image representation, machine translation, language model, global vectors, deep learning, distributional semantics, text mining, natural language processing, large language model",2014,29891,word embeddings|language resource|computer science|linguistics|computational linguistics|semantic representation|information fusion|language|semantic evaluation|vector space model|word representation|image representation|machine translation|language model|global vectors|deep learning|distributional semantics|text mining|natural language processing|large language model,https://openalex.org/W1828724394|https://openalex.org/W2896457183|https://openalex.org/W3035390927|https://openalex.org/W3105966348|https://openalex.org/W2986154550|https://openalex.org/W3111372685|https://openalex.org/W2994928925|https://openalex.org/W3019166713|https://openalex.org/W3121972911
https://openalex.org/W2157331557,Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation,"Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation

Kyunghyun Cho, Bart van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2014.

knowledge discovery, word embeddings, computer science, recurrent neural network, language model, machine learning research, deep learning, sequence modelling, natural language processing, machine translation, rnn encoder-decoder, language learning, machine learning, linguistics, data science, computational linguistics, statistical machine translation, neural machine translation, convolutional neural network, phrase representations",2014,16242,knowledge discovery|word embeddings|computer science|recurrent neural network|language model|machine learning research|deep learning|sequence modelling|natural language processing|machine translation|rnn encoder-decoder|language learning|machine learning|linguistics|data science|computational linguistics|statistical machine translation|neural machine translation|convolutional neural network|phrase representations,https://openalex.org/W2964199361|https://openalex.org/W2964308564|https://openalex.org/W1902237438|https://openalex.org/W1514535095|https://openalex.org/W2100664567|https://openalex.org/W2118434577|https://openalex.org/W2962784628|https://openalex.org/W2963216553|https://openalex.org/W2963463964|https://openalex.org/W2889326796|https://openalex.org/W3019166713|https://openalex.org/W3119872582|https://openalex.org/W3173360659
https://openalex.org/W1832693441,Convolutional Neural Networks for Sentence Classification,"Convolutional Neural Networks for Sentence Classification

We report on a series of experiments with convolutional neural networks (CNN) trained top pre-trained word vectors for sentence-level classification tasks.We show that simple CNN little hyperparameter tuning and static achieves excellent results multiple benchmarks.Learning task-specific through fine-tuning offers further gains in performance.We additionally propose modification to the architecture allow use both vectors.The models discussed herein improve upon state art 4 out 7 tasks, which include sentiment analysis question classification.

knowledge discovery, nlp task, neural network (machine learning), sequential learning, computer science, machine learning research, deep learning, neuroscience, natural language processing, machine translation, semantic interpretation, text processing, sentence classification, machine learning, neural computation, cognitive science, computational intelligence, semantic evaluation, convolutional neural network",2014,11322,knowledge discovery|nlp task|neural network (machine learning)|sequential learning|computer science|machine learning research|deep learning|neuroscience|natural language processing|machine translation|semantic interpretation|text processing|sentence classification|machine learning|neural computation|cognitive science|computational intelligence|semantic evaluation|convolutional neural network,https://openalex.org/W2170738476|https://openalex.org/W2963223306|https://openalex.org/W2307381258|https://openalex.org/W2891177506|https://openalex.org/W3038033387|https://openalex.org/W3019166713
https://openalex.org/W4297734170,Neural Machine Translation by Jointly Learning to Align and Translate,"Neural Machine Translation by Jointly Learning to Align and Translate

Neural machine translation is a recently proposed approach to translation. Unlike the traditional statistical translation, neural aims at building single network that can be jointly tuned maximize performance. The models for often belong family of encoder-decoders and consists an encoder encodes source sentence into fixed-length vector from which decoder generates In this paper, we conjecture use bottleneck in improving performance basic encoder-decoder architecture, propose extend by allowing model automatically (soft-)search parts are relevant predicting target word, without having form these as hard segment explicitly. With new approach, achieve comparable existing state-of-the-art phrase-based system on task English-to-French Furthermore, qualitative analysis reveals (soft-)alignments found agree well with our intuition.

transfer learning, neural computation, natural language processing, machine translation, computer-assisted translation, neural network (machine learning), computational intelligence, computer science, neural machine translation, machine learning, linguistics, language, deep learning, machine learning research",2014,9323,transfer learning|neural computation|natural language processing|machine translation|computer-assisted translation|neural network (machine learning)|computational intelligence|computer science|neural machine translation|machine learning|linguistics|language|deep learning|machine learning research,https://openalex.org/W2100664567|https://openalex.org/W2118434577|https://openalex.org/W2251743902|https://openalex.org/W2962784628|https://openalex.org/W2963216553|https://openalex.org/W2963223306|https://openalex.org/W2307381258|https://openalex.org/W2963260202|https://openalex.org/W1573040851|https://openalex.org/W2963463964|https://openalex.org/W2963250244|https://openalex.org/W2889326796|https://openalex.org/W2963979492|https://openalex.org/W2963807318|https://openalex.org/W2903193068|https://openalex.org/W2799020610|https://openalex.org/W3019166713|https://openalex.org/W3008653537|https://openalex.org/W3173360659
https://openalex.org/W2123442489,The Stanford CoreNLP Natural Language Processing Toolkit,"The Stanford CoreNLP Natural Language Processing Toolkit

Christopher Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven Bethard, David McClosky. Proceedings of 52nd Annual Meeting the Association for Computational Linguistics: System Demonstrations. 2014.

computer science, linguistics, knowledge representation and reasoning, keyword extraction, language model, natural language processing, natural language generation, natural language interface, syntactic parsing, computational linguistics, data science, knowledge discovery, deep learning, nlp task, machine learning research, machine translation, semantic parsing, spoken language technology",2014,6760,computer science|linguistics|knowledge representation and reasoning|keyword extraction|language model|natural language processing|natural language generation|natural language interface|syntactic parsing|computational linguistics|data science|knowledge discovery|deep learning|nlp task|machine learning research|machine translation|semantic parsing|spoken language technology,https://openalex.org/W3037109418
https://openalex.org/W2950635152,Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation,"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation

In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent networks (RNN). One encodes sequence symbols into fixed-length vector representation, and the other decodes representation another symbols. The encoder decoder proposed are jointly trained to maximize conditional probability target given source sequence. performance statistical machine translation system is empirically found improve by using probabilities phrase pairs computed as an additional feature in existing log-linear model. Qualitatively, show learns semantically syntactically meaningful linguistic phrases.

computer science, knowledge discovery, word embeddings, convolutional neural network, phrase representations, statistical machine translation, computational linguistics, data science, deep learning, language model, linguistics, machine learning, machine learning research, natural language processing, machine translation, rnn encoder-decoder, sequence modelling, neural machine translation, recurrent neural network, language learning",2014,6555,computer science|knowledge discovery|word embeddings|convolutional neural network|phrase representations|statistical machine translation|computational linguistics|data science|deep learning|language model|linguistics|machine learning|machine learning research|natural language processing|machine translation|rnn encoder-decoder|sequence modelling|neural machine translation|recurrent neural network|language learning,https://openalex.org/W2964199361|https://openalex.org/W2133564696|https://openalex.org/W1902237438|https://openalex.org/W2950178297|https://openalex.org/W2100664567|https://openalex.org/W2118434577|https://openalex.org/W1915251500|https://openalex.org/W2962784628|https://openalex.org/W2963216553|https://openalex.org/W2963260202|https://openalex.org/W2546938941|https://openalex.org/W2963463964|https://openalex.org/W2889326796|https://openalex.org/W2963206679
https://openalex.org/W2964199361,On the Properties of Neural Machine Translation: Encoder–Decoder Approaches,"On the Properties of Neural Machine Translation: Encoder–Decoder Approaches

Neural machine translation is a relatively new approach to statistical based purely on neural networks.The models often consist of an encoder and decoder.The extracts fixed-length representation from variable-length input sentence, the decoder generates correct this representation.In paper, we focus analyzing properties using two models; RNN Encoder-Decoder newly proposed gated recursive convolutional network.We show that performs well short sentences without unknown words, but its performance degrades rapidly as length sentence number words increase.Furthermore, find network learns grammatical structure automatically.

language learning, neural computation, natural language processing, machine translation, iterative decoding, autoencoders, computational intelligence, computer science, large language model, language model, machine learning, neural machine translation, linguistics, language, deep learning, recurrent neural network, machine learning research",2014,5017,language learning|neural computation|natural language processing|machine translation|iterative decoding|autoencoders|computational intelligence|computer science|large language model|language model|machine learning|neural machine translation|linguistics|language|deep learning|recurrent neural network|machine learning research,https://openalex.org/W2964308564|https://openalex.org/W2100664567|https://openalex.org/W2964241990|https://openalex.org/W2251743902|https://openalex.org/W2963260202|https://openalex.org/W2799020610|https://openalex.org/W3019166713
https://openalex.org/W2133564696,Neural Machine Translation by Jointly Learning to Align and Translate,"Neural Machine Translation by Jointly Learning to Align and Translate

Neural machine translation is a recently proposed approach to translation. Unlike the traditional statistical translation, neural aims at building single network that can be jointly tuned maximize performance. The models for often belong family of encoder-decoders and consists an encoder encodes source sentence into fixed-length vector from which decoder generates In this paper, we conjecture use bottleneck in improving performance basic encoder-decoder architecture, propose extend by allowing model automatically (soft-)search parts are relevant predicting target word, without having form these as hard segment explicitly. With new approach, achieve comparable existing state-of-the-art phrase-based system on task English-to-French Furthermore, qualitative analysis reveals (soft-)alignments found agree well with our intuition.

linguistics, computer science, machine learning, computational intelligence, transfer learning, computer-assisted translation, machine translation, language, machine learning research, natural language processing, neural machine translation, deep learning, neural network (machine learning), neural computation",2014,4033,linguistics|computer science|machine learning|computational intelligence|transfer learning|computer-assisted translation|machine translation|language|machine learning research|natural language processing|neural machine translation|deep learning|neural network (machine learning)|neural computation,https://openalex.org/W1902237438|https://openalex.org/W2950178297|https://openalex.org/W2512924740|https://openalex.org/W2963206679|https://openalex.org/W3082760180
https://openalex.org/W2283196293,Knowledge Graph Embedding by Translating on Hyperplanes,"Knowledge Graph Embedding by Translating on Hyperplanes

We deal with embedding a large scale knowledge graph composed of entities and relations into continuous vector space. TransE is promising method proposed recently, which very efficient while achieving state-of-the-art predictive performance. discuss some mapping properties should be considered in embedding, such as reflexive, one-to-many, many-to-one, many-to-many. note that does not do well dealing these properties. Some complex models are capable preserving but sacrifice efficiency the process. To make good trade-off between model capacity efficiency, this paper we propose TransH relation hyperplane together translation operation on it. In way, can preserve above almost same complexity TransE. Additionally, practical often far from completed, how to construct negative examples reduce false labels training important. Utilizing one-to-many/many-to-one property relation, simple trick possibility labeling. conduct extensive experiments link prediction, triplet classification fact extraction benchmark datasets like WordNet Freebase. Experiments show delivers significant improvements over accuracy comparable capability up.

knowledge graph, graph theory, language, knowledge graph embeddings, machine translation, translation studies",2014,2955,knowledge graph|graph theory|language|knowledge graph embeddings|machine translation|translation studies,https://openalex.org/W2890187992
https://openalex.org/W2120615054,A Convolutional Neural Network for Modelling Sentences,"A Convolutional Neural Network for Modelling Sentences

The ability to accurately represent sentences is central language understanding. We describe a convolutional architecture dubbed the Dynamic Convolutional Neural Network (DCNN) that we adopt for semantic modelling of sentences. network uses k-Max Pooling, global pooling operation over linear sequences. handles input varying length and induces feature graph sentence capable explicitly capturing short long-range relations. does not rely on parse tree easily applicable any language. test DCNN in four experiments: small scale binary multi-class sentiment prediction, six-way question classification Twitter prediction by distant supervision. achieves excellent performance first three tasks greater than 25% error reduction last task with respect strongest baseline.

linguistics, computer science, machine learning, computational intelligence, natural language generation, large language model, machine translation, neural network (machine learning), machine learning research, semantic evaluation, natural language processing, neural machine translation, convolutional neural network, nlp task, deep learning, sequence modelling, cognitive science, language model",2014,2918,linguistics|computer science|machine learning|computational intelligence|natural language generation|large language model|machine translation|neural network (machine learning)|machine learning research|semantic evaluation|natural language processing|neural machine translation|convolutional neural network|nlp task|deep learning|sequence modelling|cognitive science|language model,https://openalex.org/W1832693441|https://openalex.org/W1544827683|https://openalex.org/W2170738476|https://openalex.org/W3019166713
https://openalex.org/W2949541494,Convolutional Neural Networks for Sentence Classification,"Convolutional Neural Networks for Sentence Classification

We report on a series of experiments with convolutional neural networks (CNN) trained top pre-trained word vectors for sentence-level classification tasks. show that simple CNN little hyperparameter tuning and static achieves excellent results multiple benchmarks. Learning task-specific through fine-tuning offers further gains in performance. additionally propose modification to the architecture allow use both vectors. The models discussed herein improve upon state art 4 out 7 tasks, which include sentiment analysis question classification.

computer science, knowledge discovery, nlp task, semantic evaluation, convolutional neural network, cognitive science, neural computation, sequential learning, neuroscience, sentence classification, text processing, deep learning, neural network (machine learning), semantic interpretation, machine learning, machine learning research, natural language processing, computational intelligence, machine translation",2014,1702,computer science|knowledge discovery|nlp task|semantic evaluation|convolutional neural network|cognitive science|neural computation|sequential learning|neuroscience|sentence classification|text processing|deep learning|neural network (machine learning)|semantic interpretation|machine learning|machine learning research|natural language processing|computational intelligence|machine translation,
https://openalex.org/W2172140247,On the Properties of Neural Machine Translation: Encoder-Decoder Approaches,"On the Properties of Neural Machine Translation: Encoder-Decoder Approaches

Neural machine translation is a relatively new approach to statistical based purely on neural networks. The models often consist of an encoder and decoder. extracts fixed-length representation from variable-length input sentence, the decoder generates correct this representation. In paper, we focus analyzing properties using two models; RNN Encoder--Decoder newly proposed gated recursive convolutional network. We show that performs well short sentences without unknown words, but its performance degrades rapidly as length sentence number words increase. Furthermore, find network learns grammatical structure automatically.

linguistics, computer science, machine learning, computational intelligence, language learning, large language model, machine translation, language, machine learning research, natural language processing, iterative decoding, neural machine translation, recurrent neural network, deep learning, autoencoders, language model, neural computation",2014,1269,linguistics|computer science|machine learning|computational intelligence|language learning|large language model|machine translation|language|machine learning research|natural language processing|iterative decoding|neural machine translation|recurrent neural network|deep learning|autoencoders|language model|neural computation,https://openalex.org/W2133564696|https://openalex.org/W2251743902|https://openalex.org/W2963260202
https://openalex.org/W4303070704,A Convolutional Neural Network for Modelling Sentences,"A Convolutional Neural Network for Modelling Sentences

The ability to accurately represent sentences is central language understanding. We describe a convolutional architecture dubbed the Dynamic Convolutional Neural Network (DCNN) that we adopt for semantic modelling of sentences. network uses k-Max Pooling, global pooling operation over linear sequences. handles input varying length and induces feature graph sentence capable explicitly capturing short long-range relations. does not rely on parse tree easily applicable any language. test DCNN in four experiments: small scale binary multi-class sentiment prediction, six-way question classification Twitter prediction by distant supervision. achieves excellent performance first three tasks greater than 25% error reduction last task with respect strongest baseline.

nlp task, natural language processing, machine translation, neural network (machine learning), natural language generation, cognitive science, computational intelligence, computer science, semantic evaluation, language model, machine learning, convolutional neural network, linguistics, large language model, deep learning, neural machine translation, sequence modelling, machine learning research",2014,688,nlp task|natural language processing|machine translation|neural network (machine learning)|natural language generation|cognitive science|computational intelligence|computer science|semantic evaluation|language model|machine learning|convolutional neural network|linguistics|large language model|deep learning|neural machine translation|sequence modelling|machine learning research,https://openalex.org/W1832693441
https://openalex.org/W2889092434,"Enlarging Translation, Empowering Translators","Enlarging Translation, Empowering Translators

Beginning with the paradox that characterizes history of translation studies in last half century - more and parameters have been defined, but less closure achieved first Enlarging Translation, Empowering Translators calls for radical inclusionary approaches to translation, including a greater internationalization field. The book investigates implications expanding open definition chapter on research methods charting future studies. In second book, these enlarged views are linked empowerment agency translator. Revamped ideological frameworks new paradigms culture, ways incorporating contemporary meaning into follow from expanded conceptualization they serve as platform empowering translators promoting activist practices.
 
Addressed theorists, teachers, practising alike, this latest contribution one leading theorists field sets directions

translation studies, computer-assisted translation, machine translation",2014,565,translation studies|computer-assisted translation|machine translation,
https://openalex.org/W2053317383,Word Spotting and Recognition with Embedded Attributes,"Word Spotting and Recognition with Embedded Attributes

This paper addresses the problems of word spotting and recognition on images. In spotting, goal is to find all instances a query in dataset recognition, recognize content image, usually aided by dictionary or lexicon. We describe an approach which both images text strings are embedded common vectorial subspace. achieved combination label embedding attributes learning, subspace regression. this subspace, that represent same close together, allowing one cast retrieval tasks as nearest neighbor problem. Contrary most other existing methods, our representation has fixed length, low dimensional, very fast compute and, especially, compare. test four public datasets handwritten documents natural showing results comparable better than state-of-the-art tasks.

image analysis, pattern recognition, computer science, linguistics, machine vision, word embeddings, natural language processing, character recognition, text recognition, machine learning, feature detection, cognitive science, language recognition, image representation, embedded attributes, word spotting, machine translation, information retrieval",2014,516,image analysis|pattern recognition|computer science|linguistics|machine vision|word embeddings|natural language processing|character recognition|text recognition|machine learning|feature detection|cognitive science|language recognition|image representation|embedded attributes|word spotting|machine translation|information retrieval,
https://openalex.org/W2251682575,Fast and Robust Neural Network Joint Models for Statistical Machine Translation,"Fast and Robust Neural Network Joint Models for Statistical Machine Translation

Jacob Devlin, Rabih Zbib, Zhongqiang Huang, Thomas Lamar, Richard Schwartz, John Makhoul. Proceedings of the 52nd Annual Meeting Association for Computational Linguistics (Volume 1: Long Papers). 2014.

computer science, artificial intelligence, language model, natural language processing, neural machine translation, statistical machine translation, computational linguistics, data science, computational intelligence, machine translation, language learning, statistical model, computer-assisted translation",2014,483,computer science|artificial intelligence|language model|natural language processing|neural machine translation|statistical machine translation|computational linguistics|data science|computational intelligence|machine translation|language learning|statistical model|computer-assisted translation,https://openalex.org/W2157331557|https://openalex.org/W2950635152|https://openalex.org/W2133564696|https://openalex.org/W2964308564|https://openalex.org/W2251743902|https://openalex.org/W1915251500
https://openalex.org/W2257408573,Findings of the 2014 Workshop on Statistical Machine Translation,"Findings of the 2014 Workshop on Statistical Machine Translation

Ondřej Bojar, Christian Buck, Federmann, Barry Haddow, Philipp Koehn, Johannes Leveling, Christof Monz, Pavel Pecina, Matt Post, Herve Saint-Amand, Radu Soricut, Lucia Specia, Aleš Tamchyna. Proceedings of the Ninth Workshop on Statistical Machine Translation. 2014.

computer science, statistical machine translation, natural language processing, machine translation",2014,417,computer science|statistical machine translation|natural language processing|machine translation,https://openalex.org/W2251994258|https://openalex.org/W2512924740|https://openalex.org/W2903193068
https://openalex.org/W2605754799,Translation in Systems: Descriptive and System-oriented Approaches Explained,"Translation in Systems: Descriptive and System-oriented Approaches Explained

The notion of systems has helped revolutionize translation studies since the 1970s. As a key part many descriptive approaches, it broken with prescriptive focus on what should be, encouraging researchers to ask does in specific cultural settings. From his privileged position as direct participant these developments, Theo Hermans explains how contemporary approaches came about, basic ideas were, and those have evolved over time. His discussion addresses fundamental problems norms, equivalence, polysystems social systems, covering not only work Levý, Holmes, Even-Zohar, Toury, Lefevere, Lambert, Van Leuven-Zwart, Dhulst others, but also giving special attention recent contributions derived from Pierre Bourdieu Niklas Luhmann. An added practical questions investigate (problems definition, description, assessment readerships, etc.) makes this book essential reading for graduate students indeed any field. Hermans' account is both informed critical. At same time, he demonstrates strength concepts, which shown considerable vitality their evolution adaptation debates present day.

system of system, systems biology, system science, system specification, machine translation, system synthesis, systems modeling, translation studies, systems engineering",2014,339,system of system|systems biology|system science|system specification|machine translation|system synthesis|systems modeling|translation studies|systems engineering,
https://openalex.org/W2964308564,Neural Machine Translation by Jointly Learning to Align and Translate,"Neural Machine Translation by Jointly Learning to Align and Translate

Abstract: Neural machine translation is a recently proposed approach to translation. Unlike the traditional statistical translation, neural aims at building single network that can be jointly tuned maximize performance. The models for often belong family of encoder-decoders and consists an encoder encodes source sentence into fixed-length vector from which decoder generates In this paper, we conjecture use bottleneck in improving performance basic encoder-decoder architecture, propose extend by allowing model automatically (soft-)search parts are relevant predicting target word, without having form these as hard segment explicitly. With new approach, achieve comparable existing state-of-the-art phrase-based system on task English-to-French Furthermore, qualitative analysis reveals (soft-)alignments found agree well with our intuition.

computer science, linguistics, transfer learning, natural language processing, language, neural machine translation, machine learning, neural computation, computational intelligence, deep learning, machine learning research, machine translation, neural network (machine learning), computer-assisted translation",2015,15258,computer science|linguistics|transfer learning|natural language processing|language|neural machine translation|machine learning|neural computation|computational intelligence|deep learning|machine learning research|machine translation|neural network (machine learning)|computer-assisted translation,https://openalex.org/W1902237438|https://openalex.org/W1514535095|https://openalex.org/W1544827683|https://openalex.org/W2100664567|https://openalex.org/W2949615363|https://openalex.org/W2118434577|https://openalex.org/W2949335953|https://openalex.org/W2251743902|https://openalex.org/W1915251500|https://openalex.org/W2962784628|https://openalex.org/W2963216553|https://openalex.org/W2963223306|https://openalex.org/W2307381258|https://openalex.org/W2963088995|https://openalex.org/W2963260202|https://openalex.org/W2546938941|https://openalex.org/W1573040851|https://openalex.org/W2512924740|https://openalex.org/W2963463964|https://openalex.org/W2540404261|https://openalex.org/W2963250244|https://openalex.org/W2889326796|https://openalex.org/W2963979492|https://openalex.org/W2963807318|https://openalex.org/W2903193068|https://openalex.org/W2963206679|https://openalex.org/W2799020610|https://openalex.org/W3093871477|https://openalex.org/W2994928925|https://openalex.org/W3019166713|https://openalex.org/W3008653537|https://openalex.org/W3173360659|https://openalex.org/W3121972911
https://openalex.org/W1902237438,Effective Approaches to Attention-based Neural Machine Translation,"Effective Approaches to Attention-based Neural Machine Translation

An attentional mechanism has lately been used to improve neural machine translation (NMT) by selectively focusing on parts of the source sentence during translation.However, there little work exploring useful architectures for attention-based NMT.This paper examines two simple and effective classes mechanism: a global approach which always attends all words local one that only looks at subset time.We demonstrate effectiveness both approaches WMT tasks between English German in directions.With attention, we achieve significant gain 5.0 BLEU points over non-attentional systems already incorporate known techniques such as dropout.Our ensemble model using different attention yields new state-of-the-art result WMT'15 task with 25.9 points, an improvement 1.0 existing best system backed NMT n-gram reranker. 1

language learning, neural computation, natural language processing, machine translation, attention, cognitive science, computational intelligence, computer science, neural machine translation",2015,7464,language learning|neural computation|natural language processing|machine translation|attention|cognitive science|computational intelligence|computer science|neural machine translation,https://openalex.org/W2962784628|https://openalex.org/W2963216553|https://openalex.org/W2963088995|https://openalex.org/W2963260202|https://openalex.org/W2963463964|https://openalex.org/W2963250244|https://openalex.org/W2889326796|https://openalex.org/W2963979492|https://openalex.org/W2799020610|https://openalex.org/W3121972911
https://openalex.org/W1514535095,"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention","Show, Attend and Tell: Neural Image Caption Generation with Visual Attention

Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We how can train this a deterministic manner using standard backpropagation techniques stochastically maximizing variational lower bound. also show through visualization is able learn fix its gaze on salient objects while generating corresponding words output sequence. validate use with state-of-the-art performance three benchmark datasets: Flickr9k, Flickr30k MS COCO.

vision language model, computer science, machine learning research, deep learning, language generation, information fusion, natural language processing, machine translation, natural language generation, scene understanding, scene interpretation, visual perception, data science, computer vision, retrieval augmented generation, cognitive science, visual attention, image communication, image analysis",2015,5247,vision language model|computer science|machine learning research|deep learning|language generation|information fusion|natural language processing|machine translation|natural language generation|scene understanding|scene interpretation|visual perception|data science|computer vision|retrieval augmented generation|cognitive science|visual attention|image communication|image analysis,https://openalex.org/W1902237438|https://openalex.org/W2949335953|https://openalex.org/W2425121537|https://openalex.org/W1573040851|https://openalex.org/W2799020610|https://openalex.org/W3008653537|https://openalex.org/W3121972911
https://openalex.org/W2950178297,"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention","Show, Attend and Tell: Neural Image Caption Generation with Visual Attention

Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We how can train this a deterministic manner using standard backpropagation techniques stochastically maximizing variational lower bound. also show through visualization is able learn fix its gaze on salient objects while generating corresponding words output sequence. validate use with state-of-the-art performance three benchmark datasets: Flickr8k, Flickr30k MS COCO.

image communication, computer science, information fusion, scene interpretation, cognitive science, visual perception, vision language model, data science, deep learning, computer vision, language generation, machine learning research, scene understanding, natural language processing, retrieval augmented generation, image analysis, visual attention, natural language generation, machine translation",2015,4667,image communication|computer science|information fusion|scene interpretation|cognitive science|visual perception|vision language model|data science|deep learning|computer vision|language generation|machine learning research|scene understanding|natural language processing|retrieval augmented generation|image analysis|visual attention|natural language generation|machine translation,https://openalex.org/W1902237438|https://openalex.org/W2425121537|https://openalex.org/W2963260202|https://openalex.org/W1573040851|https://openalex.org/W2799020610|https://openalex.org/W3008653537|https://openalex.org/W3121972911
https://openalex.org/W1544827683,Teaching Machines to Read and Comprehend,"Teaching Machines to Read and Comprehend

Teaching machines to read natural language documents remains an elusive challenge. Machine reading systems can be tested on their ability answer questions posed the contents of that they have seen, but until now large scale training and test datasets been missing for this type evaluation. In work we define a new methodology resolves bottleneck provides supervised comprehension data. This allows us develop class attention based deep neural networks learn real complex with minimal prior knowledge structure.

language comprehension, language acquisition, computer science, machine learning, machine-readable representation, machine translation, artificial intelligence, language, vision language model, natural language processing, neural machine translation, reading research, deep learning, machine vision, cognitive science, language learning",2015,2244,language comprehension|language acquisition|computer science|machine learning|machine-readable representation|machine translation|artificial intelligence|language|vision language model|natural language processing|neural machine translation|reading research|deep learning|machine vision|cognitive science|language learning,https://openalex.org/W2307381258|https://openalex.org/W3034999214|https://openalex.org/W3173360659
https://openalex.org/W2170738476,Convolutional Neural Network Architectures for Matching Natural Language Sentences,"Convolutional Neural Network Architectures for Matching Natural Language Sentences

Semantic matching is of central importance to many natural language tasks \cite{bordes2014semantic,RetrievalQA}. A successful algorithm needs adequately model the internal structures objects and interaction between them. As a step toward this goal, we propose convolutional neural network models for two sentences, by adapting strategy in vision speech. The proposed not only nicely represent hierarchical sentences with their layer-by-layer composition pooling, but also capture rich patterns at different levels. Our are rather generic, requiring no prior knowledge on language, can hence be applied nature languages. empirical study variety demonstrates efficacy its superiority competitor models.

knowledge discovery, neural architecture search, nlp task, natural language processing, machine translation, natural language sentences, semantic interpretation, natural language generation, computational intelligence, computer science, neural machine translation, language model, machine learning, large language model, language, deep learning, data science, computational linguistics",2015,1065,knowledge discovery|neural architecture search|nlp task|natural language processing|machine translation|natural language sentences|semantic interpretation|natural language generation|computational intelligence|computer science|neural machine translation|language model|machine learning|large language model|language|deep learning|data science|computational linguistics,https://openalex.org/W3019166713
https://openalex.org/W2100664567,On Using Very Large Target Vocabulary for Neural Machine Translation,"On Using Very Large Target Vocabulary for Neural Machine Translation

Sébastien Jean, Kyunghyun Cho, Roland Memisevic, Yoshua Bengio. Proceedings of the 53rd Annual Meeting Association for Computational Linguistics and 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2015.

natural language processing, language, large target vocabulary, neural machine translation, machine learning, nlp task, machine translation",2015,869,natural language processing|language|large target vocabulary|neural machine translation|machine learning|nlp task|machine translation,https://openalex.org/W1902237438|https://openalex.org/W2118434577|https://openalex.org/W2949335953|https://openalex.org/W1915251500|https://openalex.org/W2962784628|https://openalex.org/W2963216553|https://openalex.org/W2963260202|https://openalex.org/W2546938941|https://openalex.org/W2963463964
https://openalex.org/W2964241990,Translating Videos to Natural Language Using Deep Recurrent Neural Networks,"Translating Videos to Natural Language Using Deep Recurrent Neural Networks

Subhashini Venugopalan, Huijuan Xu, Jeff Donahue, Marcus Rohrbach, Raymond Mooney, Kate Saenko. Proceedings of the 2015 Conference North American Chapter Association for Computational Linguistics: Human Language Technologies. 2015.

computer science, video retrieval, language model, natural language processing, language, image communication, video understanding, computer vision, machine learning, neural machine translation, video adaptation, multimedia information processing, deep learning, machine translation, video summarization",2015,851,computer science|video retrieval|language model|natural language processing|language|image communication|video understanding|computer vision|machine learning|neural machine translation|video adaptation|multimedia information processing|deep learning|machine translation|video summarization,https://openalex.org/W2425121537|https://openalex.org/W1573040851
https://openalex.org/W2949615363,Teaching Machines to Read and Comprehend,"Teaching Machines to Read and Comprehend

Teaching machines to read natural language documents remains an elusive challenge. Machine reading systems can be tested on their ability answer questions posed the contents of that they have seen, but until now large scale training and test datasets been missing for this type evaluation. In work we define a new methodology resolves bottleneck provides supervised comprehension data. This allows us develop class attention based deep neural networks learn real complex with minimal prior knowledge structure.

language learning, language acquisition, machine vision, natural language processing, machine translation, vision language model, cognitive science, language comprehension, computer science, machine-readable representation, neural machine translation, machine learning, language, deep learning, reading research, artificial intelligence",2015,665,language learning|language acquisition|machine vision|natural language processing|machine translation|vision language model|cognitive science|language comprehension|computer science|machine-readable representation|neural machine translation|machine learning|language|deep learning|reading research|artificial intelligence,https://openalex.org/W3173360659
https://openalex.org/W2118434577,Addressing the Rare Word Problem in Neural Machine Translation,"Addressing the Rare Word Problem in Neural Machine Translation

Thang Luong, Ilya Sutskever, Quoc Le, Oriol Vinyals, Wojciech Zaremba. Proceedings of the 53rd Annual Meeting Association for Computational Linguistics and 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2015.

computer science, artificial intelligence, linguistics, language model, natural language processing, language, neural machine translation, computational linguistics, rare word problem, nlp task, machine translation, language learning",2015,639,computer science|artificial intelligence|linguistics|language model|natural language processing|language|neural machine translation|computational linguistics|rare word problem|nlp task|machine translation|language learning,https://openalex.org/W1902237438|https://openalex.org/W2100664567|https://openalex.org/W2949335953|https://openalex.org/W2962784628|https://openalex.org/W2963088995|https://openalex.org/W2963463964|https://openalex.org/W3019166713
https://openalex.org/W2949335953,Effective Approaches to Attention-based Neural Machine Translation,"Effective Approaches to Attention-based Neural Machine Translation

An attentional mechanism has lately been used to improve neural machine translation (NMT) by selectively focusing on parts of the source sentence during translation. However, there little work exploring useful architectures for attention-based NMT. This paper examines two simple and effective classes mechanism: a global approach which always attends all words local one that only looks at subset time. We demonstrate effectiveness both approaches over WMT tasks between English German in directions. With attention, we achieve significant gain 5.0 BLEU points non-attentional systems already incorporate known techniques such as dropout. Our ensemble model using different attention established new state-of-the-art result WMT'15 task with 25.9 points, an improvement 1.0 existing best system backed NMT n-gram reranker.

language learning, neural computation, natural language processing, machine translation, attention, cognitive science, computational intelligence, computer science, neural machine translation",2015,637,language learning|neural computation|natural language processing|machine translation|attention|cognitive science|computational intelligence|computer science|neural machine translation,https://openalex.org/W2963260202
https://openalex.org/W2251743902,Multi-Task Learning for Multiple Language Translation,"Multi-Task Learning for Multiple Language Translation

Daxiang Dong, Hua Wu, Wei He, Dianhai Yu, Haifeng Wang. Proceedings of the 53rd Annual Meeting Association for Computational Linguistics and 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2015.

language, multi-task learning, multiple language translation, machine translation, translation studies",2015,606,language|multi-task learning|multiple language translation|machine translation|translation studies,https://openalex.org/W2525778437|https://openalex.org/W2963088995|https://openalex.org/W3173190788
https://openalex.org/W1915251500,On Using Monolingual Corpora in Neural Machine Translation,"On Using Monolingual Corpora in Neural Machine Translation

Recent work on end-to-end neural network-based architectures for machine translation has shown promising results En-Fr and En-De translation. Arguably, one of the major factors behind this success been availability high quality parallel corpora. In work, we investigate how to leverage abundant monolingual corpora Compared a phrase-based hierarchical baseline, obtain up $1.96$ BLEU improvement low-resource language pair Turkish-English, $1.59$ focused domain task Chinese-English chat messages. While our method was initially targeted toward such tasks with less data, show that it also extends resource languages as Cs-En De-En where an $0.39$ $0.47$ scores over baselines, respectively.

computer science, linguistics, language model, natural language processing, language, language engineering, neural machine translation, computational linguistics, semantic interpretation, machine translation, language learning, computer-assisted translation, monolingual corpora",2015,520,computer science|linguistics|language model|natural language processing|language|language engineering|neural machine translation|computational linguistics|semantic interpretation|machine translation|language learning|computer-assisted translation|monolingual corpora,https://openalex.org/W2963216553|https://openalex.org/W2307381258|https://openalex.org/W2546938941|https://openalex.org/W2963463964|https://openalex.org/W2889326796|https://openalex.org/W2963206679
https://openalex.org/W1985258458,From Feedforward to Recurrent LSTM Neural Networks for Language Modeling,"From Feedforward to Recurrent LSTM Neural Networks for Language Modeling

Language models have traditionally been estimated based on relative frequencies, using count statistics that can be extracted from huge amounts of text data. More recently, it has found neural networks are particularly powerful at estimating probability distributions over word sequences, giving substantial improvements state-of-the-art models. However, the performance network language strongly depends their architectural structure. This paper compares to feedforward, recurrent, and long short-term memory (LSTM) variants two large-vocabulary speech recognition tasks. We evaluate in terms perplexity error rate, experimentally validating strong correlation quantities, which we find hold regardless underlying type model. Furthermore, incur an increased computational complexity compared models, they differently model context dependences, often exceeding number words taken into account by approaches. These differences require efficient search methods for networks, analyze potential obtained when applying advanced algorithms rescoring lattices large-scale setups.

computer science, linguistics, language modeling, machine learning, principal component analysis, lstm neural networks, language, recurrent neural network, computational intelligence, neural network (machine learning), machine translation, language model, deep learning, machine learning research, language learning, large language model, natural language processing, sequential learning, sequence modelling, spoken language technology",2015,446,computer science|linguistics|language modeling|machine learning|principal component analysis|lstm neural networks|language|recurrent neural network|computational intelligence|neural network (machine learning)|machine translation|language model|deep learning|machine learning research|language learning|large language model|natural language processing|sequential learning|sequence modelling|spoken language technology,
https://openalex.org/W2294774419,Normalized Word Embedding and Orthogonal Transform for Bilingual Word Translation,"Normalized Word Embedding and Orthogonal Transform for Bilingual Word Translation

Word embedding has been found to be highly powerful translate words from one language another by a simple linear transform.However, we some inconsistence among the objective functions of and transform learning, as well distance measurement.This paper proposes solution which normalizes word vectors on hypersphere constrains an orthogonal transform.The experimental results confirmed that proposed can offer better performance similarity task English-to-Spanish translation task.

word embeddings, bilingual word translation, linguistics, speech translation, natural language processing, language, vector processing, word embedding, orthogonal transform, computational linguistics, machine translation, translation studies, text normalization",2015,401,word embeddings|bilingual word translation|linguistics|speech translation|natural language processing|language|vector processing|word embedding|orthogonal transform|computational linguistics|machine translation|translation studies|text normalization,
https://openalex.org/W4299816210,Effective Approaches to Attention-based Neural Machine Translation,"Effective Approaches to Attention-based Neural Machine Translation

An attentional mechanism has lately been used to improve neural machine translation (NMT) by selectively focusing on parts of the source sentence during translation. However, there little work exploring useful architectures for attention-based NMT. This paper examines two simple and effective classes mechanism: a global approach which always attends all words local one that only looks at subset time. We demonstrate effectiveness both approaches over WMT tasks between English German in directions. With attention, we achieve significant gain 5.0 BLEU points non-attentional systems already incorporate known techniques such as dropout. Our ensemble model using different attention established new state-of-the-art result WMT'15 task with 25.9 points, an improvement 1.0 existing best system backed NMT n-gram reranker.

computer science, computational intelligence, machine translation, natural language processing, neural machine translation, attention, cognitive science, language learning, neural computation",2015,396,computer science|computational intelligence|machine translation|natural language processing|neural machine translation|attention|cognitive science|language learning|neural computation,
https://openalex.org/W2251994258,Findings of the 2015 Workshop on Statistical Machine Translation,"Findings of the 2015 Workshop on Statistical Machine Translation

Ondřej Bojar, Rajen Chatterjee, Christian Federmann, Barry Haddow, Matthias Huck, Chris Hokamp, Philipp Koehn, Varvara Logacheva, Christof Monz, Matteo Negri, Matt Post, Carolina Scarton, Lucia Specia, Marco Turchi. Proceedings of the Tenth Workshop on Statistical Machine Translation. 2015.

computer science, statistical machine translation, natural language processing, machine translation",2015,386,computer science|statistical machine translation|natural language processing|machine translation,https://openalex.org/W2251994258|https://openalex.org/W2963216553|https://openalex.org/W2963088995|https://openalex.org/W2512924740|https://openalex.org/W2903193068
https://openalex.org/W1828724394,BilBOWA: Fast Bilingual Distributed Representations without Word Alignments,"BilBOWA: Fast Bilingual Distributed Representations without Word Alignments

We introduce BilBOWA (Bilingual Bag-of-Words without Alignments), a simple and computationally-efficient model for learning bilingual distributed representations of words which can scale to large monolingual datasets does not require word-aligned parallel training data. Instead it trains directly on data extracts signal from smaller set raw-text sentence-aligned This is achieved using novel sampled bag-of-words cross-lingual objective, used regularize two noise-contrastive language models efficient feature learning. show that embeddings learned the proposed outperform state-of-the-art methods document classification task as well lexical translation WMT11

text mining, linguistics, multilingualism, language model, word alignments, computational linguistics, cross-language retrieval, multilingual pretraining, semantic similarity, natural language processing, machine translation, computer science, cross-lingual representation, language, nlp task",2015,330,text mining|linguistics|multilingualism|language model|word alignments|computational linguistics|cross-language retrieval|multilingual pretraining|semantic similarity|natural language processing|machine translation|computer science|cross-lingual representation|language|nlp task,https://openalex.org/W3101498587
https://openalex.org/W2962784628,Neural Machine Translation of Rare Words with Subword Units,"Neural Machine Translation of Rare Words with Subword Units

Neural machine translation (NMT) models typically operate with a fixed vocabulary, but is an open-vocabulary problem.Previous work addresses the of out-of-vocabulary words by backing off to dictionary.In this paper, we introduce simpler and more effective approach, making NMT model capable encoding rare unknown as sequences subword units.This based on intuition that various word classes are translatable via smaller units than words, for instance names (via character copying or transliteration), compounds compositional translation), cognates loanwords phonological morphological transformations).We discuss suitability different segmentation techniques, including simple ngram byte pair compression algorithm, empirically show improve over back-off dictionary baseline WMT 15 tasks English→German English→Russian up 1.1 1.3 BLEU, respectively.

linguistics, subword units, neural machine translation, machine learning, computational linguistics, machine translation, rare words",2016,6410,linguistics|subword units|neural machine translation|machine learning|computational linguistics|machine translation|rare words,https://openalex.org/W2963216553|https://openalex.org/W2512924740|https://openalex.org/W2963250244|https://openalex.org/W2889326796|https://openalex.org/W2963979492|https://openalex.org/W2963807318|https://openalex.org/W2903193068|https://openalex.org/W2963206679|https://openalex.org/W2986154550|https://openalex.org/W3093871477|https://openalex.org/W3111372685|https://openalex.org/W2994928925|https://openalex.org/W3082760180|https://openalex.org/W3019166713|https://openalex.org/W3161027892|https://openalex.org/W3173190788
https://openalex.org/W2525778437,Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation,"Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation

Neural Machine Translation (NMT) is an end-to-end learning approach for automated translation, with the potential to overcome many of weaknesses conventional phrase-based translation systems. Unfortunately, NMT systems are known be computationally expensive both in training and inference. Also, most have difficulty rare words. These issues hindered NMT's use practical deployments services, where accuracy speed essential. In this work, we present GNMT, Google's system, which attempts address these issues. Our model consists a deep LSTM network 8 encoder decoder layers using attention residual connections. To improve parallelism therefore decrease time, our mechanism connects bottom layer top encoder. accelerate final speed, employ low-precision arithmetic during inference computations. handling words, divide words into limited set common sub-word units (""wordpieces"") input output. This method provides good balance between flexibility ""character""-delimited models efficiency ""word""-delimited models, naturally handles ultimately improves overall system. beam search technique employs length-normalization procedure uses coverage penalty, encourages generation output sentence that likely cover all source sentence. On WMT'14 English-to-French English-to-German benchmarks, GNMT achieves competitive results state-of-the-art. Using human side-by-side evaluation on isolated simple sentences, it reduces errors by average 60% compared production

computer science, natural language processing, language, neural machine translation, computational linguistics, machine translation, translation studies, neural network (machine learning), language learning, computer-assisted translation",2016,5286,computer science|natural language processing|language|neural machine translation|computational linguistics|machine translation|translation studies|neural network (machine learning)|language learning|computer-assisted translation,https://openalex.org/W2896457183|https://openalex.org/W2963250244|https://openalex.org/W2963979492|https://openalex.org/W2903193068|https://openalex.org/W2963206679|https://openalex.org/W2799020610|https://openalex.org/W2994928925|https://openalex.org/W3019166713|https://openalex.org/W3173360659
https://openalex.org/W2963216553,Improving Neural Machine Translation Models with Monolingual Data,"Improving Neural Machine Translation Models with Monolingual Data

Neural Machine Translation (NMT) has obtained state-of-the art performance for several language pairs, while only using parallel data training.Targetside monolingual plays an important role in boosting fluency phrasebased statistical machine translation, and we investigate the use of NMT.In contrast to previous work, which combines NMT models with separately trained models, note that encoder-decoder architectures already have capacity learn same information as a model, explore strategies train without changing neural network architecture.By pairing training automatic backtranslation, can treat it additional data, obtain substantial improvements on WMT 15 task English↔German (+2.8-3.7 BLEU), low-resourced IWSLT 14 Turkish→English (+2.1-3.4BLEU), obtaining new state-of-the-art results.We also show fine-tuning in-domain gives English→German.

computer science, linguistics, language model, natural language processing, language, neural machine translation, monolingual data, computational linguistics, nlp task, machine translation, translation studies",2016,2291,computer science|linguistics|language model|natural language processing|language|neural machine translation|monolingual data|computational linguistics|nlp task|machine translation|translation studies,https://openalex.org/W2546938941|https://openalex.org/W2963463964|https://openalex.org/W2889326796|https://openalex.org/W2963206679|https://openalex.org/W3107826490|https://openalex.org/W3001434439|https://openalex.org/W2994928925
https://openalex.org/W4300912893,Image-to-Image Translation with Conditional Adversarial Networks,"Image-to-Image Translation with Conditional Adversarial Networks

We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These not only learn the mapping from input image output image, but also loss function train this mapping. This makes it possible apply same generic approach problems that traditionally would require very different formulations. demonstrate is effective at synthesizing photos label maps, reconstructing objects edge and colorizing images, among other tasks. Indeed, since release of pix2pix software associated with paper, large number internet users (many them artists) have posted their own experiments our system, further demonstrating its wide applicability ease adoption without need for parameter tweaking. As community, we no longer hand-engineer functions, work suggests can achieve reasonable results hand-engineering functions either.

digital image processing, conditional adversarial networks, computer science, machine learning research, deep learning, machine translation, adversarial machine learning, image-to-image translation, multimodal translation, image representation, human image synthesis, computational imaging, machine learning, data science, computer vision, neural machine translation, synthetic image generation, image communication, image analysis",2016,2239,digital image processing|conditional adversarial networks|computer science|machine learning research|deep learning|machine translation|adversarial machine learning|image-to-image translation|multimodal translation|image representation|human image synthesis|computational imaging|machine learning|data science|computer vision|neural machine translation|synthetic image generation|image communication|image analysis,
https://openalex.org/W2963223306,Generating Sentences from a Continuous Space,"Generating Sentences from a Continuous Space

The standard recurrent neural network language model (rnnlm) generates sentences one word at a time and does not work from an explicit global sentence representation.In this work, we introduce study rnn-based variational autoencoder generative that incorporates distributed latent representations of entire sentences.This factorization allows it to explicitly holistic properties such as style, topic, high-level syntactic features.Samples the prior over these remarkably produce diverse well-formed through simple deterministic decoding.By examining paths space, are able generate coherent novel interpolate between known sentences.We present techniques for solving difficult learning problem presented by model, demonstrate its effectiveness in imputing missing words, explore many interesting model's negative results on use modeling.but now , they parked out front owen stepped car he could see True: transition was complete .RNNLM: "" i said .VAE: driver 's door .you kill him his men .

continuous delivery, computer science, linguistics, continuous space, language model, natural language processing, natural language generation, language engineering, syntax, generative linguistics, machine learning, computational linguistics, nlp task, machine translation, language generation",2016,1662,continuous delivery|computer science|linguistics|continuous space|language model|natural language processing|natural language generation|language engineering|syntax|generative linguistics|machine learning|computational linguistics|nlp task|machine translation|language generation,
https://openalex.org/W2425121537,MSR-VTT: A Large Video Description Dataset for Bridging Video and Language,"MSR-VTT: A Large Video Description Dataset for Bridging Video and Language

While there has been increasing interest in the task of describing video with natural language, current computer vision algorithms are still severely limited terms variability and complexity videos their associated language that they can recognize. This is part due to simplicity benchmarks, which mostly focus on specific fine-grained domains simple descriptions. researchers have provided several benchmark datasets for image captioning, we not aware any large-scale description dataset comprehensive categories yet diverse content. In this paper present MSR-VTT (standing ""MSRVideo Text"") a new understanding, especially emerging translating text. achieved by collecting 257 popular queries from commercial search engine, 118 each query. its version, provides 10K web clips 41.2 hours 200K clip-sentence pairs total, covering most visual content, representing largest sentence vocabulary. Each clip annotated about 20 sentences 1,327 AMT workers. We detailed analysis comparison complete set existing datasets, together summarization different state-of-the-art video-to-text approaches. also provide an extensive evaluation these approaches dataset, showing hybrid Recurrent Neural Networkbased approach, combines single-frame motion representations soft-attention pooling strategy, yields best generalization capability MSR-VTT.

language resource, computer science, video retrieval, language model, natural language processing, language, video understanding, computer vision, machine learning, multimedia retrieval, video adaptation, data science, multimedia information processing, deep learning, video interpretation, machine translation, multimedia computing, video summarization",2016,1195,language resource|computer science|video retrieval|language model|natural language processing|language|video understanding|computer vision|machine learning|multimedia retrieval|video adaptation|data science|multimedia information processing|deep learning|video interpretation|machine translation|multimedia computing|video summarization,
https://openalex.org/W2552465644,Image-to-Image Translation with Conditional Adversarial Networks,"Image-to-Image Translation with Conditional Adversarial Networks

We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These not only learn the mapping from input image output image, but also loss function train this mapping. This makes it possible apply same generic approach problems that traditionally would require very different formulations. demonstrate is effective at synthesizing photos label maps, reconstructing objects edge and colorizing images, among other tasks. Indeed, since release of pix2pix software associated with paper, large number internet users (many them artists) have posted their own experiments our system, further demonstrating its wide applicability ease adoption without need for parameter tweaking. As community, we no longer hand-engineer functions, work suggests can achieve reasonable results hand-engineering functions either.

image communication, computer science, conditional adversarial networks, digital image processing, image-to-image translation, data science, deep learning, machine learning, computer vision, adversarial machine learning, computational imaging, machine learning research, human image synthesis, multimodal translation, image analysis, machine translation, synthetic image generation, neural machine translation, image representation",2016,876,image communication|computer science|conditional adversarial networks|digital image processing|image-to-image translation|data science|deep learning|machine learning|computer vision|adversarial machine learning|computational imaging|machine learning research|human image synthesis|multimodal translation|image analysis|machine translation|synthetic image generation|neural machine translation|image representation,
https://openalex.org/W2567070169,Language Modeling with Gated Convolutional Networks,"Language Modeling with Gated Convolutional Networks

The pre-dominant approach to language modeling date is based on recurrent neural networks. Their success this task often linked their ability capture unbounded context. In paper we develop a finite context through stacked convolutions, which can be more efficient since they allow parallelization over sequential tokens. We propose novel simplified gating mechanism that outperforms Oord et al (2016) and investigate the impact of key architectural decisions. proposed achieves state-of-the-art WikiText-103 benchmark, even though it features long-term dependencies, as well competitive results Google Billion Words benchmark. Our model reduces latency score sentence by an order magnitude compared baseline. To our knowledge, first time non-recurrent with strong models these large scale tasks.

computer science, linguistics, convolutional neural network, large language model, language model, natural language processing, language, language engineering, gated convolutional networks, neural machine translation, machine learning, computational linguistics, computational intelligence, deep learning, language recognition, machine translation, spoken language technology, language learning",2016,805,computer science|linguistics|convolutional neural network|large language model|language model|natural language processing|language|language engineering|gated convolutional networks|neural machine translation|machine learning|computational linguistics|computational intelligence|deep learning|language recognition|machine translation|spoken language technology|language learning,
https://openalex.org/W2307381258,Neural Summarization by Extracting Sentences and Words,"Neural Summarization by Extracting Sentences and Words

Traditional approaches to extractive summarization rely heavily on humanengineered features.In this work we propose a data-driven approach based neural networks and continuous sentence features.We develop general framework for single-document composed of hierarchical document encoder an attention-based extractor.This architecture allows us different classes models which can extract sentences or words.We train our large scale corpora containing hundreds thousands document-summary pairs 1 .Experimental results two datasets demonstrate that obtain comparable the state art without any access linguistic annotation.

automatic summarization, neural summarization, annotation tool, narrative extraction, natural language processing, machine translation, keyword extraction, semantic interpretation, cognitive science, machine learning, language processing in the brain, linguistics, language, deep learning, text mining",2016,699,automatic summarization|neural summarization|annotation tool|narrative extraction|natural language processing|machine translation|keyword extraction|semantic interpretation|cognitive science|machine learning|language processing in the brain|linguistics|language|deep learning|text mining,
https://openalex.org/W2963088995,Transfer Learning for Low-Resource Neural Machine Translation,"Transfer Learning for Low-Resource Neural Machine Translation

The encoder-decoder framework for neural machine translation (NMT) has been shown effective in large data scenarios, but is much less low-resource languages.We present a transfer learning method that significantly improves BLEU scores across range of languages.Our key idea to first train high-resource language pair (the parent model), then some the learned parameters child model) initialize and constrain training.Using our we improve baseline NMT models by an average 5.6 on four pairs.Ensembling unknown word replacement add another 2 which brings performance close strong syntax based (SBMT) system, exceeding its one pair.Additionally, using model re-scoring, can SBMT system 1.3 BLEU, improving state-of-the-art translation.

transfer learning, machine translation, computer science, neural machine translation, machine learning",2016,656,transfer learning|machine translation|computer science|neural machine translation|machine learning,
https://openalex.org/W2963260202,Modeling Coverage for Neural Machine Translation,"Modeling Coverage for Neural Machine Translation

Attention mechanism has enhanced stateof-the-art Neural Machine Translation (NMT) by jointly learning to align and translate.It tends ignore past alignment information, however, which often leads over-translation under-translation.To address this problem, we propose coverage-based NMT in paper.We maintain a coverage vector keep track of the attention history.The is fed model help adjust future attention, lets system consider more about untranslated source words.Experiments show that proposed approach significantly improves both translation quality over standard attention-based NMT. 1

language learning, neural computation, natural language processing, machine translation, computational intelligence, computer science, language engineering, language model, neural machine translation, large language model, language, computational linguistics",2016,619,language learning|neural computation|natural language processing|machine translation|computational intelligence|computer science|language engineering|language model|neural machine translation|large language model|language|computational linguistics,https://openalex.org/W3019166713
https://openalex.org/W2546938941,Dual Learning for Machine Translation,"Dual Learning for Machine Translation

While neural machine translation (NMT) is making good progress in the past two years, tens of millions bilingual sentence pairs are needed for its training. However, human labeling very costly. To tackle this training data bottleneck, we develop a dual-learning mechanism, which can enable an NMT system to automatically learn from unlabeled through game. This mechanism inspired by following observation: any task has dual task, e.g., English-to-French (primal) versus French-to-English (dual); primal and tasks form closed loop, generate informative feedback signals train models, even if without involvement labeler. In use one agent represent model other then ask them teach each reinforcement learning process. Based on generated during process (e.g., language-model likelihood output model, reconstruction error original after translations), iteratively update models until convergence using policy gradient methods). We call corresponding approach \emph{dual-NMT}. Experiments show that dual-NMT works well English$\leftrightarrow$French translation; especially, monolingual (with 10% warm start), it achieves comparable accuracy trained full task.

natural language processing, machine translation, dual learning, neural machine translation, machine learning, language",2016,589,natural language processing|machine translation|dual learning|neural machine translation|machine learning|language,https://openalex.org/W2889326796|https://openalex.org/W2963206679
https://openalex.org/W1573040851,Jointly Modeling Embedding and Translation to Bridge Video and Language,"Jointly Modeling Embedding and Translation to Bridge Video and Language

Automatically describing video content with natural language is a fundamental challenge of computer vision. Re-current Neural Networks (RNNs), which models sequence dynamics, has attracted increasing attention on visual interpretation. However, most existing approaches generate word locally the given previous words and content, while relationship between sentence semantics not holistically exploited. As result, generated sentences may be contextually correct but (e.g., subjects, verbs or objects) are true. This paper presents novel unified framework, named Long Short-Term Memory visual-semantic Embedding (LSTM-E), can simultaneously explore learning LSTM embedding. The former aims to maximize probability generating next latter create embedding space for enforcing entire content. experiments YouTube2Text dataset show that our proposed LSTM-E achieves to-date best published performance in sentences: 45.3% 31.0% terms BLEU@4 METEOR, respectively. Superior performances also reported two movie description datasets (M-VAD MPII-MD). In addition, we demonstrate outperforms several state-of-the-art techniques predicting Subject-Verb-Object (SVO) triplets.

computer science, information fusion, video retrieval, language model, natural language processing, language, video understanding, video adaptation, machine learning, multimedia information processing, deep learning, video interpretation, machine translation, translation studies, cross-lingual representation",2016,566,computer science|information fusion|video retrieval|language model|natural language processing|language|video understanding|video adaptation|machine learning|multimedia information processing|deep learning|video interpretation|machine translation|translation studies|cross-lingual representation,
https://openalex.org/W2512924740,Findings of the 2016 Conference on Machine Translation,"Findings of the 2016 Conference on Machine Translation

Ondřej Bojar, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Matthias Huck, Antonio Jimeno Yepes, Philipp Koehn, Varvara Logacheva, Christof Monz, Matteo Negri, Aurélie Névéol, Mariana Neves, Martin Popel, Matt Post, Raphael Rubino, Carolina Scarton, Lucia Specia, Marco Turchi, Karin Verspoor, Marcos Zampieri. Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers. 2016.

natural language processing, language, neural machine translation, machine translation, translation studies, computer-assisted translation",2016,549,natural language processing|language|neural machine translation|machine translation|translation studies|computer-assisted translation,https://openalex.org/W2903193068|https://openalex.org/W3082760180|https://openalex.org/W3159892921
https://openalex.org/W2534253848,Optimizing Statistical Machine Translation for Text Simplification,"Optimizing Statistical Machine Translation for Text Simplification

Most recent sentence simplification systems use basic machine translation models to learn lexical and syntactic paraphrases from a manually simplified parallel corpus. These methods are limited by the quality quantity of corpora, which expensive build. In this paper, we conduct an in-depth adaptation statistical perform text simplification, taking advantage large-scale learned bilingual texts small amount manual simplifications with multiple references. Our work is first design automatic metrics that effective for tuning evaluating systems, will facilitate iterative development task.

natural language processing, statistical machine translation, text simplification, statistics, machine translation",2016,435,natural language processing|statistical machine translation|text simplification|statistics|machine translation,
https://openalex.org/W2963463964,Minimum Risk Training for Neural Machine Translation,"Minimum Risk Training for Neural Machine Translation

We propose minimum risk training for end-to-end neural machine translation.Unlike conventional maximum likelihood estimation, is capable of optimizing model parameters directly with respect to arbitrary evaluation metrics, which are not necessarily differentiable.Experiments show that our approach achieves significant improvements over estimation on a state-of-the-art translation system across various languages pairs.Transparent architectures, can be applied more networks and potentially benefit NLP tasks.

computer science, neural machine translation, machine learning, minimum risk training, machine translation",2016,401,computer science|neural machine translation|machine learning|minimum risk training|machine translation,https://openalex.org/W2963260202
https://openalex.org/W2540404261,Neural Machine Translation in Linear Time,"Neural Machine Translation in Linear Time

We present a novel neural network for processing sequences. The ByteNet is one-dimensional convolutional that composed of two parts, one to encode the source sequence and other decode target sequence. parts are connected by stacking decoder on top encoder preserving temporal resolution To address differing lengths target, we introduce an efficient mechanism which dynamically unfolded over representation encoder. uses dilation in layers increase its receptive field. resulting has core properties: it runs time linear length sequences sidesteps need excessive memorization. attains state-of-the-art performance character-level language modelling outperforms previous best results obtained with recurrent networks. also achieves character-to-character machine translation English-to-German WMT task, surpassing comparable models based networks attentional pooling run quadratic time. find latent alignment structure contained representations reflects expected between tokens.

neural computation, natural language processing, machine translation, linear time, neural network (machine learning), computer science, neural machine translation, machine learning, deep learning",2016,341,neural computation|natural language processing|machine translation|linear time|neural network (machine learning)|computer science|neural machine translation|machine learning|deep learning,https://openalex.org/W2889326796
https://openalex.org/W2896457183,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding

We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent models, BERT is designed to pre-train deep bidirectional representations unlabeled text by jointly conditioning on both left and right context in all layers. As result, the pre-trained can be fine-tuned with just one additional output layer create state-of-the-art models wide range of tasks, such as question answering inference, without substantial task-specific architecture modifications. conceptually simple empirically powerful. It obtains results eleven natural processing including pushing GLUE score 80.5% (7.7% point absolute improvement), MultiNLI accuracy 86.7% (4.6% SQuAD v1.1 Test F1 93.2 (1.5 improvement) v2.0 83.1 (5.1 improvement).

computer science, language model, natural language processing, language, language engineering, computational linguistics, deep bidirectional transformers, deep learning, machine translation, language understanding",2018,29822,computer science|language model|natural language processing|language|language engineering|computational linguistics|deep bidirectional transformers|deep learning|machine translation|language understanding,https://openalex.org/W3035390927|https://openalex.org/W3105966348|https://openalex.org/W3107826490|https://openalex.org/W2986154550|https://openalex.org/W3111372685|https://openalex.org/W3102483398|https://openalex.org/W3019166713|https://openalex.org/W3118781290|https://openalex.org/W3181186176|https://openalex.org/W3173360659
https://openalex.org/W2963767194,StarGAN: Unified Generative Adversarial Networks for Multi-domain Image-to-Image Translation,"StarGAN: Unified Generative Adversarial Networks for Multi-domain Image-to-Image Translation

Recent studies have shown remarkable success in image-to-image translation for two domains. However, existing approaches limited scalability and robustness handling more than domains, since different models should be built independently every pair of image To address this limitation, we propose StarGAN, a novel scalable approach that can perform translations multiple domains using only single model. Such unified model architecture StarGAN allows simultaneous training datasets with within network. This leads to StarGAN's superior quality translated images compared as well the capability flexibly translating an input any desired target domain. We empirically demonstrate effectiveness our on facial attribute transfer expression synthesis tasks.

image analysis, computational imaging, computer science, image communication, domain adaptation, multi-domain image-to-image translation, computer vision, machine learning, generative adversarial network, generative ai, neural machine translation, deep learning, image representation, machine learning research, machine translation, synthetic image generation, digital image processing",2018,3280,image analysis|computational imaging|computer science|image communication|domain adaptation|multi-domain image-to-image translation|computer vision|machine learning|generative adversarial network|generative ai|neural machine translation|deep learning|image representation|machine learning research|machine translation|synthetic image generation|digital image processing,https://openalex.org/W3173268697
https://openalex.org/W2923014074,GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding,"GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding

Human ability to understand language is general, flexible, and robust. In contrast, most NLU models above the word level are designed for a specific task struggle with out-of-domain data. If we aspire develop understanding beyond detection of superficial correspondences between inputs outputs, then it critical unified model that can execute range linguistic tasks across different domains. To facilitate research in this direction, present General Language Understanding Evaluation (GLUE, gluebenchmark.com): benchmark nine diverse tasks, an auxiliary dataset probing phenomena, online platform evaluating comparing models. For some training data plentiful, but others limited or does not match genre test set. GLUE thus favors represent knowledge way facilitates sample-efficient learning effective knowledge-transfer tasks. While none datasets were created from scratch benchmark, four them feature privately-held data, which used ensure fairly. We evaluate baselines use ELMo (Peters et al., 2018), powerful transfer technique, as well state-of-the-art sentence representation The best still achieve fairly low absolute scores. Analysis our diagnostic yields similarly weak performance over all phenomena tested, exceptions.

natural language understanding, nlp task, computer science, language model, deep learning, multi-task benchmark, information fusion, natural language processing, machine translation, language testing, multi-task learning, language learning, machine learning, language engineering, data science, computational linguistics, analysis platform, question answering, cognitive science, semantic evaluation, large language model",2018,2727,natural language understanding|nlp task|computer science|language model|deep learning|multi-task benchmark|information fusion|natural language processing|machine translation|language testing|multi-task learning|language learning|machine learning|language engineering|data science|computational linguistics|analysis platform|question answering|cognitive science|semantic evaluation|large language model,https://openalex.org/W3034999214|https://openalex.org/W3035390927|https://openalex.org/W3105966348|https://openalex.org/W3102483398|https://openalex.org/W3019166713
https://openalex.org/W2963250244,SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing,"SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing

This paper describes SentencePiece, a language-independent subword tokenizer and detokenizer designed for Neural-based text processing, including Neural Machine Translation. It provides open-source C++ Python implementations units. While existing segmentation tools assume that the input is pre-tokenized into word sequences, SentencePiece can train models directly from raw sentences, which allows us to make purely end-to-end language independent system. We perform validation experiment of NMT on English-Japanese machine translation, find it possible achieve comparable accuracy direct training sentences. also compare performance with various configurations. available under Apache 2 license at https://github.com/google/sentencepiece.

spoken language processing, nlp task, natural language processing, machine translation, neural text processing, text processing, text recognition, computer science, language engineering, language model, machine learning, text mining, linguistics, language, computational linguistics",2018,2297,spoken language processing|nlp task|natural language processing|machine translation|neural text processing|text processing|text recognition|computer science|language engineering|language model|machine learning|text mining|linguistics|language|computational linguistics,https://openalex.org/W3035390927|https://openalex.org/W3107826490|https://openalex.org/W3001434439|https://openalex.org/W2986154550|https://openalex.org/W3093871477|https://openalex.org/W3038033387|https://openalex.org/W3152788712
https://openalex.org/W2963310665,GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding,"GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding

Human ability to understand language is general, flexible, and robust. In contrast, most NLU models above the word level are designed for a specific task struggle with out-of-domain data. If we aspire develop understanding beyond detection of superficial correspondences between inputs outputs, then it critical unified model that can execute range linguistic tasks across different domains. To facilitate research in this direction, present General Language Understanding Evaluation (GLUE, gluebenchmark.com): benchmark nine diverse tasks, an auxiliary dataset probing phenomena, online platform evaluating comparing models. For some training data plentiful, but others limited or does not match genre test set. GLUE thus favors represent knowledge way facilitates sample-efficient learning effective knowledge-transfer tasks. While none datasets were created from scratch benchmark, four them feature privately-held data, which used ensure fairly. We evaluate baselines use ELMo (Peters et al., 2018), powerful transfer technique, as well state-of-the-art sentence representation The best still achieve fairly low absolute scores. Analysis our diagnostic yields similarly weak performance over all phenomena tested, exceptions.

natural language understanding, nlp task, computer science, language model, deep learning, multi-task benchmark, information fusion, natural language processing, machine translation, language testing, multi-task learning, language learning, machine learning, language engineering, data science, computational linguistics, analysis platform, question answering, cognitive science, semantic evaluation, large language model",2018,2102,natural language understanding|nlp task|computer science|language model|deep learning|multi-task benchmark|information fusion|natural language processing|machine translation|language testing|multi-task learning|language learning|machine learning|language engineering|data science|computational linguistics|analysis platform|question answering|cognitive science|semantic evaluation|large language model,https://openalex.org/W2896457183|https://openalex.org/W3034999214|https://openalex.org/W3035390927|https://openalex.org/W3016473712|https://openalex.org/W3102483398|https://openalex.org/W3019166713
https://openalex.org/W2794557536,Universal Sentence Encoder,"Universal Sentence Encoder

We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The are efficient and result in accurate performance on diverse Two variants of the allow trade-offs between accuracy compute resources. For both variants, we investigate report relationship model complexity, resource consumption, availability task training data, performance. Comparisons made with baselines use word level via pretrained embeddings as well do not any learning. find using sentence tends outperform transfer. With embeddings, observe surprisingly good minimal amounts supervised data a task. obtain encouraging results Word Embedding Association Tests (WEAT) targeted at detecting bias. Our pre-trained freely available download TF Hub.

computer science, artificial intelligence, natural language processing, machine learning, computational linguistics, deep learning, nlp task, machine translation, annotation tool, universal sentence encoder",2018,1236,computer science|artificial intelligence|natural language processing|machine learning|computational linguistics|deep learning|nlp task|machine translation|annotation tool|universal sentence encoder,
https://openalex.org/W2891177506,Universal Sentence Encoder for English,"Universal Sentence Encoder for English

Daniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco, Rhomni St. John, Noah Constant, Mario Guajardo-Cespedes, Steve Yuan, Chris Tar, Brian Strope, Ray Kurzweil. Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. 2018.

linguistics, english, natural language processing, language engineering, language, computational linguistics, nlp task, machine translation, english language, annotation tool, universal sentence encoder",2018,989,linguistics|english|natural language processing|language engineering|language|computational linguistics|nlp task|machine translation|english language|annotation tool|universal sentence encoder,https://openalex.org/W3038033387
https://openalex.org/W2889326796,Understanding Back-Translation at Scale,"Understanding Back-Translation at Scale

An effective method to improve neural machine translation with monolingual data is augment the parallel training corpus back-translations of target language sentences. This work broadens understanding back-translation and investigates a number methods generate synthetic source We find that in all but resource poor settings obtained via sampling or noised beam outputs are most effective. Our analysis shows noisy gives much stronger signal than generated by greedy search. also compare how compares genuine bitext study various domain effects. Finally, we scale hundreds millions sentences achieve new state art 35 BLEU on WMT’14 English-German test set.

natural language processing, machine translation, computer-assisted translation, multimodal translation, computer science, semantic evaluation, language model, text mining, large language model, linguistics, language, translation studies, neural machine translation, computational linguistics",2018,934,natural language processing|machine translation|computer-assisted translation|multimodal translation|computer science|semantic evaluation|language model|text mining|large language model|linguistics|language|translation studies|neural machine translation|computational linguistics,https://openalex.org/W2903193068|https://openalex.org/W3093871477|https://openalex.org/W3119872582
https://openalex.org/W2963979492,Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates,"Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates

Subword units are an effective way to alleviate the open vocabulary problems in neural machine translation (NMT). While sentences usually converted into unique subword sequences, segmentation is potentially ambiguous and multiple segmentations possible even with same vocabulary. The question addressed this paper whether it harness ambiguity as a noise improve robustness of NMT. We present simple regularization method, regularization, which trains model probabilistically sampled during training. In addition, for better sampling, we propose new algorithm based on unigram language model. experiment corpora report consistent improvements especially low resource out-of-domain settings.

computer science, linguistics, machine learning, computational linguistics, automatic classification, language, computational intelligence, nlp task, machine translation, language model, sparse neural network, deep learning, language learning, applied linguistics, large language model, natural language processing, multiple subword candidates, neural machine translation, subword regularization",2018,876,computer science|linguistics|machine learning|computational linguistics|automatic classification|language|computational intelligence|nlp task|machine translation|language model|sparse neural network|deep learning|language learning|applied linguistics|large language model|natural language processing|multiple subword candidates|neural machine translation|subword regularization,https://openalex.org/W2963250244|https://openalex.org/W3035390927|https://openalex.org/W2986154550|https://openalex.org/W3173360659
https://openalex.org/W2964345792,MAttNet: Modular Attention Network for Referring Expression Comprehension,"MAttNet: Modular Attention Network for Referring Expression Comprehension

In this paper, we address referring expression comprehension: localizing an image region described by a natural language expression. While most recent work treats expressions as single unit, propose to decompose them into three modular components related subject appearance, location, and relationship other objects. This allows us flexibly adapt containing different types of information in end-to-end framework. our model, which call the Modular Attention Network (MAttNet), two attention are utilized: language-based that learns module weights well word/phrase each should focus on; visual modules on relevant components. Module combine scores from all dynamically output overall score. Experiments show MAttNet outperforms previous state-of-the-art methods large margin both bounding-box-level pixel-level comprehension tasks. Demo1 code2 provided.

modular attention network, treebanks, coreference resolution, natural language processing, machine translation, nlp task, attention, inference, cognitive science, computational intelligence, computer science, semantic evaluation, language model, language comprehension, question answering, data science, computational linguistics, expression comprehension",2018,599,modular attention network|treebanks|coreference resolution|natural language processing|machine translation|nlp task|attention|inference|cognitive science|computational intelligence|computer science|semantic evaluation|language model|language comprehension|question answering|data science|computational linguistics|expression comprehension,
https://openalex.org/W2963602293,Unsupervised Machine Translation Using Monolingual Corpora Only,"Unsupervised Machine Translation Using Monolingual Corpora Only

Machine translation has recently achieved impressive performance thanks to recent advances in deep learning and the availability of large-scale parallel corpora. There have been numerous attempts extend these successes low-resource language pairs, yet requiring tens thousands sentences. In this work, we take research direction extreme investigate whether it is possible learn translate even without any data. We propose a model that takes sentences from monolingual corpora two different languages maps them into same latent space. By reconstruct both shared feature space, effectively learns using labeled demonstrate our on widely used datasets reporting BLEU scores 32.8 15.1 Multi30k WMT English-French datasets, single sentence at training time.

computer science, natural language processing, unsupervised machine learning, machine translation, unsupervised machine translation, computer-assisted translation, monolingual corpora",2018,563,computer science|natural language processing|unsupervised machine learning|machine translation|unsupervised machine translation|computer-assisted translation|monolingual corpora,https://openalex.org/W2889326796|https://openalex.org/W2963206679|https://openalex.org/W3001434439|https://openalex.org/W3173190788
https://openalex.org/W2963807318,Scaling Neural Machine Translation,"Scaling Neural Machine Translation

Sequence to sequence learning models still require several days reach state of the art performance on large benchmark datasets using a single machine. This paper shows that reduced precision and batch training can speedup by nearly 5x 8-GPU machine with careful tuning implementation. On WMT’14 English-German translation, we match accuracy Vaswani et al. (2017) in under 5 hours when 8 GPUs obtain new 29.3 BLEU after for 85 minutes 128 GPUs. We further improve these results 29.8 much larger Paracrawl dataset. English-French task, state-of-the-art 43.2 8.5

language learning, neural scaling law, neural computation, natural language processing, machine translation, neural network (machine learning), computer science, neural machine translation, language model, language, deep learning",2018,531,language learning|neural scaling law|neural computation|natural language processing|machine translation|neural network (machine learning)|computer science|neural machine translation|language model|language|deep learning,https://openalex.org/W2889326796|https://openalex.org/W2994928925
https://openalex.org/W2794365787,Achieving Human Parity on Automatic Chinese to English News Translation,"Achieving Human Parity on Automatic Chinese to English News Translation

Machine translation has made rapid advances in recent years. Millions of people are using it today online systems and mobile applications order to communicate across language barriers. The question naturally arises whether such can approach or achieve parity with human translations. In this paper, we first address the problem how define accurately measure translation. We then describe Microsoft's machine system quality its translations on widely used WMT 2017 news task from Chinese English. find that our latest neural reached a new state-of-the-art, is at when compared professional also significantly exceeds crowd-sourced non-professional

english, natural language processing, language, automatic chinese, communication, human parity, machine translation, translation studies, news semantics",2018,525,english|natural language processing|language|automatic chinese|communication|human parity|machine translation|translation studies|news semantics,https://openalex.org/W2889326796|https://openalex.org/W2903193068|https://openalex.org/W2963206679|https://openalex.org/W3159892921|https://openalex.org/W3152788712
https://openalex.org/W2903193068,Findings of the 2018 Conference on Machine Translation (WMT18),"Findings of the 2018 Conference on Machine Translation (WMT18)

Ondřej Bojar, Christian Federmann, Mark Fishel, Yvette Graham, Barry Haddow, Matthias Huck, Philipp Koehn, Christof Monz. Proceedings of the Third Conference on Machine Translation: Shared Task Papers. 2018.

linguistics, natural language processing, neural machine translation, machine translation, translation studies, computer-assisted translation",2018,523,linguistics|natural language processing|neural machine translation|machine translation|translation studies|computer-assisted translation,https://openalex.org/W2903193068|https://openalex.org/W3093871477|https://openalex.org/W3082760180
https://openalex.org/W2963206679,Phrase-Based &amp; Neural Unsupervised Machine Translation,"Phrase-Based &amp; Neural Unsupervised Machine Translation

Machine translation systems achieve near human-level performance on some languages, yet their effectiveness strongly relies the availability of large amounts parallel sentences, which hinders applicability to majority language pairs. This work investigates how learn translate when having access only monolingual corpora in each language. We propose two model variants, a neural and phrase-based model. Both versions leverage careful initialization parameters, denoising effect models automatic generation data by iterative back-translation. These are significantly better than methods from literature, while being simpler fewer hyper-parameters. On widely used WMT’14 English-French WMT’16 German-English benchmarks, our respectively obtain 28.1 25.2 BLEU points without using single sentence, outperforming state art more 11 points. low-resource languages like English-Urdu English-Romanian, even results semi-supervised supervised approaches leveraging paucity available bitexts. Our code for NMT PBSMT is publicly available.

computer science, linguistics, language model, natural language processing, language, neural machine translation, computational linguistics, neural computation, machine translation, spoken language technology",2018,479,computer science|linguistics|language model|natural language processing|language|neural machine translation|computational linguistics|neural computation|machine translation|spoken language technology,https://openalex.org/W2903193068|https://openalex.org/W2994928925
https://openalex.org/W2890187992,Cross-lingual Knowledge Graph Alignment via Graph Convolutional Networks,"Cross-lingual Knowledge Graph Alignment via Graph Convolutional Networks

Multilingual knowledge graphs (KGs) such as DBpedia and YAGO contain structured of entities in several distinct languages, they are useful resources for cross-lingual AI NLP applications. Cross-lingual KG alignment is the task matching with their counterparts different which an important way to enrich links multilingual KGs. In this paper, we propose a novel approach via graph convolutional networks (GCNs). Given set pre-aligned entities, our trains GCNs embed each language into unified vector space. Entity alignments discovered based on distances between embedding Embeddings can be learned from both structural attribute information results structure combined get accurate alignments. experiments aligning real KGs, gets best performance compared other embedding-based approaches.

computer science, linguistics, knowledge graph, graph theory, knowledge representation and reasoning, language model, language, natural language processing, feature extraction, knowledge integration, knowledge discovery, knowledge graph embeddings, graph convolutional networks, machine learning research, machine translation, cross-lingual representation, knowledge management",2018,461,computer science|linguistics|knowledge graph|graph theory|knowledge representation and reasoning|language model|language|natural language processing|feature extraction|knowledge integration|knowledge discovery|knowledge graph embeddings|graph convolutional networks|machine learning research|machine translation|cross-lingual representation|knowledge management,
https://openalex.org/W2799020610,Neural Sign Language Translation,"Neural Sign Language Translation

Sign Language Recognition (SLR) has been an active research field for the last two decades. However, most to date considered SLR as a naive gesture recognition problem. seeks recognize sequence of continuous signs but neglects underlying rich grammatical and linguistic structures sign language that differ from spoken language. In contrast, we introduce Translation (SLT) Here, objective is generate translations videos, taking into account different word orders grammar. We formalize SLT in framework Neural Machine (NMT) both end-to-end pretrained settings (using expert knowledge). This allows us jointly learn spatial representations, model, mapping between To evaluate performance SLT, collected first publicly available Continuous dataset, RWTH-PHOENIX-Weather 2014T1. It provides gloss level annotations German videos weather broadcasts. Our dataset contains over .95M frames with >67K vocabulary >1K >99K words >2.8K. report quantitative qualitative results various setups underpin future this newly established field. The upper bound translation calculated at 19.26 BLEU-4, while our frame-level gloss-level tokenization networks were able achieve 9.58 18.13 respectively.

language, neural machine translation, neural computation, language processing in the brain, machine translation, sign language",2018,400,language|neural machine translation|neural computation|language processing in the brain|machine translation|sign language,
https://openalex.org/W3034999214,"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension","BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension

Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, Luke Zettlemoyer. Proceedings of the 58th Annual Meeting Association for Computational Linguistics. 2020.

computer science, language model, natural language processing, language, natural language generation, language engineering, neural machine translation, machine learning, denoising sequence-to-sequence pre-training, computational linguistics, deep learning, machine translation, image denoising, language generation",2020,4980,computer science|language model|natural language processing|language|natural language generation|language engineering|neural machine translation|machine learning|denoising sequence-to-sequence pre-training|computational linguistics|deep learning|machine translation|image denoising|language generation,https://openalex.org/W3102483398
https://openalex.org/W3035390927,Unsupervised Cross-lingual Representation Learning at Scale,"Unsupervised Cross-lingual Representation Learning at Scale

Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov. Proceedings of the 58th Annual Meeting Association for Computational Linguistics. 2020.

computer science, cross-language perspective, text mining, language model, natural language processing, language, large language model, cross-language retrieval, second language learning, multilingual pretraining, computational linguistics, data science, knowledge discovery, machine translation, cross-lingual representation, language learning",2020,3463,computer science|cross-language perspective|text mining|language model|natural language processing|language|large language model|cross-language retrieval|second language learning|multilingual pretraining|computational linguistics|data science|knowledge discovery|machine translation|cross-lingual representation|language learning,https://openalex.org/W2986154550|https://openalex.org/W3101498587|https://openalex.org/W3102483398|https://openalex.org/W3173360659
https://openalex.org/W2912512851,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics

The year 2000 gives Asia its first opportunity to host the annual meeting of Association for Computational Linguistics. ACL Executive Committee, under leadership Wolfgang Wahlster, selected one Asia's most exciting cities, Hong Kong, as venue, and organized an international conference committee including many representatives Asian countries. ACL-2000 also signifies a change in tenor global network communication access WWW languages grows with development practical applications enabling multilingual information access.The technical program covers all areas field, from theory methodology. There are four theme sessions, each own theme.

linguistics, text mining, language model, natural language processing, language engineering, computational linguistics, data science, computational semantics, machine translation, corpus linguistics",2020,1435,linguistics|text mining|language model|natural language processing|language engineering|computational linguistics|data science|computational semantics|machine translation|corpus linguistics,https://openalex.org/W3111372685
https://openalex.org/W3105966348,TinyBERT: Distilling BERT for Natural Language Understanding,"TinyBERT: Distilling BERT for Natural Language Understanding

Language model pre-training, such as BERT, has significantly improved the performances of many natural language processing tasks. However, pre-trained models are usually computationally expensive, so it is difficult to efficiently execute them on resource-restricted devices. To accelerate inference and reduce size while maintaining accuracy, we first propose a novel Transformer distillation method that specially designed for knowledge (KD) Transformer-based models. By leveraging this new KD method, plenty encoded in large “teacher” BERT can be effectively transferred small “student” TinyBERT. Then, introduce two-stage learning framework TinyBERT, which performs at both pre-training task-specific stages. This ensures TinyBERT capture general-domain well BERT. TinyBERT4 with 4 layers empirically effective achieves more than 96.8% performance its teacher BERT-Base GLUE benchmark, being 7.5x smaller 9.4x faster inference. also better 4-layer state-of-the-art baselines distillation, only ~28% parameters ~31% time them. Moreover, TinyBERT6 6 on-par BERT-Base.

distilling bert, computer science, natural language interface, language model, natural language processing, machine learning, computational linguistics, natural language understanding, deep learning, knowledge distillation, natural language, machine translation, nlp task, automatic annotation tool",2020,1072,distilling bert|computer science|natural language interface|language model|natural language processing|machine learning|computational linguistics|natural language understanding|deep learning|knowledge distillation|natural language|machine translation|nlp task|automatic annotation tool,
https://openalex.org/W3037109418,Stanza: A Python Natural Language Processing Toolkit for Many Human Languages,"Stanza: A Python Natural Language Processing Toolkit for Many Human Languages

We introduce Stanza, an open-source Python natural language processing toolkit supporting 66 human languages. Compared to existing widely used toolkits, Stanza features a language-agnostic fully neural pipeline for text analysis, including tokenization, multi-word token expansion, lemmatization, part-of-speech and morphological feature tagging, dependency parsing, named entity recognition. have trained on total of 112 datasets, the Universal Dependencies treebanks other multilingual corpora, show that same architecture generalizes well achieves competitive performance all languages tested. Additionally, includes native interface Java Stanford CoreNLP software, which further extends its functionality cover tasks such as coreference resolution relation extraction. Source code, documentation, pretrained models are available at https://stanfordnlp.github.io/stanza/.

many human languages, machine translation, language, nlp task, natural language processing, computational linguistics",2020,1027,many human languages|machine translation|language|nlp task|natural language processing|computational linguistics,
https://openalex.org/W3107826490,Multilingual Denoising Pre-training for Neural Machine Translation,"Multilingual Denoising Pre-training for Neural Machine Translation

This paper demonstrates that multilingual denoising pre-training produces significant performance gains across a wide variety of machine translation (MT) tasks. We present mBART -- sequence-to-sequence auto-encoder pre-trained on large-scale monolingual corpora in many languages using the BART objective. is one first methods for complete model by full texts multiple languages, while previous approaches have focused only encoder, decoder, or reconstructing parts text. Pre-training allows it to be directly fine tuned supervised (both sentence-level and document-level) unsupervised translation, with no task-specific modifications. demonstrate adding initialization all but highest-resource settings, including up 12 BLEU points low resource MT over 5 document-level models. also show enables new types transfer language pairs bi-text were not corpus, extensive analysis which factors contribute most effective pre-training.

computer science, machine translation, neural machine translation, multilingualism, language learning",2020,611,computer science|machine translation|neural machine translation|multilingualism|language learning,https://openalex.org/W3093871477|https://openalex.org/W3173190788
https://openalex.org/W3001434439,Multilingual Denoising Pre-training for Neural Machine Translation,"Multilingual Denoising Pre-training for Neural Machine Translation

This paper demonstrates that multilingual denoising pre-training produces significant performance gains across a wide variety of machine translation (MT) tasks. We present mBART—a sequence-to-sequence auto-encoder pre-trained on large-scale monolingual corpora in many languages using the BART objective (Lewis et al., 2019 ). mBART is first method for complete model by full texts multiple languages, whereas previous approaches have focused only encoder, decoder, or reconstructing parts text. Pre-training allows it to be directly fine-tuned supervised (both sentence-level and document-level) unsupervised translation, with no task- specific modifications. demonstrate adding initialization all but highest-resource settings, including up 12 BLEU points low resource MT over 5 document-level models. also show enables transfer language pairs bi-text were not corpus, extensive analysis which factors contribute most effective pre-training. 1

language learning, machine translation, computer science, neural machine translation, multilingualism",2020,580,language learning|machine translation|computer science|neural machine translation|multilingualism,
https://openalex.org/W2986154550,CamemBERT: a Tasty French Language Model,"CamemBERT: a Tasty French Language Model

Louis Martin, Benjamin Muller, Pedro Javier Ortiz Suárez, Yoann Dupont, Laurent Romary, Éric de la Clergerie, Djamé Seddah, Benoît Sagot. Proceedings of the 58th Annual Meeting Association for Computational Linguistics. 2020.

linguistics, french language, large language model, natural language processing, language model, language, machine translation, french",2020,376,linguistics|french language|large language model|natural language processing|language model|language|machine translation|french,https://openalex.org/W2986154550
https://openalex.org/W3101498587,MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer,"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer

The main goal behind state-of-the-art pre-trained multilingual models such as BERT and XLM-R is enabling bootstrapping NLP applications in low-resource languages through zero-shot or few-shot cross-lingual transfer. However, due to limited model capacity, their transfer performance the weakest exactly on unseen during pre-training. We propose MAD-X, an adapter-based framework that enables high portability parameter-efficient arbitrary tasks by learning modular language task representations. In addition, we introduce a novel invertible adapter architecture strong baseline method for adapting new language. MAD-X outperforms state of art cross lingual across representative set typologically diverse named entity recognition causal commonsense reasoning, achieves competitive results question answering. Our code adapters are available at AdapterHub.ml.

cross-lingual representation, human-computer interaction, adapter-based framework, natural language processing, machine translation, cross-language perspective, computer science, multi-task cross-lingual transfer, language model, cross-language retrieval, language",2020,351,cross-lingual representation|human-computer interaction|adapter-based framework|natural language processing|machine translation|cross-language perspective|computer science|multi-task cross-lingual transfer|language model|cross-language retrieval|language,
https://openalex.org/W3093871477,Beyond English-Centric Multilingual Machine Translation,"Beyond English-Centric Multilingual Machine Translation

Existing work in translation demonstrated the potential of massively multilingual machine by training a single model able to translate between any pair languages. However, much this is English-Centric only on data which was translated from or English. While supported large sources data, it does not reflect needs worldwide. In work, we create true Many-to-Many that can directly 100 We build and open source dataset covers thousands language directions with supervised created through large-scale mining. Then, explore how effectively increase capacity combination dense scaling language-specific sparse parameters high quality models. Our focus non-English-Centric models brings gains more than 10 BLEU when translating non-English while performing competitively best systems WMT. open-source our scripts so others may reproduce evaluation, final M2M-100 model.

english, multilingualism, machine translation, computer-assisted translation, translation studies",2020,347,english|multilingualism|machine translation|computer-assisted translation|translation studies,https://openalex.org/W3173190788
https://openalex.org/W3038033387,Multilingual Universal Sentence Encoder for Semantic Retrieval,"Multilingual Universal Sentence Encoder for Semantic Retrieval

Yinfei Yang, Daniel Cer, Amin Ahmad, Mandy Guo, Jax Law, Noah Constant, Gustavo Hernandez Abrego, Steve Yuan, Chris Tar, Yun-hsuan Sung, Brian Strope, Ray Kurzweil. Proceedings of the 58th Annual Meeting Association for Computational Linguistics: System Demonstrations. 2020.

semantic learning, multilingualism, semantic search, language model, computational linguistics, cross-language retrieval, semantic retrieval, natural language processing, machine translation, computer science, language",2020,332,semantic learning|multilingualism|semantic search|language model|computational linguistics|cross-language retrieval|semantic retrieval|natural language processing|machine translation|computer science|language,
https://openalex.org/W3085380432,Captum: A unified and generic model interpretability library for PyTorch,"Captum: A unified and generic model interpretability library for PyTorch

In this paper we introduce a novel, unified, open-source model interpretability library for PyTorch [12]. The contains generic implementations of number gradient and perturbation-based attribution algorithms, also known as feature, neuron layer importance well set evaluation metrics these algorithms. It can be used both classification non-classification models including graph-structured built on Neural Networks (NN). give high-level overview supported algorithms show how to perform memory-efficient scalable computations. We emphasize that the three main characteristics are multimodality, extensibility ease use. Multimodality supports different modality inputs such image, text, audio or video. Extensibility allows adding new features. is designed easy understanding Besides, an interactive visualization tool called Captum Insights top sample-based debugging using feature metrics.

knowledge representation and reasoning, language model, knowledge discovery, interpretability, scene understanding, natural language processing, machine translation, computer science, machine learning, automated reasoning, model-based reasoning, scene interpretation, semantic interpretation, computer engineering, computational intelligence, systems engineering, information fusion, deep learning",2020,330,knowledge representation and reasoning|language model|knowledge discovery|interpretability|scene understanding|natural language processing|machine translation|computer science|machine learning|automated reasoning|model-based reasoning|scene interpretation|semantic interpretation|computer engineering|computational intelligence|systems engineering|information fusion|deep learning,
https://openalex.org/W3016473712,MPNet: Masked and Permuted Pre-training for Language Understanding,"MPNet: Masked and Permuted Pre-training for Language Understanding

BERT adopts masked language modeling (MLM) for pre-training and is one of the most successful models. Since neglects dependency among predicted tokens, XLNet introduces permuted (PLM) to address this problem. However, does not leverage full position information a sentence thus suffers from discrepancy between fine-tuning. In paper, we propose MPNet, novel method that inherits advantages avoids their limitations. MPNet leverages tokens through (vs. MLM in BERT), takes auxiliary as input make model see reducing PLM XLNet). We pre-train on large-scale dataset (over 160GB text corpora) fine-tune variety down-streaming tasks (GLUE, SQuAD, etc). Experimental results show outperforms by large margin, achieves better these compared with previous state-of-the-art pre-trained methods (e.g., BERT, XLNet, RoBERTa) under same setting. The code models are available at: https://github.com/microsoft/MPNet.

nlp task, computer science, language model, semantic parsing, text mining, spoken language technology, spoken language processing, language understanding, natural language processing, machine translation, speech recognition, language, language learning, language recognition, applied linguistics, linguistics, computational linguistics, neural machine translation, second language acquisition",2020,302,nlp task|computer science|language model|semantic parsing|text mining|spoken language technology|spoken language processing|language understanding|natural language processing|machine translation|speech recognition|language|language learning|language recognition|applied linguistics|linguistics|computational linguistics|neural machine translation|second language acquisition,
https://openalex.org/W3111372685,oLMpics-On What Language Model Pre-training Captures,"oLMpics-On What Language Model Pre-training Captures

Recent success of pre-trained language models (LMs) has spurred widespread interest in the capabilities that they possess. However, efforts to understand whether LM representations are useful for symbolic reasoning tasks have been limited and scattered. In this work, we propose eight tasks, which conceptually require operations such as comparison, conjunction, composition. A fundamental challenge is performance a on task should be attributed or process fine-tuning data. To address this, an evaluation protocol includes both zero-shot (no fine-tuning), well comparing learning curve fine-tuned multiple controls, paints rich picture capabilities. Our main findings that: (a) different LMs exhibit qualitatively abilities, e.g., RoBERTa succeeds where BERT fails completely; (b) do not reason abstract manner context-dependent, while can compare ages, it so only when ages typical range human ages; (c) On half our all fail completely. infrastructure help future work designing new datasets, models, objective functions pre-training.

linguistics, language model, computational linguistics, natural language processing, machine translation, computer science, language engineering, language, language recognition",2020,282,linguistics|language model|computational linguistics|natural language processing|machine translation|computer science|language engineering|language|language recognition,
https://openalex.org/W2994928925,Incorporating BERT into Neural Machine Translation,"Incorporating BERT into Neural Machine Translation

The recently proposed BERT has shown great power on a variety of natural language understanding tasks, such as text classification, reading comprehension, etc. However, how to effectively apply neural machine translation (NMT) lacks enough exploration. While is more commonly used fine-tuning instead contextual embedding for downstream in NMT, our preliminary exploration using better than fine-tuning. This motivates us think leverage NMT along this direction. We propose new algorithm named BERT-fused model, which we first use extract representations an input sequence, and then the are fused with each layer encoder decoder model through attention mechanisms. conduct experiments supervised (including sentence-level document-level translations), semi-supervised unsupervised translation, achieve state-of-the-art results seven benchmark datasets. Our code available at \url{https://github.com/bert-nmt/bert-nmt}.

computer science, machine learning, machine translation, artificial intelligence, language, nlp task, natural language processing, neural machine translation, deep learning, language model",2020,226,computer science|machine learning|machine translation|artificial intelligence|language|nlp task|natural language processing|neural machine translation|deep learning|language model,
https://openalex.org/W3102483398,"XGLUE: A New Benchmark Datasetfor Cross-lingual Pre-training, Understanding and Generation","XGLUE: A New Benchmark Datasetfor Cross-lingual Pre-training, Understanding and Generation

Yaobo Liang, Nan Duan, Yeyun Gong, Ning Wu, Fenfei Guo, Weizhen Qi, Ming Linjun Shou, Daxin Jiang, Guihong Cao, Xiaodong Fan, Ruofei Zhang, Rahul Agrawal, Edward Cui, Sining Wei, Taroon Bharti, Ying Qiao, Jiun-Hung Chen, Winnie Shuguang Liu, Fan Yang, Daniel Campos, Rangan Majumder, Zhou. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2020.

text mining, linguistics, cross-language perspective, language model, computational linguistics, cross-language retrieval, multilingual pretraining, data science, natural language processing, machine translation, language testing, language learning, language, cross-lingual representation, language resource, language acquisition, language generation, natural language generation",2020,213,text mining|linguistics|cross-language perspective|language model|computational linguistics|cross-language retrieval|multilingual pretraining|data science|natural language processing|machine translation|language testing|language learning|language|cross-lingual representation|language resource|language acquisition|language generation|natural language generation,
https://openalex.org/W3082760180,Transforming machine translation: a deep learning system reaches news translation quality comparable to human professionals,"Transforming machine translation: a deep learning system reaches news translation quality comparable to human professionals

Abstract The quality of human translation was long thought to be unattainable for computer systems. In this study, we present a deep-learning system, CUBBITT, which challenges view. context-aware blind evaluation by judges, CUBBITT significantly outperformed professional-agency English-to-Czech news in preserving text meaning (translation adequacy). While is still rated as more fluent, shown substantially fluent than previous state-of-the-art Moreover, most participants Translation Turing test struggle distinguish translations from translations. This work approaches the and even surpasses it adequacy certain circumstances.This suggests that deep learning may have potential replace humans applications where conservation primary aim.

human professionals, journalism, natural language processing, machine translation, neural machine translation, translation studies, deep learning system, deep learning",2020,204,human professionals|journalism|natural language processing|machine translation|neural machine translation|translation studies|deep learning system|deep learning,
https://openalex.org/W3019166713,A Survey of the Usages of Deep Learning for Natural Language Processing,"A Survey of the Usages of Deep Learning for Natural Language Processing

Over the last several years, field of natural language processing has been propelled forward by an explosion in use deep learning models. This article provides a brief introduction to and quick overview architectures methods. It then sifts through plethora recent studies summarizes large assortment relevant contributions. Analyzed research areas include core linguistic issues addition many applications computational linguistics. A discussion current state art is provided along with recommendations for future field.

computer science, linguistics, large language model, language model, natural language processing, language, language engineering, natural language interface, machine learning, computational linguistics, deep learning, natural language, nlp task, machine translation, spoken language technology",2021,1126,computer science|linguistics|large language model|language model|natural language processing|language|language engineering|natural language interface|machine learning|computational linguistics|deep learning|natural language|nlp task|machine translation|spoken language technology,
https://openalex.org/W3118781290,The Pile: An 800GB Dataset of Diverse Text for Language Modeling,"The Pile: An 800GB Dataset of Diverse Text for Language Modeling

Recent work has demonstrated that increased training dataset diversity improves general cross-domain knowledge and downstream generalization capability for large-scale language models. With this in mind, we present \textit{the Pile}: an 825 GiB English text corpus targeted at The Pile is constructed from 22 diverse high-quality subsets -- both existing newly many of which derive academic or professional sources. Our evaluation the untuned performance GPT-2 GPT-3 on shows these models struggle its components, such as writing. Conversely, trained improve significantly over Raw CC CC-100 all components Pile, while improving evaluations. Through in-depth exploratory analysis, document potentially concerning aspects data prospective users. We make publicly available code used construction.

text mining, diverse text, language model, computational linguistics, topic model, language modeling, natural language processing, machine translation, computer science, language, large language model, large-scale datasets",2021,339,text mining|diverse text|language model|computational linguistics|topic model|language modeling|natural language processing|machine translation|computer science|language|large language model|large-scale datasets,
https://openalex.org/W3181186176,"Read Like Humans: Autonomous, Bidirectional and Iterative Language Modeling for Scene Text Recognition","Read Like Humans: Autonomous, Bidirectional and Iterative Language Modeling for Scene Text Recognition

Linguistic knowledge is of great benefit to scene text recognition. However, how effectively model linguistic rules in end-to-end deep networks remains a research challenge. In this paper, we argue that the limited capacity language models comes from: 1) implicitly modeling; 2) unidirectional feature representation; and 3) with noise input. Correspondingly, propose an autonomous, bidirectional iterative ABINet for Firstly, autonomous suggests block gradient flow between vision enforce explicitly modeling. Secondly, novel cloze network (BCN) as proposed based on representation. Thirdly, execution manner correction which can alleviate impact Additionally, ensemble predictions, self-training method learn from unlabeled images effectively. Extensive experiments indicate has superiority low-quality achieves state-of-the-art results several mainstream benchmarks. Besides, trained shows promising improvement realizing human-level Code available at https://github.com/FangShancheng/ABINet.

text mining, complexity reduction, cognitive science, language model, natural language processing, machine translation, scene text recognition, computer science, machine learning, intelligent computing, language, language recognition, text recognition, iterative language, deep learning",2021,173,text mining|complexity reduction|cognitive science|language model|natural language processing|machine translation|scene text recognition|computer science|machine learning|intelligent computing|language|language recognition|text recognition|iterative language|deep learning,
https://openalex.org/W3159892921,"Experts, Errors, and Context: A Large-Scale Study of Human Evaluation for Machine Translation","Experts, Errors, and Context: A Large-Scale Study of Human Evaluation for Machine Translation

Human evaluation of modern high-quality machine translation systems is a difficult problem, and there increasing evidence that inadequate procedures can lead to erroneous conclusions. While has been considerable research on human evaluation, the field still lacks commonly-accepted standard procedure. As step toward this goal, we propose an methodology grounded in explicit error analysis, based Multidimensional Quality Metrics (MQM) framework. We carry out largest MQM study date, scoring outputs top from WMT 2020 shared task two language pairs using annotations provided by professional translators with access full document context. analyze resulting data extensively, finding among other results substantially different ranking evaluated one established crowd workers, exhibiting clear preference for over output. Surprisingly, also find automatic metrics pre-trained embeddings outperform workers. make our corpus publicly available further research.

context (linguistics), cognitive science, human evaluation, large-scale study, machine translation, human error, error analysis",2021,157,context (linguistics)|cognitive science|human evaluation|large-scale study|machine translation|human error|error analysis,
https://openalex.org/W3185909895,HateBERT: Retraining BERT for Abusive Language Detection in English,"HateBERT: Retraining BERT for Abusive Language Detection in English

We introduce HateBERT, a re-trained BERT model for abusive language detection in English. The was trained on RAL-E, large-scale dataset of Reddit comments English from communities banned being offensive, abusive, or hateful that we have curated and made available to the public. present results detailed comparison between general pre-trained retrained version three datasets hate speech tasks. In all datasets, HateBERT outperforms corresponding model. also discuss battery experiments comparing portability fine-tuned models across suggesting is affected by compatibility annotated phenomena.

english, speech analysis, language model, bias detection, language monitoring, spoken language technology, english language, machine translation, speech communication, text mining, computational linguistics, natural language processing, computer science, retraining bert, language, spam filtering, language testing, social media, language engineering, abusive language detection",2021,153,english|speech analysis|language model|bias detection|language monitoring|spoken language technology|english language|machine translation|speech communication|text mining|computational linguistics|natural language processing|computer science|retraining bert|language|spam filtering|language testing|social media|language engineering|abusive language detection,
https://openalex.org/W3008653537,SPA-GAN: Spatial Attention GAN for Image-to-Image Translation,"SPA-GAN: Spatial Attention GAN for Image-to-Image Translation

Image-to-image translation is to learn a mapping between images from source domain and target domain. In this paper, we introduce the attention mechanism directly generative adversarial network (GAN) architecture propose novel spatial GAN model (SPA-GAN) for image-to-image tasks. SPA-GAN computes in its discriminator use it help generator focus more on most discriminative regions domains, leading realistic output images. We also find helpful an additional feature map loss training preserve specific features during translation. Compared with existing attention-guided models, lightweight that does not need networks or supervision. Qualitative quantitative comparison against state-of-the-art methods benchmark datasets demonstrates superior performance of SPA-GAN.

cognitive science, pattern recognition, machine learning, synthetic image generation, deep learning, image analysis, data science, machine translation, computational imaging, image representation, computer graphic, feature detection, scene understanding, computer science, feature learning, generative adversarial network, computer vision, spatial attention gan, image-to-image translation, machine vision",2021,143,cognitive science|pattern recognition|machine learning|synthetic image generation|deep learning|image analysis|data science|machine translation|computational imaging|image representation|computer graphic|feature detection|scene understanding|computer science|feature learning|generative adversarial network|computer vision|spatial attention gan|image-to-image translation|machine vision,
https://openalex.org/W3161027892,CURE: Code-Aware Neural Machine Translation for Automatic Program Repair,"CURE: Code-Aware Neural Machine Translation for Automatic Program Repair

Automatic program repair (APR) is crucial to improve software reliability. Recently, neural machine translation (NMT) techniques have been used automatically fix bugs. While promising, these approaches two major limitations. Their search space often does not contain the correct fix, and their strategy ignores knowledge such as strict code syntax. Due limitations, existing NMT-based underperform best template-based approaches. We propose CURE, a new APR technique with three novelties. First, CURE pre-trains programming language (PL) model on large codebase learn developer-like source before task. Second, designs code-aware that finds more fixes by focusing searching for compilable patches are close in length buggy code. Finally, uses subword tokenization generate smaller contains fixes. Our evaluation widely-used benchmarks shows correctly 57 Defects4J bugs 26 QuixBugs bugs, outperforming all both benchmarks.

automatic program repair, natural language processing, machine translation, computer science, neural machine translation",2021,140,automatic program repair|natural language processing|machine translation|computer science|neural machine translation,
https://openalex.org/W3119872582,Transformer neural network for protein-specific de novo drug generation as a machine translation problem,"Transformer neural network for protein-specific de novo drug generation as a machine translation problem

Abstract Drug discovery for a protein target is very laborious, long and costly process. Machine learning approaches and, in particular, deep generative networks can substantially reduce development time costs. However, the majority of methods imply prior knowledge binders, their physicochemical characteristics or three-dimensional structure protein. The method proposed this work generates novel molecules with predicted ability to bind by relying on its amino acid sequence only. We consider target-specific de novo drug design as translational problem between “language” simplified molecular input line entry system representation molecule. To tackle problem, we apply Transformer neural network architecture, state-of-the-art approach transduction tasks. based self-attention technique, which allows capture long-range dependencies items sequence. model realistic diverse compounds structural novelty. computed properties common metrics used fall within plausible drug-like range values.

machine translation, computer science, drug generation, transformer neural network, machine translation problem",2021,137,machine translation|computer science|drug generation|transformer neural network|machine translation problem,
https://openalex.org/W4287389673,Structured Prediction as Translation between Augmented Natural Languages,"Structured Prediction as Translation between Augmented Natural Languages

We propose a new framework, Translation between Augmented Natural Languages (TANL), to solve many structured prediction language tasks including joint entity and relation extraction, nested named recognition, classification, semantic role labeling, event coreference resolution, dialogue state tracking. Instead of tackling the problem by training task-specific discriminative classifiers, we frame it as translation task augmented natural languages, from which task-relevant information can be easily extracted. Our approach match or outperform models on all tasks, in particular, achieves state-of-the-art results extraction (CoNLL04, ADE, NYT, ACE2005 datasets), classification (FewRel TACRED), labeling (CoNLL-2005 CoNLL-2012). accomplish this while using same architecture hyperparameters for even when single model at time (multi-task learning). Finally, show that our framework also significantly improve performance low-resource regime, thanks better use label semantics.

structured prediction, machine translation, language, natural language processing, augmented natural languages",2021,124,structured prediction|machine translation|language|natural language processing|augmented natural languages,
https://openalex.org/W12732426,Generating Chinese Classical Poems with Statistical Machine Translation Models,"Generating Chinese Classical Poems with Statistical Machine Translation Models

This paper describes a statistical approach to generation of Chinese classical poetry and proposes novel method automatically evaluate poems. The system accepts set keywords representing the writing intents from writer generates sentences one by form completed poem. A machine translation (SMT) is applied generate new sentences, given generated previously. For each line sentence specific model specially trained for that used, as opposed using single all sentences. To enhance coherence on every line, mutual information select candidates with better consistency previous In addition, we demonstrate effectiveness BLEU metric evaluation generating diverse references.

text mining, language model, chinese classical poems, natural language processing, classics, machine translation, translation studies, language generation, natural language generation",2021,122,text mining|language model|chinese classical poems|natural language processing|classics|machine translation|translation studies|language generation|natural language generation,
https://openalex.org/W3173268697,Dual Contrastive Learning for Unsupervised Image-to-Image Translation,"Dual Contrastive Learning for Unsupervised Image-to-Image Translation

Unsupervised image-to-image translation tasks aim to find a mapping between source domain X and target Y from unpaired training data. Contrastive learning for Unpaired Translation (CUT) yields state-of-the-art results in modeling unsupervised by maximizing mutual information input output patches using only one encoder both domains. In this paper, we propose novel method based on contrastive dual setting (exploiting two encoders) infer an efficient Additionally, while CUT suffers mode collapse, variant of our efficiently addresses issue. We further demonstrate the advantage approach through extensive ablation studies demonstrating superior performance comparing recent approaches multiple challenging image tasks. Lastly, that gap methods supervised can be closed.

dual contrastive learning, cognitive science, multimodal learning, adaptive learning, machine learning research, machine learning, deep learning, image analysis, data science, machine translation, digital image processing, computational imaging, image representation, computer science, transfer learning, feature learning, unsupervised image-to-image translation, computer vision, image sequence analysis, machine vision",2021,121,dual contrastive learning|cognitive science|multimodal learning|adaptive learning|machine learning research|machine learning|deep learning|image analysis|data science|machine translation|digital image processing|computational imaging|image representation|computer science|transfer learning|feature learning|unsupervised image-to-image translation|computer vision|image sequence analysis|machine vision,
https://openalex.org/W3173360659,XL-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages,"XL-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages

Tahmid Hasan, Abhik Bhattacharjee, Md. Saiful Islam, Kazi Mubasshir, Yuan-Fang Li, Yong-Bin Kang, M. Sohel Rahman, Rifat Shahriyar. Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021.

text mining, multilingualism, language model, knowledge discovery, computational linguistics, large language model, multilingual pretraining, data science, natural language processing, machine translation, multi-modal summarization, computer science, automatic summarization, language, neural machine translation, language resource, information fusion, natural language generation",2021,112,text mining|multilingualism|language model|knowledge discovery|computational linguistics|large language model|multilingual pretraining|data science|natural language processing|machine translation|multi-modal summarization|computer science|automatic summarization|language|neural machine translation|language resource|information fusion|natural language generation,
https://openalex.org/W3121972911,Adversarial text-to-image synthesis: A review,"Adversarial text-to-image synthesis: A review

With the advent of generative adversarial networks, synthesizing images from textual descriptions has recently become an active research area. It is a flexible and intuitive way for conditional image generation with significant progress in last years regarding visual realism, diversity, semantic alignment. However, field still faces several challenges that require further efforts such as enabling high-resolution multiple objects, developing suitable reliable evaluation metrics correlate human judgement. In this review, we contextualize state art text-to-image synthesis models, their development since inception five ago, propose taxonomy based on level supervision. We critically examine current strategies to evaluate highlight shortcomings, identify new areas research, ranging better datasets possible improvements architectural design model training. This review complements previous surveys networks focus which believe will help researchers advance field.

adversarial machine learning, image analysis, computer vision, text-to-image retrieval, natural language processing, machine translation, computer science, machine learning, text recognition, adversarial text-to-image synthesis, deep learning",2021,112,adversarial machine learning|image analysis|computer vision|text-to-image retrieval|natural language processing|machine translation|computer science|machine learning|text recognition|adversarial text-to-image synthesis|deep learning,
https://openalex.org/W3152788712,WikiMatrix: Mining 135M Parallel Sentences in 1620 Language Pairs from Wikipedia,"WikiMatrix: Mining 135M Parallel Sentences in 1620 Language Pairs from Wikipedia

Holger Schwenk, Vishrav Chaudhary, Shuo Sun, Hongyu Gong, Francisco Guzmán. Proceedings of the 16th Conference European Chapter Association for Computational Linguistics: Main Volume. 2021.

corpus linguistics, language model, knowledge discovery, cross-language retrieval, computational lexicology, parallel programming, large language model, language resource, data science, machine translation, nlp task, text mining, computational linguistics, natural language processing, computer science, language, parallel sentences, language corpus, language pairs",2021,104,corpus linguistics|language model|knowledge discovery|cross-language retrieval|computational lexicology|parallel programming|large language model|language resource|data science|machine translation|nlp task|text mining|computational linguistics|natural language processing|computer science|language|parallel sentences|language corpus|language pairs,
https://openalex.org/W3137271899,On the different methods of translating,"On the different methods of translating

In Friedrich Schleiermacher's 1813 lecture to the Berlin Academy of Sciences, ideal translation is said create an ""image"" (Bild) that incorporates knowledge and taste ""an amateur connoisseur, a man who well acquainted with foreign language, yet whom it remains nonetheless foreign."" assigning importance sense foreignness, Schleiermacher excludes not only commercial pragmatic uses translation, but sorts paraphrase imitation long prevailed in practice commentary. He most values humanistic genres disciplines, especially literature philosophy. And he at once revives rehabilitates literalizing strategies. imagines foreignizing as nationalist can build German language overcome cultural political domination France exercised over German-speaking lands.

specialized translation, multimodal translation, different methods, machine translation, computer-assisted translation, language, translation studies",2021,103,specialized translation|multimodal translation|different methods|machine translation|computer-assisted translation|language|translation studies,
https://openalex.org/W4226146865,"Scaling Language Models: Methods, Analysis &amp; Insights from Training Gopher","Scaling Language Models: Methods, Analysis &amp; Insights from Training Gopher

Language modelling provides a step towards intelligent communication systems by harnessing large repositories of written human knowledge to better predict and understand the world. In this paper, we present an analysis Transformer-based language model performance across wide range scales -- from models with tens millions parameters up 280 billion parameter called Gopher. These are evaluated on 152 diverse tasks, achieving state-of-the-art majority. Gains scale largest in areas such as reading comprehension, fact-checking, identification toxic language, but logical mathematical reasoning see less benefit. We provide holistic training dataset model's behaviour, covering intersection bias toxicity. Finally discuss application AI safety mitigation downstream harms.

language model, computational linguistics, natural language processing, machine translation, computer science, language learning, language, large language model",2021,100,language model|computational linguistics|natural language processing|machine translation|computer science|language learning|language|large language model,
https://openalex.org/W3173190788,Contrastive Learning for Many-to-many Multilingual Neural Machine Translation,"Contrastive Learning for Many-to-many Multilingual Neural Machine Translation

Xiao Pan, Mingxuan Wang, Liwei Wu, Lei Li. Proceedings of the 59th Annual Meeting Association for Computational Linguistics and 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2021.

multilingualism, language model, computational linguistics, natural language processing, machine translation, computer science, machine learning, language learning, language, neural machine translation, transfer learning, contrastive learning",2021,98,multilingualism|language model|computational linguistics|natural language processing|machine translation|computer science|machine learning|language learning|language|neural machine translation|transfer learning|contrastive learning,
https://openalex.org/W3195725782,Gender Bias in Machine Translation,"Gender Bias in Machine Translation

Abstract Machine translation (MT) technology has facilitated our daily tasks by providing accessible shortcuts for gathering, processing, and communicating information. However, it can suffer from biases that harm users society at large. As a relatively new field of inquiry, studies gender bias in MT still lack cohesion. This advocates unified framework to ease future research. To this end, we: i) critically review current conceptualizations light theoretical insights related disciplines, ii) summarize previous analyses aimed assessing MT, iii) discuss the mitigating strategies proposed so far, iv) point toward potential directions work.

gender bias, gender studies, machine translation, translation studies, computer-assisted translation",2021,83,gender bias|gender studies|machine translation|translation studies|computer-assisted translation,
