id,title,content,year,cited_by_count,keywords,children
https://openalex.org/W2019207321,ANFIS: adaptive-network-based fuzzy inference system,"ANFIS: adaptive-network-based fuzzy inference system

The architecture and learning procedure underlying ANFIS (adaptive-network-based fuzzy inference system) is presented, which a system implemented in the framework of adaptive networks. By using hybrid procedure, proposed can construct an input-output mapping based on both human knowledge (in form if-then rules) stipulated data pairs. In simulation, employed to model nonlinear functions, identify components on-line control system, predict chaotic time series, all yielding remarkable results. Comparisons with artificial neural networks earlier work modeling are listed discussed. Other extensions promising applications automatic signal processing also suggested.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>

computer science, artificial intelligence, inference, fuzzy logic, fuzzy modeling, fuzzy pattern recognition, machine learning, fuzzy optimization, cognitive science, fuzzy computing, data science, network analysis, fuzzy expert system, neural network (machine learning), fuzzy system, fuzzy set",1993,15030,computer science|artificial intelligence|inference|fuzzy logic|fuzzy modeling|fuzzy pattern recognition|machine learning|fuzzy optimization|cognitive science|fuzzy computing|data science|network analysis|fuzzy expert system|neural network (machine learning)|fuzzy system|fuzzy set,
https://openalex.org/W2158733823,Random early detection gateways for congestion avoidance,"Random early detection gateways for congestion avoidance

The authors present random early detection (RED) gateways for congestion avoidance in packet-switched networks. gateway detects incipient by computing the average queue size. could notify connections of either dropping packets arriving at or setting a bit packet headers. When size exceeds threshold, drops marks each with certain probability, where exact probability is function RED keep low while allowing occasional bursts queue. During congestion, that notifies particular connection to reduce its window roughly proportional connection's share bandwidth through gateway. are designed accompany transport-layer control protocol such as TCP. has no bias against bursty traffic and avoids global synchronization many decreasing their same time. Simulations TCP/IP network used illustrate performance gateways.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>

early detection gateways, computer science, congestion avoidance, machine learning, early detection",1993,6216,early detection gateways|computer science|congestion avoidance|machine learning|early detection,
https://openalex.org/W2797532987,Introduction to Linear Regression Analysis.,"Introduction to Linear Regression Analysis.

Preface. Introduction. Simple Linear Regression. Multiple Model Adequacy Checking. Transformations and Weighting to Correct Inadequacies. Diagnostics for Leverage Influence. Polynomial Regression Models. Indicator Variables. Variable Selection Building. Multicollinearity. Robust Introduction Nonlinear Generalized Other Topics in the Use of Analysis. Validation Appendix A. Statistical Tables. B. Data Sets Exercises. C. Supplemental Technical Material. References. Index.

estimation theory, high-dimensional statistics, econometrics, statistical methodology, econometric method, matrix analysis, statistical inference, machine learning, applied mathematics, biostatistics, regression analysis, statistics, statistical theory, machine learning research, economic analysis, regression testing",1993,5630,estimation theory|high-dimensional statistics|econometrics|statistical methodology|econometric method|matrix analysis|statistical inference|machine learning|applied mathematics|biostatistics|regression analysis|statistics|statistical theory|machine learning research|economic analysis|regression testing,
https://openalex.org/W2119538357,The New Second Generation: Segmented Assimilation and its Variants,"The New Second Generation: Segmented Assimilation and its Variants

Post-1965 immigration to the United States has given rise a vigorous literature focused on adult newcomers. There is, however, growing new second generation whose prospects of adaptation cannot be gleaned from experience their parents or that children European immigrants arriving at turn century. We present data contemporary and review challenges it confronts in seeking American society. The concept segmented assimilation is introduced describe diverse possible outcomes this process adaptation. modes incorporation used for developing typology vulnerability resources affecting such outcomes. Empirical case studies illustrate theory highlight consequences different contextual situations facing today's generation.

data science, data assimilation, deep learning, machine learning",1993,4586,data science|data assimilation|deep learning|machine learning,
https://openalex.org/W1535110649,Interpreting Qualitative Data,"Interpreting Qualitative Data

Part I: Theory and Method in Qualitative Research What Is Research? Designing a Project Generalizing from Case Study Credible Data Analysis Ethics II: Methods Interviews Focus Groups Ethnography Documents Naturally Occurring Talk Visual Images III: Implications Writing Your Report The Relevance of Potential Research: Eight Reminders

survey methodology, qualitative analysis, qualitative research, social science research, interpretation, content analysis, social science, data science, social data analysis, statistical inference, qualitative reasoning, statistics, machine learning research, qualitative data, qualitative method, quantitative science study, statistical methodology, qualitative interpretation, ethnographic theory",1993,3604,survey methodology|qualitative analysis|qualitative research|social science research|interpretation|content analysis|social science|data science|social data analysis|statistical inference|qualitative reasoning|statistics|machine learning research|qualitative data|qualitative method|quantitative science study|statistical methodology|qualitative interpretation|ethnographic theory,
https://openalex.org/W1585743408,Multi-Interval Discretization of Continuous-Valued Attributes for Classification Learning,"Multi-Interval Discretization of Continuous-Valued Attributes for Classification Learning

Since most real-world applications of classification learning involve continuous-valued attributes, properly addressing the discretization process is an important problem. This paper addresses use entropy minimization heuristic for discretizing range a attribute into multiple intervals.

computer science, multi-interval discretization, classification learning, machine learning, continuous-valued attributes",1993,2776,computer science|multi-interval discretization|classification learning|machine learning|continuous-valued attributes,
https://openalex.org/W2165389751,A Neural System for Error Detection and Compensation,"A Neural System for Error Detection and Compensation

Humans can monitor actions and compensate for errors. Analysis of the human event-related brain potentials (ERPs) accompanying errors provides evidence a neural process whose activity is specifically associated with monitoring compensating erroneous behavior. This error-related enhanced when subjects strive accurate performance but diminished response speed emphasized at expense accuracy. The also related to attempts

computer science, neural system, machine learning, neural computation, error detection, deep learning, neural network (machine learning), neural mechanism",1993,2734,computer science|neural system|machine learning|neural computation|error detection|deep learning|neural network (machine learning)|neural mechanism,
https://openalex.org/W2129476886,Discriminant Analysis and Statistical Pattern Recognition.,"Discriminant Analysis and Statistical Pattern Recognition.

Provides a systematic account of the subject area, concentrating on most recent advances in field. While focus is practical considerations, both theoretical and issues are explored. Among covered are: regularized discriminant analysis bootstrap-based assessment performance sample-based rule extensions motivated by problems statistical image analysis. Includes over 1,200 references bibliography.

statistical pattern recognition, pattern recognition, biostatistics, high-dimensional statistics, statistics, bayesian analysis, statistical inference, independent component analysis, principal component analysis, computer science, discriminant analysis, machine learning, machine learning research, biometrics",1993,2720,statistical pattern recognition|pattern recognition|biostatistics|high-dimensional statistics|statistics|bayesian analysis|statistical inference|independent component analysis|principal component analysis|computer science|discriminant analysis|machine learning|machine learning research|biometrics,
https://openalex.org/W2099838434,The Lens Opacities Classification System III,"The Lens Opacities Classification System III

To develop the Lens Opacities Classification System III (LOCS III) to overcome limitations inherent in lens classification using LOCS II. These include unequal intervals between standards, only one standard for color grading, use of integer and wide 95% tolerance limits.The contains an expanded set standards that were selected from Longitudinal Study Cataract slide library at Center Clinical Research, Boston, Mass. It consists six slit-lamp images grading nuclear (NC) opalescence (NO), five retroillumination cortical cataract (C), posterior subcapsular (P) cataract. severity is graded on a decimal scale, have regularly spaced scale. The limits are reduced 2.0 each class with II 0.7 opalescence, color, 0.5 cataract, 1.0 III, excellent interobserver agreement.The improved system age-related

image analysis, pattern recognition, optical image recognition, computer vision, localization, image representation, machine learning research, earth science, digital image processing",1993,2647,image analysis|pattern recognition|optical image recognition|computer vision|localization|image representation|machine learning research|earth science|digital image processing,
https://openalex.org/W1566585837,Qualitative Data Analysis: A User Friendly Guide for Social Scientists,"Qualitative Data Analysis: A User Friendly Guide for Social Scientists

From the Publisher:
Qualitative Data Analysis shows that learning how to analyse qualitative data by computer can be fun. Written in a stimulating style, with examples drawn mainly from every day life and contemporary humour, it should appeal wide audience.

methodology comparison, machine learning, survey methodology, mixed-methods research, computational social science, qualitative analysis, qualitative research, social science research, quantitative social science research, social science, data science, user friendly guide, social data analysis, statistics, analytics, social scientists, quantitative science study, qualitative data analysis, statistical methodology",1993,2537,methodology comparison|machine learning|survey methodology|mixed-methods research|computational social science|qualitative analysis|qualitative research|social science research|quantitative social science research|social science|data science|user friendly guide|social data analysis|statistics|analytics|social scientists|quantitative science study|qualitative data analysis|statistical methodology,
https://openalex.org/W1995945562,An Introduction to the Bootstrap,"An Introduction to the Bootstrap

This article presents bootstrap methods for estimation, using simple arguments. Minitab macros implementing these are given.

computer science, forecasting, bootstrap resampling, statistical foundation, theory of computation, statistical inference, machine learning, applied mathematics, numerical algorithm, empirical algorithmics, foundation of mathematics, data science, knowledge discovery, statistical theory, machine learning research, quantitative science study, foundation model",1994,39983,computer science|forecasting|bootstrap resampling|statistical foundation|theory of computation|statistical inference|machine learning|applied mathematics|numerical algorithm|empirical algorithmics|foundation of mathematics|data science|knowledge discovery|statistical theory|machine learning research|quantitative science study|foundation model,https://openalex.org/W2108995755|https://openalex.org/W3103362336
https://openalex.org/W1554663460,Neural networks for pattern recognition,"Neural networks for pattern recognition

From the Publisher:
This is first comprehensive treatment of feed-forward neural networks from perspective statistical pattern recognition. After introducing basic concepts, book examines techniques for modelling probability density functions and properties merits multi-layer perceptron radial basis function network models. Also covered are various forms error functions, principal algorithms minimalization, learning generalization in networks, Bayesian their applications. Designed as a text, with over 100 exercises, this fully up-to-date work will benefit anyone involved fields computation

image analysis, pattern recognition, computer science, convolutional neural network, neural architecture search, machine learning, recurrent neural network, sparse neural network, cognitive science, temporal pattern recognition, data science, computational intelligence, deep learning, neural networks, machine learning research, neural network (machine learning), machine vision",1994,19427,image analysis|pattern recognition|computer science|convolutional neural network|neural architecture search|machine learning|recurrent neural network|sparse neural network|cognitive science|temporal pattern recognition|data science|computational intelligence|deep learning|neural networks|machine learning research|neural network (machine learning)|machine vision,https://openalex.org/W2131774270|https://openalex.org/W2108995755|https://openalex.org/W2116341502|https://openalex.org/W2194775991
https://openalex.org/W2061901927,Social Network Analysis: Methods and Applications,"Social Network Analysis: Methods and Applications

Part I. Introduction: Networks, Relations, and Structure: 1. Relations networks in the social behavioral sciences 2. Social network data: collection application II. Mathematical Representations of Networks: 3. Notation 4. Graphs matrixes III. Structural Locational Properties: 5. Centrality, prestige, related actor group measures 6. balance, clusterability, transitivity 7. Cohesive subgroups 8. Affiliations, co-memberships, overlapping IV. Roles Positions: 9. equivalence 10. Blockmodels 11. Relational algebras 12. Network positions roles V. Dyadic Triadic Methods: 13. Dyads 14. Triads VI. Statistical Interaction Models: 15. analysis single relational 16. Stochastic blockmodels goodness-of-fit indices VII. Epilogue: 17. Future directions.

complex system, statistical methodology, social network analysis, social science, communication, link analysis, computational social science, data science, network analysis, network science, knowledge discovery, machine learning research, community structure, graph analysis, social network, social data analysis",1994,17270,complex system|statistical methodology|social network analysis|social science|communication|link analysis|computational social science|data science|network analysis|network science|knowledge discovery|machine learning research|community structure|graph analysis|social network|social data analysis,https://openalex.org/W2171707538
https://openalex.org/W1562811233,Statistical Methods for Psychology.,"Statistical Methods for Psychology.

This seventh edition of Statistical Methods for Psychology, like the previous editions, surveys statistical techniques commonly used in behavioral and social sciences, especially psychology education. Although it is designed advanced undergraduates graduate students, does not assume that students have had either a course statistics or mathematics beyond high-school algebra. Those who an introductory will find early material provides welcome review. The book suitable one-term full-year course, I successfully both. Since found faculty, frequently refer back to from which they originally learned when problem, included make useful reference future use. instructor wishes omit this no difficulty doing so. cut on material, however, include only what still likely be useful. idea including every interesting led was beginning daunting.

psychological science, experimental psychology, bayesian analysis, psychological method, psychology, sampling technique, applied statistics, statistical inference, statistical methods, biostatistics, quantitative psychology, statistics, machine learning research, statistical hypothesis test, estimation theory, statistical methodology, sampling, statistical analysis, psychometrics",1994,8206,psychological science|experimental psychology|bayesian analysis|psychological method|psychology|sampling technique|applied statistics|statistical inference|statistical methods|biostatistics|quantitative psychology|statistics|machine learning research|statistical hypothesis test|estimation theory|statistical methodology|sampling|statistical analysis|psychometrics,
https://openalex.org/W2155482699,Training feedforward networks with the Marquardt algorithm,"Training feedforward networks with the Marquardt algorithm

The Marquardt algorithm for nonlinear least squares is presented and incorporated into the backpropagation training feedforward neural networks. tested on several function approximation problems, compared with a conjugate gradient variable learning rate algorithm. It found that much more efficient than either of other techniques when network contains no few hundred weights.

computer science, marquardt algorithm, feedforward networks, machine learning",1994,7302,computer science|marquardt algorithm|feedforward networks|machine learning,
https://openalex.org/W2107878631,Learning long-term dependencies with gradient descent is difficult,"Learning long-term dependencies with gradient descent is difficult

Recurrent neural networks can be used to map input sequences output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent perform tasks which the temporal contingencies present input/output span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem duration of dependencies captured increases. These results expose a trade-off between efficient by descent and latching on information periods. Based understanding this problem, alternatives standard are considered.

gradient descent, computer science, long-term dependencies, machine learning",1994,7064,gradient descent|computer science|long-term dependencies|machine learning,https://openalex.org/W2112796928|https://openalex.org/W2072128103|https://openalex.org/W2130942839|https://openalex.org/W2964308564|https://openalex.org/W2194775991|https://openalex.org/W2962730651
https://openalex.org/W1504694836,Programs for Machine Learning,"Programs for Machine Learning

Algorithms for constructing decision trees are among the most well known and widely used of all machine learning methods. Among tree algorithms, J. Ross Quinlan's ID3 its successor, C4.5, probably popular in community. These algorithms variations on them have been subject numerous research papers since Quinlan introduced ID3. Until recently, researchers looking an introduction to turned seminal 1986 Machine Learning journal article [Quinlan, 1986]. In his new book, C4.5: Programs Learning, has put together a definitive, much needed description complete system, including latest developments. As such, this book will be welcome addition library many students.

computer science, supervised learning, machine learning tool, unsupervised machine learning, machine learning, data science, reinforcement learning, knowledge discovery, machine learning model, machine learning research, neural network (machine learning), statistical software, automated machine learning",1994,5865,computer science|supervised learning|machine learning tool|unsupervised machine learning|machine learning|data science|reinforcement learning|knowledge discovery|machine learning model|machine learning research|neural network (machine learning)|statistical software|automated machine learning,https://openalex.org/W1484413656
https://openalex.org/W3125696988,Comparing Predictive Accuracy,"Comparing Predictive Accuracy

We propose and evaluate explicit tests of the null hypothesis no difference in accuracy two competing forecasts. In contrast to previously developed tests, a wide variety measures can be used (in particular, loss function need not quadratic even symmetric), forecast errors non-Gaussian, nonzero mean, serially correlated, contemporaneously correlated. Asymptotic exact finite-sample are proposed, evaluated, illustrated.

predictive learning, predictive accuracy, machine learning, accuracy and precision, statistics, performance comparison",1994,5623,predictive learning|predictive accuracy|machine learning|accuracy and precision|statistics|performance comparison,
https://openalex.org/W2102314894,An Introduction to Statistical Methods and Data Analysis,"An Introduction to Statistical Methods and Data Analysis

PART I: INTRODUCTION 1. WHAT IS STATISTICS? Introduction / Why Study Statistics? Some Current Applications of Statistics What Do Statisticians Do? Quality and Process Improvement A Note to the Student Summary Supplementary Exercises II: COLLECTING THE DATA 2. USING SURVEYS AND SCIENTIFIC STUDIES TO COLLECT Surveys Scientific Studies Observational Data Management: Preparing for Summarization Analysis III: SUMMARIZING 3. DESCRIPTION Describing on a Single Variable: Graphical Methods Measures Central Tendency Variability The Box Plot Summarizing from More Than One Variable Calculators, Computers, Software Systems Key Formulas IV: TOOLS CONCEPTS 4. PROBABILITY DISTRIBUTIONS How Probability Can Be Used in Making Inferences Finding an Event Basic Relations Laws Conditional Independence Bayes's Formula Variables: Discrete Continuous Distributions Random Variables Useful Binomial Normal Distribution Sampling Approximation V: ANALYZING DATA: CENTRAL VALUES, VARIANCES, PROPORTIONS 5. INFERENCES ON POPULATION VALUE Case Estimation Choosing Sample Size Estimating Statistical Test Testing Level Significance about Population, s Unknown Population Median 6. COMPARING TWO VALUES 1 - 2: Independent Samples Nonparametric Alternative: Wilcoxon Rank Sum Paired Signed-Rank Sizes 2 7. ABOUT VARIANCES Tests Variance Comparing Two Variances k > 8. About Checking Assumptions Alternative When are Violated: Transformations Kruskal-Wallis 9. MULTIPLE COMPARISONS Planned Comparisons Among Treatments: Linear Contrasts Which Error Rate Is Controlled Multiple with Best Treatment Comparison Treatments Control Pairwise All 10. CATEGORICAL Proportion p Proportions p1 p2 Multinomial Experiment Chi-Square Goodness-of-Fit Homogeneity Nominal Fisher's Exact Test, Permutation Association Combining Sets Contingency Tables VI: REGRESSION METHODS, MODEL BUILDING 11. SIMPLE LINEAR CORRELATION Regression Method Least Squares Linearize Correlation Look Ahead: Formulas. Exercises. 12. RELATED Diagnostics Detecting Violations Model Conditions Intercept Slope Line Mean Specified Value Explanatory Predictions Prediction Intervals Examining Lack Fit Inverse Problem (Calibration): Predicting Values x y 13. GENERAL General Estimates Parameters Several Lines Logistic Matrix Formulation 14. MODELS WITH DIAGNOSTICS Selecting (Step 1) 2) 3) VII: DESIGN OF EXPERIMENTS ANOVA 15. FOR Experiments, Treatments, Experimental Units, Blocking, Randomization, Measurement Units Many Replications? Means versus 16. ANALYSIS VARIANCE STANDARD DESIGNS Completely Randomized Design Factor Block Latin Square Factorial Experiments Differences Analyses: Transformation Friedman's Rank-Based 17. COVARIANCE Covariate Extrapolation Covariates Complicated Designs 18. SOME UNBALANCED or Missing Observations Incomplete 19. FIXED EFFECTS, RANDOM MIXED EFFECTS One-Factor Effects Extensions Random-Effects Models Mixed Model: Both Fixed Nested Factors Rules Obtaining Expected 20. SPLIT-PLOT REPEATED MEASURES Split-Plot Single-Factor Repeated Two-Factor Crossover VIII: COMMUNICATING DOCUMENTING RESULTS STUDY OR EXPERIMENT 21. Difficulty Good Communication Hurdles: Distortions Biased Report Documentation Storage Results

regression analysis, exploratory data analysis, statistics, bayesian analysis, computational statistic, statistical methods, machine learning research, applied statistics, statistical analysis, statistical software, biostatistics, statistical hypothesis test, statistical inference, logistic regression, data science, statistical model, statistical theory, statistical methodology, data analysis, data analytics",1994,5258,regression analysis|exploratory data analysis|statistics|bayesian analysis|computational statistic|statistical methods|machine learning research|applied statistics|statistical analysis|statistical software|biostatistics|statistical hypothesis test|statistical inference|logistic regression|data science|statistical model|statistical theory|statistical methodology|data analysis|data analytics,
https://openalex.org/W2030038103,"The MOS 36-ltem Short-Form Health Survey (SF-36): III. Tests of Data Quality, Scaling Assumptions, and Reliability Across Diverse Patient Groups","The MOS 36-ltem Short-Form Health Survey (SF-36): III. Tests of Data Quality, Scaling Assumptions, and Reliability Across Diverse Patient Groups

The widespread use of standardized health surveys is predicated on the largely untested assumption that scales constructed from those will satisfy minimum psychometric requirements across diverse population groups. Data Medical Outcomes Study (MOS) were used to evaluate data completeness and quality, test scaling assumptions, estimate internal-consistency reliability for eight MOS SF-36 Health Survey. Analyses conducted among 3,445 patients replicated 24 subgroups differing in sociodemographic characteristics, diagnosis, disease severity. For each scale, item-completion rates high all groups (88% 95%), but tended be somewhat lower elderly, with less than a school education, poverty. On average, complete enough compute scale scores more 96% sample. Across patient groups, passed tests item-internal consistency (97% passed) item-discriminant validity (92% passed). Reliability coefficients ranged low 0.65 0.94 (median=0.85) varied subgroups. Floor effects negligible except two role disability scales. Noteworthy ceiling observed both social functioning scale. These findings support survey populations studied identify which status measures may or not problematic.

health data, outcomes research, quality of life, weight disorder, diverse patient groups, digital medicine, physiological measurement, health informatics, patient-reported outcome, public health, statistics, machine learning research, epidemiology, quantitative science study, health services research, data quality, reliability, real world data, clinical data",1994,4342,health data|outcomes research|quality of life|weight disorder|diverse patient groups|digital medicine|physiological measurement|health informatics|patient-reported outcome|public health|statistics|machine learning research|epidemiology|quantitative science study|health services research|data quality|reliability|real world data|clinical data,
https://openalex.org/W2136796925,Markov Chains for Exploring Posterior Distributions,"Markov Chains for Exploring Posterior Distributions

Several Markov chain methods are available for sampling from a posterior distribution. Two important examples the Gibbs sampler and Metropolis algorithm. In addition, several strategies constructing hybrid algorithms. This paper outlines some of basic discusses related theoretical practical issues. On side, results theory general state space chains can be used to obtain convergence rates, laws large numbers central limit theorems estimates obtained methods. These guide construction more efficient For use methods, standard simulation methodology provides variance reduction techniques also give guidance on choice sample size allocation.

markov chains, machine learning, posterior distributions, biostatistics, statistics, markov chain monte carlo",1994,3429,markov chains|machine learning|posterior distributions|biostatistics|statistics|markov chain monte carlo,
https://openalex.org/W3124550551,Automatic Lag Selection in Covariance Matrix Estimation,"Automatic Lag Selection in Covariance Matrix Estimation

Journal Article Automatic Lag Selection in Covariance Matrix Estimation Get access Whitney K. Newey, Newey MIT Search for other works by this author on: Oxford Academic Google Scholar Kenneth D. West University of Wisconsin The Review Economic Studies, Volume 61, Issue 4, October 1994, Pages 631–653, https://doi.org/10.2307/2297912 Published: 01 1994 history Received: September 1992 Accepted: April

estimation theory, latent modeling, statistical inference, machine learning, applied mathematics, data science, statistics, machine learning research, automatic lag selection, covariance matrix estimation, principal component analysis, model selection",1994,3070,estimation theory|latent modeling|statistical inference|machine learning|applied mathematics|data science|statistics|machine learning research|automatic lag selection|covariance matrix estimation|principal component analysis|model selection,
https://openalex.org/W1608292140,"Fundamentals of neural networks: architectures, algorithms, and applications","Fundamentals of neural networks: architectures, algorithms, and applications

1. Introduction. 2. Simple Neural Nets for Pattern Classification. 3. Association. 4. Networks Based on Competition. 5. Adaptive Resonance Theory. 6. Backpropagation Net. 7. A Sampler of Other Nets. Glossary. References. Index.

computer science, artificial intelligence, neuroscience, machine learning, neural architecture search, cognitive science, neural networks, neural computation, computational neuroscience, computational intelligence, evolving neural network, neural network (machine learning)",1994,2995,computer science|artificial intelligence|neuroscience|machine learning|neural architecture search|cognitive science|neural networks|neural computation|computational neuroscience|computational intelligence|evolving neural network|neural network (machine learning),
https://openalex.org/W2157823046,"Bias in meta-analysis detected by a simple, graphical test","Bias in meta-analysis detected by a simple, graphical test

<h3>Abstract</h3> <b>Objective:</b> Funnel plots (plots of effect estimates against sample size) may be useful to detect bias in meta-analyses that were later contradicted by large trials. We examined whether a simple test asymmetry funnel predicts discordance results when are compared trials, and we assessed the prevalence published meta-analyses. <b>Design:</b> Medline search identify pairs consisting meta-analysis single trial (concordance was assumed if effects same direction meta-analytic estimate within 30% trial); analysis from 37 identified hand four leading general medicine journals 1993-6 38 second 1996 issue <i>Cochrane Database Systematic Reviews</i>. <b>Main outcome measure:</b> Degree plot as measured intercept regression standard normal deviates precision. <b>Results:</b> In eight (five cardiovascular medicine, one diabetic geriatric perinatal medicine) there concordant discordant pairs. all cases due showing larger effects. present three out but none 14 (38%) journal 5 (13%) Cochrane reviews, indicated bias. <b>Conclusions:</b> A provides for likely presence meta-analyses, capacity will limited based on number small trials such analyses should treated with considerable caution. <h3>Key messages</h3> reviews randomised best strategy appraising evidence; however, findings some plots, trials9 size, skewed asymmetrical publication other biases asymmetry, analysis, found 38% 13% Reviews</i> Critical examination systematic related considered routine procedure

meta-analysis, bias, medical internet research, bias detection, selection bias, statistical inference, research ethics, outcomes research, causal inference, biostatistics, model test, statistics, machine learning research, test coverage, graphical test, quantitative science study, clinical investigation, public health",1997,45672,meta-analysis|bias|medical internet research|bias detection|selection bias|statistical inference|research ethics|outcomes research|causal inference|biostatistics|model test|statistics|machine learning research|test coverage|graphical test|quantitative science study|clinical investigation|public health,
https://openalex.org/W1499170180,Multivariate Data Analysis,"Multivariate Data Analysis

This chapter contains sections titled: General Remarks Graphical Methods of Data Presentation Introduction Transformation Visualization Similar Features – Correlations Objects or Groups Nesting Techniques Star Plots Pictoral Representation Functional Box-Whisker Multiple Limitations Cluster Analysis Objectives Similarity Measures and Preprocessing Clustering Algorithms CA Calculations Demonstrated with a Simple Example Typical Results Illustrated an Extended Principal Components Factor Description PCA FA Canonical Correlation CCA Multivariate Variance Discriminant DA Modeling Causal Dependencies Regression Partial Least Squares Method Simultaneous Equations Path

statistical methodology, multivariate data analysis, machine learning, multivariate analysis, data science, statistics, principal component analysis",1997,17169,statistical methodology|multivariate data analysis|machine learning|multivariate analysis|data science|statistics|principal component analysis,
https://openalex.org/W2121647436,Eigenfaces vs. Fisherfaces: recognition using class specific linear projection,"Eigenfaces vs. Fisherfaces: recognition using class specific linear projection

We develop a face recognition algorithm which is insensitive to large variation in lighting direction and facial expression. Taking pattern classification approach, we consider each pixel an image as coordinate high-dimensional space. take advantage of the observation that images particular face, under varying illumination but fixed pose, lie 3D linear subspace high dimensional space-if Lambertian surface without shadowing. However, since faces are not truly surfaces do indeed produce self-shadowing, will deviate from this subspace. Rather than explicitly modeling deviation, linearly project into manner discounts those regions with deviation. Our projection method based on Fisher's discriminant produces well separated classes low-dimensional subspace, even severe expressions. The eigenface technique, another projecting space low has similar computational requirements. Yet, extensive experimental results demonstrate proposed ""Fisherface"" error rates lower technique for tests Harvard Yale databases.

image analysis, pattern recognition, computer science, computational imaging, object recognition, computer vision, machine learning, numerical linear algebra, image representation, 3d object recognition, machine learning research, facial recognition system, machine vision, face detection, facial expression recognition",1997,11826,image analysis|pattern recognition|computer science|computational imaging|object recognition|computer vision|machine learning|numerical linear algebra|image representation|3d object recognition|machine learning research|facial recognition system|machine vision|face detection|facial expression recognition,https://openalex.org/W2121647436|https://openalex.org/W2123921160|https://openalex.org/W2129812935
https://openalex.org/W2015642465,SWISS‐MODEL and the Swiss‐Pdb Viewer: An environment for comparative protein modeling,"SWISS‐MODEL and the Swiss‐Pdb Viewer: An environment for comparative protein modeling

Comparative protein modeling is increasingly gaining interest since it of great assistance during the rational design mutagenesis experiments. The availability this method, and resulting models, has however been restricted by expensive computer hardware software. To overcome these limitations, we have developed an environment for comparative that consists SWISS-MODEL, a server automated SWISS-PdbViewer, sequence to structure workbench. Swiss-PdbViewer not only acts as client but also provides large selection analysis display tools. In addition, provide SWISS-MODEL Repository, database containing more than 3500 automatically generated models. By making such tools freely available scientific community, hope increase use structures models in process experiment design.

molecular biology, bioinformatics, protein bioinformatics, protein modeling, proteomics, biomolecular structure, systems biology, protein structure prediction, comparative protein, computational biology, machine learning research, protein science, swiss-pdb viewer, biomolecular engineering, biomolecular structure prediction, protein structure, protein assembly, proteome research, structural biology, molecular informatics",1997,10779,molecular biology|bioinformatics|protein bioinformatics|protein modeling|proteomics|biomolecular structure|systems biology|protein structure prediction|comparative protein|computational biology|machine learning research|protein science|swiss-pdb viewer|biomolecular engineering|biomolecular structure prediction|protein structure|protein assembly|proteome research|structural biology|molecular informatics,
https://openalex.org/W2131774270,Bidirectional recurrent neural networks,"Bidirectional recurrent neural networks

In the first part of this paper, a regular recurrent neural network (RNN) is extended to bidirectional (BRNN). The BRNN can be trained without limitation using input information just up preset future frame. This accomplished by training it simultaneously in positive and negative time direction. Structure procedure proposed are explained. regression classification experiments on artificial data, structure gives better results than other approaches. For real for phonemes from TIMIT database show same tendency. second shown how easily modified allow efficient estimation conditional posterior probability complete symbol sequences making any explicit assumption about shape distribution. part, data reported.

computer science, machine learning, recurrent neural network, neural computation, computational neuroscience, deep learning, neural network (machine learning)",1997,7843,computer science|machine learning|recurrent neural network|neural computation|computational neuroscience|deep learning|neural network (machine learning),https://openalex.org/W2964308564|https://openalex.org/W2799041689
https://openalex.org/W2122450421,Applied Linear Statistical Models,"Applied Linear Statistical Models

Applied Linear Statistical Models 5e is the long established leading authoritative text and reference on statistical modeling. The includes brief introductory review material, then proceeds through regression modeling for first half, ANOVA Experimental Design in second half. All topics are presented a precise clear style supported with solved examples, numbered formulae, graphic illustrations, Notes to provide depth accuracy precision. Fifth edition provides an increased use of computing graphical analysis throughout, without sacrificing concepts or rigor. In general, uses larger data sets examples exercises, where methods can be automated within software loss understanding, it so done.

applied statistics, applied mathematics, statistical theory, applied mathematical modelling, statistical modeling, biostatistics, statistics, linear statistical models, statistical inference, statistical methodology, mathematical statistic, computational statistic, latent variable model, machine learning research, statistical model, applied probability",1997,6530,applied statistics|applied mathematics|statistical theory|applied mathematical modelling|statistical modeling|biostatistics|statistics|linear statistical models|statistical inference|statistical methodology|mathematical statistic|computational statistic|latent variable model|machine learning research|statistical model|applied probability,https://openalex.org/W2165389751
https://openalex.org/W2339500526,Tabu Search,"Tabu Search

From the Publisher:
This book explores meta-heuristics approach called tabu search, which is dramatically changing our ability to solve a hostof problems that stretch over realms of resource planning,telecommunications, VLSI design, financial analysis, scheduling, spaceplanning, energy distribution, molecular engineering, logistics,pattern classification, flexible manufacturing, waste management,mineral exploration, biomedical environmental conservationand scores other problems. The major ideas search arepresented with examples show their relevance multipleapplications. Numerous illustrations and diagrams are used clarifyprinciples deserve emphasis, have not always been wellunderstood or applied. book's goal provide ''hands-on' knowledge insight alike, rather than focus exclusively eitheron computational recipes on abstract themes. This designedto be useful accessible researchers practitioners inmanagement science, industrial economics, computerscience. It can appropriately as textbook in masterscourse doctoral seminar. Because its emphasis presentingideas through diagrams, identifyingassociated practical applications, it also asupplementary text upper division undergraduate courses. 

Finally, there many more applications canpossibly covered single book, new ones emerging everyday. grounding essential ideasof will allow readers create successfulapplications own. Along essentialideas,understanding advanced issues provided, enabling togo beyond today's developments methods tomorrow.

interactive information retrieval, information retrieval, web search, clustering, knowledge discovery, information fusion, data mining, knowledge representation and reasoning, semantic search, tabu search, search technology, computer science, machine learning, linguistics, machine learning research, data science, combinatorial optimization, exploratory search",1997,5917,interactive information retrieval|information retrieval|web search|clustering|knowledge discovery|information fusion|data mining|knowledge representation and reasoning|semantic search|tabu search|search technology|computer science|machine learning|linguistics|machine learning research|data science|combinatorial optimization|exploratory search,
https://openalex.org/W2115309705,The model checker SPIN,"The model checker SPIN

SPIN is an efficient verification system for models of distributed software systems. It has been used to detect design errors in applications ranging from high-level descriptions algorithms detailed code controlling telephone exchanges. The paper gives overview the and structure verifier, reviews its theoretical foundation, significant practical applications.

model checking, computer science, model checker spin, machine learning",1997,3739,model checking|computer science|model checker spin|machine learning,
https://openalex.org/W1990061958,"Algorithms on Strings, Trees and Sequences: Computer Science and Computational Biology","Algorithms on Strings, Trees and Sequences: Computer Science and Computational Biology

Part I. Exact String Matching: The Fundamental Problem: 1. matching: fundamental preprocessing and first algorithms 2. classical comparison-based methods 3. a deeper look at 4. Semi-numerical string matching II. Suffix Trees their Uses: 5. Introduction to suffix trees 6. Linear time construction of 7. First applications 8. Constant lowest common ancestor retrieval 9. More III. Inexact Matching, Sequence Alignment Dynamic Programming: 10. importance (sub)sequence comparison in molecular biology 11. Core edits, alignments dynamic programming 12. Refining core edits 13. Extending the problems 14. Multiple comparison: Holy Grail 15. database uses: motherlode IV. Currents, Cousins Cameos: 16. Maps, mapping, sequencing superstrings 17. Strings evolutionary 18. Three short topics 19. Models genome-level mutations.

pattern recognition, computer science, fuzzy logic, sequence analysis, string processing, theory of computation, combinatorial theory, applied mathematics, evolutionary computation, data science, computational biology, combinatorics on word, string-searching algorithm, machine learning research, sequence alignment, scientific computing, computational science, bioinformatics",1997,3612,pattern recognition|computer science|fuzzy logic|sequence analysis|string processing|theory of computation|combinatorial theory|applied mathematics|evolutionary computation|data science|computational biology|combinatorics on word|string-searching algorithm|machine learning research|sequence alignment|scientific computing|computational science|bioinformatics,
https://openalex.org/W2002151188,A spatial scan statistic,"A spatial scan statistic

The scan statistic is commonly used to test if a one dimensional point process purely random, or any clusters can be detected. Here it simultaneously extended in three directions:(i) spatial for the detection of multi-dimensional proposed, (ii) area scanning window allowed vary, and (iii) baseline may inhomogeneous Poisson Bernoulli with intensity pro-portional some known function. main interest detecting not explained by process. These methods are illustrated on an epidemiological data set, but there other potential areas application as well.

spatial scan statistic, spatial analysis, statistics, machine learning research, spatial statistical analysis",1997,3606,spatial scan statistic|spatial analysis|statistics|machine learning research|spatial statistical analysis,
https://openalex.org/W2105464873,Sparse coding with an overcomplete basis set: A strategy employed by V1?,"Sparse coding with an overcomplete basis set: A strategy employed by V1?

The spatial receptive fields of simple cells in mammalian striate cortex have been reasonably well described physiologically and can be characterized as being localized, oriented, bandpass, comparable with the basis functions wavelet transforms. Previously, we shown that these field properties may accounted for terms a strategy producing sparse distribution output activity response to natural images. Here, addition describing this work more expansive fashion, examine neurobiological implications coding. Of particular interest is case when code overcomplete--i.e., number elements greater than effective dimensionality input space. Because are non-orthogonal not linearly independent each other, sparsifying will recruit only those necessary representing given input, so input-output function deviate from purely linear. These deviations linearity provide potential explanation weak forms non-linearity observed cortical cells, they further make predictions about expected interactions among units naturalistic stimuli.

overcomplete basis, machine learning, sparse neural network",1997,3593,overcomplete basis|machine learning|sparse neural network,https://openalex.org/W2129812935|https://openalex.org/W2072128103
https://openalex.org/W2044503966,Time Series Analysis,"Time Series Analysis

Preface1Difference Equations12Lag Operators253Stationary ARMA Processes434Forecasting725Maximum Likelihood Estimation1176Spectral Analysis1527Asymptotic Distribution Theory1808Linear Regression Models2009Linear Systems of Simultaneous Equations23310Covariance-Stationary Vector Processes25711Vector Autoregressions29112Bayesian Analysis35113The Kalman Filter37214Generalized Method Moments40915Models Nonstationary Time Series43516Processes with Deterministic Trends45417Univariate Processes Unit Roots47518Unit Roots in Multivariate Series54419Cointegration57120Full-Information Maximum Analysis Cointegrated Systems63021Time Series Models Heteroskedasticity65722Modeling Changes Regime677A Mathematical Review704B Statistical Tables751C Answers to Selected Exercises769D Greek Letters and Symbols Used the Text786Author Index789Subject Index792

financial analysis, forecasting, trend analysis, time series analysis, nonlinear time series, applied mathematics, trend prediction, temporal pattern recognition, data science, financial time series analysis, statistics, time series, machine learning research, quantitative science study, economic analysis",1997,3571,financial analysis|forecasting|trend analysis|time series analysis|nonlinear time series|applied mathematics|trend prediction|temporal pattern recognition|data science|financial time series analysis|statistics|time series|machine learning research|quantitative science study|economic analysis,
https://openalex.org/W2149199519,THE LASSO METHOD FOR VARIABLE SELECTION IN THE COX MODEL,"THE LASSO METHOD FOR VARIABLE SELECTION IN THE COX MODEL

I propose a new method for variable selection and shrinkage in Cox's proportional hazards model. My proposal minimizes the log partial likelihood subject to sum of absolute values parameters being bounded by constant. Because nature this constraint, it shrinks coefficients produces some that are exactly zero. As result reduces estimation variance while providing an interpretable final The is variation 'lasso' Tibshirani, designed linear regression context. Simulations indicate lasso can be more accurate than stepwise setting. © 1997 John Wiley & Sons, Ltd.

high-dimensional statistics, survival analysis, variable selection, parameter identification, lasso method, statistical inference, applied mathematics, biostatistics, statistics, machine learning research, combinatorial optimization, cox model, model selection",1997,3457,high-dimensional statistics|survival analysis|variable selection|parameter identification|lasso method|statistical inference|applied mathematics|biostatistics|statistics|machine learning research|combinatorial optimization|cox model|model selection,
https://openalex.org/W2019502123,A Fast Fixed-Point Algorithm for Independent Component Analysis,"A Fast Fixed-Point Algorithm for Independent Component Analysis

We introduce a novel fast algorithm for independent component analysis, which can be used blind source separation and feature extraction. show how neural network learning rule transformed into fixedpoint iteration, provides an that is very simple, does not depend on any user-defined parameters, to converge the most accurate solution allowed by data. The finds, one at time, all nongaussian components, regardless of their probability distributions. computations performed in either batch mode or semiadaptive manner. convergence rigorously proved, speed shown cubic. Some comparisons gradient-based algorithms are made, showing new usually 10 100 times faster, sometimes giving just few iterations.

image analysis, pattern recognition, computer science, kernel method, independent component analysis, fast fixed-point algorithm, sequential algorithm, algorithmic development, mathematical optimization, machine learning, numerical algorithm, source separation, systems engineering, deep learning, computational optimization, computational science, computer engineering",1997,3353,image analysis|pattern recognition|computer science|kernel method|independent component analysis|fast fixed-point algorithm|sequential algorithm|algorithmic development|mathematical optimization|machine learning|numerical algorithm|source separation|systems engineering|deep learning|computational optimization|computational science|computer engineering,
https://openalex.org/W2112796928,Gradient-based learning applied to document recognition,"Gradient-based learning applied to document recognition

Multilayer neural networks trained with the back-propagation algorithm constitute best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based algorithms can be used to synthesize complex decision surface that classify high-dimensional patterns, such as handwritten characters, minimal preprocessing. This paper reviews various methods applied character recognition and compares them on standard digit task. Convolutional networks, which are specifically designed deal variability 2D shapes, shown outperform all other techniques. Real-life document systems composed multiple modules including field extraction, segmentation recognition, language modeling. A new paradigm, called graph transformer (GTN), allows multimodule globally using so minimize overall performance measure. Two for online handwriting described. Experiments demonstrate advantage global training, flexibility networks. reading bank cheque is also It uses convolutional recognizers combined training techniques provide record accuracy business personal cheques. deployed commercially reads several million cheques per day.

computer science, machine learning",1998,46479,computer science|machine learning,https://openalex.org/W2072128103|https://openalex.org/W2102605133|https://openalex.org/W2130942839|https://openalex.org/W1832693441|https://openalex.org/W2145287260|https://openalex.org/W2016053056|https://openalex.org/W2097117768|https://openalex.org/W1836465849|https://openalex.org/W2949117887|https://openalex.org/W1885185971|https://openalex.org/W2963446712|https://openalex.org/W2099471712|https://openalex.org/W2412782625|https://openalex.org/W2964081807|https://openalex.org/W4210257598|https://openalex.org/W3014641072|https://openalex.org/W3132455321|https://openalex.org/W3131500599|https://openalex.org/W1710476689|https://openalex.org/W4312443924|https://openalex.org/W3168997536|https://openalex.org/W3016719260|https://openalex.org/W3216759837
https://openalex.org/W2124776405,Neural Networks: A Comprehensive Foundation,"Neural Networks: A Comprehensive Foundation

From the Publisher:
This book represents most comprehensive treatment available of neural networks from an engineering perspective. Thorough, well-organized, and completely up to date, it examines all important aspects this emerging technology, including learning process, back-propagation learning, radial-basis function networks, self-organizing systems, modular temporal processing neurodynamics, VLSI implementation networks. Written in a concise fluid manner, by foremost textbook author, make material more accessible, is ideal for professional engineers graduate students entering exciting field. Computer experiments, problems, worked examples, bibliography, photographs, illustrations reinforce key concepts.

computer science, machine learning, comprehensive foundation, neural networks, neural computation, deep learning, neural network (machine learning), neuronal network",1998,30166,computer science|machine learning|comprehensive foundation|neural networks|neural computation|deep learning|neural network (machine learning)|neuronal network,https://openalex.org/W2108995755|https://openalex.org/W2118978333|https://openalex.org/W2116341502
https://openalex.org/W1484413656,Fast algorithms for mining association rules,"Fast algorithms for mining association rules

We consider the problem of discovering association rules between items in a large database sales transactions. present two new algorithms for solving thii that are fundamentally different from known algorithms. Empirical evaluation shows these outperform by factors ranging three small problems to more than an order magnitude problems. also show how best features proposed can be combined into hybrid algorithm, called AprioriHybrid. Scale-up experiments AprioriHybrid scales linearly with number has excellent scale-up properties respect transaction size and database.

computer science, pattern discovery, association rule, machine learning, knowledge discovery, frequent pattern mining, rule induction, data mining, pattern mining",1998,10779,computer science|pattern discovery|association rule|machine learning|knowledge discovery|frequent pattern mining|rule induction|data mining|pattern mining,
https://openalex.org/W2128272608,A model of saliency-based visual attention for rapid scene analysis,"A model of saliency-based visual attention for rapid scene analysis

A visual attention system, inspired by the behavior and neuronal architecture of early primate is presented. Multiscale image features are combined into a single topographical saliency map. dynamical neural network then selects attended locations in order decreasing saliency. The system breaks down complex problem scene understanding rapidly selecting, computationally efficient manner, conspicuous to be analyzed detail.

computer science, vision recognition, information fusion, scene analysis, scene interpretation, cognitive science, vision language model, data science, deep learning, pattern recognition, machine learning, computer vision, computational imaging, scene understanding, rapid scene analysis, saliency-based visual attention, machine vision, image analysis, image representation",1998,10626,computer science|vision recognition|information fusion|scene analysis|scene interpretation|cognitive science|vision language model|data science|deep learning|pattern recognition|machine learning|computer vision|computational imaging|scene understanding|rapid scene analysis|saliency-based visual attention|machine vision|image analysis|image representation,https://openalex.org/W2752782242
https://openalex.org/W2140095548,Nonlinear Component Analysis as a Kernel Eigenvalue Problem,"Nonlinear Component Analysis as a Kernel Eigenvalue Problem

A new method for performing a nonlinear form of principal component analysis is proposed. By the use integral operator kernel functions, one can efficiently compute components in high-dimensional feature spaces, related to input space by some map—for instance, all possible five-pixel products 16 × images. We give derivation and present experimental results on polynomial extraction pattern recognition.

mathematics, kernel method, nonlinear system, operator theory, nonlinear analysis, nonlinear functional analysis, mathematical optimization, nonlinear component analysis, numerical linear algebra, applied mathematics, kernel eigenvalue problem, spectral theory, markov kernel, machine learning research, nonlinear science",1998,7729,mathematics|kernel method|nonlinear system|operator theory|nonlinear analysis|nonlinear functional analysis|mathematical optimization|nonlinear component analysis|numerical linear algebra|applied mathematics|kernel eigenvalue problem|spectral theory|markov kernel|machine learning research|nonlinear science,https://openalex.org/W2008056655|https://openalex.org/W2165874743|https://openalex.org/W2108995755|https://openalex.org/W2072128103|https://openalex.org/W2106053110|https://openalex.org/W3041133507
https://openalex.org/W1515851193,Introduction to Reinforcement Learning,"Introduction to Reinforcement Learning

From the Publisher:
In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear simple account of key ideas algorithms reinforcement learning. Their discussion ranges from history field's intellectual foundations to most recent developments applications. The only necessary mathematical background is familiarity with elementary concepts probability.

computer science, artificial intelligence, deep reinforcement learning, sequential decision making, control optimization, machine learning, markov decision process, reinforcement learning, learning control, multi-agent learning",1998,6998,computer science|artificial intelligence|deep reinforcement learning|sequential decision making|control optimization|machine learning|markov decision process|reinforcement learning|learning control|multi-agent learning,https://openalex.org/W2072128103|https://openalex.org/W3011594683
https://openalex.org/W2121016876,Base-Calling of Automated Sequencer Traces Using<i>Phred.</i> I. Accuracy Assessment,"Base-Calling of Automated Sequencer Traces Using<i>Phred.</i> I. Accuracy Assessment

The availability of massive amounts DNA sequence information has begun to revolutionize the practice biology. As a result, current large-scale sequencing output, while impressive, is not adequate keep pace with growing demand and, in particular, far short what will be required obtain 3-billion-base human genome by target date 2005. To reach this goal, improved automation essential, and it particularly important that involvement data processing significantly reduced or eliminated. Progress respect require both accuracy software reliable measures reduce need for error correction make review more efficient. Here, we describe one step toward goal: base-calling program automated sequencer traces, phred, accuracy. phred appears first achieve lower rate than ABI software, averaging 40%–50% fewer errors sets examined independent position read, machine running conditions, chemistry.

automated sequencer traces, computer science, speech recognition, information fusion, sequence analysis, systems biology, clustering, machine learning, data science, computational biology, network analysis, machine learning research, high throughput sequencing, automated analysis, automated mining, sequence assembly",1998,6893,automated sequencer traces|computer science|speech recognition|information fusion|sequence analysis|systems biology|clustering|machine learning|data science|computational biology|network analysis|machine learning research|high throughput sequencing|automated analysis|automated mining|sequence assembly,https://openalex.org/W2119923823
https://openalex.org/W2048679005,Combining labeled and unlabeled data with co-training,"Combining labeled and unlabeled data with co-training

Article Free Access Share on Combining labeled and unlabeled data with co-training Authors: Avrim Blum School of Computer Science, Carnegie Mellon University, Pittsburgh, PA PAView Profile , Tom Mitchell Authors Info & Claims COLT' 98: Proceedings the eleventh annual conference Computational learning theoryJuly 1998Pages 92–100https://doi.org/10.1145/279943.279962Published:24 July 1998Publication History 3,333citation12,128DownloadsMetricsTotal Citations3,333Total Downloads12,128Last 12 Months1,744Last 6 weeks220 Get Citation AlertsNew Alert added!This alert has been successfully added will be sent to:You notified whenever a record that you have chosen cited.To manage your preferences, click button below.Manage my Alert!Please log in to account Save BinderSave BinderCreate New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF

pattern recognition, computer science, information fusion, data integration, unsupervised machine learning, machine learning, data science, knowledge discovery, data annotation, classification method, data mining",1998,5386,pattern recognition|computer science|information fusion|data integration|unsupervised machine learning|machine learning|data science|knowledge discovery|data annotation|classification method|data mining,https://openalex.org/W2118978333|https://openalex.org/W3041133507
https://openalex.org/W2119923823,Base-Calling of Automated Sequencer Traces Using <i>Phred.</i> II. Error Probabilities,"Base-Calling of Automated Sequencer Traces Using <i>Phred.</i> II. Error Probabilities

Elimination of the data processing bottleneck in high-throughput sequencing will require both improved accuracy software and reliable measures that accuracy. We have developed implemented our base-calling program phred ability to estimate a probability error for each base-call, as function certain parameters computed from trace data. These probabilities are shown here be valid (correspond actual rates) high power discriminate correct base-calls incorrect ones, read collected under several different chemistries electrophoretic conditions. They play critical role assembly phrap finishing consed.

automated sequencer traces, computer science, error probabilities, sequence analysis, outlier detection, clustering, automated deduction, biostatistics, data science, machine learning research, sequence alignment, error correction, sequence assembly",1998,5346,automated sequencer traces|computer science|error probabilities|sequence analysis|outlier detection|clustering|automated deduction|biostatistics|data science|machine learning research|sequence alignment|error correction|sequence assembly,https://openalex.org/W2121016876
https://openalex.org/W1512098439,Fast Training of Support Vector Machines Using Sequential Minimal Optimization,"Fast Training of Support Vector Machines Using Sequential Minimal Optimization

This chapter describes a new algorithm for training Support Vector Machines: Sequential Minimal Optimization, or SMO. Training Machine (SVM) requires the solution of very large quadratic programming (QP) optimization problem. SMO breaks this QP problem into series smallest possible problems. These small problems are solved analytically, which avoids using time-consuming numerical as an inner loop. The amount memory required is linear in set size, allows to handle sets. Because matrix computation avoided, scales somewhere between and size various test problems, while standard projected conjugate gradient (PCG) chunking cubic size. SMO's time dominated by SVM evaluation, hence fastest SVMs sparse data For MNIST database, fast PCG chunking; UCI Adult database SVMs, can be more than 1000 times faster algorithm.

support vector machine, sequential minimal optimization, computer science, machine learning",1998,5345,support vector machine|sequential minimal optimization|computer science|machine learning,https://openalex.org/W2008056655|https://openalex.org/W2108995755|https://openalex.org/W2172000360|https://openalex.org/W2118978333
https://openalex.org/W2151831732,Profile hidden Markov models.,"Profile hidden Markov models.

The recent literature on profile hidden Markov model (profile HMM) methods and software is reviewed. Profile HMMs turn a multiple sequence alignment into position-specific scoring system suitable for searching databases remotely homologous sequences. HMM analyses complement standard pairwise comparison large-scale analysis. Several implementations two large libraries of common protein domains are available. performed comparably to threading in the CASP2 structure prediction exercise.

topic model, statistical inference, machine learning, probabilistic graph theory, biostatistics, knowledge discovery, statistics, machine learning research, statistical model, hidden markov model",1998,5207,topic model|statistical inference|machine learning|probabilistic graph theory|biostatistics|knowledge discovery|statistics|machine learning research|statistical model|hidden markov model,
https://openalex.org/W2158275940,On combining classifiers,"On combining classifiers

We develop a common theoretical framework for combining classifiers which use distinct pattern representations and show that many existing schemes can be considered as special cases of compound classification where all the are used jointly to make decision. An experimental comparison various classifier combination demonstrates rule developed under most restrictive assumptions-the sum rule-outperforms other combinations schemes. A sensitivity analysis estimation errors is carried out this finding justified theoretically.

pattern recognition, computer science, information fusion, multiple classifier system, machine learning, unified classification, intelligent classification, machine learning research, classification method, classifier system",1998,5173,pattern recognition|computer science|information fusion|multiple classifier system|machine learning|unified classification|intelligent classification|machine learning research|classification method|classifier system,
https://openalex.org/W2008056655,Support vector machines,"Support vector machines

My first exposure to Support Vector Machines came this spring when heard Sue Dumais present impressive results on text categorization using analysis technique. This issue's collection of essays should help familiarize our readers with interesting new racehorse in the Machine Learning stable. Bernhard Scholkopf, an introductory overview, points out that a particular advantage SVMs over other learning algorithms is it can be analyzed theoretically concepts from computational theory, and at same time achieve good performance applied real problems. Examples these real-world applications are provided by Dumais, who describes aforementioned text-categorization problem, yielding best date Reuters collection, Edgar Osuna, presents strong application face detection. Our fourth author, John Platt, gives us practical guide technique for implementing algorithm efficiently.

support vector machine, computer science, deep learning, machine learning",1998,4936,support vector machine|computer science|deep learning|machine learning,https://openalex.org/W2140095548|https://openalex.org/W2108995755|https://openalex.org/W3011594683
https://openalex.org/W2912369344,Multiuser Detection,"Multiuser Detection

From the Publisher:
The development of multiuser detection techniques is one most important recent advances in communications technology. This self-contained and comprehensive book sets out basic details detection, starting with simple examples progressing to state-of-the-art applications. The only prerequisites assumed are undergraduate-level probability, linear algebra, digital communications. contains over 240 exercises will be a suitable textbook for electrical engineering students. It also an ideal self-study guide practicing engineers, as well valuable reference volume researchers communications, information theory, signal processing.

computer science, multi-user detection, anomaly detection, machine learning, deep learning, multiuser detection",1998,4875,computer science|multi-user detection|anomaly detection|machine learning|deep learning|multiuser detection,
https://openalex.org/W2147717514,Approximate nearest neighbors,"Approximate nearest neighbors

Article Free Access Share on Approximate nearest neighbors: towards removing the curse of dimensionality Authors: Piotr Indyk Department Computer Science, Stanford University, Stanford, CA CAView Profile , Rajeev Motwani Authors Info & Claims STOC '98: Proceedings thirtieth annual ACM symposium Theory computingMay 1998 Pages 604–613https://doi.org/10.1145/276698.276876Online:23 May 1998Publication History 2,363citation11,545DownloadsMetricsTotal Citations2,363Total Downloads11,545Last 12 Months769Last 6 weeks97 Get Citation AlertsNew Alert added!This alert has been successfully added and will be sent to:You notified whenever a record that you have chosen cited.To manage your preferences, click button below.Manage my Alert!Please log in to account Save BinderSave BinderCreate New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF

mathematics, graph theory, approximation theory, approximation method, mathematical optimization, low-rank approximation, applied mathematics, numerical linear algebra, similarity search, sparse representation, variable neighborhood search, numerical analysis, machine learning research, approximate reasoning, approximate nearest neighbors",1998,3982,mathematics|graph theory|approximation theory|approximation method|mathematical optimization|low-rank approximation|applied mathematics|numerical linear algebra|similarity search|sparse representation|variable neighborhood search|numerical analysis|machine learning research|approximate reasoning|approximate nearest neighbors,https://openalex.org/W2106053110
https://openalex.org/W1678356000,Greedy function approximation: A gradient boosting machine.,"Greedy function approximation: A gradient boosting machine.

Function estimation/approximation is viewed from the perspective of numerical optimization in function space, rather than parameter space. A connection made between stagewise additive expansions and steepest-descent minimization. general gradient descent “boosting” paradigm developed for based on any fitting criterion.Specific algorithms are presented least-squares, least absolute deviation, Huber-M loss functions regression, multiclass logistic likelihood classification. Special enhancements derived particular case where individual components regression trees, tools interpreting such “TreeBoost” models presented. Gradient boosting trees produces competitive, highly robust, interpretable procedures both classification, especially appropriate mining less clean data. Connections this approach methods Freund Shapire Friedman, Hastie Tibshirani discussed.

computational learning theory, computer science, supervised learning, mathematical optimization, machine learning, reinforcement learning, greedy function approximation",2001,20204,computational learning theory|computer science|supervised learning|mathematical optimization|machine learning|reinforcement learning|greedy function approximation,
https://openalex.org/W2165874743,On Spectral Clustering: Analysis and an algorithm,"On Spectral Clustering: Analysis and an algorithm

Despite many empirical successes of spectral clustering methods— algorithms that cluster points using eigenvectors matrices derived from the data—there are several unresolved issues. First. there a wide variety use in slightly different ways. Second, these have no proof they will actually compute reasonable clustering. In this paper, we present simple algorithm can be implemented few lines Matlab. Using tools matrix perturbation theory, analyze algorithm, and give conditions under which it expected to do well. We also show surprisingly good experimental results on number challenging problems.

computer science, dimensionality reduction, clustering, data science, spectral theory, spectral clustering, statistics, machine learning research, spectral analysis",2001,7646,computer science|dimensionality reduction|clustering|data science|spectral theory|spectral clustering|statistics|machine learning research|spectral analysis,https://openalex.org/W3041133507
https://openalex.org/W2123921160,From few to many: illumination cone models for face recognition under variable lighting and pose,"From few to many: illumination cone models for face recognition under variable lighting and pose

We present a generative appearance-based method for recognizing human faces under variation in lighting and viewpoint. Our exploits the fact that set of images an object fixed pose, but all possible illumination conditions, is convex cone space images. Using small number training each face taken with different directions, shape albedo can be reconstructed. In turn, this reconstruction serves as model used to render (or synthesize) novel poses conditions. The pose then sampled and, corresponding approximated by low-dimensional linear subspace whose basis vectors are estimated using model. recognition algorithm assigns test image identity closest cone. Test results show performs almost without error, except on most extreme directions.

image analysis, pattern recognition, computer science, object recognition, computer vision, machine learning, face recognition, illumination modeling, variable lighting, illumination cone models, machine vision",2001,4777,image analysis|pattern recognition|computer science|object recognition|computer vision|machine learning|face recognition|illumination modeling|variable lighting|illumination cone models|machine vision,https://openalex.org/W2129812935
https://openalex.org/W2171707538,A faster algorithm for betweenness centrality*,"A faster algorithm for betweenness centrality*

Motivated by the fast‐growing need to compute centrality indices on large, yet very sparse, networks, new algorithms for betweenness are introduced in this paper. They require O(n + m) space and run O(nm) O(nm n2 log n) time unweighted weighted respectively, where m is number of links. Experimental evidence provided that substantially increases range networks which analysis feasible. The index essential social but costly compute. Currently, fastest known ?(n 3) 2) space, n actors network.

computer science, graph theory, social network analysis, faster algorithm, algorithmic development, pseudorandom number generator, clustering, communication, applied mathematics, numerical algorithm, network analysis, network science, error correction, machine learning research, scientific computing, computational optimization",2001,4297,computer science|graph theory|social network analysis|faster algorithm|algorithmic development|pseudorandom number generator|clustering|communication|applied mathematics|numerical algorithm|network analysis|network science|error correction|machine learning research|scientific computing|computational optimization,
https://openalex.org/W4241996101,Quantile Regression,"Quantile Regression

Quantile regression, as introduced by Koenker and Bassett (1978), may be viewed an extension of classical least squares estimation conditional mean models to the ensemble for several quantile functions. The central special case is median regression estimator which minimizes a sum absolute errors. Other functions are estimated minimizing asymmetrically weighted methods illustrated with applications CEO pay, food expenditure, infant birthweight.

mathematical statistic, statistical methodology, econometrics, econometric method, applied statistics, statistical inference, applied mathematics, biostatistics, regression analysis, computational statistic, statistics, machine learning research, latent variable model, quantile regression",2001,3539,mathematical statistic|statistical methodology|econometrics|econometric method|applied statistics|statistical inference|applied mathematics|biostatistics|regression analysis|computational statistic|statistics|machine learning research|latent variable model|quantile regression,
https://openalex.org/W2082179468,Incremental dynamic analysis,"Incremental dynamic analysis

Abstract Incremental dynamic analysis (IDA) is a parametric method that has recently emerged in several different forms to estimate more thoroughly structural performance under seismic loads. It involves subjecting model one (or more) ground motion record(s), each scaled multiple levels of intensity, thus producing curve(s) response parameterized versus intensity level. To establish common frame reference, the fundamental concepts are analysed, unified terminology proposed, suitable algorithms presented, and properties IDA curve looked into for both single‐degree‐of‐freedom multi‐degree‐of‐freedom structures. In addition, summarization techniques multi‐record studies association study with conventional static pushover yield reduction R‐factor discussed. Finally, framework performance‐based earthquake engineering, assessment demand capacity viewed through lens an study. Copyright © 2001 John Wiley &amp; Sons, Ltd.

incremental dynamic analysis, computer science, machine learning, applied mathematics, dynamical analysis, program analysis, dynamic analysis, incremental learning, principal component analysis",2001,3487,incremental dynamic analysis|computer science|machine learning|applied mathematics|dynamical analysis|program analysis|dynamic analysis|incremental learning|principal component analysis,
https://openalex.org/W2108995755,An introduction to kernel-based learning algorithms,"An introduction to kernel-based learning algorithms

This paper provides an introduction to support vector machines, kernel Fisher discriminant analysis, and principal component as examples for successful kernel-based learning methods. We first give a short background about Vapnik-Chervonenkis theory feature spaces then proceed based in supervised unsupervised scenarios including practical algorithmic considerations. illustrate the usefulness of algorithms by discussing applications such optical character recognition DNA analysis.

supervised learning, reproducing kernel method, computational learning theory, kernel method, algorithmic learning, computer science, machine learning, machine learning research, kernel-based learning algorithms, deep learning",2001,3397,supervised learning|reproducing kernel method|computational learning theory|kernel method|algorithmic learning|computer science|machine learning|machine learning research|kernel-based learning algorithms|deep learning,https://openalex.org/W2106053110
https://openalex.org/W1497099219,"Matrix population models : construction, analysis, and interpretation","Matrix population models : construction, analysis, and interpretation

The age-classified matrix model stage-classified life cycles models analysis of the life-cycle graph sensitivity and evolutionary demography statistical inference time-varying stochastic density-dependent two-sex models.

mathematics, matrix analysis, random matrix, statistical inference, applied mathematics, matrix population models, matrix theory, demography, statistics, machine learning research, computational model",2001,2862,mathematics|matrix analysis|random matrix|statistical inference|applied mathematics|matrix population models|matrix theory|demography|statistics|machine learning research|computational model,
https://openalex.org/W2165715280,The recognition of human movement using temporal templates,"The recognition of human movement using temporal templates

A view-based approach to the representation and recognition of human movement is presented. The basis a temporal template-a static vector-image where vector value at each point function motion properties corresponding spatial location in an image sequence. Using aerobics exercises as test domain, we explore representational power simple, two component version templates: first binary indicating presence second recency We then develop method matching templates against stored instances views known actions. automatically performs segmentation, invariant linear changes speed, runs real-time on standard platforms.

human movement, image analysis, kinematics, pattern recognition, motion analysis, temporal templates, neuroscience, kinesiology, machine learning, motion detection, cognitive science, image representation, gesture recognition, activity recognition, movement analysis",2001,2751,human movement|image analysis|kinematics|pattern recognition|motion analysis|temporal templates|neuroscience|kinesiology|machine learning|motion detection|cognitive science|image representation|gesture recognition|activity recognition|movement analysis,
https://openalex.org/W2003582562,"Efficient, Multiple-Range Random Walk Algorithm to Calculate the Density of States","Efficient, Multiple-Range Random Walk Algorithm to Calculate the Density of States

We present a new Monte Carlo algorithm that produces results of high accuracy with reduced simulational effort. Independent random walks are performed (concurrently or serially) in different, restricted ranges energy, and the resultant density states is modified continuously to produce locally flat histograms. This method permits us directly access free energy entropy, independent temperature, efficient for study both 1st order 2nd phase transitions. It should also be useful complex systems rough landscape.

computer science, state space search, sampling, monte carlo sampling, applied mathematics, numerical algorithm, machine learning research, markov chain monte carlo",2001,2739,computer science|state space search|sampling|monte carlo sampling|applied mathematics|numerical algorithm|machine learning research|markov chain monte carlo,
https://openalex.org/W1582484699,Wavelet methods for time series analysis,"Wavelet methods for time series analysis

1. Introduction to wavelets 2. Review of Fourier theory and filters 3. Orthonormal transforms time series 4. The discrete wavelet transform 5. maximal overlap 6. packet 7. Random variables stochastic processes 8. variance 9. Analysis synthesis long memory 10. Wavelet-based signal estimation 11. Wavelet analysis finite energy signals Appendix. Answers embedded exercises References Author index Subject index.

applied mathematics, mathematical analysis, wavelet theory, time series analysis, principal component analysis, temporal pattern recognition, nonlinear time series, wavelet methods, computer science, statistical signal processing, signal processing, machine learning research, time series, wavelet",2001,2683,applied mathematics|mathematical analysis|wavelet theory|time series analysis|principal component analysis|temporal pattern recognition|nonlinear time series|wavelet methods|computer science|statistical signal processing|signal processing|machine learning research|time series|wavelet,
https://openalex.org/W2613161123,Principles of data mining,"Principles of data mining

The growing interest in data mining is motivated by a common problem across disciplines: how does one store, access, model, and ultimately describe understand very large sets? Historically, different aspects of have been addressed independently disciplines. This the first truly interdisciplinary text on mining, blending contributions information science, computer statistics. book consists three sections. first, foundations, provides tutorial overview principles underlying algorithms their application. presentation emphasizes intuition rather than rigor. second section, algorithms, shows are constructed to solve specific problems principled manner. covered include trees rules for classification regression, association rules, belief networks, classical statistical models, nonlinear models such as neural local memory-based models. third section all preceding analysis fits together when applied real-world problems. Topics role metadata, handle missing data, preprocessing.

pattern recognition, computer science, statistical methodology, evolutionary data mining, educational data mining, data classification, machine learning, predictive analytics, data science, knowledge discovery, optimization-based data mining, classification method, data mining",2001,2490,pattern recognition|computer science|statistical methodology|evolutionary data mining|educational data mining|data classification|machine learning|predictive analytics|data science|knowledge discovery|optimization-based data mining|classification method|data mining,
https://openalex.org/W2148143831,SMOTE: Synthetic Minority Over-sampling Technique,"SMOTE: Synthetic Minority Over-sampling Technique

An approach to the construction of classifiers from imbalanced datasets is described. A dataset if classification categories are not approximately equally represented. Often real-world data sets predominately composed ""normal"" examples with only a small percentage ""abnormal"" or ""interesting"" examples. It also case that cost misclassifying an abnormal (interesting) example as normal often much higher than reverse error. Under-sampling majority (normal) class has been proposed good means increasing sensitivity classifier minority class. This paper shows combination our method over-sampling (abnormal) and under-sampling can achieve better performance (in ROC space) varying loss ratios in Ripper priors Naive Bayes. Our involves creating synthetic Experiments performed using C4.5, Bayes classifier. The evaluated area under Receiver Operating Characteristic curve (AUC) convex hull strategy.

sampling (statistics), sampling, monte carlo sampling, sampling technique, applied statistics, machine learning, data heterogeneity, biostatistics, data science, deep learning, statistics, machine learning research, complex sample, data mining",2002,21724,sampling (statistics)|sampling|monte carlo sampling|sampling technique|applied statistics|machine learning|data heterogeneity|biostatistics|data science|deep learning|statistics|machine learning research|complex sample|data mining,https://openalex.org/W2148143831|https://openalex.org/W2118978333
https://openalex.org/W2160337655,A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking,"A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking

Increasingly, for many application areas, it is becoming important to include elements of nonlinearity and non-Gaussianity in order model accurately the underlying dynamics a physical system. Moreover, typically crucial process data on-line as arrives, both from point view storage costs well rapid adaptation changing signal characteristics. In this paper, we review optimal suboptimal Bayesian algorithms nonlinear/non-Gaussian tracking problems, with focus on particle filters. Particle filters are sequential Monte Carlo methods based mass (or ""particle"") representations probability densities, which can be applied any state-space generalize traditional Kalman filtering methods. Several variants filter such SIR, ASIR, RPF introduced within generic framework importance sampling (SIS) algorithm. These discussed compared standard EKF through an illustrative example.

image analysis, shift detection, computer science, nonlinear system identification, nonlinear system, object tracking, parameter identification, particle filters, computer vision, machine learning, applied mathematics, bayesian analysis, moving object tracking, statistics, nonlinear dynamic, machine vision, nonlinear science",2002,10947,image analysis|shift detection|computer science|nonlinear system identification|nonlinear system|object tracking|parameter identification|particle filters|computer vision|machine learning|applied mathematics|bayesian analysis|moving object tracking|statistics|nonlinear dynamic|machine vision|nonlinear science,
https://openalex.org/W2067191022,Mean shift: a robust approach toward feature space analysis,"Mean shift: a robust approach toward feature space analysis

A general non-parametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module an old pattern recognition procedure: mean shift. For discrete data, we prove convergence recursive shift procedure nearest stationary point underlying density function and, thus, its utility detecting modes density. relation Nadaraya-Watson estimator from kernel regression robust M-estimators; location also established. Algorithms two low-level vision tasks discontinuity-preserving smoothing image segmentation - are described as applications. In these algorithms, only user-set parameter resolution analysis, either gray-level or color images accepted input. Extensive experimental results illustrate their excellent performance.

pattern recognition, computer science, machine learning, feature space analysis, mean shift, image analysis, information fusion, structure from motion, feature detection, data science, feature (computer vision), computational imaging, robust feature, deep learning, computational statistic, machine learning research, shift detection, machine vision, computer vision, applied mathematics",2002,10781,pattern recognition|computer science|machine learning|feature space analysis|mean shift|image analysis|information fusion|structure from motion|feature detection|data science|feature (computer vision)|computational imaging|robust feature|deep learning|computational statistic|machine learning research|shift detection|machine vision|computer vision|applied mathematics,
https://openalex.org/W2999905431,Advances in Neural Information Processing Systems 14,"Advances in Neural Information Processing Systems 14

The proceedings of the 2001 Neural Information Processing Systems (NIPS) Conference. annual conference on is flagship neural computation. interdisciplinary, with contributions in algorithms, learning theory, cognitive science, neuroscience, vision, speech and signal processing, reinforcement control, implementations, diverse applications. Only about 30 percent papers submitted are accepted for presentation at NIPS, so quality exceptionally high. These contain all that were presented conference. Bradford Books imprint

computer science, artificial intelligence, machine learning, neural science, neural computation, computational intelligence, deep learning, machine learning research, neural network (machine learning), intelligent information processing, neural information",2002,8662,computer science|artificial intelligence|machine learning|neural science|neural computation|computational intelligence|deep learning|machine learning research|neural network (machine learning)|intelligent information processing|neural information,https://openalex.org/W2116341502
https://openalex.org/W2118020653,Machine learning in automated text categorization,"Machine learning in automated text categorization

The automated categorization (or classification) of texts into predefined categories has witnessed a booming interest in the last 10 years, due to increased availability documents digital form and ensuing need organize them. In research community dominant approach this problem is based on machine learning techniques: general inductive process automatically builds classifier by learning, from set preclassified documents, characteristics categories. advantages over knowledge engineering (consisting manual definition domain experts) are very good effectiveness, considerable savings terms expert labor power, straightforward portability different domains. This survey discusses main approaches text that fall within paradigm. We will discuss detail issues pertaining three problems, namely, document representation, construction, evaluation.

computer science, text mining, natural language processing, automated text categorization, machine learning, text segmentation, automatic classification, automated machine learning",2002,7691,computer science|text mining|natural language processing|automated text categorization|machine learning|text segmentation|automatic classification|automated machine learning,
https://openalex.org/W2099244020,Bilateral filtering for gray and color images,"Bilateral filtering for gray and color images

Bilateral filtering smooths images while preserving edges, by means of a nonlinear combination nearby image values. The method is noniterative, local, and simple. It combines gray levels or colors based on both their geometric closeness photometric similarity, prefers near values to distant in domain range. In contrast with filters that operate the three bands color separately, bilateral filter can enforce perceptual metric underlying CIE-Lab space, smooth preserve edges way tuned human perception. Also, standard filtering, produces no phantom along images, reduces where they appear original image.

image analysis, computational imaging, computer science, color correction, bilateral filtering, image enhancement, computer vision, machine learning, feature detection, image restoration, object detection, color images, machine vision, digital image processing",2002,7491,image analysis|computational imaging|computer science|color correction|bilateral filtering|image enhancement|computer vision|machine learning|feature detection|image restoration|object detection|color images|machine vision|digital image processing,https://openalex.org/W2067191022|https://openalex.org/W2963091558
https://openalex.org/W2172000360,A comparison of methods for multiclass support vector machines,"A comparison of methods for multiclass support vector machines

Support vector machines (SVMs) were originally designed for binary classification. How to effectively extend it multiclass classification is still an ongoing research issue. Several methods have been proposed where typically we construct a classifier by combining several classifiers. Some authors also that consider all classes at once. As computationally more expensive solve problems, comparisons of these using large-scale problems not seriously conducted. Especially solving SVM in one step, much larger optimization problem required so up now experiments are limited small data sets. In this paper give decomposition implementations two such ""all-together"" methods. We then compare their performance with three based on classifications: ""one-against-all,"" ""one-against-one,"" and directed acyclic graph (DAGSVM). Our indicate the ""one-against-one"" DAG suitable practical use than other Results show large considering once general need fewer support vectors.

kernel method, computer science, support vector machine, machine learning, applied mathematics, machine learning research",2002,6526,kernel method|computer science|support vector machine|machine learning|applied mathematics|machine learning research,
https://openalex.org/W954331293,Qualitative data analysis,"Qualitative data analysis

“Bengkel Penyelidikan Kualitatif dan Aplikasi NVivo” (Qualitative Research and Nvivo Application Workshop)” is designed for medical practitioners of the Department Public Health, School Medical Sciences, USM. Topics covered in workshop include stages qualitative research, data collection techniques report writing, with a greater emphasis on analysis.

machine learning, survey methodology, qualitative analysis, qualitative research, psychological method, social science research, content analysis, social science, data science, social data analysis, statistical software, applied statistics, statistics, qualitative method, quantitative science study, qualitative data analysis, statistical methodology, qualitative interpretation, exploratory data analysis",2002,6339,machine learning|survey methodology|qualitative analysis|qualitative research|psychological method|social science research|content analysis|social science|data science|social data analysis|statistical software|applied statistics|statistics|qualitative method|quantitative science study|qualitative data analysis|statistical methodology|qualitative interpretation|exploratory data analysis,
https://openalex.org/W2076983043,Categorical Data Analysis,"Categorical Data Analysis

Preface. 1. Introduction: Distributions and Inference for Categorical Data. 1.1 Response 1.2 1.3 Statistical 1.4 Binomial Parameters. 1.5 Multinomial Notes. Problems. 2. Describing Contingency Tables. 2.1 Probability Structure 2.2 Comparing Two Proportions. 2.3 Partial Association in Stratified 2 x 2.4 Extensions I J 3. 3.1 Confidence Intervals 3.2 Testing Independence Way 3.3 Following Up Chi Squared Tests. 3.4 Tables with Ordered Classifications. 3.5 Small Sample Tests of Independence. 3.6 . 3.7 Multiway Nontabulated Responses. 4. Introduction to Generalized Linear Models. 4.1 Model. 4.2 Models Binary 4.3 Counts. 4.4 Moments Likelihood 4.5 4.6 Fitting 4.7 Quasi likelihood 4.8 Additive 5. Logistic Regression. 5.1 Interpreting Parameters 5.2 5.3 Logit Predictors. 5.4 Multiple 5.5 Regression 6. Building Applying 6.1 Strategies Model Selection. 6.2 Diagnostics. 6.3 About Conditional Associations K 6.4 Using Improve Inferential Power. 6.5 Size Power Considerations 6.6 Probit Complementary Log 6.7 Exact 7. 7.1 Nominal Responses: Baseline Category 7.2 Ordinal Cumulative 7.3 Link 7.4 Alternative Responses 7.5 7.6 Discrete Choice 8. Loglinear 8.1 8.2 Interaction Three 8.3 8.4 Higher Dimensions. 8.5 The Connection. 8.6 Fitting: Equations Asymptotic 8.7 Iterative Methods their Application 9. Extending Loglinear/Logit 9.1 Graphs Collapsibility. 9.2 Selection Comparison. 9.3 Diagnostics Checking 9.4 Modeling Associations. 9.5 9.6 Models, Correlation Correspondence Analysis 9.7 Poisson Rates. 9.8 Empty Cells Sparseness 10. Matched Pairs. 10.1 Dependent 10.2 10.3 Marginal Square 10.4 Symmetry, symmetry, Quasiindependence. 10.5 Measuring Agreement Between Observers. 10.6 Bradley Terry Paired Preferences. 10.7 symmetry Sets 11. Analyzing Repeated 11.1 Distributions: 11.2 Modeling: Maximum Approach. 11.3 Estimating 11.4 Its GEE Multivariate Extension: Details 11.5 Markov Chains: Transitional Modeling. 12. Random Effects: Mixed 12.1 Effects Clustered 12.2 Normal 12.3 Examples 12.4 12.5 12.6 GLMM Fitting, Inference, Prediction. 13. Other Mixture Data 13.1 Latent Class 13.2 Nonparametric 13.3 Beta 13.4 Negative 13.5 Effects. 14. Theory Parametric 14.1 Delta Method. 14.2 Estimators Cell Probabilities. 14.3 Residuals Goodnessof Fit Statistics. 14.4 Logit/Loglinear 15. Estimation 15.1 Weighted Least Squares 15.2 Bayesian 15.3 Estimation. 16. Historical Tour 16.1 Pearson Yule Controversy. 16.2 R. A. Fisher s Contributions. 16.3 16.4 16.5 Recent Future? Developments. Appendix Computer Software Analyze A.1 Analysis. A.2 SAS Code by Chapter. B. Distribution Values. References. Index. Author Subject Sections marked an asterisk are less important overview.

applied mathematics, functional data analysis, data mining, statistics, combinatorial data analysis, exploratory data analysis, statistical methodology, principal component analysis, scientific data, categorical model, quantitative science study, data modeling, analytics, machine learning research, categorical data analysis, data science, statistical model, symbolic data analysis",2002,5532,applied mathematics|functional data analysis|data mining|statistics|combinatorial data analysis|exploratory data analysis|statistical methodology|principal component analysis|scientific data|categorical model|quantitative science study|data modeling|analytics|machine learning research|categorical data analysis|data science|statistical model|symbolic data analysis,
https://openalex.org/W2098693229,Face recognition using eigenfaces,"Face recognition using eigenfaces

An approach to the detection and identification of human faces is presented, a working, near-real-time face recognition system which tracks subject's head then recognizes person by comparing characteristics those known individuals described. This treats as two-dimensional problem, taking advantage fact that are normally upright thus may be described small set 2-D characteristic views. Face images projected onto feature space ('face space') best encodes variation among images. The defined 'eigenfaces', eigenvectors faces; they do not necessarily correspond isolated features such eyes, ears, noses. framework provides ability learn recognize new in an unsupervised manner.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>

pattern recognition, computer science, face recognition, image analysis, information fusion, feature detection, data science, computational imaging, localization, deep learning, machine learning research, machine vision, digital image processing, face detection, object recognition, feature extraction, computer vision, applied mathematics, image classification",2002,5301,pattern recognition|computer science|face recognition|image analysis|information fusion|feature detection|data science|computational imaging|localization|deep learning|machine learning research|machine vision|digital image processing|face detection|object recognition|feature extraction|computer vision|applied mathematics|image classification,https://openalex.org/W2121647436|https://openalex.org/W2129812935
https://openalex.org/W2161160262,An efficient k-means clustering algorithm: analysis and implementation,"An efficient k-means clustering algorithm: analysis and implementation

In k-means clustering, we are given a set of n data points in d-dimensional space R/sup d/ and an integer k the problem is to determine Rd, called centers, so as minimize mean squared distance from each point its nearest center. A popular heuristic for clustering Lloyd's (1982) algorithm. We present simple efficient implementation algorithm, which call filtering This algorithm easy implement, requiring kd-tree only major structure. establish practical efficiency two ways. First, data-sensitive analysis algorithm's running time, shows that runs faster separation between clusters increases. Second, number empirical studies both on synthetically generated real sets applications color quantization, compression, image segmentation.

computer science, unsupervised machine learning, clustering, applied mathematics, machine learning, data science, knowledge discovery, machine learning research, large-scale datasets, efficient k-means, data mining",2002,5256,computer science|unsupervised machine learning|clustering|applied mathematics|machine learning|data science|knowledge discovery|machine learning research|large-scale datasets|efficient k-means|data mining,
https://openalex.org/W2123504579,Data mining,"Data mining

No abstract available.

predictive analytics, knowledge discovery, optimization-based data mining, data mining, data stream mining, machine learning, educational data mining, pattern mining, data science, evolutionary data mining",2002,5109,predictive analytics|knowledge discovery|optimization-based data mining|data mining|data stream mining|machine learning|educational data mining|pattern mining|data science|evolutionary data mining,
https://openalex.org/W2112078820,Empirical Statistical Model To Estimate the Accuracy of Peptide Identifications Made by MS/MS and Database Search,"Empirical Statistical Model To Estimate the Accuracy of Peptide Identifications Made by MS/MS and Database Search

We present a statistical model to estimate the accuracy of peptide assignments tandem mass (MS/MS) spectra made by database search applications such as SEQUEST. Employing expectation maximization algorithm, analysis learns distinguish correct from incorrect results, computing probabilities that are based upon scores and number tryptic termini peptides. Using SEQUEST results for generated sample known protein components, we demonstrate computed accurate have high power discriminate between correctly incorrectly assigned This makes it possible filter large volumes MS/MS with predictable false identification error rates can serve common standard which different research groups compared.

functional genomics, molecular evidence, peptide, empirical statistical model, molecular biology, peptide science, bioinformatics, protein modeling, proteomics, systems biology, drug discovery, system identification, database search, molecular recognition, biostatistics, machine learning research, protein science, protein mass spectrometry, mass spectrometry, molecular informatics, peptide identifications",2002,4787,functional genomics|molecular evidence|peptide|empirical statistical model|molecular biology|peptide science|bioinformatics|protein modeling|proteomics|systems biology|drug discovery|system identification|database search|molecular recognition|biostatistics|machine learning research|protein science|protein mass spectrometry|mass spectrometry|molecular informatics|peptide identifications,
https://openalex.org/W2116064496,Training Products of Experts by Minimizing Contrastive Divergence,"Training Products of Experts by Minimizing Contrastive Divergence

It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way combining individual ""expert"" makes it hard generate samples from combined model but easy infer values latent variables each expert, because combination rule ensures that different experts are conditionally independent when given data. A product (PoE) therefore an interesting candidate for a perceptual system in which rapid inference vital generation unnecessary. Training PoE maximizing likelihood difficult even approximate derivatives renormalization term rule. Fortunately, can be trained using objective function called ""contrastive divergence"" whose with regard parameters approximated accurately efficiently. Examples presented contrastive divergence learning several types expert on

pattern recognition, computer science, training products, machine learning, knowledge distillation, image analysis, information fusion, supervised learning, robot learning, cognitive science, computational intelligence, multiple instance learning, contrastive divergence, systems engineering, deep learning, machine learning research, ensemble algorithm, machine vision, mixture of expert, neural network (machine learning)",2002,4698,pattern recognition|computer science|training products|machine learning|knowledge distillation|image analysis|information fusion|supervised learning|robot learning|cognitive science|computational intelligence|multiple instance learning|contrastive divergence|systems engineering|deep learning|machine learning research|ensemble algorithm|machine vision|mixture of expert|neural network (machine learning),https://openalex.org/W2072128103|https://openalex.org/W2799041689
https://openalex.org/W2158242434,Verification Strategies for Establishing Reliability and Validity in Qualitative Research,"Verification Strategies for Establishing Reliability and Validity in Qualitative Research

The rejection of reliability and validity in qualitative inquiry the 1980s has resulted an interesting shift for “ensuring rigor” from investigator's actions during course research, to reader or consumer inquiry. emphasis on strategies that are implemented research process been replaced by evaluating trustworthiness utility once a study is completed. In this article, we argue remain appropriate concepts attaining rigor research. We researchers should reclaim responsibility implementing verification integral self-correcting conduct itself. This ensures attainment using inherent within each design, moves incorporating maintaining external reviewers' judgements investigators themselves. Finally, make plea return terminology ensuring used mainstream science.

survey methodology, qualitative analysis, qualitative research, psychological method, confirmatory research, social science research, psychological assessment, verification strategies, statistics, machine learning research, reliability, qualitative interpretation, method validation, health science, verification, formal verification, reliability analysis, reliability engineering, public health",2002,4377,survey methodology|qualitative analysis|qualitative research|psychological method|confirmatory research|social science research|psychological assessment|verification strategies|statistics|machine learning research|reliability|qualitative interpretation|method validation|health science|verification|formal verification|reliability analysis|reliability engineering|public health,
https://openalex.org/W2156718197,Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering,"Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering

Drawing on the correspondence between graph Laplacian, Laplace-Beltrami operator a manifold, and connections to heat equation, we propose geometrically motivated algorithm for constructing representation data sampled from low dimensional manifold embedded in higher space. The provides computationally efficient approach nonlinear dimensionality reduction that has locality preserving properties natural connection clustering. Several applications are considered.

computer science, parameter identification, spectral theory, image analysis, high-dimensional statistics, graph theory, numerical linear algebra, vector space model, data science, geometrical accuracy, computational imaging, structure discovery, computational statistic, machine learning research, laplacian eigenmaps, spectral techniques, clustering, applied mathematics, knowledge discovery, spectral analysis",2002,4310,computer science|parameter identification|spectral theory|image analysis|high-dimensional statistics|graph theory|numerical linear algebra|vector space model|data science|geometrical accuracy|computational imaging|structure discovery|computational statistic|machine learning research|laplacian eigenmaps|spectral techniques|clustering|applied mathematics|knowledge discovery|spectral analysis,https://openalex.org/W2786672974|https://openalex.org/W3011667710
https://openalex.org/W2134967712,"AutoDock Vina: Improving the speed and accuracy of docking with a new scoring function, efficient optimization, and multithreading","AutoDock Vina: Improving the speed and accuracy of docking with a new scoring function, efficient optimization, and multithreading

AutoDock Vina, a new program for molecular docking and virtual screening, is presented. Vina achieves an approximately two orders of magnitude speed-up compared with the software previously developed in our lab (AutoDock 4), while also significantly improving accuracy binding mode predictions, judging by tests on training set used 4 development. Further achieved from parallelism, using multithreading multicore machines. automatically calculates grid maps clusters results way transparent to user. © 2009 Wiley Periodicals, Inc. J Comput Chem 2010

aerospace engineering, efficient optimization, machine learning, autodock vina, interactive performance system, mobile computing, unmanned aerial vehicle, drone, computer engineering, human-computer interaction, instrumentation, real-time operation, multidisciplinary optimization, performance prediction, performance portability, active control, systems engineering, automatic control, performance evaluation, performance scalability",2009,25956,aerospace engineering|efficient optimization|machine learning|autodock vina|interactive performance system|mobile computing|unmanned aerial vehicle|drone|computer engineering|human-computer interaction|instrumentation|real-time operation|multidisciplinary optimization|performance prediction|performance portability|active control|systems engineering|automatic control|performance evaluation|performance scalability,https://openalex.org/W3168436232
https://openalex.org/W3118608800,Learning Multiple Layers of Features from Tiny Images,"Learning Multiple Layers of Features from Tiny Images

In this work we describe how to train a multi-layer generative model of natural images. We use dataset millions tiny colour images, described in the next section. This has been attempted by several groups but without success. The models on which focus are RBMs (Restricted Boltzmann Machines) and DBNs (Deep Belief Networks). These learn interesting-looking filters, show more useful classifier than raw pixels. labeled subset that have collected call CIFAR-10 dataset.

image analysis, computational imaging, computer science, feature learning, computer vision, machine learning, tiny images, feature fusion, multiple layers, data science, knowledge discovery, deep learning, image representation, few-shot learning, machine vision, digital image processing, multiple instance learning",2009,21388,image analysis|computational imaging|computer science|feature learning|computer vision|machine learning|tiny images|feature fusion|multiple layers|data science|knowledge discovery|deep learning|image representation|few-shot learning|machine vision|digital image processing|multiple instance learning,https://openalex.org/W2095705004|https://openalex.org/W2102605133|https://openalex.org/W2194775991|https://openalex.org/W2963446712|https://openalex.org/W2618530766|https://openalex.org/W2099471712|https://openalex.org/W2549139847|https://openalex.org/W2752782242|https://openalex.org/W2964081807|https://openalex.org/W1710476689|https://openalex.org/W3168997536|https://openalex.org/W3216759837
https://openalex.org/W2054141820,Matrix Factorization Techniques for Recommender Systems,"Matrix Factorization Techniques for Recommender Systems

As the Netflix Prize competition has demonstrated, matrix factorization models are superior to classic nearest neighbor techniques for producing product recommendations, allowing incorporation of additional information such as implicit feedback, temporal effects, and confidence levels.

computer science, ranking algorithm, machine learning, recommender system, cold-start problem, data science, deep learning, matrix factorization, machine learning research, principal component analysis, information retrieval, matrix factorization techniques, data mining",2009,9886,computer science|ranking algorithm|machine learning|recommender system|cold-start problem|data science|deep learning|matrix factorization|machine learning research|principal component analysis|information retrieval|matrix factorization techniques|data mining,
https://openalex.org/W2129812935,Robust Face Recognition via Sparse Representation,"Robust Face Recognition via Sparse Representation

We consider the problem of automatically recognizing human faces from frontal views with varying expression and illumination, as well occlusion disguise. cast recognition one classifying among multiple linear regression models argue that new theory sparse signal representation offers key to addressing this problem. Based on a computed by l{1}-minimization, we propose general classification algorithm for (image-based) object recognition. This framework provides insights into two crucial issues in face recognition: feature extraction robustness occlusion. For extraction, show if sparsity is properly harnessed, choice features no longer critical. What critical, however, whether number sufficiently large correctly computed. Unconventional such downsampled images random projections perform just conventional Eigenfaces Laplacianfaces, long dimension space surpasses certain threshold, predicted representation. can handle errors due corruption uniformly exploiting fact these are often respect standard (pixel) basis. The helps predict how much choose training maximize conduct extensive experiments publicly available databases verify efficacy proposed corroborate above claims.

image analysis, pattern recognition, computer science, computational imaging, object recognition, feature learning, feature extraction, computer vision, machine learning, feature detection, data science, sparse representation, deep learning, image representation, machine vision, robust face recognition",2009,9264,image analysis|pattern recognition|computer science|computational imaging|object recognition|feature learning|feature extraction|computer vision|machine learning|feature detection|data science|sparse representation|deep learning|image representation|machine vision|robust face recognition,
https://openalex.org/W2024165284,Tensor Decompositions and Applications,"Tensor Decompositions and Applications

This survey provides an overview of higher-order tensor decompositions, their applications, and available software. A is a multidimensional or N-way array. Decompositions tensors (i.e., arrays with $N \geq 3$) have applications in psycho-metrics, chemometrics, signal processing, numerical linear algebra, computer vision, analysis, data mining, neuroscience, graph elsewhere. Two particular decompositions can be considered to extensions the matrix singular value decomposition: CANDECOMP/PARAFAC (CP) decomposes as sum rank-one tensors, Tucker decomposition form principal component analysis. There are many other including INDSCAL, PARAFAC2, CANDELINC, DEDICOM, PARATUCK2 well nonnegative variants all above. The Toolbox, Tensor Multilinear Engine examples software packages for working tensors.

mathematics, computational imaging, computer science, dimensionality reduction, linear algebra, operator theory, parameter identification, tensor decompositions, matrix analysis, computer vision, low-rank approximation, applied mathematics, numerical linear algebra, spectral theory, machine learning research, feature construction, computational geometry",2009,8929,mathematics|computational imaging|computer science|dimensionality reduction|linear algebra|operator theory|parameter identification|tensor decompositions|matrix analysis|computer vision|low-rank approximation|applied mathematics|numerical linear algebra|spectral theory|machine learning research|feature construction|computational geometry,
https://openalex.org/W2118978333,Learning from Imbalanced Data,"Learning from Imbalanced Data

With the continuous expansion of data availability in many large-scale, complex, and networked systems, such as surveillance, security, Internet, finance, it becomes critical to advance fundamental understanding knowledge discovery analysis from raw support decision-making processes. Although existing engineering techniques have shown great success real-world applications, problem learning imbalanced (the problem) is a relatively new challenge that has attracted growing attention both academia industry. The concerned with performance algorithms presence underrepresented severe class distribution skews. Due inherent complex characteristics sets, requires understandings, principles, algorithms, tools transform vast amounts efficiently into information representation. In this paper, we provide comprehensive review development research data. Our focus nature problem, state-of-the-art technologies, current assessment metrics used evaluate under scenario. Furthermore, order stimulate future field, also highlight major opportunities challenges, well potential important directions for

data science, machine learning, class imbalance",2009,7398,data science|machine learning|class imbalance,
https://openalex.org/W1511986666,Probabilistic graphical models : principles and techniques,"Probabilistic graphical models : principles and techniques

Most tasks require a person or an automated system to reason -- reach conclusions based on available information. The framework of probabilistic graphical models, presented in this book, provides general approach for task. is model-based, allowing interpretable models be constructed and then manipulated by reasoning algorithms. These can also learned automatically from data, the used cases where manually constructing model difficult even impossible. Because uncertainty inescapable aspect most real-world applications, book focuses which make explicit provide that are more faithful reality. Probabilistic Graphical Models discusses variety spanning Bayesian networks, undirected Markov discrete continuous extensions deal with dynamical systems relational data. For each class text describes three fundamental cornerstones: representation, inference, learning, presenting both basic concepts advanced techniques. Finally, considers use proposed causal decision making under uncertainty. main chapter detailed technical development key ideas. chapters include boxes additional material: skill boxes, describe techniques; case study discuss empirical related described text, including applications computer vision, robotics, natural language understanding, computational biology; concept present significant drawn material chapter. Instructors (and readers) group various combinations, core topics technically material, suit their particular needs.

computer science, statistical methodology, probabilistic graphical models, probabilistic programming, uncertainty analysis, statistical inference, probability theory, applied mathematics, predictive modeling, applied probability, bayesian analysis, probabilistic graph theory, probabilistic system, computational statistic, statistics, machine learning research, statistical model, graphical model",2009,6230,computer science|statistical methodology|probabilistic graphical models|probabilistic programming|uncertainty analysis|statistical inference|probability theory|applied mathematics|predictive modeling|applied probability|bayesian analysis|probabilistic graph theory|probabilistic system|computational statistic|statistics|machine learning research|statistical model|graphical model,
https://openalex.org/W2116341502,The Graph Neural Network Model,"The Graph Neural Network Model

Many underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, biology, pattern recognition, mining, can be represented terms graphs. In this paper, we propose a new neural network model, called graph (GNN) that extends existing methods for processing the domains. This GNN which directly process most practically useful types graphs, acyclic, cyclic, directed, undirected, implements function tau(G,n) isin IR <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">m</sup> maps G one its nodes <i xmlns:xlink=""http://www.w3.org/1999/xlink"">n</i> into an xmlns:xlink=""http://www.w3.org/1999/xlink"">m</i> -dimensional Euclidean space. A supervised learning algorithm is derived to estimate parameters proposed model. The computational cost also considered. Some experimental results are shown validate algorithm, demonstrate generalization capabilities.

computer science, graph theory, machine learning, neural network (machine learning), graph neural network",2009,5998,computer science|graph theory|machine learning|neural network (machine learning)|graph neural network,https://openalex.org/W2963091558|https://openalex.org/W4210257598|https://openalex.org/W3168997536|https://openalex.org/W3011667710|https://openalex.org/W3040304705
https://openalex.org/W2149531726,SeaView Version 4: A Multiplatform Graphical User Interface for Sequence Alignment and Phylogenetic Tree Building,"SeaView Version 4: A Multiplatform Graphical User Interface for Sequence Alignment and Phylogenetic Tree Building

We present SeaView version 4, a multiplatform program designed to facilitate multiple alignment and phylogenetic tree building from molecular sequence data through the use of graphical user interface. 4 combines all functions widely used programs (in its previous versions) Phylo_win, expands them by adding network access databases, with arbitrary algorithm, maximum-likelihood PhyML, display, printing, copy-to-clipboard rooted or unrooted, binary multifurcating trees. In relation wide offer tools algorithms for analyses, is especially useful teaching occasional users such software. freely available at http://pbil.univ-lyon1.fr/software/seaview.

phylogeny comparison, machine learning, molecular biology, molecular evolution, bioinformatics, avian biology, hierarchical classification, mammalogy, molecular ecology, biology, unified classification, genomics, sequence alignment, genome biology, phylogenetic tree building, sequence analysis, evolutionary biology, phylogenetics, systematics",2009,5311,phylogeny comparison|machine learning|molecular biology|molecular evolution|bioinformatics|avian biology|hierarchical classification|mammalogy|molecular ecology|biology|unified classification|genomics|sequence alignment|genome biology|phylogenetic tree building|sequence analysis|evolutionary biology|phylogenetics|systematics,
https://openalex.org/W2072128103,Learning Deep Architectures for AI,"Learning Deep Architectures for AI

Can machine learning deliver AI? Theoretical results, inspiration from the brain and cognition, as well experiments suggest that in order to learn kind of complicated functions can represent high-level abstractions (e.g. vision, language, other AI-level tasks), one would need deep architectures. Deep architectures are composed multiple levels non-linear operations, such neural nets with many hidden layers, graphical models latent variables, or propositional formulae re-using sub-formulae. Each level architecture represents features at a different abstraction, defined composition lower-level features. Searching parameter space is difficult task, but new algorithms have been discovered sub-area has emerged community since 2006, following these discoveries. Learning those for Belief Networks related unsupervised recently proposed train architectures, yielding exciting results beating state-of-the-art certain areas. Architectures AI discusses motivations principles By analyzing comparing recent explanations their success discussed, highlighting challenges suggesting avenues future explorations this area.

machine learning, computer science, deep architectures, artificial intelligence, deep learning, ai architecture",2009,5170,machine learning|computer science|deep architectures|artificial intelligence|deep learning|ai architecture,https://openalex.org/W2964153729|https://openalex.org/W2145287260|https://openalex.org/W2099471712|https://openalex.org/W1710476689
https://openalex.org/W3103362336,Power-Law Distributions in Empirical Data,"Power-Law Distributions in Empirical Data

Power-law distributions occur in many situations of scientific interest and have significant consequences for our understanding natural man-made phenomena. Unfortunately, the detection characterization power laws is complicated by large fluctuations that tail distribution—the part distribution representing but rare events—and difficulty identifying range over which power-law behavior holds. Commonly used methods analyzing data, such as least-squares fitting, can produce substantially inaccurate estimates parameters distributions, even cases where return accurate answers they are still unsatisfactory because give no indication whether data obey a law at all. Here we present principled statistical framework discerning quantifying empirical data. Our approach combines maximum-likelihood fitting with goodness-of-fit tests based on Kolmogorov–Smirnov (KS) statistic likelihood ratios. We evaluate effectiveness synthetic critical comparisons to previous approaches. also apply proposed twenty-four real-world sets from different disciplines, each has been conjectured follow distribution. In some find these conjectures be consistent while others ruled out.

economics, econometrics, power-law distributions, statistical inference, data science, data distribution, empirical data, statistics, machine learning research",2009,4061,economics|econometrics|power-law distributions|statistical inference|data science|data distribution|empirical data|statistics|machine learning research,
https://openalex.org/W2106053110,Distance Metric Learning for Large Margin Nearest Neighbor Classification,"Distance Metric Learning for Large Margin Nearest Neighbor Classification

The accuracy of k-nearest neighbor (kNN) classification depends significantly on the metric used to compute distances between different examples. In this paper, we show how learn a Mahalanobis distance for kNN from labeled can equivalently be viewed as global linear transformation input space that precedes using Euclidean distances. our approach, is trained with goal neighbors always belong same class while examples classes are separated by large margin. As in support vector machines (SVMs), margin criterion leads convex optimization based hinge loss. Unlike learning SVMs, however, approach requires no modification or extension problems multiway (as opposed binary) classification. framework, obtained solution semidefinite program. On several data sets varying size and difficulty, find metrics way lead significant improvements Sometimes these results further improved clustering training an individual within each cluster. We combine local globally integrated manner.

data science, machine learning, distance metric learning",2009,4059,data science|machine learning|distance metric learning,
https://openalex.org/W2132619562,Supervised Risk Predictor of Breast Cancer Based on Intrinsic Subtypes,"Supervised Risk Predictor of Breast Cancer Based on Intrinsic Subtypes

Purpose To improve on current standards for breast cancer prognosis and prediction of chemotherapy benefit by developing a risk model that incorporates the gene expression–based “intrinsic” subtypes luminal A, B, HER2-enriched, basal-like. Methods A 50-gene subtype predictor was developed using microarray quantitative reverse transcriptase polymerase chain reaction data from 189 prototype samples. Test sets 761 patients (no systemic therapy) were evaluated prognosis, 133 pathologic complete response (pCR) to taxane anthracycline regimen. Results The intrinsic as discrete entities showed prognostic significance (P = 2.26E-12) remained significant in multivariable analyses incorporated standard parameters (estrogen receptor status, histologic grade, tumor size, node status). node-negative built clinical information. C-index estimate combined (subtype size) improvement either clinicopathologic or alone. predicted neoadjuvant efficacy with negative predictive value pCR 97%. Conclusion Diagnosis adds information cancer. properties continuous score will be management cancers. can also used assess likelihood chemotherapy.

breast oncology, cancer care, oncology, genetics, cancer discovery, survival analysis, key site, cancer genomics, breast cancer, biostatistics, machine learning research, epidemiology, intrinsic subtypes, cancer risk, prognostic biomarkers, risk predictor, tumor biology, clinical proteomics, cancer research, biomedical informatics",2009,4012,breast oncology|cancer care|oncology|genetics|cancer discovery|survival analysis|key site|cancer genomics|breast cancer|biostatistics|machine learning research|epidemiology|intrinsic subtypes|cancer risk|prognostic biomarkers|risk predictor|tumor biology|clinical proteomics|cancer research|biomedical informatics,
https://openalex.org/W1623080549,Pattern Recognition Principles,"Pattern Recognition Principles

The present work gives an account of basic principles and available techniques for the analysis design pattern processing recognition systems. Areas covered include decision functions, classification by distance likelihood perceptron potential function approaches to trainable classifiers, statistical approach preprocessing feature selection, syntactic recognition.

image analysis, pattern recognition, computer science, fuzzy pattern recognition, statistical pattern recognition, machine learning, feature detection, pattern recognition application, deep learning, machine learning research, automatic classification, pattern recognition principles",2009,3462,image analysis|pattern recognition|computer science|fuzzy pattern recognition|statistical pattern recognition|machine learning|feature detection|pattern recognition application|deep learning|machine learning research|automatic classification|pattern recognition principles,
https://openalex.org/W2962835968,Very Deep Convolutional Networks for Large-Scale Image Recognition,"Very Deep Convolutional Networks for Large-Scale Image Recognition

In this work we investigate the effect of convolutional network depth on its accuracy in large-scale image recognition setting. Our main contribution is a thorough evaluation networks increasing using an architecture with very small (3x3) convolution filters, which shows that significant improvement prior-art configurations can be achieved by pushing to 16-19 weight layers. These findings were basis our ImageNet Challenge 2014 submission, where team secured first and second places localisation classification tracks respectively. We also show representations generalise well other datasets, they achieve state-of-the-art results. have made two best-performing ConvNet models publicly available facilitate further research use deep visual computer vision.

digital image processing, automatic classification, deep convolutional networks, computer science, machine learning research, deep learning, pattern recognition, machine vision, image representation, large-scale image recognition, large-scale datasets, computational imaging, machine learning, data science, cognitive science, computational intelligence, convolutional neural network, feature detection, unsupervised machine learning, image analysis",2014,49225,digital image processing|automatic classification|deep convolutional networks|computer science|machine learning research|deep learning|pattern recognition|machine vision|image representation|large-scale image recognition|large-scale datasets|computational imaging|machine learning|data science|cognitive science|computational intelligence|convolutional neural network|feature detection|unsupervised machine learning|image analysis,https://openalex.org/W1903029394|https://openalex.org/W1536680647|https://openalex.org/W2953106684|https://openalex.org/W2613718673|https://openalex.org/W2109255472|https://openalex.org/W2194775991|https://openalex.org/W2183341477|https://openalex.org/W2295107390|https://openalex.org/W2962914239|https://openalex.org/W639708223|https://openalex.org/W2565639579|https://openalex.org/W2962793481|https://openalex.org/W2531409750|https://openalex.org/W2962858109|https://openalex.org/W2963470893|https://openalex.org/W2549139847|https://openalex.org/W2752782242|https://openalex.org/W2412782625|https://openalex.org/W2963163009|https://openalex.org/W2963091558|https://openalex.org/W2963125010|https://openalex.org/W2962785568|https://openalex.org/W2963857746|https://openalex.org/W2964081807|https://openalex.org/W2964241181|https://openalex.org/W2962730651|https://openalex.org/W3014641072|https://openalex.org/W3132455321|https://openalex.org/W3131500599|https://openalex.org/W3170841864|https://openalex.org/W4312443924|https://openalex.org/W4313156423|https://openalex.org/W3168997536|https://openalex.org/W3016719260|https://openalex.org/W2799041689|https://openalex.org/W4386076325
https://openalex.org/W1686810756,Very Deep Convolutional Networks for Large-Scale Image Recognition,"Very Deep Convolutional Networks for Large-Scale Image Recognition

In this work we investigate the effect of convolutional network depth on its accuracy in large-scale image recognition setting. Our main contribution is a thorough evaluation networks increasing using an architecture with very small (3x3) convolution filters, which shows that significant improvement prior-art configurations can be achieved by pushing to 16-19 weight layers. These findings were basis our ImageNet Challenge 2014 submission, where team secured first and second places localisation classification tracks respectively. We also show representations generalise well other datasets, they achieve state-of-the-art results. have made two best-performing ConvNet models publicly available facilitate further research use deep visual computer vision.

computer science, unsupervised machine learning, convolutional neural network, large-scale datasets, deep convolutional networks, cognitive science, digital image processing, large-scale image recognition, data science, deep learning, pattern recognition, automatic classification, machine learning, computational imaging, machine learning research, machine vision, image analysis, computational intelligence, feature detection, image representation",2014,42084,computer science|unsupervised machine learning|convolutional neural network|large-scale datasets|deep convolutional networks|cognitive science|digital image processing|large-scale image recognition|data science|deep learning|pattern recognition|automatic classification|machine learning|computational imaging|machine learning research|machine vision|image analysis|computational intelligence|feature detection|image representation,https://openalex.org/W1903029394|https://openalex.org/W1536680647|https://openalex.org/W1677182931|https://openalex.org/W2109255472|https://openalex.org/W2183341477|https://openalex.org/W2962914239|https://openalex.org/W639708223|https://openalex.org/W2962793481|https://openalex.org/W2963881378|https://openalex.org/W2531409750|https://openalex.org/W2560023338|https://openalex.org/W2612445135|https://openalex.org/W2963125010|https://openalex.org/W2962785568|https://openalex.org/W2963857746|https://openalex.org/W3140854437|https://openalex.org/W3131500599|https://openalex.org/W3016719260|https://openalex.org/W2799041689
https://openalex.org/W2095705004,Dropout: a simple way to prevent neural networks from overfitting,"Dropout: a simple way to prevent neural networks from overfitting

Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is serious problem in such networks. Large networks also slow to use, making it difficult deal by combining the predictions many different at test time. Dropout technique for addressing this problem. The key idea randomly drop units (along their connections) from network during training. This prevents co-adapting too much. During training, dropout samples an exponential thinned At time, easy approximate effect averaging all these simply using single unthinned that has smaller weights. significantly reduces and gives major improvements over other regularization methods. We show improves performance on supervised tasks vision, speech recognition, document classification computational biology, obtaining state-of-the-art results benchmark data sets.

adversarial machine learning, computer science, artificial intelligence, machine learning, neural networks, neural computation, deep learning, neural network (machine learning)",2014,31290,adversarial machine learning|computer science|artificial intelligence|machine learning|neural networks|neural computation|deep learning|neural network (machine learning),https://openalex.org/W1836465849|https://openalex.org/W2949117887|https://openalex.org/W1677182931|https://openalex.org/W1821462560|https://openalex.org/W2963446712|https://openalex.org/W2964081807|https://openalex.org/W3140854437|https://openalex.org/W3011667710|https://openalex.org/W3016719260|https://openalex.org/W2799041689|https://openalex.org/W3042609801
https://openalex.org/W2102605133,Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation,"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation

Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable algorithm improves mean average precision (mAP) by more than 30% relative to previous best result 2012 -- achieving mAP of 53.3%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) bottom-up region proposals order localize segment objects (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed domain-specific fine-tuning, yields significant performance boost. Since CNNs, call our method R-CNN: Regions CNN features. We also present experiments provide insight into what network learns, revealing rich hierarchy Source code complete system available at http://www.cs.berkeley.edu/~rbg/rcnn.

pattern recognition, computer science, machine learning, fuzzy set, image analysis, information fusion, accurate object detection, feature detection, cognitive science, object detection, data science, object categorization, computational imaging, localization, deep learning, machine vision, rich feature hierarchies, semantic segmentation, object recognition, computer vision, scene analysis",2014,24628,pattern recognition|computer science|machine learning|fuzzy set|image analysis|information fusion|accurate object detection|feature detection|cognitive science|object detection|data science|object categorization|computational imaging|localization|deep learning|machine vision|rich feature hierarchies|semantic segmentation|object recognition|computer vision|scene analysis,https://openalex.org/W1686810756|https://openalex.org/W2964153729|https://openalex.org/W2016053056|https://openalex.org/W2097117768|https://openalex.org/W1903029394|https://openalex.org/W1536680647|https://openalex.org/W2953106684|https://openalex.org/W1677182931|https://openalex.org/W2613718673|https://openalex.org/W2109255472|https://openalex.org/W2194775991|https://openalex.org/W2963037989|https://openalex.org/W2183341477|https://openalex.org/W2295107390|https://openalex.org/W639708223|https://openalex.org/W2963150697|https://openalex.org/W2565639579|https://openalex.org/W2962858109|https://openalex.org/W2549139847|https://openalex.org/W2412782625|https://openalex.org/W2963125010|https://openalex.org/W2963857746|https://openalex.org/W2964241181|https://openalex.org/W4312443924|https://openalex.org/W3168997536|https://openalex.org/W2799041689|https://openalex.org/W4320002812
https://openalex.org/W2105846236,A new criterion for assessing discriminant validity in variance-based structural equation modeling,"A new criterion for assessing discriminant validity in variance-based structural equation modeling

Discriminant validity assessment has become a generally accepted prerequisite for analyzing relationships between latent variables. For variance-based structural equation modeling, such as partial least squares, the Fornell-Larcker criterion and examination of cross-loadings are dominant approaches evaluating discriminant validity. By means simulation study, we show that these do not reliably detect lack in common research situations. We therefore propose an alternative approach, based on multitrait-multimethod matrix, to assess validity: heterotrait-monotrait ratio correlations. demonstrate its superior performance by Monte Carlo which compare new approach (partial) cross-loadings. Finally, provide guidelines how handle issues modeling.

discriminant validity, machine learning, statistics, latent variable model",2014,18455,discriminant validity|machine learning|statistics|latent variable model,
https://openalex.org/W2111647009,IQ-TREE: A Fast and Effective Stochastic Algorithm for Estimating Maximum-Likelihood Phylogenies,"IQ-TREE: A Fast and Effective Stochastic Algorithm for Estimating Maximum-Likelihood Phylogenies

Large phylogenomics data sets require fast tree inference methods, especially for maximum-likelihood (ML) phylogenies. Fast programs exist, but due to inherent heuristics find optimal trees, it is not clear whether the best found. Thus, there need additional approaches that employ different search strategies ML trees and are at same time as currently available programs. We show a combination of hill-climbing stochastic perturbation method can be time-efficiently implemented. If we allow CPU RAxML PhyML, then our software IQ-TREE found higher likelihoods between 62.2% 87.1% studied alignments, thus efficiently exploring tree-space. use stopping rule, PhyML faster in 75.7% 47.1% DNA alignments 42.2% 100% protein respectively. However, range obtaining with improves 73.3–97.1%. freely http://www.cibiv.at/software/iqtree.

effective stochastic algorithm, sequence analysis, evolutionary biology, statistical inference, clustering, machine learning, outlier detection, biostatistics, data science, phylogenetics, maximum-likelihood phylogenies, bioinformatics",2014,18339,effective stochastic algorithm|sequence analysis|evolutionary biology|statistical inference|clustering|machine learning|outlier detection|biostatistics|data science|phylogenetics|maximum-likelihood phylogenies|bioinformatics,
https://openalex.org/W2157331557,Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation,"Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation

Kyunghyun Cho, Bart van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2014.

knowledge discovery, word embeddings, computer science, recurrent neural network, language model, machine learning research, deep learning, sequence modelling, natural language processing, machine translation, rnn encoder-decoder, language learning, machine learning, linguistics, data science, computational linguistics, statistical machine translation, neural machine translation, convolutional neural network, phrase representations",2014,16242,knowledge discovery|word embeddings|computer science|recurrent neural network|language model|machine learning research|deep learning|sequence modelling|natural language processing|machine translation|rnn encoder-decoder|language learning|machine learning|linguistics|data science|computational linguistics|statistical machine translation|neural machine translation|convolutional neural network|phrase representations,https://openalex.org/W2964199361|https://openalex.org/W2964308564|https://openalex.org/W2962784628|https://openalex.org/W4210257598|https://openalex.org/W3011667710
https://openalex.org/W2130942839,Sequence to Sequence Learning with Neural Networks,"Sequence to Sequence Learning with Neural Networks

Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets available, they cannot be used to map sequences sequences. In this paper, we present a general end-to-end approach sequence makes minimal assumptions the structure. Our method uses multilayered Long Short-Term Memory (LSTM) input vector of fixed dimensionality, and then another deep LSTM decode target from vector. main result is an English French translation task WMT'14 dataset, translations produced by achieve BLEU score 34.8 entire test set, where LSTM's was penalized out-of-vocabulary words. Additionally, did not difficulty long sentences. For comparison, phrase-based SMT system achieves 33.3 same dataset. When rerank 1000 hypotheses aforementioned system, its increases 36.5, which close previous best task. The also learned sensible phrase sentence representations sensitive word order relatively invariant active passive voice. Finally, found reversing words in all source sentences (but sentences) improved markedly, because doing so introduced many short term dependencies between made optimization problem easier.

neural networks, knowledge discovery, sparse neural network, neural network (machine learning), sequential learning, computer science, recurrent neural network, deep reinforcement learning, machine learning research, deep learning, sequence modelling, machine vision, natural language processing, natural language generation, machine learning, data science, neural computation, cognitive science, computational intelligence",2014,12686,neural networks|knowledge discovery|sparse neural network|neural network (machine learning)|sequential learning|computer science|recurrent neural network|deep reinforcement learning|machine learning research|deep learning|sequence modelling|machine vision|natural language processing|natural language generation|machine learning|data science|neural computation|cognitive science|computational intelligence,https://openalex.org/W2964199361|https://openalex.org/W2271840356|https://openalex.org/W2962784628
https://openalex.org/W1832693441,Convolutional Neural Networks for Sentence Classification,"Convolutional Neural Networks for Sentence Classification

We report on a series of experiments with convolutional neural networks (CNN) trained top pre-trained word vectors for sentence-level classification tasks.We show that simple CNN little hyperparameter tuning and static achieves excellent results multiple benchmarks.Learning task-specific through fine-tuning offers further gains in performance.We additionally propose modification to the architecture allow use both vectors.The models discussed herein improve upon state art 4 out 7 tasks, which include sentiment analysis question classification.

knowledge discovery, nlp task, neural network (machine learning), sequential learning, computer science, machine learning research, deep learning, neuroscience, natural language processing, machine translation, semantic interpretation, text processing, sentence classification, machine learning, neural computation, cognitive science, computational intelligence, semantic evaluation, convolutional neural network",2014,11322,knowledge discovery|nlp task|neural network (machine learning)|sequential learning|computer science|machine learning research|deep learning|neuroscience|natural language processing|machine translation|semantic interpretation|text processing|sentence classification|machine learning|neural computation|cognitive science|computational intelligence|semantic evaluation|convolutional neural network,https://openalex.org/W3168997536|https://openalex.org/W3185341429
https://openalex.org/W4297734170,Neural Machine Translation by Jointly Learning to Align and Translate,"Neural Machine Translation by Jointly Learning to Align and Translate

Neural machine translation is a recently proposed approach to translation. Unlike the traditional statistical translation, neural aims at building single network that can be jointly tuned maximize performance. The models for often belong family of encoder-decoders and consists an encoder encodes source sentence into fixed-length vector from which decoder generates In this paper, we conjecture use bottleneck in improving performance basic encoder-decoder architecture, propose extend by allowing model automatically (soft-)search parts are relevant predicting target word, without having form these as hard segment explicitly. With new approach, achieve comparable existing state-of-the-art phrase-based system on task English-to-French Furthermore, qualitative analysis reveals (soft-)alignments found agree well with our intuition.

transfer learning, neural computation, natural language processing, machine translation, computer-assisted translation, neural network (machine learning), computational intelligence, computer science, neural machine translation, machine learning, linguistics, language, deep learning, machine learning research",2014,9323,transfer learning|neural computation|natural language processing|machine translation|computer-assisted translation|neural network (machine learning)|computational intelligence|computer science|neural machine translation|machine learning|linguistics|language|deep learning|machine learning research,https://openalex.org/W2962784628
https://openalex.org/W1924770834,Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling,"Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling

In this paper we compare different types of recurrent units in neural networks (RNNs). Especially, focus on more sophisticated that implement a gating mechanism, such as long short-term memory (LSTM) unit and recently proposed gated (GRU). We evaluate these the tasks polyphonic music modeling speech signal modeling. Our experiments revealed advanced are indeed better than traditional tanh units. Also, found GRU to be comparable LSTM.

computer science, sequence modeling, neuroimaging, neuroscience, machine learning, recurrent neural network, sequential learning, sparse neural network, data science, neural computation, deep learning, computational intelligence, machine learning research, sequence modelling, neural network (machine learning), empirical evaluation",2014,9208,computer science|sequence modeling|neuroimaging|neuroscience|machine learning|recurrent neural network|sequential learning|sparse neural network|data science|neural computation|deep learning|computational intelligence|machine learning research|sequence modelling|neural network (machine learning)|empirical evaluation,
https://openalex.org/W2125389028,Conditional Generative Adversarial Nets,"Conditional Generative Adversarial Nets

Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of adversarial nets, which can be constructed by simply feeding data, y, wish condition on both generator and discriminator. We show that model generate MNIST digits conditioned class labels. also illustrate how could used learn multi-modal model, provide preliminary examples an application image tagging in demonstrate approach descriptive tags are not part training

adversarial machine learning, computer science, generative adversarial network, machine learning, generative model, generative ai, generative system, deep learning, machine learning research, neural network (machine learning)",2014,7898,adversarial machine learning|computer science|generative adversarial network|machine learning|generative model|generative ai|generative system|deep learning|machine learning research|neural network (machine learning),https://openalex.org/W2963073614|https://openalex.org/W3132455321|https://openalex.org/W2799041689|https://openalex.org/W3216759837
https://openalex.org/W2123442489,The Stanford CoreNLP Natural Language Processing Toolkit,"The Stanford CoreNLP Natural Language Processing Toolkit

Christopher Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven Bethard, David McClosky. Proceedings of 52nd Annual Meeting the Association for Computational Linguistics: System Demonstrations. 2014.

computer science, linguistics, knowledge representation and reasoning, keyword extraction, language model, natural language processing, natural language generation, natural language interface, syntactic parsing, computational linguistics, data science, knowledge discovery, deep learning, nlp task, machine learning research, machine translation, semantic parsing, spoken language technology",2014,6760,computer science|linguistics|knowledge representation and reasoning|keyword extraction|language model|natural language processing|natural language generation|natural language interface|syntactic parsing|computational linguistics|data science|knowledge discovery|deep learning|nlp task|machine learning research|machine translation|semantic parsing|spoken language technology,
https://openalex.org/W2170892587,"Estimating the sample mean and standard deviation from the sample size, median, range and/or interquartile range","Estimating the sample mean and standard deviation from the sample size, median, range and/or interquartile range

In systematic reviews and meta-analysis, researchers often pool the results of sample mean standard deviation from a set similar clinical trials. A number trials, however, reported study using median, minimum maximum values, and/or first third quartiles. Hence, in order to combine results, one may have estimate for such this paper, we propose improve existing literature several directions. First, show that estimation Hozo et al.'s method (BMC Med Res Methodol 5:13, 2005) has some serious limitations is always less satisfactory practice. Inspired by this, new incorporating size. Second, systematically problem under other interesting settings where interquartile range also available We demonstrate performance proposed methods through simulation studies three frequently encountered scenarios, respectively. For two our greatly improves provides nearly unbiased true normal data slightly biased skewed data. scenario, still performs very well both Furthermore, compare estimators all scenarios present suggestions on which scenario preferred real-world applications. discuss different approximation literature. conclude work with summary table (an Excel spread sheet including formulas) serves as comprehensive guidance performing meta-analysis situations.

estimation statistic, sample size, statistical theory, statistical software, medical statistic, logistic regression, applied statistics, statistical inference, biostatistics, regression analysis, computational statistic, statistics, machine learning research, epidemiology, standard deviation, quantitative science study, statistical hypothesis test, statistical methodology, sample mean, sampling, parameter estimation",2014,6661,estimation statistic|sample size|statistical theory|statistical software|medical statistic|logistic regression|applied statistics|statistical inference|biostatistics|regression analysis|computational statistic|statistics|machine learning research|epidemiology|standard deviation|quantitative science study|statistical hypothesis test|statistical methodology|sample mean|sampling|parameter estimation,
https://openalex.org/W2964153729,Intriguing properties of neural networks,"Intriguing properties of neural networks

Abstract: Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is reason they succeed, it also causes them to learn uninterpretable solutions could counter-intuitive properties. In this paper we report two such 
First, find there no distinction between individual high level units random linear combinations units, according various methods unit analysis. It suggests space, rather than contains semantic information in layers networks. 
Second, deep input-output mappings fairly discontinuous a significant extend. We can cause network misclassify an image by applying certain imperceptible perturbation, which found maximizing network's prediction error. addition, specific nature these perturbations not artifact learning: same perturbation different network, was trained subset dataset, input.

computer science, convolutional neural network, neuroscience, machine learning, neural networks, neural computation, neural network (machine learning)",2014,6598,computer science|convolutional neural network|neuroscience|machine learning|neural networks|neural computation|neural network (machine learning),https://openalex.org/W2099471712
https://openalex.org/W2950635152,Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation,"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation

In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent networks (RNN). One encodes sequence symbols into fixed-length vector representation, and the other decodes representation another symbols. The encoder decoder proposed are jointly trained to maximize conditional probability target given source sequence. performance statistical machine translation system is empirically found improve by using probabilities phrase pairs computed as an additional feature in existing log-linear model. Qualitatively, show learns semantically syntactically meaningful linguistic phrases.

computer science, knowledge discovery, word embeddings, convolutional neural network, phrase representations, statistical machine translation, computational linguistics, data science, deep learning, language model, linguistics, machine learning, machine learning research, natural language processing, machine translation, rnn encoder-decoder, sequence modelling, neural machine translation, recurrent neural network, language learning",2014,6555,computer science|knowledge discovery|word embeddings|convolutional neural network|phrase representations|statistical machine translation|computational linguistics|data science|deep learning|language model|linguistics|machine learning|machine learning research|natural language processing|machine translation|rnn encoder-decoder|sequence modelling|neural machine translation|recurrent neural network|language learning,https://openalex.org/W2130942839|https://openalex.org/W2964199361|https://openalex.org/W2962784628
https://openalex.org/W2145287260,DeepFace: Closing the Gap to Human-Level Performance in Face Verification,"DeepFace: Closing the Gap to Human-Level Performance in Face Verification

In modern face recognition, the conventional pipeline consists of four stages: detect => align represent classify. We revisit both alignment step and representation by employing explicit 3D modeling in order to apply a piecewise affine transformation, derive from nine-layer deep neural network. This network involves more than 120 million parameters using several locally connected layers without weight sharing, rather standard convolutional layers. Thus we trained it on largest facial dataset to-date, an identity labeled images belonging 4, 000 identities. The learned representations coupling accurate model-based with large database generalize remarkably well faces unconstrained environments, even simple classifier. Our method reaches accuracy 97.35% Labeled Faces Wild (LFW) dataset, reducing error current state art 27%, closely approaching human-level performance.

image analysis, pattern recognition, computer science, information fusion, adversarial machine learning, face verification, human-level performance, computer vision, biometrics, cognitive science, data science, computational intelligence, deep learning, deepfakes, human image synthesis, facial recognition system, machine vision, face detection",2014,5810,image analysis|pattern recognition|computer science|information fusion|adversarial machine learning|face verification|human-level performance|computer vision|biometrics|cognitive science|data science|computational intelligence|deep learning|deepfakes|human image synthesis|facial recognition system|machine vision|face detection,https://openalex.org/W1677182931|https://openalex.org/W2109255472|https://openalex.org/W3171007011|https://openalex.org/W3168997536
https://openalex.org/W2016053056,Large-Scale Video Classification with Convolutional Neural Networks,"Large-Scale Video Classification with Convolutional Neural Networks

Convolutional Neural Networks (CNNs) have been established as a powerful class of models for image recognition problems. Encouraged by these results, we provide an extensive empirical evaluation CNNs on large-scale video classification using new dataset 1 million YouTube videos belonging to 487 classes. We study multiple approaches extending the connectivity CNN in time domain take advantage local spatio-temporal information and suggest multiresolution, foveated architecture promising way speeding up training. Our best networks display significant performance improvements compared strong feature-based baselines (55.3% 63.9%), but only surprisingly modest improvement single-frame (59.3% 60.9%). further generalization our model retraining top layers UCF-101 Action Recognition observe baseline (63.3% from 43.9%).

neural network (machine learning), computer science, machine learning research, deep learning, pattern recognition, machine vision, multimedia information processing, multimedia retrieval, scene understanding, computational imaging, machine learning, data science, video interpretation, video retrieval, computer vision, video understanding, cognitive science, large-scale video classification, convolutional neural network",2014,5630,neural network (machine learning)|computer science|machine learning research|deep learning|pattern recognition|machine vision|multimedia information processing|multimedia retrieval|scene understanding|computational imaging|machine learning|data science|video interpretation|video retrieval|computer vision|video understanding|cognitive science|large-scale video classification|convolutional neural network,https://openalex.org/W2183341477|https://openalex.org/W2271840356|https://openalex.org/W2402144811
https://openalex.org/W2964199361,On the Properties of Neural Machine Translation: Encoder–Decoder Approaches,"On the Properties of Neural Machine Translation: Encoder–Decoder Approaches

Neural machine translation is a relatively new approach to statistical based purely on neural networks.The models often consist of an encoder and decoder.The extracts fixed-length representation from variable-length input sentence, the decoder generates correct this representation.In paper, we focus analyzing properties using two models; RNN Encoder-Decoder newly proposed gated recursive convolutional network.We show that performs well short sentences without unknown words, but its performance degrades rapidly as length sentence number words increase.Furthermore, find network learns grammatical structure automatically.

language learning, neural computation, natural language processing, machine translation, iterative decoding, autoencoders, computational intelligence, computer science, large language model, language model, machine learning, neural machine translation, linguistics, language, deep learning, recurrent neural network, machine learning research",2014,5017,language learning|neural computation|natural language processing|machine translation|iterative decoding|autoencoders|computational intelligence|computer science|large language model|language model|machine learning|neural machine translation|linguistics|language|deep learning|recurrent neural network|machine learning research,https://openalex.org/W1924770834|https://openalex.org/W2964308564
https://openalex.org/W1951724000,Fitting Linear Mixed-Effects Models Using<b>lme4</b>,"Fitting Linear Mixed-Effects Models Using<b>lme4</b>

Maximum likelihood or restricted maximum (REML) estimates of the parameters in linear mixed-effects models can be determined using lmer function lme4 package for R. As most model-fitting functions R, model is described an call by a formula, this case including both fixed- and random-effects terms. The formula data together determine numerical representation from which profiled deviance REML criterion evaluated as some parameters. appropriate optimized, one constrained optimization to provide parameter estimates. We describe structure model, steps evaluating criterion, classes types that represents such model. Sufficient detail included allow specialization these structures users who wish write fit specialized mixed models, incorporating pedigrees smoothing splines, are not easily expressible language used lmer.

machine learning, linear mixed-effects models, statistics, latent variable model",2015,61542,machine learning|linear mixed-effects models|statistics|latent variable model,
https://openalex.org/W2097117768,Going deeper with convolutions,"Going deeper with convolutions

We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of art for classification and detection in ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark this is improved utilization computing resources inside network. By carefully crafted design, we increased depth width while keeping computational budget constant. To optimize quality, architectural decisions were based on Hebbian principle intuition multi-scale processing. One particular incarnation used our submission ILSVRC14 called GoogLeNet, 22 layers network, quality which assessed context detection.

image analysis, computational imaging, computer science, information fusion, convolutional neural network, large language model, deep reinforcement learning, machine learning, applied mathematics, sparse neural network, data science, neural computation, deep learning, computational intelligence, machine learning research, deepfakes, neural network (machine learning), machine vision",2015,40093,image analysis|computational imaging|computer science|information fusion|convolutional neural network|large language model|deep reinforcement learning|machine learning|applied mathematics|sparse neural network|data science|neural computation|deep learning|computational intelligence|machine learning research|deepfakes|neural network (machine learning)|machine vision,https://openalex.org/W1903029394|https://openalex.org/W1677182931|https://openalex.org/W2109255472|https://openalex.org/W2194775991|https://openalex.org/W2963037989|https://openalex.org/W2183341477|https://openalex.org/W2271840356|https://openalex.org/W2295107390|https://openalex.org/W2402144811|https://openalex.org/W2963446712|https://openalex.org/W2618530766|https://openalex.org/W639708223|https://openalex.org/W2963881378|https://openalex.org/W2531409750|https://openalex.org/W2560023338|https://openalex.org/W2963470893|https://openalex.org/W2549139847|https://openalex.org/W2752782242|https://openalex.org/W2412782625|https://openalex.org/W2963163009|https://openalex.org/W2963125010|https://openalex.org/W2964081807|https://openalex.org/W3041133507|https://openalex.org/W3140854437|https://openalex.org/W3014641072|https://openalex.org/W3131500599|https://openalex.org/W4312443924|https://openalex.org/W3168997536|https://openalex.org/W3016719260|https://openalex.org/W2799041689|https://openalex.org/W4386076325
https://openalex.org/W1903029394,Fully convolutional networks for semantic segmentation,"Fully convolutional networks for semantic segmentation

Convolutional networks are powerful visual models that yield hierarchies of features. We show convolutional by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build ""fully convolutional"" take input arbitrary size and produce correspondingly-sized output with efficient inference learning. define detail space fully networks, explain their application spatially dense prediction tasks, draw connections prior models. adapt contemporary classification (AlexNet [20], VGG net [31], GoogLeNet [32]) into transfer learned representations fine-tuning [3] segmentation task. then a skip architecture combines information from deep, coarse layer appearance shallow, fine accurate detailed segmentations. network achieves PASCAL VOC (20% relative improvement 62.2% mean IU on 2012), NYUDv2, SIFT Flow, while takes less than one fifth second for typical image.

pattern recognition, computer science, machine learning, image segmentation, image analysis, information fusion, convolutional neural network, convolutional networks, cognitive science, data science, computational imaging, scene understanding, deep learning, machine learning research, machine vision, semantic segmentation, medical image computing, feature extraction, computer vision, scene analysis",2015,28292,pattern recognition|computer science|machine learning|image segmentation|image analysis|information fusion|convolutional neural network|convolutional networks|cognitive science|data science|computational imaging|scene understanding|deep learning|machine learning research|machine vision|semantic segmentation|medical image computing|feature extraction|computer vision|scene analysis,https://openalex.org/W2953106684|https://openalex.org/W2613718673|https://openalex.org/W2194775991|https://openalex.org/W2183341477|https://openalex.org/W2962914239|https://openalex.org/W2963446712|https://openalex.org/W639708223|https://openalex.org/W2963150697|https://openalex.org/W2565639579|https://openalex.org/W2962793481|https://openalex.org/W2963073614|https://openalex.org/W2963881378|https://openalex.org/W2962858109|https://openalex.org/W2560023338|https://openalex.org/W2549139847|https://openalex.org/W2752782242|https://openalex.org/W2412782625|https://openalex.org/W2963125010|https://openalex.org/W2963857746|https://openalex.org/W3014641072|https://openalex.org/W3132455321|https://openalex.org/W3131500599|https://openalex.org/W3170841864|https://openalex.org/W3168997536|https://openalex.org/W3016719260|https://openalex.org/W3040304705
https://openalex.org/W1536680647,Fast R-CNN,"Fast R-CNN

This paper proposes a Fast Region-based Convolutional Network method (Fast R-CNN) for object detection. R-CNN builds on previous work to efficiently classify proposals using deep convolutional networks. Compared work, employs several innovations improve training and testing speed while also increasing detection accuracy. trains the very VGG16 network 9x faster than R-CNN, is 213x at test-time, achieves higher mAP PASCAL VOC 2012. SPPnet, 3x faster, tests 10x more accurate. implemented in Python C++ (using Caffe) available under open-source MIT License https://github.com/rbgirshick/fast-rcnn.

computational imaging, machine vision, natural language processing, neural network (machine learning), cognitive science, computer science, recurrent neural network, convolutional neural network, machine learning, deep reinforcement learning, machine learning research, object detection, deep learning, data science, object recognition, image analysis",2015,20208,computational imaging|machine vision|natural language processing|neural network (machine learning)|cognitive science|computer science|recurrent neural network|convolutional neural network|machine learning|deep reinforcement learning|machine learning research|object detection|deep learning|data science|object recognition|image analysis,https://openalex.org/W1677182931|https://openalex.org/W2194775991|https://openalex.org/W2963037989|https://openalex.org/W639708223|https://openalex.org/W2963150697|https://openalex.org/W2565639579|https://openalex.org/W2549139847|https://openalex.org/W2412782625|https://openalex.org/W2963857746|https://openalex.org/W2964241181|https://openalex.org/W4312443924|https://openalex.org/W3168997536|https://openalex.org/W4320002812
https://openalex.org/W1836465849,Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift,"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift

Training Deep Neural Networks is complicated by the fact that distribution of each layer's inputs changes during training, as parameters previous layers change. This slows down training requiring lower learning rates and careful parameter initialization, makes it notoriously hard to train models with saturating nonlinearities. We refer this phenomenon internal covariate shift, address problem normalizing layer inputs. Our method draws its strength from making normalization a part model architecture performing for mini-batch. Batch Normalization allows us use much higher be less about initialization. It also acts regularizer, in some cases eliminating need Dropout. Applied state-of-the-art image classification model, achieves same accuracy 14 times fewer steps, beats original significant margin. Using an ensemble batch-normalized networks, we improve upon best published result on ImageNet classification: reaching 4.9% top-5 validation error (and 4.8% test error), exceeding human raters.

neural network (machine learning), internal covariate shift, batch normalization, computer science, machine learning, deep learning, data science",2015,19668,neural network (machine learning)|internal covariate shift|batch normalization|computer science|machine learning|deep learning|data science,https://openalex.org/W1677182931|https://openalex.org/W2194775991|https://openalex.org/W2183341477|https://openalex.org/W2963446712|https://openalex.org/W2963073614|https://openalex.org/W2531409750|https://openalex.org/W2560023338|https://openalex.org/W2963470893|https://openalex.org/W2549139847|https://openalex.org/W2752782242|https://openalex.org/W2963091558|https://openalex.org/W2963125010|https://openalex.org/W2963857746|https://openalex.org/W2964081807|https://openalex.org/W3171007011|https://openalex.org/W4313156423|https://openalex.org/W3168997536|https://openalex.org/W3016719260|https://openalex.org/W3042609801
https://openalex.org/W2953106684,Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks,"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks

State-of-the-art object detection networks depend on region proposal algorithms to hypothesize locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these networks, exposing computation as a bottleneck. In this work, we introduce Region Proposal Network (RPN) that shares full-image convolutional features with network, thus enabling nearly cost-free proposals. An RPN is fully network simultaneously predicts bounds objectness scores at each position. The trained end-to-end generate high-quality proposals, which are used by for detection. We further merge into single sharing their features---using recently popular terminology neural 'attention' mechanisms, component tells unified where look. For very deep VGG-16 model, our system has frame rate 5fps (including all steps) GPU, while achieving state-of-the-art accuracy PASCAL VOC 2007, 2012, MS COCO datasets only 300 proposals per image. ILSVRC 2015 competitions, Faster foundations 1st-place winning entries in several tracks. Code been made publicly available.

vehicular technology, computer science, deep learning, pattern recognition, information fusion, machine vision, object detection, scene understanding, object recognition, region proposal networks, computational imaging, machine learning, localization, data science, computer vision, cognitive science, object tracking, scene analysis, image analysis",2015,18973,vehicular technology|computer science|deep learning|pattern recognition|information fusion|machine vision|object detection|scene understanding|object recognition|region proposal networks|computational imaging|machine learning|localization|data science|computer vision|cognitive science|object tracking|scene analysis|image analysis,https://openalex.org/W2194775991|https://openalex.org/W2963037989|https://openalex.org/W2565639579|https://openalex.org/W2549139847|https://openalex.org/W2612445135|https://openalex.org/W2752782242|https://openalex.org/W2412782625|https://openalex.org/W2963163009|https://openalex.org/W2963125010|https://openalex.org/W2963857746|https://openalex.org/W2964081807|https://openalex.org/W2964241181|https://openalex.org/W4210257598|https://openalex.org/W2962730651|https://openalex.org/W3131500599|https://openalex.org/W3171007011|https://openalex.org/W3168997536|https://openalex.org/W3016719260|https://openalex.org/W4320002812
https://openalex.org/W2949117887,Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift,"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift

Training Deep Neural Networks is complicated by the fact that distribution of each layer's inputs changes during training, as parameters previous layers change. This slows down training requiring lower learning rates and careful parameter initialization, makes it notoriously hard to train models with saturating nonlinearities. We refer this phenomenon internal covariate shift, address problem normalizing layer inputs. Our method draws its strength from making normalization a part model architecture performing for mini-batch. Batch Normalization allows us use much higher be less about initialization. It also acts regularizer, in some cases eliminating need Dropout. Applied state-of-the-art image classification model, achieves same accuracy 14 times fewer steps, beats original significant margin. Using an ensemble batch-normalized networks, we improve upon best published result on ImageNet classification: reaching 4.9% top-5 validation error (and 4.8% test error), exceeding human raters.

machine learning, computer science, batch normalization, internal covariate shift, data science, deep learning, neural network (machine learning)",2015,16638,machine learning|computer science|batch normalization|internal covariate shift|data science|deep learning|neural network (machine learning),https://openalex.org/W1677182931|https://openalex.org/W2271840356|https://openalex.org/W2953384591|https://openalex.org/W2402144811|https://openalex.org/W2963073614|https://openalex.org/W2963881378|https://openalex.org/W2612445135|https://openalex.org/W2963125010|https://openalex.org/W2964081807|https://openalex.org/W3140854437|https://openalex.org/W2799041689
https://openalex.org/W2964308564,Neural Machine Translation by Jointly Learning to Align and Translate,"Neural Machine Translation by Jointly Learning to Align and Translate

Abstract: Neural machine translation is a recently proposed approach to translation. Unlike the traditional statistical translation, neural aims at building single network that can be jointly tuned maximize performance. The models for often belong family of encoder-decoders and consists an encoder encodes source sentence into fixed-length vector from which decoder generates In this paper, we conjecture use bottleneck in improving performance basic encoder-decoder architecture, propose extend by allowing model automatically (soft-)search parts are relevant predicting target word, without having form these as hard segment explicitly. With new approach, achieve comparable existing state-of-the-art phrase-based system on task English-to-French Furthermore, qualitative analysis reveals (soft-)alignments found agree well with our intuition.

computer science, linguistics, transfer learning, natural language processing, language, neural machine translation, machine learning, neural computation, computational intelligence, deep learning, machine learning research, machine translation, neural network (machine learning), computer-assisted translation",2015,15258,computer science|linguistics|transfer learning|natural language processing|language|neural machine translation|machine learning|neural computation|computational intelligence|deep learning|machine learning research|machine translation|neural network (machine learning)|computer-assisted translation,https://openalex.org/W2130942839|https://openalex.org/W2962784628|https://openalex.org/W3159481202
https://openalex.org/W1677182931,Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification,"Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification

Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier networks image classification from two aspects. First, propose a Parametric Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, derive robust initialization method particularly considers nonlinearities. This enables us to train extremely deep models directly scratch investigate deeper or wider network architectures. Based on learnable advanced initialization, achieve 4.94% top-5 test error ImageNet 2012 dataset. is 26% relative improvement over ILSVRC 2014 winner (GoogLeNet, 6.66% [33]). To our knowledge, result first surpass reported human-level performance (5.1%, [26])

digital image processing, sparse neural network, imagenet classification, computer science, machine learning research, deep learning, machine vision, adversarial machine learning, image representation, human-level performance, human image synthesis, computational imaging, geometric learning, machine learning, data science, computer vision, cognitive science, computational intelligence, convolutional neural network, image analysis",2015,14420,digital image processing|sparse neural network|imagenet classification|computer science|machine learning research|deep learning|machine vision|adversarial machine learning|image representation|human-level performance|human image synthesis|computational imaging|geometric learning|machine learning|data science|computer vision|cognitive science|computational intelligence|convolutional neural network|image analysis,https://openalex.org/W1836465849|https://openalex.org/W2949117887|https://openalex.org/W2194775991|https://openalex.org/W2183341477|https://openalex.org/W2962914239|https://openalex.org/W2963446712|https://openalex.org/W2963881378|https://openalex.org/W2963470893|https://openalex.org/W2549139847|https://openalex.org/W2752782242|https://openalex.org/W2963091558|https://openalex.org/W3168997536|https://openalex.org/W3016719260|https://openalex.org/W2799041689
https://openalex.org/W2613718673,Faster R-CNN: towards real-time object detection with region proposal networks,"Faster R-CNN: towards real-time object detection with region proposal networks

State-of-the-art object detection networks depend on region proposal algorithms to hypothesize locations. Advances like SPPnet [7] and Fast R-CNN [5] have reduced the running time of these networks, exposing computation as a bottleneck. In this work, we introduce Region Proposal Network (RPN) that shares full-image convolutional features with network, thus enabling nearly cost-free proposals. An RPN is fully-convolutional network simultaneously predicts bounds objectness scores at each position. RPNs are trained end-to-end generate high-quality proposals, which used by for detection. With simple alternating optimization, can be share features. For very deep VGG-16 model [19], our system has frame rate 5fps (including all steps) GPU, while achieving state-of-the-art accuracy PASCAL VOC 2007 (73.2% mAP) 2012 (70.4% using 300 proposals per image. Code available https://github.com/ShaoqingRen/faster_rcnn.

computer science, information fusion, vehicular technology, scene analysis, cognitive science, data science, deep learning, pattern recognition, machine learning, computer vision, object recognition, computational imaging, object detection, scene understanding, object tracking, region proposal networks, machine vision, image analysis, localization",2015,13298,computer science|information fusion|vehicular technology|scene analysis|cognitive science|data science|deep learning|pattern recognition|machine learning|computer vision|object recognition|computational imaging|object detection|scene understanding|object tracking|region proposal networks|machine vision|image analysis|localization,https://openalex.org/W2194775991|https://openalex.org/W2963150697|https://openalex.org/W2565639579|https://openalex.org/W2549139847|https://openalex.org/W2752782242|https://openalex.org/W2412782625|https://openalex.org/W2963163009|https://openalex.org/W2963125010|https://openalex.org/W2963857746|https://openalex.org/W2964081807|https://openalex.org/W2964241181|https://openalex.org/W4210257598|https://openalex.org/W2962730651|https://openalex.org/W3131500599|https://openalex.org/W3171007011|https://openalex.org/W3016719260
https://openalex.org/W1821462560,Distilling the Knowledge in a Neural Network,"Distilling the Knowledge in a Neural Network

A very simple way to improve the performance of almost any machine learning algorithm is train many different models on same data and then average their predictions. Unfortunately, making predictions using a whole ensemble cumbersome may be too computationally expensive allow deployment large number users, especially if individual are neural nets. Caruana his collaborators have shown that it possible compress knowledge in an into single model which much easier deploy we develop this approach further compression technique. We achieve some surprising results MNIST show can significantly acoustic heavily used commercial system by distilling model. also introduce new type composed one or more full specialist learn distinguish fine-grained classes confuse. Unlike mixture experts, these trained rapidly parallel.

computer science, knowledge representation and reasoning, machine learning, neural network, knowledge distillation, neural network (machine learning)",2015,11760,computer science|knowledge representation and reasoning|machine learning|neural network|knowledge distillation|neural network (machine learning),https://openalex.org/W2531409750|https://openalex.org/W2612445135|https://openalex.org/W2963125010|https://openalex.org/W3159481202
https://openalex.org/W2099085143,Second-generation PLINK: rising to the challenge of larger and richer datasets,"Second-generation PLINK: rising to the challenge of larger and richer datasets

PLINK 1 is a widely used open-source C/C++ toolset for genome-wide association studies (GWAS) and research in population genetics. However, the steady accumulation of data from imputation whole-genome sequencing has exposed strong need even faster more scalable implementations key functions. In addition, GWAS population-genetic now frequently contain probabilistic calls, phase information, and/or multiallelic variants, none which can be represented by 1's primary format. To address these issues, we are developing second-generation codebase PLINK. The first major release this codebase, 1.9, introduces extensive use bit-level parallelism, O(sqrt(n))-time/constant-space Hardy-Weinberg equilibrium Fisher's exact tests, many other algorithmic improvements. combination, changes accelerate most operations 1-4 orders magnitude, allow program to handle datasets too large fit RAM. This will followed 2.0, introduce (a) new format capable efficiently representing probabilities, phase, (b) extensions functions account types information. versions offer dramatic improvements performance compatibility. For time, users without access high-end computing resources perform several essential analyses feature-rich very genetic coming into use.

computer science, benchmark datasets, data integration, real-time data, richer datasets, large-scale datasets, missing data, machine learning, data heterogeneity, data-driven science, data science, deep learning, statistics, machine learning research, scientific data, second-generation plink, big data",2015,9075,computer science|benchmark datasets|data integration|real-time data|richer datasets|large-scale datasets|missing data|machine learning|data heterogeneity|data-driven science|data science|deep learning|statistics|machine learning research|scientific data|second-generation plink|big data,
https://openalex.org/W2109255472,Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition,"Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition

Existing deep convolutional neural networks (CNNs) require a fixed-size (e.g., 224 × 224) input image. This requirement is ""artificial"" and may reduce the recognition accuracy for images or sub-images of an arbitrary size/scale. In this work, we equip with another pooling strategy, ""spatial pyramid pooling"", to eliminate above requirement. The new network structure, called SPP-net, can generate fixed-length representation regardless image Pyramid also robust object deformations. With these advantages, SPP-net should in general improve all CNN-based classification methods. On ImageNet 2012 dataset, demonstrate that boosts variety CNN architectures despite their different designs. Pascal VOC 2007 Caltech101 datasets, achieves state-of-the-art results using single full-image no fine-tuning. power significant detection. Using compute feature maps from entire only once, then pool features regions (sub-images) representations training detectors. method avoids repeatedly computing features. processing test images, our 24-102 faster than R-CNN method, while achieving better comparable on 2007. Large Scale Visual Recognition Challenge (ILSVRC) 2014, methods rank #2 detection #3 among 38 teams. manuscript introduces improvement made competition.

computer science, machine learning, visual recognition, image analysis, information fusion, convolutional neural network, feature detection, cognitive science, data science, object categorization, image representation, vision recognition, computational imaging, deep convolutional networks, deep learning, spatial pyramid pooling, machine learning research, machine vision, digital image processing, computer vision, geometric learning",2015,8381,computer science|machine learning|visual recognition|image analysis|information fusion|convolutional neural network|feature detection|cognitive science|data science|object categorization|image representation|vision recognition|computational imaging|deep convolutional networks|deep learning|spatial pyramid pooling|machine learning research|machine vision|digital image processing|computer vision|geometric learning,https://openalex.org/W1536680647|https://openalex.org/W2963037989|https://openalex.org/W639708223|https://openalex.org/W2560023338|https://openalex.org/W2963857746|https://openalex.org/W3168997536
https://openalex.org/W2194775991,Deep Residual Learning for Image Recognition,"Deep Residual Learning for Image Recognition

Deeper neural networks are more difficult to train. We present a residual learning framework ease the training of that substantially deeper than those used previously. explicitly reformulate layers as functions with reference layer inputs, instead unreferenced functions. provide comprehensive empirical evidence showing these easier optimize, and can gain accuracy from considerably increased depth. On ImageNet dataset we evaluate nets depth up 152 - 8× VGG [40] but still having lower complexity. An ensemble achieves 3.57% error on test set. This result won 1st place ILSVRC 2015 classification task. also analysis CIFAR-10 100 1000 layers. The representations is central importance for many visual recognition tasks. Solely due our extremely deep representations, obtain 28% relative improvement COCO object detection dataset. Deep foundations submissions & competitions1, where places tasks detection, localization, segmentation.

image analysis, pattern recognition, computer science, computational imaging, convolutional neural network, object recognition, unsupervised machine learning, machine learning, deep residual learning, deep learning, image representation, image recognition, principal component analysis, image classification, digital image processing",2016,159317,image analysis|pattern recognition|computer science|computational imaging|convolutional neural network|object recognition|unsupervised machine learning|machine learning|deep residual learning|deep learning|image representation|image recognition|principal component analysis|image classification|digital image processing,https://openalex.org/W2962914239|https://openalex.org/W2402144811|https://openalex.org/W2963446712|https://openalex.org/W2618530766|https://openalex.org/W639708223|https://openalex.org/W2963150697|https://openalex.org/W2565639579|https://openalex.org/W2962793481|https://openalex.org/W2531409750|https://openalex.org/W2962858109|https://openalex.org/W2560023338|https://openalex.org/W2963470893|https://openalex.org/W2549139847|https://openalex.org/W2612445135|https://openalex.org/W2752782242|https://openalex.org/W2412782625|https://openalex.org/W2963163009|https://openalex.org/W2963091558|https://openalex.org/W2963125010|https://openalex.org/W2963857746|https://openalex.org/W2964081807|https://openalex.org/W2964241181|https://openalex.org/W4210257598|https://openalex.org/W3041133507|https://openalex.org/W3140854437|https://openalex.org/W2962730651|https://openalex.org/W3014641072|https://openalex.org/W3132455321|https://openalex.org/W3131500599|https://openalex.org/W3170841864|https://openalex.org/W3171007011|https://openalex.org/W3159481202|https://openalex.org/W4312443924|https://openalex.org/W4313156423|https://openalex.org/W3168997536|https://openalex.org/W3011667710|https://openalex.org/W3016719260|https://openalex.org/W2799041689|https://openalex.org/W4386076325|https://openalex.org/W4320002812|https://openalex.org/W3040304705
https://openalex.org/W2311203695,MEGA7: Molecular Evolutionary Genetics Analysis Version 7.0 for Bigger Datasets,"MEGA7: Molecular Evolutionary Genetics Analysis Version 7.0 for Bigger Datasets

Abstract We present the latest version of Molecular Evolutionary Genetics Analysis (M ega ) software, which contains many sophisticated methods and tools for phylogenomics phylomedicine. In this major upgrade, M has been optimized use on 64-bit computing systems analyzing larger datasets. Researchers can now explore analyze tens thousands sequences in . The new also provides an advanced wizard building timetrees includes a functionality to automatically predict gene duplication events family trees. is made available two interfaces: graphical command line. user interface (GUI) native Microsoft Windows application that be used Mac OS X. line as applications Windows, Linux, They are intended high-throughput scripted analysis. Both versions from www.megasoftware.net free charge.

molecular ecology, computational genomics, sequence analysis, genome biology, evolutionary biology, bigger datasets, omics datasets, molecular biology, phylogenetics, genetic variation, genomics, molecular evolution, machine learning research, evolutionary genetics, phylogenomics, genetics, bioinformatics",2016,37789,molecular ecology|computational genomics|sequence analysis|genome biology|evolutionary biology|bigger datasets|omics datasets|molecular biology|phylogenetics|genetic variation|genomics|molecular evolution|machine learning research|evolutionary genetics|phylogenomics|genetics|bioinformatics,
https://openalex.org/W2963037989,"You Only Look Once: Unified, Real-Time Object Detection","You Only Look Once: Unified, Real-Time Object Detection

We present YOLO, a new approach to object detection. Prior work on detection repurposes classifiers perform Instead, we frame as regression problem spatially separated bounding boxes and associated class probabilities. A single neural network predicts probabilities directly from full images in one evaluation. Since the whole pipeline is network, it can be optimized end-to-end performance. Our unified architecture extremely fast. base YOLO model processes real-time at 45 frames per second. smaller version of Fast an astounding 155 second while still achieving double mAP other detectors. Compared state-of-the-art systems, makes more localization errors but less likely predict false positives background. Finally, learns very general representations objects. It outperforms methods, including DPM R-CNN, when generalizing natural domains like artwork.

image analysis, pattern recognition, computer science, computational imaging, information fusion, object tracking, scene understanding, computer vision, machine learning, feature detection, motion detection, object detection, real-time object detection, data science, deep learning, image representation, machine vision",2016,26723,image analysis|pattern recognition|computer science|computational imaging|information fusion|object tracking|scene understanding|computer vision|machine learning|feature detection|motion detection|object detection|real-time object detection|data science|deep learning|image representation|machine vision,https://openalex.org/W2964241181|https://openalex.org/W4210257598|https://openalex.org/W3168997536|https://openalex.org/W4386076325|https://openalex.org/W4320002812|https://openalex.org/W3042609801
https://openalex.org/W2183341477,Rethinking the Inception Architecture for Computer Vision,"Rethinking the Inception Architecture for Computer Vision

Convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety tasks. Since 2014 very deep convolutional started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend translate immediate quality tasks (as long as enough labeled data is provided training), efficiency low parameter count still enabling factors use cases such mobile big-data scenarios. Here we exploring ways scale up that aim utilizing added computation efficiently possible by suitably factorized convolutions aggressive regularization. We benchmark our methods on ILSVRC 2012 classification challenge validation set demonstrate over art: 21:2% top-1 5:6% top-5 error single frame evaluation using network with 5 billion multiply-adds per inference less than 25 million parameters. With an ensemble 4 models multi-crop evaluation, report 3:5% 17:3% 3:6% official test set.

image analysis, computational imaging, computer science, artificial intelligence, object recognition, scene understanding, computer vision, machine learning, feature detection, inception architecture, object detection, deep learning, image representation, vision recognition, machine vision",2016,23508,image analysis|computational imaging|computer science|artificial intelligence|object recognition|scene understanding|computer vision|machine learning|feature detection|inception architecture|object detection|deep learning|image representation|vision recognition|machine vision,https://openalex.org/W2963446712|https://openalex.org/W2531409750|https://openalex.org/W2549139847|https://openalex.org/W2612445135|https://openalex.org/W2752782242|https://openalex.org/W2963125010|https://openalex.org/W2964081807|https://openalex.org/W3140854437|https://openalex.org/W3131500599|https://openalex.org/W4312443924|https://openalex.org/W4313156423|https://openalex.org/W3168997536|https://openalex.org/W3016719260|https://openalex.org/W2799041689|https://openalex.org/W4386076325|https://openalex.org/W4320002812
https://openalex.org/W2964015378,Semi-Supervised Classification with Graph Convolutional Networks,"Semi-Supervised Classification with Graph Convolutional Networks

We present a scalable approach for semi-supervised learning on graph-structured data that is based an efficient variant of convolutional neural networks which operate directly graphs. motivate the choice our architecture via localized first-order approximation spectral graph convolutions. Our model scales linearly in number edges and learns hidden layer representations encode both local structure features nodes. In experiments citation knowledge dataset we demonstrate outperforms related methods by significant margin.

graph theory, pattern recognition, semi-supervised classification, neural network (machine learning), semi-supervised learning, data classification, graph neural network, computer science, graph processing, graph convolutional networks, machine learning, machine learning research, graph analysis, deep learning, data science",2016,11848,graph theory|pattern recognition|semi-supervised classification|neural network (machine learning)|semi-supervised learning|data classification|graph neural network|computer science|graph processing|graph convolutional networks|machine learning|machine learning research|graph analysis|deep learning|data science,https://openalex.org/W4210257598|https://openalex.org/W3003265726|https://openalex.org/W3168997536|https://openalex.org/W3040304705
https://openalex.org/W2557283755,Deep Learning,"Deep Learning

Deep learning is a form of machine that enables computers to learn from experience and understand the world in terms hierarchy concepts. Because computer gathers knowledge experience, there no need for human operator formally specify all needs. The concepts allows complicated by building them out simpler ones; graph these hierarchies would be many layers deep. This book introduces broad range topics deep learning. text offers mathematical conceptual background, covering relevant linear algebra, probability theory information theory, numerical computation, It describes techniques used practitioners industry, including feedforward networks, regularization, optimization algorithms, convolutional sequence modeling, practical methodology; it surveys such applications as natural language processing, speech recognition, vision, online recommendation systems, bioinformatics, videogames. Finally, research perspectives, theoretical factor models, autoencoders, representation learning, structured probabilistic Monte Carlo methods, partition function, approximate inference, generative models. Learning can undergraduate or graduate students planning careers either industry research, software engineers who want begin using their products platforms. A website supplementary material both readers instructors.

supervised learning, neural computation, neural network (machine learning), computer science, machine learning, machine learning research, deep learning",2016,9537,supervised learning|neural computation|neural network (machine learning)|computer science|machine learning|machine learning research|deep learning,https://openalex.org/W3140854437
https://openalex.org/W2271840356,TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems,"TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems

TensorFlow is an interface for expressing machine learning algorithms, and implementation executing such algorithms. A computation expressed using can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices as phones tablets up to large-scale distributed systems hundreds machines thousands computational GPU cards. The system flexible used express including training inference algorithms deep neural network models, it has been conducting research deploying into production across more than dozen areas computer science other fields, speech recognition, vision, robotics, information retrieval, natural language processing, geographic extraction, drug discovery. This paper describes the that we have built at Google. API reference were released open-source package under Apache 2.0 license in November, 2015 are available www.tensorflow.org.

distributed system, computer science, heterogeneous computing, large-scale machine, machine learning",2016,8543,distributed system|computer science|heterogeneous computing|large-scale machine|machine learning,https://openalex.org/W2412782625
https://openalex.org/W2953384591,TensorFlow: A system for large-scale machine learning,"TensorFlow: A system for large-scale machine learning

TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. uses dataflow graphs to represent computation, shared state, the operations mutate state. It maps nodes of graph across many machines cluster, within multiple computational devices, including multicore CPUs, general-purpose GPUs, custom designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility application developer: whereas previous ""parameter server"" designs management state built into system, enables developers experiment with novel optimizations training algorithms. supports variety applications, particularly strong support for inference on deep neural networks. Several Google services use production, we have released it an open-source project, has become widely used research. In this paper, describe model contrast existing systems, demonstrate compelling performance achieves several real-world applications.

systems engineering, massive data processing, automated machine learning, large ai model, algorithmic learning, computer science, large-scale datasets, machine learning, machine learning research, large-scale machine learning, data science",2016,8380,systems engineering|massive data processing|automated machine learning|large ai model|algorithmic learning|computer science|large-scale datasets|machine learning|machine learning research|large-scale machine learning|data science,
https://openalex.org/W2295107390,Learning Deep Features for Discriminative Localization,"Learning Deep Features for Discriminative Localization

In this work, we revisit the global average pooling layer proposed in [13], and shed light on how it explicitly enables convolutional neural network (CNN) to have remarkable localization ability despite being trained imagelevel labels. While technique was previously as a means for regularizing training, find that actually builds generic localizable deep representation exposes implicit attention of CNNs an image. Despite apparent simplicity pooling, are able achieve 37.1% top-5 error object ILSVRC 2014 without training any bounding box annotation. We demonstrate variety experiments our is localize discriminative image regions just solving classification task1.

computer science, feature learning, machine learning, discriminative localization, localization, deep learning, automatic classification, deep features",2016,8054,computer science|feature learning|machine learning|discriminative localization|localization|deep learning|automatic classification|deep features,https://openalex.org/W2962858109|https://openalex.org/W4320002812
https://openalex.org/W1885185971,Image Super-Resolution Using Deep Convolutional Networks,"Image Super-Resolution Using Deep Convolutional Networks

We propose a deep learning method for single image super-resolution (SR). Our directly learns an end-to-end mapping between the low/high-resolution images. The is represented as convolutional neural network (CNN) that takes low-resolution input and outputs high-resolution one. further show traditional sparse-coding-based SR methods can also be viewed network. But unlike handle each component separately, our jointly optimizes all layers. CNN has lightweight structure, yet demonstrates state-of-the-art restoration quality, achieves fast speed practical on-line usage. explore different structures parameter settings to achieve trade-offs performance speed. Moreover, we extend cope with three color channels simultaneously, better overall reconstruction quality.

computer science, high resolution, machine learning, image analysis, convolutional neural network, biomedical imaging, data science, image representation, computational imaging, deep convolutional networks, deep learning, image super-resolution, image resolution, machine vision, single-image super-resolution, digital image processing, medical image computing, super-resolution imaging, computer vision",2016,7136,computer science|high resolution|machine learning|image analysis|convolutional neural network|biomedical imaging|data science|image representation|computational imaging|deep convolutional networks|deep learning|image super-resolution|image resolution|machine vision|single-image super-resolution|digital image processing|medical image computing|super-resolution imaging|computer vision,https://openalex.org/W2963470893
https://openalex.org/W2962914239,V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation,"V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation

Convolutional Neural Networks (CNNs) have been recently employed to solve problems from both the computer vision and medical image analysis fields. Despite their popularity, most approaches are only able process 2D images while data used in clinical practice consists of 3D volumes. In this work we propose an approach segmentation based on a volumetric, fully convolutional, neural network. Our CNN is trained end-to-end MRI volumes depicting prostate, learns predict for whole volume at once. We introduce novel objective function, that optimise during training, Dice coefficient. way can deal with situations where there strong imbalance between number foreground background voxels. To cope limited annotated available augment applying random non-linear transformations histogram matching. show our experimental evaluation achieves good performances challenging test requiring fraction processing time needed by other previous methods.

image segmentation, computed tomography, digital image processing, medical image computing, computer vision, radiology, biomedical imaging, computational imaging, machine vision, medical image analysis, biomedical engineering, medical imaging, computer science, digital medicine, convolutional neural network, machine learning, deep learning, 3d imaging",2016,6563,image segmentation|computed tomography|digital image processing|medical image computing|computer vision|radiology|biomedical imaging|computational imaging|machine vision|medical image analysis|biomedical engineering|medical imaging|computer science|digital medicine|convolutional neural network|machine learning|deep learning|3d imaging,https://openalex.org/W3140854437|https://openalex.org/W3132455321
https://openalex.org/W2962784628,Neural Machine Translation of Rare Words with Subword Units,"Neural Machine Translation of Rare Words with Subword Units

Neural machine translation (NMT) models typically operate with a fixed vocabulary, but is an open-vocabulary problem.Previous work addresses the of out-of-vocabulary words by backing off to dictionary.In this paper, we introduce simpler and more effective approach, making NMT model capable encoding rare unknown as sequences subword units.This based on intuition that various word classes are translatable via smaller units than words, for instance names (via character copying or transliteration), compounds compositional translation), cognates loanwords phonological morphological transformations).We discuss suitability different segmentation techniques, including simple ngram byte pair compression algorithm, empirically show improve over back-off dictionary baseline WMT 15 tasks English→German English→Russian up 1.1 1.3 BLEU, respectively.

linguistics, subword units, neural machine translation, machine learning, computational linguistics, machine translation, rare words",2016,6410,linguistics|subword units|neural machine translation|machine learning|computational linguistics|machine translation|rare words,https://openalex.org/W2493916176
https://openalex.org/W2537623931,"The STRING database in 2017: quality-controlled protein–protein association networks, made broadly accessible","The STRING database in 2017: quality-controlled protein–protein association networks, made broadly accessible

A system-wide understanding of cellular function requires knowledge all functional interactions between the expressed proteins. The STRING database aims to collect and integrate this information, by consolidating known predicted protein–protein association data for a large number organisms. associations in include direct (physical) interactions, as well indirect (functional) long both are specific biologically meaningful. Apart from collecting reassessing available experimental on importing pathways protein complexes curated databases, interaction predictions derived following sources: (i) systematic co-expression analysis, (ii) detection shared selective signals across genomes, (iii) automated text-mining scientific literature (iv) computational transfer organisms based gene orthology. In latest version 10.5 STRING, biggest changes concerned with dissemination: web frontend has been completely redesigned reduce dependency outdated browser technologies, can now also be queried inside popular Cytoscape software framework. Further improvements background analysis user inputs enrichments, streamlined download options. resource is online, at http://string-db.org/.

bioinformatics database, molecular biology, network analysis, bioinformatics, protein bioinformatics, protein modeling, proteomics, systems biology, data science, structural bioinformatics, computational biology, machine learning research, protein science, protein structure, string database, proteome research, knowledge discovery, omics integration, molecular informatics",2016,6355,bioinformatics database|molecular biology|network analysis|bioinformatics|protein bioinformatics|protein modeling|proteomics|systems biology|data science|structural bioinformatics|computational biology|machine learning research|protein science|protein structure|string database|proteome research|knowledge discovery|omics integration|molecular informatics,
https://openalex.org/W2402144811,TensorFlow: a system for large-scale machine learning,"TensorFlow: a system for large-scale machine learning

TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. Tensor-Flow uses dataflow graphs to represent computation, shared state, the operations mutate state. It maps nodes of graph across many machines cluster, within multiple computational devices, including multicore CPUs, general-purpose GPUs, custom-designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility application developer: whereas previous parameter server designs management state built into system, enables developers experiment with novel optimizations training algorithms. supports variety applications, focus on inference deep neural networks. Several Google services use production, we have released it an open-source project, has become widely used for research. In this paper, describe model demonstrate compelling performance achieves several real-world applications.

massive data processing, machine learning, computer science, systems engineering, large ai model, machine learning research, large-scale datasets, data science, algorithmic learning, automated machine learning, large-scale machine learning",2016,6009,massive data processing|machine learning|computer science|systems engineering|large ai model|machine learning research|large-scale datasets|data science|algorithmic learning|automated machine learning|large-scale machine learning,
https://openalex.org/W2174661749,"Radiomics: Images Are More than Pictures, They Are Data","Radiomics: Images Are More than Pictures, They Are Data

In the past decade, field of medical image analysis has grown exponentially, with an increased number pattern recognition tools and increase in data set sizes. These advances have facilitated development processes for high-throughput extraction quantitative features that result conversion images into mineable subsequent these decision support; this practice is termed radiomics. This contrast to traditional treating as pictures intended solely visual interpretation. Radiomic contain first-, second-, higher-order statistics. are combined other patient mined sophisticated bioinformatics develop models may potentially improve diagnostic, prognostic, predictive accuracy. Because radiomics analyses be conducted standard care images, it conceivable digital will eventually become routine practice. report describes process radiomics, its challenges, potential power facilitate better clinical making, particularly patients cancer.

image analysis, pattern recognition, computer science, computational imaging, content-based image retrieval, radiomics, image communication, computer vision, data and information visualization, image sequence analysis, data science, image representation, radiographic imaging, machine learning research, machine vision, digital image processing, image database",2016,5990,image analysis|pattern recognition|computer science|computational imaging|content-based image retrieval|radiomics|image communication|computer vision|data and information visualization|image sequence analysis|data science|image representation|radiographic imaging|machine learning research|machine vision|digital image processing|image database,
https://openalex.org/W2963446712,Densely Connected Convolutional Networks,"Densely Connected Convolutional Networks

Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close the input those output. In this paper, we embrace observation introduce Dense Convolutional Network (DenseNet), which connects each layer every other in a feed-forward fashion. Whereas traditional with L have connections-one its subsequent layer-our network L(L+1)/2 direct connections. For layer, feature-maps of all preceding are used as inputs, own inputs into layers. DenseNets several compelling advantages: alleviate vanishing-gradient problem, strengthen feature propagation, encourage reuse, reduce number parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, ImageNet). obtain significant improvements over state-of-the-art most them, whilst requiring less memory computation achieve high performance. Code pre-trained models available at https://github.com/liuzhuang13/DenseNet.

computer science, convolutional neural network, convolutional networks, computer vision, machine learning, deep learning, large-scale datasets, neural network (machine learning), machine vision",2017,33093,computer science|convolutional neural network|convolutional networks|computer vision|machine learning|deep learning|large-scale datasets|neural network (machine learning)|machine vision,https://openalex.org/W2752782242|https://openalex.org/W2963857746|https://openalex.org/W2964081807|https://openalex.org/W3140854437|https://openalex.org/W2962730651|https://openalex.org/W3014641072|https://openalex.org/W3131500599|https://openalex.org/W4312443924|https://openalex.org/W3168997536|https://openalex.org/W3016719260|https://openalex.org/W4386076325
https://openalex.org/W2618530766,ImageNet classification with deep convolutional neural networks,"ImageNet classification with deep convolutional neural networks

We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in ImageNet LSVRC-2010 contest into 1000 different classes. On test data, we achieved top-1 and top-5 error rates of 37.5% 17.0%, respectively, which is considerably better than previous state-of-the-art. The network, has 60 parameters 650,000 neurons, consists five layers, some are followed by max-pooling three fully connected layers with final 1000-way softmax. To make training faster, used non-saturating neurons very efficient GPU implementation convolution operation. reduce overfitting employed recently developed regularization method called ""dropout"" that proved be effective. also entered variant this model ILSVRC-2012 competition winning rate 15.3%, compared 26.2% second-best entry.

computer science, data classification, machine learning, intelligent classification, automatic classification, image analysis, convolutional neural network, biomedical imaging, data science, image representation, computational imaging, deep learning, machine learning research, digital image processing, medical image computing, imagenet classification, health science, neural network (machine learning), image classification",2017,28416,computer science|data classification|machine learning|intelligent classification|automatic classification|image analysis|convolutional neural network|biomedical imaging|data science|image representation|computational imaging|deep learning|machine learning research|digital image processing|medical image computing|imagenet classification|health science|neural network (machine learning)|image classification,https://openalex.org/W1832693441|https://openalex.org/W2109255472|https://openalex.org/W1885185971|https://openalex.org/W2402144811|https://openalex.org/W639708223|https://openalex.org/W2963163009|https://openalex.org/W3140854437|https://openalex.org/W3132455321|https://openalex.org/W4312443924|https://openalex.org/W2799041689|https://openalex.org/W3209696639
https://openalex.org/W639708223,Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks,"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks

State-of-the-art object detection networks depend on region proposal algorithms to hypothesize locations. Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these networks, exposing computation as a bottleneck. In this work, we introduce Region Proposal Network(RPN) that shares full-image convolutional features with network, thus enabling nearly cost-free proposals. An RPN is fully network simultaneously predicts bounds objectness scores at each position. The trained end-to-end generate high-quality proposals, which are used by for detection. We further merge into single sharing their features-using recently popular terminology neural 'attention' mechanisms, component tells unified where look. For very deep VGG-16 model [3], our system has frame rate 5 fps (including all steps) GPU, while achieving state-of-the-art accuracy PASCAL VOC 2007, 2012, MS COCO datasets only 300 proposals per image. ILSVRC 2015 competitions, Faster foundations 1st-place winning entries in several tracks. Code been made publicly available.

pattern recognition, computer science, machine learning, image analysis, information fusion, cognitive science, object detection, data science, computational imaging, scene understanding, localization, deep learning, machine vision, region proposal networks, object tracking, object recognition, computer vision, scene analysis, vehicular technology",2017,26058,pattern recognition|computer science|machine learning|image analysis|information fusion|cognitive science|object detection|data science|computational imaging|scene understanding|localization|deep learning|machine vision|region proposal networks|object tracking|object recognition|computer vision|scene analysis|vehicular technology,https://openalex.org/W2963037989|https://openalex.org/W639708223|https://openalex.org/W2963091558|https://openalex.org/W3014641072|https://openalex.org/W4312443924|https://openalex.org/W4320002812
https://openalex.org/W2099471712,GAN（Generative Adversarial Nets）,"GAN（Generative Adversarial Nets）

We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: model G that captures the data distribution, and discriminative D estimates probability sample came from training rather than G. The procedure is to maximize of making mistake. This corresponds minimax two-player game. In space arbitrary functions D, unique solution exists, with recovering distribution equal ½ everywhere. case where are defined by multilayer perceptrons, entire system can be trained backpropagation. There no need any Markov chains or unrolled approximate inference networks during either generation samples. Experiments demonstrate potential through qualitative quantitative evaluation generated

adversarial machine learning, computer science, generative adversarial nets, generative adversarial network, machine learning, generative ai, neural network (machine learning)",2017,23283,adversarial machine learning|computer science|generative adversarial nets|generative adversarial network|machine learning|generative ai|neural network (machine learning),https://openalex.org/W2125389028|https://openalex.org/W2953384591|https://openalex.org/W2962793481|https://openalex.org/W2963073614|https://openalex.org/W2963470893|https://openalex.org/W4210257598|https://openalex.org/W3041133507|https://openalex.org/W3127561923|https://openalex.org/W3042609801
https://openalex.org/W2963150697,Mask R-CNN,"Mask R-CNN

We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating high-quality segmentation mask each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding branch predicting parallel with the existing bounding box recognition. is simple to train adds only small overhead running at 5 fps. Moreover, easy generalize other tasks, e.g., allowing us estimate human poses same framework. show top results all three tracks of COCO suite challenges, including segmentation, bounding-box detection, person keypoint detection. Without tricks, outperforms existing, single-model entries on every task, 2016 challenge winners. hope our effective will serve as solid baseline help ease future research instance-level Code be made available.

human identification, biomedical imaging, pattern recognition, automatic classification, computational imaging, information fusion, machine vision, mask r-cnn, neural network (machine learning), cognitive science, computer science, convolutional neural network, machine learning, feature detection, object detection, deep learning, data science, image analysis",2017,19893,human identification|biomedical imaging|pattern recognition|automatic classification|computational imaging|information fusion|machine vision|mask r-cnn|neural network (machine learning)|cognitive science|computer science|convolutional neural network|machine learning|feature detection|object detection|deep learning|data science|image analysis,https://openalex.org/W2565639579|https://openalex.org/W2549139847|https://openalex.org/W2963091558|https://openalex.org/W2963857746|https://openalex.org/W2964241181|https://openalex.org/W2962730651|https://openalex.org/W3014641072|https://openalex.org/W3132455321|https://openalex.org/W3131500599|https://openalex.org/W3171007011|https://openalex.org/W4312443924|https://openalex.org/W4313156423|https://openalex.org/W3168997536|https://openalex.org/W3016719260|https://openalex.org/W4320002812|https://openalex.org/W3040304705
https://openalex.org/W2565639579,Feature Pyramid Networks for Object Detection,"Feature Pyramid Networks for Object Detection

Feature pyramids are a basic component in recognition systems for detecting objects at different scales. But pyramid representations have been avoided recent object detectors that based on deep convolutional networks, partially because they slow to compute and memory intensive. In this paper, we exploit the inherent multi-scale, pyramidal hierarchy of networks construct feature with marginal extra cost. A top-down architecture lateral connections is developed building high-level semantic maps all This architecture, called Pyramid Network (FPN), shows significant improvement as generic extractor several applications. Using Faster R-CNN system, our method achieves state-of-the-art single-model results COCO detection benchmark without bells whistles, surpassing existing entries including those from 2016 challenge winners. addition, can run 5 FPS GPU thus practical accurate solution multi-scale detection. Code will be made publicly available.

image analysis, pattern recognition, computer science, feature pyramid networks, computer vision, machine learning, feature detection, object detection, object categorization, deep learning, image representation, feature construction, machine vision, feature (computer vision)",2017,17369,image analysis|pattern recognition|computer science|feature pyramid networks|computer vision|machine learning|feature detection|object detection|object categorization|deep learning|image representation|feature construction|machine vision|feature (computer vision),https://openalex.org/W2963150697|https://openalex.org/W2963091558|https://openalex.org/W2963857746|https://openalex.org/W2964081807|https://openalex.org/W2964241181|https://openalex.org/W3014641072|https://openalex.org/W3132455321|https://openalex.org/W3131500599|https://openalex.org/W3170841864|https://openalex.org/W4313156423|https://openalex.org/W3168997536|https://openalex.org/W3016719260|https://openalex.org/W4320002812
https://openalex.org/W2962793481,Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks,"Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks

Image-to-image translation is a class of vision and graphics problems where the goal to learn mapping between an input image output using training set aligned pairs. However, for many tasks, paired data will not be available. We present approach learning translate from source domain X target Y in absence examples. Our G : → such that distribution images G(X) indistinguishable adversarial loss. Because this highly under-constrained, we couple it with inverse F introduce cycle consistency loss push F(G(X)) ≈ (and vice versa). Qualitative results are presented on several tasks does exist, including collection style transfer, object transfiguration, season photo enhancement, etc. Quantitative comparisons against prior methods demonstrate superiority our approach.

digital image processing, biomedical imaging, unpaired image-to-image translation, computer science, deep learning, machine translation, adversarial machine learning, cycle-consistent adversarial networks, image representation, human image synthesis, computational imaging, machine learning, domain adaptation, generative adversarial network, data science, computer vision, cognitive science, synthetic image generation, image communication, image analysis",2017,16550,digital image processing|biomedical imaging|unpaired image-to-image translation|computer science|deep learning|machine translation|adversarial machine learning|cycle-consistent adversarial networks|image representation|human image synthesis|computational imaging|machine learning|domain adaptation|generative adversarial network|data science|computer vision|cognitive science|synthetic image generation|image communication|image analysis,https://openalex.org/W4320002812|https://openalex.org/W3216759837
https://openalex.org/W2963073614,Image-to-Image Translation with Conditional Adversarial Networks,"Image-to-Image Translation with Conditional Adversarial Networks

We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These not only learn the mapping from input image output image, but also loss function train this mapping. This makes it possible apply same generic approach problems that traditionally would require very different formulations. demonstrate is effective at synthesizing photos label maps, reconstructing objects edge and colorizing images, among other tasks. Moreover, since release of pi×2pi× software associated with paper, hundreds twitter users have posted their own artistic experiments using our system. As community, we no longer hand-engineer functions, work suggests can achieve reasonable results without handengineering functions either.

computer science, conditional adversarial networks, machine learning, multimodal translation, synthetic image generation, image analysis, data science, image representation, machine translation, image-to-image translation, computational imaging, adversarial machine learning, image communication, deep learning, machine learning research, digital image processing, computer vision, neural machine translation, human image synthesis",2017,15243,computer science|conditional adversarial networks|machine learning|multimodal translation|synthetic image generation|image analysis|data science|image representation|machine translation|image-to-image translation|computational imaging|adversarial machine learning|image communication|deep learning|machine learning research|digital image processing|computer vision|neural machine translation|human image synthesis,https://openalex.org/W2962785568|https://openalex.org/W3216759837
https://openalex.org/W2963881378,SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation,"SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation

We present a novel and practical deep fully convolutional neural network architecture for semantic pixel-wise segmentation termed SegNet. This core trainable engine consists of an encoder network, corresponding decoder followed by classification layer. The the is topologically identical to 13 layers in VGG16 [1] . role map low resolution feature maps full input classification. novelty SegNet lies manner which upsamples its lower map(s). Specifically, uses pooling indices computed max-pooling step perform non-linear upsampling. eliminates need learning upsample. upsampled are sparse then convolved with filters produce dense maps. compare our proposed widely adopted FCN [2] also well known DeepLab-LargeFOV [3] , DeconvNet [4] architectures. comparison reveals memory versus accuracy trade-off involved achieving good performance. was primarily motivated scene understanding applications. Hence, it designed be efficient both terms computational time during inference. It significantly smaller number parameters than other competing architectures can trained end-to-end using stochastic gradient descent. performed controlled benchmark on road scenes SUN RGB-D indoor tasks. These quantitative assessments show that provides performance competitive inference most memory-wise as compared provide Caffe implementation web demo at http://mi.eng.cam.ac.uk/projects/segnet/.

image analysis, pattern recognition, computer science, computational imaging, medical image computing, autoencoders, convolutional neural network, scene understanding, computer vision, machine learning, scene analysis, cognitive science, data science, deep learning, image representation, machine learning research, image segmentation, machine vision",2017,14516,image analysis|pattern recognition|computer science|computational imaging|medical image computing|autoencoders|convolutional neural network|scene understanding|computer vision|machine learning|scene analysis|cognitive science|data science|deep learning|image representation|machine learning research|image segmentation|machine vision,https://openalex.org/W2560023338|https://openalex.org/W2412782625|https://openalex.org/W3014641072|https://openalex.org/W3132455321|https://openalex.org/W3170841864|https://openalex.org/W3040304705
https://openalex.org/W2531409750,Xception: Deep Learning with Depthwise Separable Convolutions,"Xception: Deep Learning with Depthwise Separable Convolutions

We present an interpretation of Inception modules in convolutional neural networks as being intermediate step in-between regular convolution and the depthwise separable operation (a followed by a pointwise convolution). In this light, can be understood module with maximally large number towers. This observation leads us to propose novel deep network architecture inspired Inception, where have been replaced convolutions. show that architecture, dubbed Xception, slightly outperforms V3 on ImageNet dataset (which was designed for), significantly larger image classification comprising 350 million images 17,000 classes. Since Xception has same parameters V3, performance gains are not due increased capacity but rather more efficient use model parameters.

image analysis, computer science, convolutional neural network, depthwise separable convolutions, machine learning, deep learning",2017,12835,image analysis|computer science|convolutional neural network|depthwise separable convolutions|machine learning|deep learning,https://openalex.org/W2752782242|https://openalex.org/W2963163009|https://openalex.org/W2963125010|https://openalex.org/W2964081807|https://openalex.org/W3140854437|https://openalex.org/W4312443924|https://openalex.org/W3168997536|https://openalex.org/W4320002812
https://openalex.org/W2249595199,Discovering Statistics Using Ibm Spss Statistics,"Discovering Statistics Using Ibm Spss Statistics

Unrivalled in the way it makes teaching of statistics compelling and accessible to even most anxious students, only textbook you your students will ever need just got better! Andy Field's comprehensive bestselling Discovering Statistics Using SPSS 4th Edition takes from introductory statistical concepts through very advanced concepts, incorporating throughout. The Fourth focuses on providing essential content updates, better accessibility key features, more instructor resources, specific select disciplines. It also incorporates powerful new digital developments textbook's companion website(visit sagepub.com for information). WebAssign be available WebAssign, allowing instructors produce manage assignments with their studnets online using a grade book that allows them track monitor students' progress. Students receive unlimited practice combination approximately 2000 multiple choice algorithmic questions. provided instant feedback links directly accompanying eBook section where concept was covered, find correct solution. SAGE MobileStudy equipped smartphones tablets access material, such as Cramming Sam's Study Tips, anywhere they mobile service. With QR codes included throughout text, it's easy get right study, continue study virtually anywhere, when are away thier printed copy text. Click here preview site (available late spring 2013). Education Sport Sciences support materials enhanced ones Psychology, Business Management Health sciences make relevant wider range subjects across social is taught cross-disciplinary audience. Major Updates Fully compatible recent releases up including version 20.0 Exciting characters, cult leader Oditi, who provides interesting helpful video clips illustrate Confusious, helps clarify confusing quantitative terminology New discipline matierlas have been added Education, Sports Sciences, & Management, making Social, Behavioral, an interdisciplinary An Companion Website 2013) offers wealth material can used conjunction textbook, including: PowerPoints Testbanks Answers Smart Alex tasks at end each chapter Datafiles testing problems Flashcards Self-assessment multiple-choice questions Online videos procedures

ibm spss statistics, statistical methodology, applied statistics, statistical analysis, statistical inference, machine learning, data science, knowledge discovery, computational statistic, statistics, analytics, regression analysis, statistical database, statistical science, statistical software, data mining, data analytics",2017,12706,ibm spss statistics|statistical methodology|applied statistics|statistical analysis|statistical inference|machine learning|data science|knowledge discovery|computational statistic|statistics|analytics|regression analysis|statistical database|statistical science|statistical software|data mining|data analytics,
https://openalex.org/W2962858109,Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization,"Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization

We propose a technique for producing `visual explanations' decisions from large class of Convolutional Neural Network (CNN)-based models, making them more transparent. Our approach - Gradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients any target concept (say logits `dog' or even caption), flowing into final convolutional layer to produce coarse localization map highlighting important regions in image predicting concept. Unlike previous approaches, Grad- CAM is applicable wide variety CNN model-families: (1) CNNs with fully-connected layers (e.g. VGG), (2) used structured outputs captioning), (3) tasks multi-modal inputs visual question answering) reinforcement learning, without architectural changes re-training. combine Grad-CAM existing fine-grained visualizations create high-resolution class-discriminative visualization, Guided Grad-CAM, and apply it classification, captioning, answering (VQA) including ResNet-based architectures. In context classification our (a) lend insights failure modes these models (showing that seemingly unreasonable predictions have reasonable explanations), (b) outperform methods on ILSVRC-15 weakly-supervised task, (c) are faithful underlying model, (d) help achieve model generalization by identifying dataset bias. For captioning VQA, show non-attention based can localize inputs. Finally, we design conduct human studies measure if explanations users establish appropriate trust deep networks helps untrained successfully discern `stronger' network `weaker' one when both make identical predictions. code available at https: //github.com/ramprs/grad-cam/ along demo CloudCV [2] video youtu.be/COjUB9Izk6E.

computer science, vision language model, machine learning, visual science, image analysis, information visualization, visualization, feature detection, cognitive science, data science, computational imaging, scene understanding, deep networks, localization, deep learning, machine vision, visual explanations, visual question answering, interactive visualization, computer vision, gradient-based localization",2017,12443,computer science|vision language model|machine learning|visual science|image analysis|information visualization|visualization|feature detection|cognitive science|data science|computational imaging|scene understanding|deep networks|localization|deep learning|machine vision|visual explanations|visual question answering|interactive visualization|computer vision|gradient-based localization,
https://openalex.org/W2560023338,Pyramid Scene Parsing Network,"Pyramid Scene Parsing Network

Scene parsing is challenging for unrestricted open vocabulary and diverse scenes. In this paper, we exploit the capability of global context information by different-region-based aggregation through our pyramid pooling module together with proposed scene network (PSPNet). Our prior representation effective to produce good quality results on task, while PSPNet provides a superior framework pixel-level prediction. The approach achieves state-of-the-art performance various datasets. It came first in ImageNet challenge 2016, PASCAL VOC 2012 benchmark Cityscapes benchmark. A single yields new record mIoU accuracy 85.4% 80.2% Cityscapes.

image analysis, pattern recognition, computer science, computational imaging, structure from motion, scene interpretation, scene understanding, multi-view geometry, computer vision, scene analysis, multimedia retrieval, data science, systems engineering, deep learning, image representation, machine learning research, machine vision, digital image processing",2017,11099,image analysis|pattern recognition|computer science|computational imaging|structure from motion|scene interpretation|scene understanding|multi-view geometry|computer vision|scene analysis|multimedia retrieval|data science|systems engineering|deep learning|image representation|machine learning research|machine vision|digital image processing,https://openalex.org/W2963857746|https://openalex.org/W3014641072|https://openalex.org/W3132455321|https://openalex.org/W3131500599|https://openalex.org/W3170841864|https://openalex.org/W3168997536|https://openalex.org/W3016719260|https://openalex.org/W3040304705
https://openalex.org/W4297775537,MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications,"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications

We present a class of efficient models called MobileNets for mobile and embedded vision applications. are based on streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. introduce two simple global hyper-parameters efficiently trade off between latency accuracy. These allow the model builder choose right sized their application constraints problem. extensive experiments resource accuracy tradeoffs show strong performance compared other popular ImageNet classification. then demonstrate effectiveness across wide range applications use cases including object detection, finegrain classification, face attributes large scale geo-localization.

computer vision, mobile sensing, machine vision, neural network (machine learning), motion detection, cognitive science, computational intelligence, computer science, convolutional neural network, machine learning, feature detection, machine learning research, object detection, deep learning, data science, mobile vision applications, image analysis",2017,10304,computer vision|mobile sensing|machine vision|neural network (machine learning)|motion detection|cognitive science|computational intelligence|computer science|convolutional neural network|machine learning|feature detection|machine learning research|object detection|deep learning|data science|mobile vision applications|image analysis,https://openalex.org/W2531409750|https://openalex.org/W2752782242|https://openalex.org/W2963163009|https://openalex.org/W2963125010|https://openalex.org/W2964081807|https://openalex.org/W4312443924|https://openalex.org/W3168997536|https://openalex.org/W4386076325|https://openalex.org/W4320002812
https://openalex.org/W2963470893,Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network,"Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network

Despite the breakthroughs in accuracy and speed of single image super-resolution using faster deeper convolutional neural networks, one central problem remains largely unsolved: how do we recover finer texture details when super-resolve at large upscaling factors? The behavior optimization-based methods is principally driven by choice objective function. Recent work has focused on minimizing mean squared reconstruction error. resulting estimates have high peak signal-to-noise ratios, but they are often lacking high-frequency perceptually unsatisfying sense that fail to match fidelity expected higher resolution. In this paper, present SRGAN, a generative adversarial network (GAN) for (SR). To our knowledge, it first framework capable inferring photo-realistic natural images 4x factors. achieve this, propose perceptual loss function which consists an content loss. pushes solution manifold discriminator trained differentiate between super-resolved original images. addition, use motivated similarity instead pixel space. Our deep residual able textures from heavily downsampled public benchmarks. An extensive mean-opinion-score (MOS) test shows hugely significant gains quality SRGAN. MOS scores obtained with SRGAN closer those high-resolution than any state-of-the-art method.

image analysis, computational imaging, computer science, super-resolution imaging, computer vision, machine learning, generative adversarial network, generative ai, single-image super-resolution, deep learning, image representation, synthetic image generation, machine vision, digital image processing",2017,9742,image analysis|computational imaging|computer science|super-resolution imaging|computer vision|machine learning|generative adversarial network|generative ai|single-image super-resolution|deep learning|image representation|synthetic image generation|machine vision|digital image processing,https://openalex.org/W2962793481|https://openalex.org/W2963073614|https://openalex.org/W2962785568|https://openalex.org/W4320002812|https://openalex.org/W3216759837
https://openalex.org/W2549139847,Aggregated Residual Transformations for Deep Neural Networks,"Aggregated Residual Transformations for Deep Neural Networks

We present a simple, highly modularized network architecture for image classification. Our is constructed by repeating building block that aggregates set of transformations with the same topology. simple design results in homogeneous, multi-branch has only few hyper-parameters to set. This strategy exposes new dimension, which we call cardinality (the size transformations), as an essential factor addition dimensions depth and width. On ImageNet-1K dataset, empirically show even under restricted condition maintaining complexity, increasing able improve classification accuracy. Moreover, more effective than going deeper or wider when increase capacity. models, named ResNeXt, are foundations our entry ILSVRC 2016 task secured 2nd place. further investigate ResNeXt on ImageNet-5K COCO detection set, also showing better its ResNet counterpart. The code models publicly available online.

computer science, machine learning, deep neural networks, neural computation, deep learning, residual transformations, neural network (machine learning)",2017,8913,computer science|machine learning|deep neural networks|neural computation|deep learning|residual transformations|neural network (machine learning),https://openalex.org/W2963150697|https://openalex.org/W2752782242|https://openalex.org/W2963163009|https://openalex.org/W2963091558|https://openalex.org/W2963125010|https://openalex.org/W2963857746|https://openalex.org/W2964081807|https://openalex.org/W3140854437|https://openalex.org/W3014641072|https://openalex.org/W3131500599|https://openalex.org/W4312443924|https://openalex.org/W3168997536|https://openalex.org/W3016719260
https://openalex.org/W2493916176,Enriching Word Vectors with Subword Information,"Enriching Word Vectors with Subword Information

Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Popular models that learn such representations ignore the morphology of words, by assigning a distinct vector to each word. This is limitation, especially languages with vocabularies and rare words. In this paper, we propose new approach based skipgram model, where represented as bag character n-grams. A representation associated n-gram; words being sum these representations. Our method fast, allowing train quickly allows us compute did not appear in training data. We evaluate our nine different languages, both similarity analogy By comparing recently proposed morphological show vectors achieve state-of-the-art performance

word embeddings, computer science, linguistics, keyword extraction, text mining, language model, natural language processing, topic model, semantic evaluation, terminology extraction, computational linguistics, knowledge discovery, nlp task, machine learning research, word vectors, information retrieval, subword information",2017,8508,word embeddings|computer science|linguistics|keyword extraction|text mining|language model|natural language processing|topic model|semantic evaluation|terminology extraction|computational linguistics|knowledge discovery|nlp task|machine learning research|word vectors|information retrieval|subword information,
https://openalex.org/W2612445135,MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications,"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications

We present a class of efficient models called MobileNets for mobile and embedded vision applications. are based on streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. introduce two simple global hyper-parameters efficiently trade off between latency accuracy. These allow the model builder choose right sized their application constraints problem. extensive experiments resource accuracy tradeoffs show strong performance compared other popular ImageNet classification. then demonstrate effectiveness across wide range applications use cases including object detection, finegrain classification, face attributes large scale geo-localization.

image analysis, computer science, computer vision, machine learning, computational intelligence, motion detection, feature detection, mobile sensing, object detection, neural network (machine learning), machine learning research, convolutional neural network, data science, deep learning, mobile vision applications, machine vision, cognitive science",2017,8181,image analysis|computer science|computer vision|machine learning|computational intelligence|motion detection|feature detection|mobile sensing|object detection|neural network (machine learning)|machine learning research|convolutional neural network|data science|deep learning|mobile vision applications|machine vision|cognitive science,https://openalex.org/W2752782242|https://openalex.org/W2963163009|https://openalex.org/W2964081807|https://openalex.org/W3016719260
https://openalex.org/W2891378911,PRISMA Extension for Scoping Reviews (PRISMA-ScR): Checklist and Explanation,"PRISMA Extension for Scoping Reviews (PRISMA-ScR): Checklist and Explanation

Scoping reviews, a type of knowledge synthesis, follow systematic approach to map evidence on topic and identify main concepts, theories, sources, gaps. Although more scoping reviews are being done, their methodological reporting quality need improvement. This document presents the PRISMA-ScR (Preferred Reporting Items for Systematic Meta-Analyses extension Reviews) checklist explanation. The was developed by 24-member expert panel 2 research leads following published guidance from EQUATOR (Enhancing QUAlity Transparency Of health Research) Network. final contains 20 essential items optional items. authors provide rationale an example good each item. intent is help readers (including researchers, publishers, commissioners, policymakers, care providers, guideline developers, patients or consumers) develop greater understanding relevant terminology, core key report reviews.

reliability, computer science, content analysis, model verification, machine learning, verification, selective separation, evaluation protocol, prisma extension",2018,19183,reliability|computer science|content analysis|model verification|machine learning|verification|selective separation|evaluation protocol|prisma extension,
https://openalex.org/W2752782242,Squeeze-and-Excitation Networks,"Squeeze-and-Excitation Networks

Convolutional neural networks are built upon the convolution operation, which extracts informative features by fusing spatial and channel-wise information together within local receptive fields. In order to boost representational power of a network, several recent approaches have shown benefit enhancing encoding. this work, we focus on channel relationship propose novel architectural unit, term ""Squeeze-and-Excitation"" (SE) block, that adaptively recalibrates feature responses explicitly modelling interdependencies between channels. We demonstrate stacking these blocks together, can construct SENet architectures generalise extremely well across challenging datasets. Crucially, find SE produce significant performance improvements for existing state-of-the-art deep at minimal additional computational cost. SENets formed foundation our ILSVRC 2017 classification submission won first place significantly reduced top-5 error 2.251%, achieving ~25% relative improvement over winning entry 2016. Code models available https://github.com/hujie-frank/SENet.

computer science, information fusion, convolutional neural network, squeeze-and-excitation networks, electrical engineering, quantum machine learning, neuroimaging, neuroscience, recurrent neural network, sparse neural network, systems neuroscience, neural computation, computational neuroscience, computational intelligence, machine learning research, neural network (machine learning), shift detection",2018,16843,computer science|information fusion|convolutional neural network|squeeze-and-excitation networks|electrical engineering|quantum machine learning|neuroimaging|neuroscience|recurrent neural network|sparse neural network|systems neuroscience|neural computation|computational neuroscience|computational intelligence|machine learning research|neural network (machine learning)|shift detection,https://openalex.org/W2963125010|https://openalex.org/W2963857746|https://openalex.org/W2964081807|https://openalex.org/W3140854437|https://openalex.org/W3131500599|https://openalex.org/W4312443924|https://openalex.org/W3168997536|https://openalex.org/W3016719260
https://openalex.org/W2412782625,"DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs","DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs

In this work we address the task of semantic image segmentation with Deep Learning and make three main contributions that are experimentally shown to have substantial practical merit. First, highlight convolution upsampled filters, or 'atrous convolution', as a powerful tool in dense prediction tasks. Atrous allows us explicitly control resolution at which feature responses computed within Convolutional Neural Networks. It also effectively enlarge field view filters incorporate larger context without increasing number parameters amount computation. Second, propose atrous spatial pyramid pooling (ASPP) robustly segment objects multiple scales. ASPP probes an incoming convolutional layer sampling rates effective fields-of-views, thus capturing well Third, improve localization object boundaries by combining methods from DCNNs probabilistic graphical models. The commonly deployed combination max-pooling downsampling achieves invariance but has toll on accuracy. We overcome final DCNN fully connected Conditional Random Field (CRF), is both qualitatively quantitatively performance. Our proposed ""DeepLab"" system sets new state-of-art PASCAL VOC-2012 task, reaching 79.7 percent mIOU test set, advances results other datasets: PASCAL-Context, PASCAL-Person-Part, Cityscapes. All our code made publicly available online.

computer science, deep convolutional nets, machine learning, atrous convolution, image segmentation, image analysis, convolutional neural network, biomedical imaging, cognitive science, data science, image representation, computational imaging, scene understanding, deep learning, semantic image segmentation, machine vision, digital image processing, medical image computing, scene interpretation, computer vision, scene analysis",2018,16224,computer science|deep convolutional nets|machine learning|atrous convolution|image segmentation|image analysis|convolutional neural network|biomedical imaging|cognitive science|data science|image representation|computational imaging|scene understanding|deep learning|semantic image segmentation|machine vision|digital image processing|medical image computing|scene interpretation|computer vision|scene analysis,https://openalex.org/W2560023338|https://openalex.org/W2963163009|https://openalex.org/W3140854437|https://openalex.org/W3014641072|https://openalex.org/W3132455321|https://openalex.org/W3131500599|https://openalex.org/W3170841864|https://openalex.org/W3168997536|https://openalex.org/W3040304705
https://openalex.org/W2963163009,MobileNetV2: Inverted Residuals and Linear Bottlenecks,"MobileNetV2: Inverted Residuals and Linear Bottlenecks

In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of art performance models on multiple tasks and benchmarks as well across spectrum different model sizes. We also efficient ways applying these to object detection in novel framework call SSDLite. Additionally, demonstrate how build semantic segmentation through reduced form DeepLabv3 which Mobile DeepLabv3. is based an inverted residual structure where shortcut connections are between thin bottleneck layers. The intermediate expansion layer uses lightweight depthwise convolutions filter features source non-linearity. find it important remove non-linearities narrow layers order maintain representational power. provide intuition led design. Finally, our approach allows decoupling input/output domains from expressiveness transformation, provides convenient for further analysis. measure ImageNet [1] classification, COCO [2], VOC image [3]. evaluate trade-offs accuracy, number operations measured by multiply-adds (MAdd), actual latency, parameters.

temporal complexity, linear bottlenecks, computer science, machine learning, inverted residuals",2018,15965,temporal complexity|linear bottlenecks|computer science|machine learning|inverted residuals,https://openalex.org/W4312443924|https://openalex.org/W3168997536|https://openalex.org/W4386076325|https://openalex.org/W4320002812
https://openalex.org/W2963091558,Non-local Neural Networks,"Non-local Neural Networks

Both convolutional and recurrent operations are building blocks that process one local neighborhood at a time. In this paper, we present non-local as generic family of for capturing long-range dependencies. Inspired by the classical means method in computer vision, our operation computes response position weighted sum features all positions. This block can be plugged into many vision architectures. On task video classification, even without any bells whistles, models compete or outperform current competition winners on both Kinetics Charades datasets. static image recognition, improve object detection/segmentation pose estimation COCO suite tasks. Code is available https://github.com/facebookresearch/video-nonlocal-net .

computer science, non-local neural networks, machine learning, neural computation, neural network (machine learning), neuronal network",2018,8614,computer science|non-local neural networks|machine learning|neural computation|neural network (machine learning)|neuronal network,https://openalex.org/W3131500599|https://openalex.org/W3170841864|https://openalex.org/W4312443924|https://openalex.org/W3016719260|https://openalex.org/W4320002812|https://openalex.org/W3040304705
https://openalex.org/W1560724230,Learning with Kernels,"Learning with Kernels

A comprehensive introduction to Support Vector Machines and related kernel methods. In the 1990s, a new type of learning algorithm was developed, based on results from statistical theory: Machine (SVM). This gave rise class theoretically elegant machines that use central concept SVMs—-kernels—for number tasks. Kernel provide modular framework can be adapted different tasks domains by choice function base algorithm. They are replacing neural networks in variety fields, including engineering, information retrieval, bioinformatics. Learning with Kernels provides an SVMs Although book begins basics, it also includes latest research. It all concepts necessary enable reader equipped some basic mathematical knowledge enter world machine using well-founded yet easy-to-use algorithms understand apply powerful have been developed over last few years.

kernel method, computer science, computational learning theory, supervised learning, machine learning, neural computation, computational intelligence, deep learning, knowledge discovery, machine learning research, markov kernel, reproducing kernel method, neural network (machine learning)",2018,7885,kernel method|computer science|computational learning theory|supervised learning|machine learning|neural computation|computational intelligence|deep learning|knowledge discovery|machine learning research|markov kernel|reproducing kernel method|neural network (machine learning),
https://openalex.org/W2899760200,The PRIDE database and related tools and resources in 2019: improving support for quantification data,"The PRIDE database and related tools and resources in 2019: improving support for quantification data

The PRoteomics IDEntifications (PRIDE) database (https://www.ebi.ac.uk/pride/) is the world's largest data repository of mass spectrometry-based proteomics data, and one founding members global ProteomeXchange (PX) consortium. In this manuscript, we summarize developments in PRIDE resources related tools since previous update manuscript was published Nucleic Acids Research 2016. last 3 years, public sharing through (as part PX) has definitely become norm field. parallel, re-use increased enormously, with multiple applications. We first describe new architecture Archive, archival component PRIDE. Archive submission framework have been further developed to support increase submitted volumes additional types. A scalable fault tolerant storage backend, Application Programming Interface web interface implemented, as a an ongoing process. Additionally, emphasize improved for quantitative mzTab format. At last, outline key statistics on current contents volume downloads, how are starting be disseminated added-value including Ensembl, UniProt Expression Atlas.

quantification data, related tools, pride database, data science, statistics, analytics, machine learning research, tool use",2018,6359,quantification data|related tools|pride database|data science|statistics|analytics|machine learning research|tool use,
https://openalex.org/W2963125010,ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices,"ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices

We introduce an extremely computation-efficient CNN architecture named ShuffleNet, which is designed specially for mobile devices with very limited computing power (e.g., 10-150 MFLOPs). The new utilizes two operations, pointwise group convolution and channel shuffle, to greatly reduce computation cost while maintaining accuracy. Experiments on ImageNet classification MS COCO object detection demonstrate the superior performance of ShuffleNet over other structures, e.g. lower top-1 error (absolute 7.8%) than recent MobileNet [12] task, under budget 40 MFLOPs. On ARM-based device, achieves ~13× actual speedup AlexNet comparable

computer science, mobile computing, convolutional neural network, mobile learning, neural architecture search, machine learning, recurrent neural network, mobile devices, neural computation, deep learning, neural network (machine learning)",2018,6329,computer science|mobile computing|convolutional neural network|mobile learning|neural architecture search|machine learning|recurrent neural network|mobile devices|neural computation|deep learning|neural network (machine learning),https://openalex.org/W2752782242|https://openalex.org/W2963163009|https://openalex.org/W2964081807|https://openalex.org/W3168997536|https://openalex.org/W4386076325|https://openalex.org/W4320002812
https://openalex.org/W2962785568,The Unreasonable Effectiveness of Deep Features as a Perceptual Metric,"The Unreasonable Effectiveness of Deep Features as a Perceptual Metric

While it is nearly effortless for humans to quickly assess the perceptual similarity between two images, underlying processes are thought be quite complex. Despite this, most widely used metrics today, such as PSNR and SSIM, simple, shallow functions, fail account many nuances of human perception. Recently, deep learning community has found that features VGG network trained on ImageNet classification been remarkably useful a training loss image synthesis. But how these so-called ""perceptual losses""? What elements critical their success? To answer questions, we introduce new dataset judgments. We systematically evaluate across different architectures tasks compare them with classic metrics. find outperform all previous by large margins our dataset. More surprisingly, this result not restricted ImageNet-trained features, but holds levels supervision (supervised, self-supervised, or even unsupervised). Our results suggest an emergent property shared visual representations.

visual science, unreasonable effectiveness, principal component analysis, computer science, feature learning, machine learning research, deep learning, feature construction, pattern recognition, machine vision, neuroscience, image representation, feature (computer vision), computational imaging, machine learning, deep features, computer vision, cognitive science, feature detection, image analysis",2018,5839,visual science|unreasonable effectiveness|principal component analysis|computer science|feature learning|machine learning research|deep learning|feature construction|pattern recognition|machine vision|neuroscience|image representation|feature (computer vision)|computational imaging|machine learning|deep features|computer vision|cognitive science|feature detection|image analysis,
https://openalex.org/W2889326414,UMAP: Uniform Manifold Approximation and Projection,"UMAP: Uniform Manifold Approximation and Projection

Uniform Manifold Approximation and Projection (UMAP) is a dimension reduction technique that can be used for visualisation similarly to t-SNE, but also general non-linear reduction.UMAP has rigorous mathematical foundation, simple use, with scikit-learn compatible API.UMAP among the fastest manifold learning implementations available -significantly faster than most t-SNE implementations.UMAP supports number of useful features, including ability use labels (or partial labels) supervised semi-supervised) reduction, transform new unseen data into pretrained embedding space.

applied mathematics, differential geometry, manifold modeling, computational geometry, manifold learning, pade approximant, projection system, sparse representation, uniform manifold approximation, numerical simulation, approximation theory, computer science, geometric modeling, machine learning research",2018,5566,applied mathematics|differential geometry|manifold modeling|computational geometry|manifold learning|pade approximant|projection system|sparse representation|uniform manifold approximation|numerical simulation|approximation theory|computer science|geometric modeling|machine learning research,
https://openalex.org/W2257024953,Aplikasi Analisis Multivariate Dengan Program IBM SPSS 25,"Aplikasi Analisis Multivariate Dengan Program IBM SPSS 25

Bab 1 : Skala Pengukuran dan Metode Analisis Data
Bab 2 Pengnalan Program SPSS, Aplikasi Statistik Deskriptif
dan Crosstab.
Bab 3 Data Screening Transformasi data
Bab 4 Uji Validitas Reliabilitas Suatu Konstruk
Bab 5 Beda, ANOVA, ANCOVA MANOVA
Bab 6 Regresi
Bab 7 Asumsi Klasik
Bab 8 Regresi dengan Klasik, Variabel Dummy dan
Chow test
Bab 9 Model Bentuk Fungsional
Bab 10 Moderasi
Bab 11 Mediator
Bab 12 Moderator
Bab 13 Diskriminan

Bab 14 Logistic Regression
Bab 15 Korelasi Kanonikal
Bab 16 Conjoint
Bab 17 Faktor
Bab 18 Kluster
Bab 19 Multidimensional Scaling
Bab 20 Loglinear

computer science, software engineering, multivariate calibration, machine learning, applied mathematics, multivariate analysis, software analysis, deep learning, statistics, program analysis, multivariate approximation, statistical software, computational science",2018,5468,computer science|software engineering|multivariate calibration|machine learning|applied mathematics|multivariate analysis|software analysis|deep learning|statistics|program analysis|multivariate approximation|statistical software|computational science,
https://openalex.org/W2786672974,UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction,"UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction

UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. constructed from theoretical framework based in Riemannian geometry algebraic topology. The result practical scalable algorithm that applies to real world data. competitive with t-SNE visualization quality, arguably preserves more of the global structure superior run time performance. Furthermore, has no computational restrictions on embedding dimension, making it viable as general purpose reduction machine learning.

computer science, dimensionality reduction, geometric modeling, uniform manifold approximation, low-rank approximation, applied mathematics, dimension reduction, machine learning research, manifold learning, manifold modeling, computational geometry",2018,5285,computer science|dimensionality reduction|geometric modeling|uniform manifold approximation|low-rank approximation|applied mathematics|dimension reduction|machine learning research|manifold learning|manifold modeling|computational geometry,
https://openalex.org/W2963857746,Path Aggregation Network for Instance Segmentation,"Path Aggregation Network for Instance Segmentation

The way that information propagates in neural networks is of great importance. In this paper, we propose Path Aggregation Network (PANet) aiming at boosting flow proposal-based instance segmentation framework. Specifically, enhance the entire feature hierarchy with accurate localization signals lower layers by bottom-up path augmentation, which shortens between and topmost feature. We present adaptive pooling, links grid all levels to make useful each level propagate directly following proposal subnetworks. A complementary branch capturing different views for created further improve mask prediction. These improvements are simple implement, subtle extra computational overhead. Yet they our PANet reach 1st place COCO 2017 Challenge Instance Segmentation task 2nd Object Detection without large-batch training. also state-of-the-art on MVD Cityscapes.

computer vision, pattern recognition, instance segmentation, multi-user detection, computer science, machine learning, data science, path aggregation network, image analysis",2018,5050,computer vision|pattern recognition|instance segmentation|multi-user detection|computer science|machine learning|data science|path aggregation network|image analysis,https://openalex.org/W3014641072|https://openalex.org/W3132455321
https://openalex.org/W2964081807,Learning Transferable Architectures for Scalable Image Recognition,"Learning Transferable Architectures for Scalable Image Recognition

Developing neural network image classification models often requires significant architecture engineering. In this paper, we study a method to learn the model architectures directly on dataset of interest. As approach is expensive when large, propose search for an architectural building block small and then transfer larger dataset. The key contribution work design new space (which call ""NASNet space"") which enables transferability. our experiments, best convolutional layer (or ""cell"") CIFAR-10 apply cell ImageNet by stacking together more copies cell, each with their own parameters architecture, name architecture"". We also introduce regularization technique called ScheduledDropPath that significantly improves generalization in NASNet models. On itself, found achieves 2.4% error rate, state-of-the-art. Although not searched ImageNet, constructed from achieves, among published works, state-of-the-art accuracy 82.7% top-1 96.2% top-5 ImageNet. Our 1.2% better than human-invented while having 9 billion fewer FLOPS - reduction 28% computational demand previous model. When evaluated at different levels cost, accuracies NASNets exceed those human-designed For instance, version 74% accuracy, 3.1% equivalently-sized, mobile platforms. Finally, features learned are generically useful can be transferred other computer vision problems. task object detection, used Faster-RCNN framework surpass 4.0% achieving 43.1% mAP COCO

image analysis, pattern recognition, computer science, computational imaging, transfer learning, scalable image recognition, machine learning, data science, computational intelligence, deep learning, image representation, machine learning research, transferable architectures, model reuse, digital image processing",2018,4644,image analysis|pattern recognition|computer science|computational imaging|transfer learning|scalable image recognition|machine learning|data science|computational intelligence|deep learning|image representation|machine learning research|transferable architectures|model reuse|digital image processing,https://openalex.org/W2752782242|https://openalex.org/W2963163009|https://openalex.org/W2963125010|https://openalex.org/W3016719260
https://openalex.org/W2964241181,Cascade R-CNN: Delving Into High Quality Object Detection,"Cascade R-CNN: Delving Into High Quality Object Detection

In object detection, an intersection over union (IoU) threshold is required to define positives and negatives. An detector, trained with low IoU threshold, e.g. 0.5, usually produces noisy detections. However, detection performance tends degrade increasing the thresholds. Two main factors are responsible for this: 1) overfitting during training, due exponentially vanishing positive samples, 2) inference-time mismatch between IoUs which detector optimal those of input hypotheses. A multi-stage architecture, Cascade R-CNN, proposed address these problems. It consists a sequence detectors thresholds, be sequentially more selective against close false positives. The stage by stage, leveraging observation that output good distribution training next higher quality detector. resampling progressively improved hypotheses guarantees all have set examples equivalent size, reducing problem. same cascade procedure applied at inference, enabling closer match each stage. simple implementation R-CNN shown surpass single-model on challenging COCO dataset. Experiments also show widely applicable across architectures, achieving consistent gains independently baseline strength. code available https://github.com/zhaoweicai/cascade-rcnn.

pattern recognition, computer science, machine learning, image analysis, information fusion, convolutional neural network, biomedical imaging, cognitive science, object detection, data science, computational imaging, scene understanding, localization, deep learning, machine vision, high quality, cascade r-cnn, object tracking, object recognition, computer vision",2018,4389,pattern recognition|computer science|machine learning|image analysis|information fusion|convolutional neural network|biomedical imaging|cognitive science|object detection|data science|computational imaging|scene understanding|localization|deep learning|machine vision|high quality|cascade r-cnn|object tracking|object recognition|computer vision,https://openalex.org/W3014641072|https://openalex.org/W3131500599|https://openalex.org/W4312443924|https://openalex.org/W3016719260|https://openalex.org/W4320002812
https://openalex.org/W2104465908,"Randomization, Bootstrap and Monte Carlo Methods in Biology","Randomization, Bootstrap and Monte Carlo Methods in Biology

Modern computer-intensive statistical methods play a key role in solving many problems across wide range of scientific disciplines. This new edition the bestselling Randomization, Bootstrap and Monte Carlo Methods Biology illustrates value number these with an emphasis on biological applications. textbook focuses three related areas computational statistics: randomization, bootstrapping, inference. The author emphasizes sampling approach within randomization testing confidence intervals. Similar to book shows how or resampling, can be used for intervals tests significance. It also explores use test hypotheses construct intervals.New Third EditionUpdated information regression time series analysis, multivariate methods, survival growth data as well software statisticsReferences that reflect recent developments methodology computing techniquesAdditional references applications biologyProviding comprehensive coverage while offering sets online, Biology, Edition supplies solid foundation ever-expanding field statistics quantitative analysis biology.

theoretical biology, quantitative biology, mathematical bioscience, bootstrap resampling, monte carlo sampling, mathematical biology, systems biology, statistical inference, biology, monte carlo, monte carlo method, biostatistics, computational biology, machine learning research, experimental biology, quantitative science study",2018,4146,theoretical biology|quantitative biology|mathematical bioscience|bootstrap resampling|monte carlo sampling|mathematical biology|systems biology|statistical inference|biology|monte carlo|monte carlo method|biostatistics|computational biology|machine learning research|experimental biology|quantitative science study,
https://openalex.org/W3175752499,clusterProfiler 4.0: A universal enrichment tool for interpreting omics data,"clusterProfiler 4.0: A universal enrichment tool for interpreting omics data

Public summary•clusterProfiler supports exploring functional characteristics of both coding and non-coding genomics data for thousands species with up-to-date gene annotation•It provides a universal interface annotation from variety sources thus can be applied in diverse scenarios•It tidy to access, manipulate, visualize enrichment results help users achieve efficient interpretation•Datasets obtained multiple treatments time points analyzed compared single run, easily revealing consensus differences among distinct conditionsSummaryFunctional analysis is pivotal interpreting high-throughput omics life science. It crucial this type tool use the latest databases as many organisms possible. To meet these requirements, we present here an updated version our popular Bioconductor package, clusterProfiler 4.0. This package has been enhanced considerably its original published 9 years ago. The new based on internally supported ontologies pathways well provided by or derived online databases. also extends dplyr ggplot2 packages offer interfaces operation visualization. Other features include set comparison lists. We anticipate that 4.0 will wide range scenarios across organisms.Graphical abstract

computer science, omics technology, cluster computing, omics, large-scale datasets, clustering, machine learning, omics datasets, omics data, data science, omics integration, deep learning, statistics, benchmark datasets, universal enrichment tool, biomedical informatics, bioinformatics",2021,5864,computer science|omics technology|cluster computing|omics|large-scale datasets|clustering|machine learning|omics datasets|omics data|data science|omics integration|deep learning|statistics|benchmark datasets|universal enrichment tool|biomedical informatics|bioinformatics,
https://openalex.org/W4210257598,A Comprehensive Survey on Graph Neural Networks,"A Comprehensive Survey on Graph Neural Networks

Deep learning has revolutionized many machine tasks in recent years, ranging from image classification and video processing to speech recognition natural language understanding. The data these are typically represented the Euclidean space. However, there is an increasing number of applications, where generated non-Euclidean domains as graphs with complex relationships interdependency between objects. complexity graph imposed significant challenges on existing algorithms. Recently, studies extending deep approaches for have emerged. In this article, we provide a comprehensive overview neural networks (GNNs) mining fields. We propose new taxonomy divide state-of-the-art GNNs into four categories, namely, recurrent GNNs, convolutional autoencoders, spatial-temporal GNNs. further discuss applications across various summarize open-source codes, benchmark sets, model evaluation Finally, potential research directions rapidly growing field.

computer science, graph theory, machine learning, neural network (machine learning), graph neural network",2021,3453,computer science|graph theory|machine learning|neural network (machine learning)|graph neural network,
https://openalex.org/W3186179742,Accurate prediction of protein structures and interactions using a three-track neural network,"Accurate prediction of protein structures and interactions using a three-track neural network

Deep learning takes on protein folding In 1972, Anfinsen won a Nobel prize for demonstrating connection between protein’s amino acid sequence and its three-dimensional structure. Since 1994, scientists have competed in the biannual Critical Assessment of Structure Prediction (CASP) protein-folding challenge. methods took center stage at CASP14, with DeepMind’s Alphafold2 achieving remarkable accuracy. Baek et al . explored network architectures based DeepMind framework. They used three-track to process sequence, distance, coordinate information simultaneously achieved accuracies approaching those DeepMind. The method, RoseTTA fold, can solve challenging x-ray crystallography cryo–electron microscopy modeling problems generate accurate models protein-protein complexes. —VV

protein bioinformatics, protein modeling, accurate prediction, protein structure prediction, three-track neural network, systems biology, machine learning, protein structure, structural bioinformatics, computational biology, neural network (machine learning), protein science, bioinformatics",2021,3371,protein bioinformatics|protein modeling|accurate prediction|protein structure prediction|three-track neural network|systems biology|machine learning|protein structure|structural bioinformatics|computational biology|neural network (machine learning)|protein science|bioinformatics,https://openalex.org/W4220887281
https://openalex.org/W3041133507,A Comprehensive Survey on Transfer Learning,"A Comprehensive Survey on Transfer Learning

Transfer learning aims at improving the performance of target learners on domains by transferring knowledge contained in different but related source domains. In this way, dependence a large number target-domain data can be reduced for constructing learners. Due to wide application prospects, transfer has become popular and promising area machine learning. Although there are already some valuable impressive surveys learning, these introduce approaches relatively isolated way lack recent advances rapid expansion area, it is both necessary challenging comprehensively review relevant studies. This survey attempts connect systematize existing research studies, as well summarize interpret mechanisms strategies comprehensive which may help readers have better understanding current status ideas. Unlike previous surveys, article reviews more than 40 representative approaches, especially homogeneous from perspectives model. The applications also briefly introduced. order show models, over 20 models used experiments. performed three sets, that is, Amazon Reviews, Reuters-21578, Office-31, experimental results demonstrate importance selecting appropriate practice.

transfer learning, knowledge transfer, machine learning, data science, machine learning research",2021,3282,transfer learning|knowledge transfer|machine learning|data science|machine learning research,
https://openalex.org/W3140854437,"Review of deep learning: concepts, CNN architectures, challenges, applications, future directions","Review of deep learning: concepts, CNN architectures, challenges, applications, future directions

In the last few years, deep learning (DL) computing paradigm has been deemed Gold Standard in machine (ML) community. Moreover, it gradually become most widely used computational approach field of ML, thus achieving outstanding results on several complex cognitive tasks, matching or even beating those provided by human performance. One benefits DL is ability to learn massive amounts data. The grown fast years and extensively successfully address a wide range traditional applications. More importantly, outperformed well-known ML techniques many domains, e.g., cybersecurity, natural language processing, bioinformatics, robotics control, medical information among others. Despite contributed works reviewing State-of-the-Art DL, all them only tackled one aspect which leads an overall lack knowledge about it. Therefore, this contribution, we propose using more holistic order provide suitable starting point from develop full understanding DL. Specifically, review attempts comprehensive survey important aspects including enhancements recently added field. particular, paper outlines importance presents types networks. It then convolutional neural networks (CNNs) utilized network type describes development CNNs architectures together with their main features, AlexNet closing High-Resolution (HR.Net). Finally, further present challenges suggested solutions help researchers understand existing research gaps. followed list major Computational tools FPGA, GPU, CPU are summarized along description influence ends evolution matrix, benchmark datasets, summary conclusion.

pattern recognition, computer science, convolutional neural network, machine learning, cnn architectures, neural computation, data science, deep learning, image representation, machine learning research, future directions, neural network (machine learning)",2021,3267,pattern recognition|computer science|convolutional neural network|machine learning|cnn architectures|neural computation|data science|deep learning|image representation|machine learning research|future directions|neural network (machine learning),
https://openalex.org/W2962730651,OpenPose: Realtime Multi-Person 2D Pose Estimation Using Part Affinity Fields,"OpenPose: Realtime Multi-Person 2D Pose Estimation Using Part Affinity Fields

Realtime multi-person 2D pose estimation is a key component in enabling machines to have an understanding of people images and videos. In this work, we present realtime approach detect the multiple image. The proposed method uses nonparametric representation, which refer as Part Affinity Fields (PAFs), learn associate body parts with individuals This bottom-up system achieves high accuracy performance, regardless number previous PAFs part location were refined simultaneously across training stages. We demonstrate that PAF-only refinement rather than both PAF results substantial increase runtime performance accuracy. also first combined foot keypoint detector, based on internal annotated dataset publicly released. show detector not only reduces inference time compared running them sequentially, but maintains each individually. work has culminated release OpenPose, open-source for detection, including body, foot, hand, facial keypoints.

image analysis, human pose estimation, computer science, multi-view geometry, computer vision, machine learning, pose estimation, gesture recognition, 3d pose estimation, machine vision, part affinity fields",2021,3042,image analysis|human pose estimation|computer science|multi-view geometry|computer vision|machine learning|pose estimation|gesture recognition|3d pose estimation|machine vision|part affinity fields,
https://openalex.org/W3166396011,Learning Transferable Visual Models From Natural Language Supervision,"Learning Transferable Visual Models From Natural Language Supervision

State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form supervision limits their generality and usability since additional labeled data is needed specify any other visual concept. Learning directly from raw text about images promising alternative which leverages much broader source supervision. We demonstrate that the simple pre-training task predicting caption goes with image an efficient scalable way learn SOTA representations scratch on dataset 400 million (image, text) pairs collected internet. After pre-training, natural language used reference learned concepts (or describe new ones) enabling zero-shot transfer model downstream tasks. study performance this approach by benchmarking over 30 different existing datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, many types fine-grained classification. The transfers non-trivially most often competitive fully supervised baseline without need for specific training. For instance, we match accuracy original ResNet-50 ImageNet needing use 1.28 training examples it was on. release our code pre-trained weights at https://github.com/OpenAI/CLIP.

transferable visual models, transfer learning, natural language processing, vision language model, scene interpretation, computer science, language model, machine learning, natural language supervision, deep learning",2021,2746,transferable visual models|transfer learning|natural language processing|vision language model|scene interpretation|computer science|language model|machine learning|natural language supervision|deep learning,
https://openalex.org/W3014641072,Deep High-Resolution Representation Learning for Visual Recognition,"Deep High-Resolution Representation Learning for Visual Recognition

High-resolution representations are essential for position-sensitive vision problems, such as human pose estimation, semantic segmentation, and object detection. Existing state-of-the-art frameworks first encode the input image a low-resolution representation through subnetwork that is formed by connecting high-to-low resolution convolutions <i>in series</i> (e.g., ResNet, VGGNet), then recover high-resolution from encoded representation. Instead, our proposed network, named High-Resolution Network (HRNet), maintains whole process. There two key characteristics: (i) Connect convolution streams parallel</i> (ii) repeatedly exchange information across resolutions. The benefit resulting semantically richer spatially more precise. We show superiority of HRNet in wide range applications, including detection, suggesting stronger backbone computer problems. All codes available at <uri>https://github.com/HRNet</uri>.

computer science, high resolution, machine learning, visual science, visual recognition, image analysis, feature detection, cognitive science, data science, image representation, vision recognition, computational imaging, deep high-resolution representation, deep learning, machine vision, digital image processing, feature extraction, computer vision, image classification",2021,2367,computer science|high resolution|machine learning|visual science|visual recognition|image analysis|feature detection|cognitive science|data science|image representation|vision recognition|computational imaging|deep high-resolution representation|deep learning|machine vision|digital image processing|feature extraction|computer vision|image classification,https://openalex.org/W3140854437
https://openalex.org/W1492815834,An Introduction to Statistical Learning: with Applications in R,"An Introduction to Statistical Learning: with Applications in R

An Introduction to Statistical Learning provides an accessible overview of the field statistical learning, essential toolset for making sense vast and complex data sets that have emerged in fields ranging from biology finance marketing astrophysics past twenty years. This book presents some most important modeling prediction techniques, along with relevant applications. Topics include linear regression, classification, resampling methods, shrinkage approaches, tree-based support vector machines, clustering, more. Color graphics real-world examples are used illustrate methods presented. Since goal this textbook is facilitate use these learning techniques by practitioners science, industry, other fields, each chapter contains a tutorial on implementing analyses presented R, extremely popular open source software platform. Two authors co-wrote The Elements (Hastie, Tibshirani Friedman, 2nd edition 2009), reference statistics machine researchers. covers many same topics, but at level much broader audience. targeted statisticians non-statisticians alike who wish cutting-edge analyze their data. text assumes only previous course regression no knowledge matrix algebra.

statistical methodology, statistical learning, applied statistics, statistical learning theory, machine learning, data science, statistics",2021,2205,statistical methodology|statistical learning|applied statistics|statistical learning theory|machine learning|data science|statistics,
https://openalex.org/W3204438512,An introduction to statistical learning with applications in R,"An introduction to statistical learning with applications in R

In the twenty-first century, Machine learning is a hot trend procedure for handling real-life problem. Several books and research articles are now available in literature on this topic. An intr...

statistical methodology, statistical learning, applied statistics, statistical learning theory, statistical inference, machine learning, data science, statistics, algorithmic learning",2021,2155,statistical methodology|statistical learning|applied statistics|statistical learning theory|statistical inference|machine learning|data science|statistics|algorithmic learning,
https://openalex.org/W3168436232,"AutoDock Vina 1.2.0: New Docking Methods, Expanded Force Field, and Python Bindings","AutoDock Vina 1.2.0: New Docking Methods, Expanded Force Field, and Python Bindings

AutoDock Vina is arguably one of the fastest and most widely used open-source programs for molecular docking. However, compared to other in Suite, it lacks support modeling specific features such as macrocycles or explicit water molecules. Here, we describe implementation this functionality 1.2.0. Additionally, 1.2.0 supports AutoDock4.2 scoring function, simultaneous docking multiple ligands, a batch mode large number ligands. Furthermore, implemented Python bindings facilitate scripting development workflows. This work an effort toward unification AutoDock4 programs. The source code available at https://github.com/ccsb-scripps/AutoDock-Vina.

active control, force field, biophysics, nanotechnology, mechanical engineering, protein science, full duplex, python bindings, numerical simulation, intrinsic impurity, field method, computer science, magnetism, machine learning, collapse behaviour, friction, sensor, molecular docking",2021,2151,active control|force field|biophysics|nanotechnology|mechanical engineering|protein science|full duplex|python bindings|numerical simulation|intrinsic impurity|field method|computer science|magnetism|machine learning|collapse behaviour|friction|sensor|molecular docking,
https://openalex.org/W3132455321,Image Segmentation Using Deep Learning: A Survey,"Image Segmentation Using Deep Learning: A Survey

Image segmentation is a key task in computer vision and image processing with important applications such as scene understanding, medical analysis, robotic perception, video surveillance, augmented reality, compression, among others, numerous algorithms are found the literature. Against this backdrop, broad success of deep learning (DL) has prompted development new approaches leveraging DL models. We provide comprehensive review recent literature, covering spectrum pioneering efforts semantic instance segmentation, including convolutional pixel-labeling networks, encoder-decoder architectures, multiscale pyramid-based approaches, recurrent visual attention models, generative models adversarial settings. investigate relationships, strengths, challenges these DL-based examine widely used datasets, compare performances, discuss promising research directions.

pattern recognition, computer science, scene understanding, computer vision, machine learning, deep learning, image segmentation, digital image processing",2021,2095,pattern recognition|computer science|scene understanding|computer vision|machine learning|deep learning|image segmentation|digital image processing,https://openalex.org/W3132455321
https://openalex.org/W3131500599,Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions,"Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions

Although convolutional neural networks (CNNs) have achieved great success in computer vision, this work investigates a simpler, convolution-free backbone network use-fid for many dense prediction tasks. Unlike the recently-proposed Vision Transformer (ViT) that was designed image classification specifically, we introduce Pyramid (PVT), which overcomes difficulties of porting to various PVT has several merits compared current state arts. (1) Different from ViT typically yields low-resolution outputs and incurs high computational memory costs, not only can be trained on partitions an achieve output resolution, is important prediction, but also uses progressive shrinking pyramid reduce computations large feature maps. (2) inherits advantages both CNN Transformer, making it unified vision tasks without convolutions, where used as direct replacement backbones. (3) We validate through extensive experiments, showing boosts performance downstream tasks, including object detection, instance semantic segmentation. For example, with comparable number parameters, PVT+RetinaNet achieves 40.4 AP COCO dataset, surpassing ResNet50+RetinNet (36.3 AP) by 4.1 absolute (see Figure 2). hope could, serre alternative useful pixel-level predictions facilitate future research.

computer vision, computational imaging, neural computation, dense prediction, versatile backbone, computer science, convolutional neural network, machine learning, image representation, deep learning, pyramid vision transformer, machine learning research, image analysis",2021,2089,computer vision|computational imaging|neural computation|dense prediction|versatile backbone|computer science|convolutional neural network|machine learning|image representation|deep learning|pyramid vision transformer|machine learning research|image analysis,
https://openalex.org/W3181414820,A Survey on Bias and Fairness in Machine Learning,"A Survey on Bias and Fairness in Machine Learning

With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance designing engineering such systems. AI can be used many sensitive environments to make important life-changing decisions; thus, it is crucial ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work been developed traditional machine learning deep address challenges different subdomains. commercialization systems, researchers are becoming more aware biases contain attempting them. In this survey, we investigated real-world have shown various ways, listed sources affect applications. We then created a taxonomy definitions defined avoid existing bias addition that, examined domains subdomains showing what observed with regard unfair outcomes state-of-the-art methods ways they tried There still future directions solutions taken mitigate problem hoping survey will motivate tackle issues near by observing their respective fields.

adversarial machine learning, disparate impact, computer science, bias, algorithmic bias, machine learning, algorithmic fairness, data science, machine learning research, fairness",2021,1988,adversarial machine learning|disparate impact|computer science|bias|algorithmic bias|machine learning|algorithmic fairness|data science|machine learning research|fairness,
https://openalex.org/W3170841864,Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers,"Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers

Most recent semantic segmentation methods adopt a fully-convolutional network (FCN) with an encoder-decoder architecture. The encoder progressively reduces the spatial resolution and learns more abstract/semantic visual concepts larger receptive fields. Since context modeling is critical for segmentation, latest efforts have been focused on increasing field, through either dilated/atrous convolutions or inserting attention modules. However, based FCN architecture remains unchanged. In this paper, we aim to provide alternative perspective by treating as sequence-to-sequence prediction task. Specifically, deploy pure transformer (i.e., without convolution reduction) encode image sequence of patches. With global modeled in every layer transformer, can be combined simple decoder powerful model, termed SEgmentation TRansformer (SETR). Extensive experiments show that SETR achieves new state art ADE20K (50.28% mIoU), Pascal Context (55.83% mIoU) competitive results Cityscapes. Particularly, achieve first position highly test server leaderboard day submission.

computer science, natural language processing, sequence-to-sequence perspective, computer vision, machine learning, deep learning, image segmentation, semantic segmentation",2021,1934,computer science|natural language processing|sequence-to-sequence perspective|computer vision|machine learning|deep learning|image segmentation|semantic segmentation,
https://openalex.org/W3145969289,Gene Set Knowledge Discovery with Enrichr,"Gene Set Knowledge Discovery with Enrichr

Profiling samples from patients, tissues, and cells with genomics, transcriptomics, epigenomics, proteomics, metabolomics ultimately produces lists of genes proteins that need to be further analyzed integrated in the context known biology. Enrichr (Chen et al., 2013; Kuleshov 2016) is a gene set search engine enables querying hundreds thousands annotated sets. uniquely integrates knowledge many high-profile projects provide synthesized information about mammalian The platform provides various methods compute enrichment, results are visualized several interactive ways. This protocol summary key features Enrichr, which include using programmatically embedding an button on any website. © 2021 Wiley Periodicals LLC. Basic Protocol 1: Analyzing differentially expressed proteomics phosphoproteomics, GWAS studies, or other experimental studies 2: Searching by single term 3: Preparing raw processed RNA-seq data through BioJupies preparation for analysis 4: sets model organisms modEnrichr 5: Using Geneshot 6: ARCHS4 7: enrichment visualization Appyter visualize 8: API 9: Adding

gene expression, gene sequence annotation, computational genomics, genome biology, systems biology, machine learning, omics datasets, data science, biomedical informatics, deep learning, knowledge discovery, genomics, machine learning research, gene recognition, molecular informatics, genetics, bioinformatics",2021,1854,gene expression|gene sequence annotation|computational genomics|genome biology|systems biology|machine learning|omics datasets|data science|biomedical informatics|deep learning|knowledge discovery|genomics|machine learning research|gene recognition|molecular informatics|genetics|bioinformatics,
https://openalex.org/W3171007011,Exploring Simple Siamese Representation Learning,"Exploring Simple Siamese Representation Learning

Siamese networks have become a common structure in various recent models for unsupervised visual representation learning. These maximize the similarity between two augmentations of one image, subject to certain conditions avoiding collapsing solutions. In this paper, we report surprising empirical results that simple can learn meaningful representations even using none following: (i) negative sample pairs, (ii) large batches, (iii) momentum encoders. Our experiments show solutions do exist loss and structure, but stop-gradient operation plays an essential role preventing collapsing. We provide hypothesis on implication stop-gradient, further proof-of-concept verifying it. ""SimSiam"" method achieves competitive ImageNet downstream tasks. hope baseline will motivate people rethink roles architectures Code is made available. <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">1</sup>

image analysis, computational imaging, computer science, linguistics, information fusion, language model, natural language processing, machine learning, multilingual pretraining, geometric learning, data science, knowledge discovery, deep learning, image representation, similarity search, machine vision, representation analysis, manifold learning",2021,1739,image analysis|computational imaging|computer science|linguistics|information fusion|language model|natural language processing|machine learning|multilingual pretraining|geometric learning|data science|knowledge discovery|deep learning|image representation|similarity search|machine vision|representation analysis|manifold learning,https://openalex.org/W3159481202|https://openalex.org/W4313156423
https://openalex.org/W3159481202,Emerging Properties in Self-Supervised Vision Transformers,"Emerging Properties in Self-Supervised Vision Transformers

In this paper, we question if self-supervised learning provides new properties to Vision Transformer (ViT) [16] that stand out compared convolutional networks (convnets). Beyond the fact adapting methods architecture works particularly well, make following observations: first, ViT features contain explicit information about semantic segmentation of an image, which does not emerge as clearly with supervised ViTs, nor convnets. Second, these are also excellent k-NN classifiers, reaching 78.3% top-1 on ImageNet a small ViT. Our study underlines importance momentum encoder [26], multi-crop training [9], and use patches ViTs. We implement our findings into simple method, called DINO, interpret form self-distillation no labels. show synergy between DINO ViTs by achieving 80.1% in linear evaluation ViT-Base.

computational imaging, computer science, self-supervised vision transformers, computer vision, machine learning, self-supervised learning, deep learning, neural network (machine learning), vision recognition, machine vision, vision robotics",2021,1623,computational imaging|computer science|self-supervised vision transformers|computer vision|machine learning|self-supervised learning|deep learning|neural network (machine learning)|vision recognition|machine vision|vision robotics,https://openalex.org/W4313156423
https://openalex.org/W1710476689,Generative Adversarial Networks,"Generative Adversarial Networks

The Science of Deep Learning emerged from courses taught by the author that have provided thousands students with training and experience for their academic studies, prepared them careers in deep learning, machine artificial intelligence top companies industry academia. book begins covering foundations followed key learning architectures. Subsequent parts on generative models reinforcement may be used as part a course or each topic. includes state-of-the-art topics such Transformers, graph neural networks, variational autoencoders, broad range applications. appendices provide equations computing gradients backpropagation optimization, best practices scientific writing reviewing. text presents an up-to-date guide to field built upon clear visualizations using unified notation equations, lowering barrier entry reader. accompanying website provides complementary code hundreds exercises solutions.

generative adversarial network, computer science, machine learning",2022,2645,generative adversarial network|computer science|machine learning,
https://openalex.org/W4312443924,A ConvNet for the 2020s,"A ConvNet for the 2020s

The ""Roaring 20s"" of visual recognition began with the introduction Vision Transformers (ViTs), which quickly superseded ConvNets as state-of-the-art image classification model. A vanilla ViT, on other hand, faces difficulties when applied to general computer vision tasks such object detection and semantic segmentation. It is hierarchical (e.g., Swin Transformers) that reintroduced several ConvNet priors, making practically viable a generic backbone demonstrating remarkable performance wide variety tasks. However, effectiveness hybrid approaches still largely credited intrinsic superiority Transformers, rather than inherent inductive biases convolutions. In this work, we reexamine design spaces test limits what pure can achieve. We gradually ""modernize"" standard ResNet toward Transformer, discover key components contribute difference along way. outcome exploration family models dubbed ConvNeXt. Constructed entirely from modules, ConvNeXts compete favorably in terms accuracy scalability, achieving 87.8% ImageNet top-1 outperforming COCO ADE20K segmentation, while maintaining simplicity efficiency ConvNets.

computer vision, machine vision, neural network (machine learning), computer science, convolutional neural network, machine learning, deep learning, image analysis",2022,2053,computer vision|machine vision|neural network (machine learning)|computer science|convolutional neural network|machine learning|deep learning|image analysis,
https://openalex.org/W4313156423,Masked Autoencoders Are Scalable Vision Learners,"Masked Autoencoders Are Scalable Vision Learners

This paper shows that masked autoencoders (MAE) are scalable self-supervised learners for computer vision. Our MAE approach is simple: we mask random patches of the input image and reconstruct missing pixels. It based on two core designs. First, develop an asymmetric encoder-decoder architecture, with encoder operates only visible subset (without tokens), along a lightweight decoder reconstructs original from latent representation tokens. Second, find masking high proportion image, e.g., 75%, yields nontrivial meaningful self-supervisory task. Coupling these designs enables us to train large models efficiently effectively: accelerate training (by 3× or more) improve accuracy. allows learning high-capacity generalize well: vanilla ViT-Huge model achieves best accuracy (87.8%) among methods use ImageNet-1K data. Transfer performance in downstream tasks outperforms supervised pretraining promising scaling behavior.

image analysis, autoencoders, computer science, convolutional neural network, scalable vision learners, scene understanding, computer vision, machine learning, digital learning, deep learning, image representation, autonomous learning, neural network (machine learning), machine vision",2022,2022,image analysis|autoencoders|computer science|convolutional neural network|scalable vision learners|scene understanding|computer vision|machine learning|digital learning|deep learning|image representation|autonomous learning|neural network (machine learning)|machine vision,
https://openalex.org/W3003265726,"A Survey on Knowledge Graphs: Representation, Acquisition, and Applications","A Survey on Knowledge Graphs: Representation, Acquisition, and Applications

Human knowledge provides a formal understanding of the world. Knowledge graphs that represent structural relations between entities have become an increasingly popular research direction toward cognition and human-level intelligence. In this survey, we provide comprehensive review graph covering overall topics about: 1) representation learning; 2) acquisition completion; 3) temporal graph; 4) knowledge-aware applications summarize recent breakthroughs perspective directions to facilitate future research. We propose full-view categorization new taxonomies on these topics. embedding is organized from four aspects space, scoring function, encoding models, auxiliary information. For acquisition, especially completion, methods, path inference, logical rule reasoning are reviewed. further explore several emerging topics, including metarelational learning, commonsense reasoning, graphs. To graphs, also curated collection data sets open-source libraries different tasks. end, thorough outlook promising directions.

computer science, knowledge representation and reasoning, knowledge graph, information science, knowledge engineering, knowledge modeling, social science, distributed knowledge, clustering, semantic web, data science, network analysis, knowledge discovery, knowledge extraction, machine learning research, knowledge graph embeddings, database, knowledge management",2022,1439,computer science|knowledge representation and reasoning|knowledge graph|information science|knowledge engineering|knowledge modeling|social science|distributed knowledge|clustering|semantic web|data science|network analysis|knowledge discovery|knowledge extraction|machine learning research|knowledge graph embeddings|database|knowledge management,
https://openalex.org/W3168997536,"A Survey of Convolutional Neural Networks: Analysis, Applications, and Prospects","A Survey of Convolutional Neural Networks: Analysis, Applications, and Prospects

A convolutional neural network (CNN) is one of the most significant networks in deep learning field. Since CNN made impressive achievements many areas, including but not limited to computer vision and natural language processing, it attracted much attention from both industry academia past few years. The existing reviews mainly focus on CNN's applications different scenarios without considering a general perspective, some novel ideas proposed recently are covered. In this review, we aim provide prospects fast-growing Besides, only 2-D convolution also 1-D multidimensional ones involved. First, review introduces history CNN. Second, an overview various convolutions. Third, classic advanced models introduced; especially those key points making them reach state-of-the-art results. Fourth, through experimental analysis, draw conclusions several rules thumb for functions hyperparameter selection. Fifth, 1-D, 2-D, Finally, open issues promising directions discussed as guidelines future work.

image analysis, computer science, convolutional neural network, neuroscience, machine learning, sparse neural network, data science, neural computation, deep learning, machine learning research, neural network (machine learning)",2022,1427,image analysis|computer science|convolutional neural network|neuroscience|machine learning|sparse neural network|data science|neural computation|deep learning|machine learning research|neural network (machine learning),
https://openalex.org/W4221143046,Chain-of-Thought Prompting Elicits Reasoning in Large Language Models,"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models

We explore how generating a chain of thought -- series intermediate reasoning steps significantly improves the ability large language models to perform complex reasoning. In particular, we show such abilities emerge naturally in sufficiently via simple method called prompting, where few demonstrations are provided as exemplars prompting. Experiments on three that prompting performance range arithmetic, commonsense, and symbolic tasks. The empirical gains can be striking. For instance, 540B-parameter model with just eight achieves state art accuracy GSM8K benchmark math word problems, surpassing even finetuned GPT-3 verifier.

computer science, knowledge representation and reasoning, artificial intelligence, large language model, language model, natural language processing, reasoning system, machine learning, model-based reasoning, cognitive science",2022,1291,computer science|knowledge representation and reasoning|artificial intelligence|large language model|language model|natural language processing|reasoning system|machine learning|model-based reasoning|cognitive science,
https://openalex.org/W4283387379,How much should we trust staggered difference-in-differences estimates?,"How much should we trust staggered difference-in-differences estimates?

We explain when and how staggered difference-in-differences regression estimators, commonly applied to assess the impact of policy changes, are biased. These biases likely be relevant for a large portion research settings in finance, accounting, law that rely on treatment timing, can result Type-I Type-II errors. summarize three alternative estimators developed econometrics literature addressing these biases, including their differences tradeoffs. apply re-examine prior published results show, many cases, causal estimates or inferences differ substantially from papers.

model comparison, forecasting, latent variable model, difference-in-differences estimates, policy analysis, choice-process data, statistical inference, machine learning, data science, statistics, time series, machine learning research, quantitative science study, principal component analysis",2022,1249,model comparison|forecasting|latent variable model|difference-in-differences estimates|policy analysis|choice-process data|statistical inference|machine learning|data science|statistics|time series|machine learning research|quantitative science study|principal component analysis,
https://openalex.org/W4206950245,SignalP 6.0 predicts all five types of signal peptides using protein language models,"SignalP 6.0 predicts all five types of signal peptides using protein language models

Abstract Signal peptides (SPs) are short amino acid sequences that control protein secretion and translocation in all living organisms. SPs can be predicted from sequence data, but existing algorithms unable to detect known types of SPs. We introduce SignalP 6.0, a machine learning model detects five SP is applicable metagenomic data.

protein bioinformatics, protein modeling, signal integrity, proteomics, protein structure prediction, protein language models, peptide, systems biology, molecular biology, computational biology, machine learning research, peptide science, signal peptides, protein science, molecular informatics, bioinformatics",2022,1177,protein bioinformatics|protein modeling|signal integrity|proteomics|protein structure prediction|protein language models|peptide|systems biology|molecular biology|computational biology|machine learning research|peptide science|signal peptides|protein science|molecular informatics|bioinformatics,
https://openalex.org/W3011667710,Deep Learning on Graphs: A Survey,"Deep Learning on Graphs: A Survey

Deep learning has been shown to be successful in a number of domains, ranging from acoustics, images, natural language processing. However, applying deep the ubiquitous graph data is non-trivial because unique characteristics graphs. Recently, substantial research efforts have devoted methods graphs, resulting beneficial advances analysis techniques. In this survey, we comprehensively review different types on We divide existing into five categories based their model architectures and training strategies: recurrent neural networks, convolutional autoencoders, reinforcement learning, adversarial methods. then provide comprehensive overview these systematic manner mainly by following development history. also analyze differences compositions Finally, briefly outline applications which they used discuss potential future directions.

computer science, graph theory, machine learning, graph analysis, deep learning, neural network (machine learning), graph neural network, graph processing",2022,1035,computer science|graph theory|machine learning|graph analysis|deep learning|neural network (machine learning)|graph neural network|graph processing,https://openalex.org/W3140854437
https://openalex.org/W4206965224,UALCAN: An update to the integrated cancer data analysis platform,"UALCAN: An update to the integrated cancer data analysis platform

Cancer genomic, transcriptomic, and proteomic profiling has generated extensive data that necessitate the development of tools for its analysis dissemination. We developed UALCAN to provide a portal easy exploring, analyzing, visualizing these data, allowing users integrate better understand gene, proteins, pathways perturbed in cancer make discoveries. web enables analyzing delivering transcriptome, proteomics, patient survival research community. With obtained from The Genome Atlas (TCGA) project, enabled evaluate protein-coding gene expression impact on across 33 types cancers. been used extensively since release received immense popularity, underlined by usage researchers more than 100 countries. present manuscript highlights task we have undertaken updates made 2017. Extensive user feedback motivated us expand resource including a) microRNAs (miRNAs), long non-coding RNAs (lncRNAs), promoter DNA methylation TCGA b) mass spectrometry-based proteomics Clinical Proteomic Tumor Analysis Consortium (CPTAC). provides access pre-computed, tumor subgroup-based gene/protein expression, status, Kaplan-Meier analyses. It also new visualization features comprehend observations aids generating hypotheses testing. is accessible at http://ualcan.path.uab.edu.

cancer discovery, medical image computing, biomedical data integration, tumor biology, data integration, omics datasets, biostatistics, data science, oncology, statistics, cancer research, cancer imaging, machine learning research, biomedical data analysis, omics integration, cancer genomics, biomedical informatics, bioinformatics",2022,972,cancer discovery|medical image computing|biomedical data integration|tumor biology|data integration|omics datasets|biostatistics|data science|oncology|statistics|cancer research|cancer imaging|machine learning research|biomedical data analysis|omics integration|cancer genomics|biomedical informatics|bioinformatics,
https://openalex.org/W3011594683,A Survey on Deep Learning for Named Entity Recognition,"A Survey on Deep Learning for Named Entity Recognition

Named entity recognition (NER) is the task to identify mentions of rigid designators from text belonging predefined semantic types such as person, location, organization etc. NER always serves foundation for many natural language applications question answering, summarization, and machine translation. Early systems got a huge success in achieving good performance with cost human engineering designing domain-specific features rules. In recent years, deep learning, empowered by continuous real-valued vector representations composition through nonlinear processing, has been employed systems, yielding stat-of-the-art performance. this paper, we provide comprehensive review on existing learning techniques NER. We first introduce resources, including tagged corpora off-the-shelf tools. Then, systematically categorize works based taxonomy along three axes: distributed input, context encoder, tag decoder. Next, survey most representative methods applied new problem settings applications. Finally, present readers challenges faced outline future directions area.

computer science, keyword extraction, entity recognition, machine learning, cognitive science, data science, knowledge discovery, deep learning, knowledge extraction, machine learning research, entity disambiguation, named-entity recognition, nlp task",2022,913,computer science|keyword extraction|entity recognition|machine learning|cognitive science|data science|knowledge discovery|deep learning|knowledge extraction|machine learning research|entity disambiguation|named-entity recognition|nlp task,
https://openalex.org/W3141797743,A Survey on Multi-Task Learning,"A Survey on Multi-Task Learning

Multi-Task Learning (MTL) is a learning paradigm in machine and its aim to leverage useful information contained multiple related tasks help improve the generalization performance of all tasks. In this paper, we give survey for MTL from perspective algorithmic modeling, applications theoretical analyses. For definition then classify different algorithms into five categories, including feature approach, low-rank task clustering relation approach decomposition as well discussing characteristics each approach. order further, can be combined with other paradigms semi-supervised learning, active unsupervised reinforcement multi-view graphical models. When number large or data dimensionality high, review online, parallel distributed models reduction hashing reveal their computational storage advantages. Many real-world use boost representative works paper. Finally, present analyses discuss several future directions MTL.

computer science, multi-task learning, machine learning, cognitive science, machine learning research",2022,903,computer science|multi-task learning|machine learning|cognitive science|machine learning research,https://openalex.org/W3209696639
https://openalex.org/W3127561923,Deep Reinforcement Learning for Autonomous Driving: A Survey,"Deep Reinforcement Learning for Autonomous Driving: A Survey

With the development of deep representation learning, domain reinforcement learning (RL) has become a powerful framework now capable complex policies in high dimensional environments. This review summarises (DRL) algorithms and provides taxonomy automated driving tasks where (D)RL methods have been employed, while addressing key computational challenges real world deployment autonomous agents. It also delineates adjacent domains such as behavior cloning, imitation inverse that are related but not classical RL algorithms. The role simulators training agents, to validate, test robustify existing solutions discussed.

computer science, artificial intelligence, autonomous navigation, machine learning, reinforcement learning, deep reinforcement learning, control optimization, robot learning, cognitive science, neural computation, swarm intelligence, learning control, autonomous learning, computer engineering, automatic control, deep learning, autonomous driving, intelligent computing, deep reinforcement",2022,897,computer science|artificial intelligence|autonomous navigation|machine learning|reinforcement learning|deep reinforcement learning|control optimization|robot learning|cognitive science|neural computation|swarm intelligence|learning control|autonomous learning|computer engineering|automatic control|deep learning|autonomous driving|intelligent computing|deep reinforcement,
https://openalex.org/W4221151978,Instant neural graphics primitives with a multiresolution hash encoding,"Instant neural graphics primitives with a multiresolution hash encoding

Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate. We reduce this cost with a versatile new input encoding that permits the use of smaller network without sacrificing quality, thus significantly reducing number floating point memory access operations: small is augmented multiresolution hash table trainable feature vectors whose values are optimized through stochastic gradient descent. The structure allows disambiguate collisions, making for simple architecture trivial parallelize on modern GPUs. leverage parallelism implementing whole system using fully-fused CUDA kernels focus minimizing wasted bandwidth compute operations. achieve combined speedup several orders magnitude, enabling training high-quality primitives in matter seconds, rendering tens milliseconds at resolution ${1920\!\times\!1080}$.

multiresolution hash, computer science, machine learning, neural computation, hash function",2022,872,multiresolution hash|computer science|machine learning|neural computation|hash function,
https://openalex.org/W3016719260,ResNeSt: Split-Attention Networks,"ResNeSt: Split-Attention Networks

The ability to learn richer network representations generally boosts the performance of deep learning models. To improve representation-learning in convolutional neural networks, we present a multi-branch architecture, which applies channel-wise attention across different branches leverage complementary strengths both feature-map and multi-path representation. Our proposed Split-Attention module provides simple modular computation block that can serve as drop-in replacement for popular residual block, while producing more diverse via cross-feature interactions. Adding into architecture design space RegNet-Y FBNetV2 directly improves resulting network. Replacing blocks with our module, further new variant ResNet model, named ResNeSt, outperforms EfficientNet terms accuracy/latency trade-off.

computer science, machine learning, recurrent neural network, cognitive science, deep learning, machine learning research, split-attention networks",2022,752,computer science|machine learning|recurrent neural network|cognitive science|deep learning|machine learning research|split-attention networks,https://openalex.org/W3132455321|https://openalex.org/W3131500599
https://openalex.org/W4220887281,Harnessing protein folding neural networks for peptide–protein docking,"Harnessing protein folding neural networks for peptide–protein docking

Highly accurate protein structure predictions by deep neural networks such as AlphaFold2 and RoseTTAFold have tremendous impact on structural biology beyond. Here, we show that, although these learning approaches originally been developed for the in silico folding of monomers, also enables quick modeling peptide-protein interactions. Our simple implementation generates complex models without requiring multiple sequence alignment information peptide partner, can handle binding-induced conformational changes receptor. We explore what has memorized learned, describe specific examples that highlight differences compared to state-of-the-art docking protocol PIPER-FlexPepDock. These results holds great promise providing insight into a wide range complexes, serving starting point detailed characterization manipulation

protein bioinformatics, protein modeling, systems biology, protein structure, peptide-protein docking, neural networks, computational biology, neural network (machine learning), biophysics, protein science, protein folding",2022,748,protein bioinformatics|protein modeling|systems biology|protein structure|peptide-protein docking|neural networks|computational biology|neural network (machine learning)|biophysics|protein science|protein folding,
https://openalex.org/W2799041689,Deep Facial Expression Recognition: A Survey,"Deep Facial Expression Recognition: A Survey

With the transition of facial expression recognition (FER) from laboratory-controlled to challenging in-the-wild conditions and recent success deep learning techniques in various fields, neural networks have increasingly been leveraged learn discriminative representations for automatic FER. Recent FER systems generally focus on two important issues: overfitting caused by a lack sufficient training data expression-unrelated variations, such as illumination, head pose identity bias. In this paper, we provide comprehensive survey FER, including datasets algorithms that insights into these intrinsic problems. First, describe standard pipeline system with related background knowledge suggestions applicable implementations each stage. We then introduce available are widely used literature accepted selection evaluation principles datasets. For state art review existing novel strategies designed based both static images dynamic image sequences, discuss their advantages limitations. Competitive performances benchmarks also summarized section. extend our additional issues application scenarios. Finally, remaining challenges corresponding opportunities field well future directions design robust systems.

image analysis, pattern recognition, computer science, affective computing, computer vision, machine learning, facial recognition system, data science, computational intelligence, deep learning, emotion recognition, machine vision, face detection, facial expression recognition",2022,717,image analysis|pattern recognition|computer science|affective computing|computer vision|machine learning|facial recognition system|data science|computational intelligence|deep learning|emotion recognition|machine vision|face detection|facial expression recognition,
https://openalex.org/W4386076325,YOLOv7: Trainable Bag-of-Freebies Sets New State-of-the-Art for Real-Time Object Detectors,"YOLOv7: Trainable Bag-of-Freebies Sets New State-of-the-Art for Real-Time Object Detectors

Real-time object detection is one of the most important research topics in computer vision. As new approaches regarding architecture optimization and training are continually being developed, we have found two that spawned when dealing with these latest state-of-the-art methods. To address topics, propose a trainable bag-of-freebies oriented solution. We combine flexible efficient tools proposed compound scaling method. YOLOv7 surpasses all known detectors both speed accuracy range from 5 FPS to 120 has highest 56.8% AP among real-time 30 or higher on GPU V100. Source code released https://github.com/WongKinYiu/yolov7.

computer science, object tracking, object recognition, real-time monitoring, computer vision, machine learning, object detection, object categorization, real-time object detectors, machine vision",2023,3524,computer science|object tracking|object recognition|real-time monitoring|computer vision|machine learning|object detection|object categorization|real-time object detectors|machine vision,https://openalex.org/W4320002812
https://openalex.org/W3185341429,"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing","Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing

This article surveys and organizes research works in a new paradigm natural language processing, which we dub “prompt-based learning.” Unlike traditional supervised learning, trains model to take an input x predict output y as P ( y|x ), prompt-based learning is based on models that the probability of text directly. To use these perform prediction tasks, original modified using template into textual string prompt x′ has some unfilled slots, then used probabilistically fill information obtain final x̂ , from can be derived. framework powerful attractive for number reasons: It allows pre-trained massive amounts raw text, by defining prompting function able few-shot or even zero-shot adapting scenarios with few no labeled data. In this article, introduce basics promising paradigm, describe unified set mathematical notations cover wide variety existing work, organize work along several dimensions, e.g., choice models, prompts, tuning strategies. make field more accessible interested beginners, not only systematic review highly structured typology concepts but also release other resources, website NLPedia–Pretrain including constantly updated survey paperlist.

computer science, natural language processing, language model, predictive learning, machine learning, nlp task, machine learning research",2023,1053,computer science|natural language processing|language model|predictive learning|machine learning|nlp task|machine learning research,
https://openalex.org/W4320002812,Object Detection in 20 Years: A Survey,"Object Detection in 20 Years: A Survey

Object detection, as of one the most fundamental and challenging problems in computer vision, has received great attention recent years. Over past two decades, we have seen a rapid technological evolution object detection its profound impact on entire vision field. If consider today's technique revolution driven by deep learning, then, back 1990s, would see ingenious thinking long-term perspective design early vision. This article extensively reviews this fast-moving research field light technical evolution, spanning over quarter-century's time (from 1990s to 2022). A number topics been covered article, including milestone detectors history, datasets, metrics, building blocks system, speedup techniques, state-of-the-art methods.

image analysis, pattern recognition, computer science, object tracking, object recognition, visual surveillance, computer vision, machine learning, scene analysis, object detection, data science, deep learning, image representation, machine vision",2023,859,image analysis|pattern recognition|computer science|object tracking|object recognition|visual surveillance|computer vision|machine learning|scene analysis|object detection|data science|deep learning|image representation|machine vision,
https://openalex.org/W3042609801,Learning From Noisy Labels With Deep Neural Networks: A Survey,"Learning From Noisy Labels With Deep Neural Networks: A Survey

Deep learning has achieved remarkable success in numerous domains with help from large amounts of big data. However, the quality data labels is a concern because lack high-quality many real-world scenarios. As noisy severely degrade generalization performance deep neural networks, (robust training) becoming an important task modern applications. In this survey, we first describe problem label noise supervised perspective. Next, provide comprehensive review 62 state-of-the-art robust training methods, all which are categorized into five groups according to their methodological difference, followed by systematic comparison six properties used evaluate superiority. Subsequently, perform in-depth analysis rate estimation and summarize typically evaluation methodology, including public datasets metrics. Finally, present several promising research directions that can serve as guideline for future studies.

computer science, supervised learning, machine learning, noisy labels, deep neural networks, deep learning, machine learning research, neural network (machine learning), automatic classification",2023,472,computer science|supervised learning|machine learning|noisy labels|deep neural networks|deep learning|machine learning research|neural network (machine learning)|automatic classification,
https://openalex.org/W3209696639,"A Survey on Federated Learning Systems: Vision, Hype and Reality for Data Privacy and Protection","A Survey on Federated Learning Systems: Vision, Hype and Reality for Data Privacy and Protection

Federated learning has been a hot research topic in enabling the collaborative training of machine models among different organizations under privacy restrictions. As researchers try to support more with privacy-preserving approaches, there is requirement developing systems and infrastructures ease development various federated algorithms. Similar deep such as PyTorch TensorFlow that boost learning, (FLSs) are equivalently important, face challenges from aspects effectiveness, efficiency, privacy. In this survey, we conduct comprehensive review on systems. To achieve smooth flow guide future research, introduce definition analyze system components. Moreover, provide thorough categorization for according six aspects, including data distribution, model, mechanism, communication architecture, scale federation motivation federation. The can help design shown our case studies. By systematically summarizing existing systems, present factors, studies, opportunities.

data management, computer science, federated learning, machine learning, data privacy, data security, data science, decentralized privacy, privacy system, privacy by design, privacy engineering",2023,427,data management|computer science|federated learning|machine learning|data privacy|data security|data science|decentralized privacy|privacy system|privacy by design|privacy engineering,
https://openalex.org/W4361298490,"Artificial Intelligence and Machine Learning in Clinical Medicine, 2023","Artificial Intelligence and Machine Learning in Clinical Medicine, 2023

This first article in a series describes the history of artificial intelligence medicine; use AI image analysis, identification disease outbreaks, and diagnosis; chatbots.

artificial intelligence, ai healthcare, machine learning, medicine, biomedical informatics",2023,402,artificial intelligence|ai healthcare|machine learning|medicine|biomedical informatics,
https://openalex.org/W3216759837,"A Review on Generative Adversarial Networks: Algorithms, Theory, and Applications","A Review on Generative Adversarial Networks: Algorithms, Theory, and Applications

Generative adversarial networks (GANs) have recently become a hot research topic; however, they been studied since 2014, and large number of algorithms proposed. Nevertheless, few comprehensive studies explain the connections among different GAN variants how evolved. In this paper, we attempt to provide review various methods from perspectives algorithms, theory, applications. First, motivations, mathematical representations, structures most are introduced in detail, compare their commonalities differences. Second, theoretical issues related GANs investigated. Finally, typical applications image processing computer vision, natural language processing, music, speech audio, medical field, data science discussed.

generative adversarial network, generative ai, adversarial machine learning, knowledge discovery, data science, pattern recognition, machine learning research, generative model, computer science, machine learning, generative system, computational intelligence, deep learning",2023,349,generative adversarial network|generative ai|adversarial machine learning|knowledge discovery|data science|pattern recognition|machine learning research|generative model|computer science|machine learning|generative system|computational intelligence|deep learning,
https://openalex.org/W3040304705,CCNet: Criss-Cross Attention for Semantic Segmentation,"CCNet: Criss-Cross Attention for Semantic Segmentation

Contextual information is vital in visual understanding problems, such as semantic segmentation and object detection. We propose a criss-cross network (CCNet) for obtaining full-image contextual very effective efficient way. Concretely, each pixel, novel attention module harvests the of all pixels on its path. By taking further recurrent operation, pixel can finally capture dependencies. Besides, category consistent loss proposed to enforce produce more discriminative features. Overall, CCNet with following merits: 1) GPU memory friendly. Compared non-local block, requires 11× less usage. 2) High computational efficiency. The significantly reduces FLOPs by about 85 percent block. 3) state-of-the-art performance. conduct extensive experiments benchmarks including Cityscapes, ADE20K, human parsing benchmark LIP, instance COCO, video CamVid. In particular, our achieves mIoU scores 81.9, 45.76 55.47 Cityscapes test set, ADE20K validation set LIP respectively, which are new results. source codes available at https://github.com/speedinghzl/CCNethttps://github.com/speedinghzl/CCNet.

cognitive science, scene analysis, semantic segmentation, pattern recognition, machine learning, deep learning, convolutional neural network, multi-view geometry, image analysis, data science, computational imaging, image representation, scene understanding, criss-cross attention, machine vision, computer science, scene interpretation, computer vision, information fusion",2023,342,cognitive science|scene analysis|semantic segmentation|pattern recognition|machine learning|deep learning|convolutional neural network|multi-view geometry|image analysis|data science|computational imaging|image representation|scene understanding|criss-cross attention|machine vision|computer science|scene interpretation|computer vision|information fusion,https://openalex.org/W3131500599
