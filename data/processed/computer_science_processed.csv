id,title,content,year,cited_by_count,keywords,children
https://openalex.org/W1981368803,Generalized Gradient Approximation Made Simple,"Generalized Gradient Approximation Made Simple

Generalized gradient approximations (GGA's) for the exchange-correlation energy improve upon local spin density (LSD) description of atoms, molecules, and solids. We present a simple derivation GGA, in which all parameters (other than those LSD) are fundamental constants. Only general features detailed construction underlying Perdew-Wang 1991 (PW91) GGA invoked. Improvements over PW91 include an accurate linear response uniform electron gas, correct behavior under scaling, smoother potential.

mathematics, computer science, approximation theory, approximation method, gradient approximation, mathematical optimization, low-rank approximation, applied mathematics, numerical analysis, machine learning research, computational optimization",1996,168684,mathematics|computer science|approximation theory|approximation method|gradient approximation|mathematical optimization|low-rank approximation|applied mathematics|numerical analysis|machine learning research|computational optimization,
https://openalex.org/W2194775991,Deep Residual Learning for Image Recognition,"Deep Residual Learning for Image Recognition

Deeper neural networks are more difficult to train. We present a residual learning framework ease the training of that substantially deeper than those used previously. explicitly reformulate layers as functions with reference layer inputs, instead unreferenced functions. provide comprehensive empirical evidence showing these easier optimize, and can gain accuracy from considerably increased depth. On ImageNet dataset we evaluate nets depth up 152 - 8× VGG [40] but still having lower complexity. An ensemble achieves 3.57% error on test set. This result won 1st place ILSVRC 2015 classification task. also analysis CIFAR-10 100 1000 layers. The representations is central importance for many visual recognition tasks. Solely due our extremely deep representations, obtain 28% relative improvement COCO object detection dataset. Deep foundations submissions & competitions1, where places tasks detection, localization, segmentation.

image analysis, pattern recognition, computer science, computational imaging, convolutional neural network, object recognition, unsupervised machine learning, machine learning, deep residual learning, deep learning, image representation, image recognition, principal component analysis, image classification, digital image processing",2016,159317,image analysis|pattern recognition|computer science|computational imaging|convolutional neural network|object recognition|unsupervised machine learning|machine learning|deep residual learning|deep learning|image representation|image recognition|principal component analysis|image classification|digital image processing,https://openalex.org/W2963446712|https://openalex.org/W2618530766|https://openalex.org/W639708223|https://openalex.org/W2963150697|https://openalex.org/W2963351448|https://openalex.org/W2565639579|https://openalex.org/W2752782242|https://openalex.org/W2962793481|https://openalex.org/W2412782625|https://openalex.org/W2963163009|https://openalex.org/W2570343428|https://openalex.org/W2531409750|https://openalex.org/W2962858109|https://openalex.org/W3138516171|https://openalex.org/W2560023338|https://openalex.org/W2963420686|https://openalex.org/W2963470893|https://openalex.org/W3094502228|https://openalex.org/W2549139847|https://openalex.org/W2963091558|https://openalex.org/W2612445135|https://openalex.org/W3018757597|https://openalex.org/W2954996726|https://openalex.org/W3035524453|https://openalex.org/W2963524571|https://openalex.org/W2962914239|https://openalex.org/W2508457857|https://openalex.org/W2963125010|https://openalex.org/W2963857521|https://openalex.org/W2402144811|https://openalex.org/W2559085405|https://openalex.org/W3005680577
https://openalex.org/W2064675550,Long Short-Term Memory,"Long Short-Term Memory

Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis this problem, then address it introducing novel, efficient, gradient based method called short-term memory (LSTM). Truncating the where does not do harm, LSTM can learn bridge minimal lags in excess 1000 discrete-time steps enforcing constant flow through carousels within special units. Multiplicative gate units open and close access flow. is local space time; its computational complexity per step weight O. 1. Our experiments with artificial data involve local, distributed, real-valued, noisy pattern representations. In comparisons real-time learning, back propagation cascade correlation, Elman nets, neural sequence chunking, leads many more successful runs, learns much faster. also solves complex, long-time-lag tasks that have never been solved previous network algorithms.

computer science, neuroimaging, neuroscience, explicit memory, short-term memory, cognitive science, cognitive neuroscience, neural computation, memory",1997,73671,computer science|neuroimaging|neuroscience|explicit memory|short-term memory|cognitive science|cognitive neuroscience|neural computation|memory,https://openalex.org/W2194775991|https://openalex.org/W2752782242|https://openalex.org/W2157331557|https://openalex.org/W2964308564|https://openalex.org/W2130942839|https://openalex.org/W2963420686|https://openalex.org/W1924770834|https://openalex.org/W2963091558|https://openalex.org/W2271840356|https://openalex.org/W2143612262|https://openalex.org/W2950635152|https://openalex.org/W2402144811|https://openalex.org/W1895577753
https://openalex.org/W2163605009,ImageNet Classification with Deep Convolutional Neural Networks,"ImageNet Classification with Deep Convolutional Neural Networks

We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in ImageNet LSVRC-2010 contest into 1000 different classes. On test data, we achieved top-1 and top-5 error rates of 37.5% 17.0% which is considerably better than previous state-of-the-art. The network, has 60 parameters 650,000 neurons, consists five layers, some are followed by max-pooling three fully-connected layers with final 1000-way softmax. To make training faster, used non-saturating neurons very efficient GPU implementation convolution operation. reduce overriding employed recently-developed regularization method called dropout that proved be effective. also entered variant this model ILSVRC-2012 competition winning rate 15.3%, compared 26.2% second-best entry.

digital image processing, biomedical imaging, automatic classification, intelligent classification, neural network (machine learning), imagenet classification, computer science, health science, machine learning research, deep learning, image representation, medical image computing, computational imaging, data classification, machine learning, image classification, data science, convolutional neural network, image analysis",2012,63969,digital image processing|biomedical imaging|automatic classification|intelligent classification|neural network (machine learning)|imagenet classification|computer science|health science|machine learning research|deep learning|image representation|medical image computing|computational imaging|data classification|machine learning|image classification|data science|convolutional neural network|image analysis,https://openalex.org/W2194775991|https://openalex.org/W2097117768|https://openalex.org/W2963446712|https://openalex.org/W2095705004|https://openalex.org/W1903029394|https://openalex.org/W2102605133|https://openalex.org/W2183341477|https://openalex.org/W2099471712|https://openalex.org/W1536680647|https://openalex.org/W2963150697|https://openalex.org/W2963351448|https://openalex.org/W2565639579|https://openalex.org/W2752782242|https://openalex.org/W2157331557|https://openalex.org/W2412782625|https://openalex.org/W2570343428|https://openalex.org/W1677182931|https://openalex.org/W2613718673|https://openalex.org/W2531409750|https://openalex.org/W2130942839|https://openalex.org/W2962858109|https://openalex.org/W1821462560|https://openalex.org/W3138516171|https://openalex.org/W1832693441|https://openalex.org/W2560023338|https://openalex.org/W2963420686|https://openalex.org/W2963470893|https://openalex.org/W3094502228|https://openalex.org/W2549139847|https://openalex.org/W2340897893|https://openalex.org/W2109255472|https://openalex.org/W2295107390|https://openalex.org/W1522734439|https://openalex.org/W1885185971|https://openalex.org/W2964153729|https://openalex.org/W2950635152|https://openalex.org/W2508457857|https://openalex.org/W2963125010|https://openalex.org/W1834627138|https://openalex.org/W2963857521|https://openalex.org/W1901616594|https://openalex.org/W2962785568|https://openalex.org/W2145287260|https://openalex.org/W2016053056|https://openalex.org/W3005680577
https://openalex.org/W2101234009,Scikit-learn: Machine Learning in Python,"Scikit-learn: Machine Learning in Python

Scikit-learn is a Python module integrating wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing to non-specialists using general-purpose high-level language. Emphasis put ease use, performance, documentation, API consistency. It has minimal dependencies distributed under the simplified BSD license, encouraging its use in both academic commercial settings. Source code, binaries, documentation can be downloaded from http://scikit-learn.org.

computer science, automated machine learning, machine learning",2012,54358,computer science|automated machine learning|machine learning,https://openalex.org/W3099878876|https://openalex.org/W3103145119
https://openalex.org/W2108234281,The Sequence Alignment/Map format and SAMtools,"The Sequence Alignment/Map format and SAMtools

Summary: The Sequence Alignment/Map (SAM) format is a generic alignment for storing read alignments against reference sequences, supporting short and long reads (up to 128 Mbp) produced by different sequencing platforms. It flexible in style, compact size, efficient random access the which from 1000 Genomes Project are released. SAMtools implements various utilities post-processing SAM format, such as indexing, variant caller viewer, thus provides universal tools processing alignments. Availability: http://samtools.sourceforge.net Contact: rd@sanger.ac.uk

sequence analysis, computer science, sequence alignment",2009,52027,sequence analysis|computer science|sequence alignment,https://openalex.org/W2149992227|https://openalex.org/W4247053599|https://openalex.org/W2099085143
https://openalex.org/W2962835968,Very Deep Convolutional Networks for Large-Scale Image Recognition,"Very Deep Convolutional Networks for Large-Scale Image Recognition

In this work we investigate the effect of convolutional network depth on its accuracy in large-scale image recognition setting. Our main contribution is a thorough evaluation networks increasing using an architecture with very small (3x3) convolution filters, which shows that significant improvement prior-art configurations can be achieved by pushing to 16-19 weight layers. These findings were basis our ImageNet Challenge 2014 submission, where team secured first and second places localisation classification tracks respectively. We also show representations generalise well other datasets, they achieve state-of-the-art results. have made two best-performing ConvNet models publicly available facilitate further research use deep visual computer vision.

digital image processing, automatic classification, deep convolutional networks, computer science, machine learning research, deep learning, pattern recognition, machine vision, image representation, large-scale image recognition, large-scale datasets, computational imaging, machine learning, data science, cognitive science, computational intelligence, convolutional neural network, feature detection, unsupervised machine learning, image analysis",2014,49225,digital image processing|automatic classification|deep convolutional networks|computer science|machine learning research|deep learning|pattern recognition|machine vision|image representation|large-scale image recognition|large-scale datasets|computational imaging|machine learning|data science|cognitive science|computational intelligence|convolutional neural network|feature detection|unsupervised machine learning|image analysis,https://openalex.org/W2194775991|https://openalex.org/W1903029394|https://openalex.org/W639708223|https://openalex.org/W2183341477|https://openalex.org/W1536680647|https://openalex.org/W2953106684|https://openalex.org/W2565639579|https://openalex.org/W2752782242|https://openalex.org/W2962793481|https://openalex.org/W2412782625|https://openalex.org/W2963163009|https://openalex.org/W2570343428|https://openalex.org/W2613718673|https://openalex.org/W2531409750|https://openalex.org/W2962858109|https://openalex.org/W3138516171|https://openalex.org/W2963420686|https://openalex.org/W2963470893|https://openalex.org/W2549139847|https://openalex.org/W2963091558|https://openalex.org/W2340897893|https://openalex.org/W2109255472|https://openalex.org/W2295107390|https://openalex.org/W2395611524|https://openalex.org/W1522734439|https://openalex.org/W3035524453|https://openalex.org/W2963524571|https://openalex.org/W2962914239|https://openalex.org/W2508457857|https://openalex.org/W2963125010|https://openalex.org/W2962770929|https://openalex.org/W2242218935|https://openalex.org/W2962785568|https://openalex.org/W2559085405
https://openalex.org/W2112796928,Gradient-based learning applied to document recognition,"Gradient-based learning applied to document recognition

Multilayer neural networks trained with the back-propagation algorithm constitute best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based algorithms can be used to synthesize complex decision surface that classify high-dimensional patterns, such as handwritten characters, minimal preprocessing. This paper reviews various methods applied character recognition and compares them on standard digit task. Convolutional networks, which are specifically designed deal variability 2D shapes, shown outperform all other techniques. Real-life document systems composed multiple modules including field extraction, segmentation recognition, language modeling. A new paradigm, called graph transformer (GTN), allows multimodule globally using so minimize overall performance measure. Two for online handwriting described. Experiments demonstrate advantage global training, flexibility networks. reading bank cheque is also It uses convolutional recognizers combined training techniques provide record accuracy business personal cheques. deployed commercially reads several million cheques per day.

computer science, machine learning",1998,46479,computer science|machine learning,https://openalex.org/W2097117768|https://openalex.org/W2963446712|https://openalex.org/W2102605133|https://openalex.org/W2099471712|https://openalex.org/W1836465849|https://openalex.org/W2949117887|https://openalex.org/W2412782625|https://openalex.org/W2136922672|https://openalex.org/W2130942839|https://openalex.org/W3138516171|https://openalex.org/W1832693441|https://openalex.org/W1533861849|https://openalex.org/W2954996726|https://openalex.org/W1885185971|https://openalex.org/W1904365287|https://openalex.org/W2057175746|https://openalex.org/W2963857521|https://openalex.org/W2242218935|https://openalex.org/W2145287260|https://openalex.org/W2016053056|https://openalex.org/W1983364832|https://openalex.org/W2158899491
https://openalex.org/W2133665775,Image Quality Assessment: From Error Visibility to Structural Similarity,"Image Quality Assessment: From Error Visibility to Structural Similarity

Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted and reference using variety known properties human visual system. Under assumption that perception is highly adapted extracting structural information from scene, we introduce an alternative complementary framework assessment based on degradation information. As specific example this concept, develop similarity index demonstrate its promise through set intuitive examples, as well comparison both subjective ratings state-of-the-art objective database images compressed with JPEG JPEG2000. A MATLAB implementation proposed algorithm available online at http://www.cns.nyu.edu//spl sim/lcv/ssim/.

image analysis, pattern recognition, computer science, computational imaging, error visibility, structural similarity, image quality assessment, image restoration, computer vision, image representation, image similarity, digital image processing",2004,42555,image analysis|pattern recognition|computer science|computational imaging|error visibility|structural similarity|image quality assessment|image restoration|computer vision|image representation|image similarity|digital image processing,https://openalex.org/W2963073614|https://openalex.org/W2963470893|https://openalex.org/W1885185971|https://openalex.org/W2962785568
https://openalex.org/W1686810756,Very Deep Convolutional Networks for Large-Scale Image Recognition,"Very Deep Convolutional Networks for Large-Scale Image Recognition

In this work we investigate the effect of convolutional network depth on its accuracy in large-scale image recognition setting. Our main contribution is a thorough evaluation networks increasing using an architecture with very small (3x3) convolution filters, which shows that significant improvement prior-art configurations can be achieved by pushing to 16-19 weight layers. These findings were basis our ImageNet Challenge 2014 submission, where team secured first and second places localisation classification tracks respectively. We also show representations generalise well other datasets, they achieve state-of-the-art results. have made two best-performing ConvNet models publicly available facilitate further research use deep visual computer vision.

computer science, unsupervised machine learning, convolutional neural network, large-scale datasets, deep convolutional networks, cognitive science, digital image processing, large-scale image recognition, data science, deep learning, pattern recognition, automatic classification, machine learning, computational imaging, machine learning research, machine vision, image analysis, computational intelligence, feature detection, image representation",2014,42084,computer science|unsupervised machine learning|convolutional neural network|large-scale datasets|deep convolutional networks|cognitive science|digital image processing|large-scale image recognition|data science|deep learning|pattern recognition|automatic classification|machine learning|computational imaging|machine learning research|machine vision|image analysis|computational intelligence|feature detection|image representation,https://openalex.org/W1903029394|https://openalex.org/W639708223|https://openalex.org/W2183341477|https://openalex.org/W1536680647|https://openalex.org/W2962793481|https://openalex.org/W2963881378|https://openalex.org/W2570343428|https://openalex.org/W1677182931|https://openalex.org/W2531409750|https://openalex.org/W2560023338|https://openalex.org/W2340897893|https://openalex.org/W2109255472|https://openalex.org/W2612445135|https://openalex.org/W3018757597|https://openalex.org/W1522734439|https://openalex.org/W2954996726|https://openalex.org/W2962914239|https://openalex.org/W2963125010|https://openalex.org/W2962785568|https://openalex.org/W2279098554|https://openalex.org/W3005680577
https://openalex.org/W2009435671,Model Selection and Multimodel Inference: A Practical Information-Theoretic Approach,"Model Selection and Multimodel Inference: A Practical Information-Theoretic Approach

Introduction * Information and Likelihood Theory: A Basis for Model Selection Inference Basic Use of the Information-Theoretic Approach Formal From More Than One Model: Multi-Model (MMI) Monte Carlo Insights Extended Examples Statistical Theory Numerical Results Summary

computer science, model selection, multimodel inference",2003,40566,computer science|model selection|multimodel inference,https://openalex.org/W2158196600
https://openalex.org/W2132629607,UCSF Chimera—A visualization system for exploratory research and analysis,"UCSF Chimera—A visualization system for exploratory research and analysis

The design, implementation, and capabilities of an extensible visualization system, UCSF Chimera, are discussed. Chimera is segmented into a core that provides basic services visualization, extensions provide most higher level functionality. This architecture ensures the extension mechanism satisfies demands outside developers who wish to incorporate new features. Two unusual presented: Multiscale, which adds ability visualize large-scale molecular assemblies such as viral coats, Collaboratory, allows researchers share session interactively despite being at separate locales. Other include Multalign Viewer, for showing multiple sequence alignments associated structures; ViewDock, screening docked ligand orientations; Movie, replaying dynamics trajectories; Volume display analysis volumetric data. A discussion usage in real-world situations given, along with anticipated future directions. includes full user documentation, free academic nonprofit users, available Microsoft Windows, Linux, Apple Mac OS X, SGI IRIX, HP Tru64 Unix from http://www.cgl.ucsf.edu/chimera/.

computer science, data and information visualization, geographic information system, scientific visualization, image analysis, visualization system, information visualization, data exploration, systems biology, visualization, statistical software, interactive data exploration, ucsf chimera, biostatistics, scientific data, visual analytics, interactive visualization, computer graphic, knowledge discovery",2004,40158,computer science|data and information visualization|geographic information system|scientific visualization|image analysis|visualization system|information visualization|data exploration|systems biology|visualization|statistical software|interactive data exploration|ucsf chimera|biostatistics|scientific data|visual analytics|interactive visualization|computer graphic|knowledge discovery,https://openalex.org/W3083406432
https://openalex.org/W2097117768,Going deeper with convolutions,"Going deeper with convolutions

We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of art for classification and detection in ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark this is improved utilization computing resources inside network. By carefully crafted design, we increased depth width while keeping computational budget constant. To optimize quality, architectural decisions were based on Hebbian principle intuition multi-scale processing. One particular incarnation used our submission ILSVRC14 called GoogLeNet, 22 layers network, quality which assessed context detection.

image analysis, computational imaging, computer science, information fusion, convolutional neural network, large language model, deep reinforcement learning, machine learning, applied mathematics, sparse neural network, data science, neural computation, deep learning, computational intelligence, machine learning research, deepfakes, neural network (machine learning), machine vision",2015,40093,image analysis|computational imaging|computer science|information fusion|convolutional neural network|large language model|deep reinforcement learning|machine learning|applied mathematics|sparse neural network|data science|neural computation|deep learning|computational intelligence|machine learning research|deepfakes|neural network (machine learning)|machine vision,https://openalex.org/W2194775991|https://openalex.org/W2963446712|https://openalex.org/W2618530766|https://openalex.org/W1903029394|https://openalex.org/W2963037989|https://openalex.org/W639708223|https://openalex.org/W2183341477|https://openalex.org/W2752782242|https://openalex.org/W2412782625|https://openalex.org/W2963163009|https://openalex.org/W2963881378|https://openalex.org/W2570343428|https://openalex.org/W1677182931|https://openalex.org/W2531409750|https://openalex.org/W3138516171|https://openalex.org/W2560023338|https://openalex.org/W2963420686|https://openalex.org/W2963470893|https://openalex.org/W2549139847|https://openalex.org/W2271840356|https://openalex.org/W2109255472|https://openalex.org/W2295107390|https://openalex.org/W2395611524|https://openalex.org/W3099206234|https://openalex.org/W2508457857|https://openalex.org/W2963125010|https://openalex.org/W2402144811|https://openalex.org/W3005680577
https://openalex.org/W2126105956,A fast and elitist multiobjective genetic algorithm: NSGA-II,"A fast and elitist multiobjective genetic algorithm: NSGA-II

Multi-objective evolutionary algorithms (MOEAs) that use non-dominated sorting and sharing have been criticized mainly for: (1) their O(MN/sup 3/) computational complexity (where M is the number of objectives N population size); (2) non-elitism approach; (3) need to specify a parameter. In this paper, we suggest sorting-based MOEA, called NSGA-II (Non-dominated Sorting Genetic Algorithm II), which alleviates all above three difficulties. Specifically, fast approach with 2/) presented. Also, selection operator presented creates mating pool by combining parent offspring populations selecting best solutions (with respect fitness spread). Simulation results on difficult test problems show able, for most problems, find much better spread convergence near true Pareto-optimal front compared Pareto-archived evolution strategy strength-Pareto algorithm - two other elitist MOEAs pay special attention creating diverse front. Moreover, modify definition dominance in order solve constrained multi-objective efficiently. including five-objective, seven-constraint nonlinear problem, are another optimizer, performance observed.

computational optimization, computational science, genetic programming, computer science, evolutionary computation, genetic algorithm",2002,38403,computational optimization|computational science|genetic programming|computer science|evolutionary computation|genetic algorithm,https://openalex.org/W2143381319
https://openalex.org/W2099111195,Elements of Information Theory,"Elements of Information Theory

Preface to the Second Edition. First Acknowledgments for 1. Introduction and Preview. 1.1 Preview of Book. 2. Entropy, Relative Mutual Information. 2.1 Entropy. 2.2 Joint Entropy Conditional 2.3 2.4 Relationship Between 2.5 Chain Rules 2.6 Jensen's Inequality Its Consequences. 2.7 Log Sum Applications. 2.8 Data-Processing Inequality. 2.9 Sufficient Statistics. 2.10 Fano's Summary. Problems. Historical Notes. 3. Asymptotic Equipartition Property. 3.1 Property Theorem. 3.2 Consequences AEP: Data Compression. 3.3 High-Probability Sets Typical Set. 4. Rates a Stochastic Process. 4.1 Markov Chains. 4.2 Rate. 4.3 Example: Rate Random Walk on Weighted Graph. 4.4 Law Thermodynamics. 4.5 Functions 5. 5.1 Examples Codes. 5.2 Kraft 5.3 Optimal 5.4 Bounds Code Length. 5.5 Uniquely Decodable 5.6 Huffman 5.7 Some Comments 5.8 Optimality 5.9 Shannon-Fano-Elias Coding. 5.10 Competitive Shannon Code. 5.11 Generation Discrete Distributions from Fair Coins. 6. Gambling 6.1 The Horse Race. 6.2 Side 6.3 Dependent Races 6.4 English. 6.5 Compression Gambling. 6.6 Estimate 7. Channel Capacity. 7.1 7.2 Symmetric Channels. 7.3 Properties 7.4 Coding 7.5 Definitions. 7.6 Jointly Sequences. 7.7 7.8 Zero-Error 7.9 Converse 7.10 Equality in 7.11 Hamming 7.12 Feedback 7.13 Source-Channel Separation 8. Differential 8.1 8.2 AEP Continuous Variables. 8.3 Relation 8.4 8.5 8.6 9. Gaussian Channel. 9.1 Channel: 9.2 Theorem 9.3 Bandlimited 9.4 Parallel 9.5 Channels with Colored Noise. 9.6 Feedback. 10. Distortion Theory. 10.1 Quantization. 10.2 10.3 Calculation Function. 10.4 10.5 Achievability 10.6 Strongly Sequences Distortion. 10.7 Characterization 10.8 Computation Capacity 11. Information Theory 11.1 Method Types. 11.2 Large Numbers. 11.3 Universal Source 11.4 Deviation 11.5 Sanov's 11.6 Limit 11.7 Hypothesis Testing. 11.8 Chernoff-Stein Lemma. 11.9 Chernoff 11.10 Fisher Cram-er-Rao 12. Maximum 12.1 Distributions. 12.2 Examples. 12.3 Anomalous Problem. 12.4 Spectrum Estimation. 12.5 12.6 Burg's 13. 13.1 Codes 13.2 Binary 13.3 Arithmetic 13.4 Lempel-Ziv 13.5 Algorithms. 14. Kolmogorov Complexity. 14.1 Models Computation. 14.2 Complexity: Definitions 14.3 Complexity 14.4 Integers. 14.5 Algorithmically Incompressible 14.6 Probability. 14.7 complexity. 14.9 14.10 Occam's Razor. 14.11 14.12 Statistic. 14.13 Minimum Description Length Principle. 15. Network 15.1 Multiple-User 15.2 15.3 Multiple-Access 15.4 Encoding Correlated Sources. 15.5 Duality Slepian-Wolf 15.6 Broadcast 15.7 Relay 15.8 15.9 15.10 General Multiterminal Networks. 16. Portfolio 16.1 Stock Market: 16.2 Kuhn-Tucker Log-Optimal Portfolio. 16.3 16.4 Growth 16.5 Investment Stationary Markets. 16.6 16.7 Portfolios. 16.8 Shannon-McMillan-Breiman (General AEP). 17. Inequalities 17.1 Basic 17.2 17.3 17.4 17.5 Combinatorial 17.6 Subsets. 17.7 17.8 Power Brunn-Minkowski 17.9 Determinants. 17.10 Ratios Bibliography. List Symbols. Index.

information science, computer science, information fusion, information theory, information structure, multi-terminal information theory, algorithmic information theory, information theoretic security",2001,38043,information science|computer science|information fusion|information theory|information structure|multi-terminal information theory|algorithmic information theory|information theoretic security,https://openalex.org/W2158266834|https://openalex.org/W2154053567|https://openalex.org/W2165232124|https://openalex.org/W2141224535
https://openalex.org/W2152195021,Particle swarm optimization,"Particle swarm optimization

A concept for the optimization of nonlinear functions using particle swarm methodology is introduced. The evolution several paradigms outlined, and an implementation one discussed. Benchmark testing paradigm described, applications, including function neural network training, are proposed. relationships between both artificial life genetic algorithms described.

design optimization, computational optimization, computer science, drone, networked swarm, multiagent system, applied mathematics, mathematical optimization, swarm dynamic, swarm intelligence, trajectory optimization, control system, reinforcement learning, evolutionary computation, adaptive optimization, systems engineering, natural computing, swarm robotics, particle swarm optimization",2002,36704,design optimization|computational optimization|computer science|drone|networked swarm|multiagent system|applied mathematics|mathematical optimization|swarm dynamic|swarm intelligence|trajectory optimization|control system|reinforcement learning|evolutionary computation|adaptive optimization|systems engineering|natural computing|swarm robotics|particle swarm optimization,https://openalex.org/W2109364787
https://openalex.org/W2056760934,Equation of State Calculations by Fast Computing Machines,"Equation of State Calculations by Fast Computing Machines

A general method, suitable for fast computing machines, investigating such properties as equations of state substances consisting interacting individual molecules is described. The method consists a modified Monte Carlo integration over configuration space. Results the two-dimensional rigid-sphere system have been obtained on Los Alamos MANIAC and are presented here. These results compared to free volume equation four-term virial coefficient expansion.

computer science, state calculations, fast computing machines",1953,34515,computer science|state calculations|fast computing machines,https://openalex.org/W2041902442|https://openalex.org/W2148534890|https://openalex.org/W2577537660|https://openalex.org/W1993885071
https://openalex.org/W2963446712,Densely Connected Convolutional Networks,"Densely Connected Convolutional Networks

Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close the input those output. In this paper, we embrace observation introduce Dense Convolutional Network (DenseNet), which connects each layer every other in a feed-forward fashion. Whereas traditional with L have connections-one its subsequent layer-our network L(L+1)/2 direct connections. For layer, feature-maps of all preceding are used as inputs, own inputs into layers. DenseNets several compelling advantages: alleviate vanishing-gradient problem, strengthen feature propagation, encourage reuse, reduce number parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, ImageNet). obtain significant improvements over state-of-the-art most them, whilst requiring less memory computation achieve high performance. Code pre-trained models available at https://github.com/liuzhuang13/DenseNet.

computer science, convolutional neural network, convolutional networks, computer vision, machine learning, deep learning, large-scale datasets, neural network (machine learning), machine vision",2017,33093,computer science|convolutional neural network|convolutional networks|computer vision|machine learning|deep learning|large-scale datasets|neural network (machine learning)|machine vision,https://openalex.org/W2752782242|https://openalex.org/W3138516171|https://openalex.org/W2963420686|https://openalex.org/W3018757597|https://openalex.org/W2954996726
https://openalex.org/W2095705004,Dropout: a simple way to prevent neural networks from overfitting,"Dropout: a simple way to prevent neural networks from overfitting

Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is serious problem in such networks. Large networks also slow to use, making it difficult deal by combining the predictions many different at test time. Dropout technique for addressing this problem. The key idea randomly drop units (along their connections) from network during training. This prevents co-adapting too much. During training, dropout samples an exponential thinned At time, easy approximate effect averaging all these simply using single unthinned that has smaller weights. significantly reduces and gives major improvements over other regularization methods. We show improves performance on supervised tasks vision, speech recognition, document classification computational biology, obtaining state-of-the-art results benchmark data sets.

adversarial machine learning, computer science, artificial intelligence, machine learning, neural networks, neural computation, deep learning, neural network (machine learning)",2014,31290,adversarial machine learning|computer science|artificial intelligence|machine learning|neural networks|neural computation|deep learning|neural network (machine learning),https://openalex.org/W2963446712|https://openalex.org/W1836465849|https://openalex.org/W2949117887|https://openalex.org/W1677182931|https://openalex.org/W1821462560|https://openalex.org/W3018757597|https://openalex.org/W2954996726|https://openalex.org/W2279098554
https://openalex.org/W2187089797,Visualizing Data using t-SNE,"Visualizing Data using t-SNE

We present a new technique called “t-SNE” that visualizes high-dimensional data by giving each datapoint location in two or three-dimensional map. The is variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) much easier to optimize, produces significantly better visualizations reducing the tendency crowd points together center t-SNE than existing techniques at creating single map reveals structure many different scales. This particularly important for lie on several different, but related, low-dimensional manifolds, such as images objects from multiple classes seen viewpoints. For visualizing very large datasets, we show how can use random walks neighborhood graphs allow implicit all influence way which subset displayed. illustrate performance wide variety datasets compare it with other non-parametric visualization techniques, including Sammon mapping, Isomap, Locally Linear Embedding. produced are those almost datasets.

image analysis, computational imaging, computer science, information fusion, information visualization, interactive visualization, linked data visualization, visual analytics, visualization, applied mathematics, data and information visualization, data science, deep learning, image representation, scientific visualization, data modeling, machine vision, visual data mining",2008,30661,image analysis|computational imaging|computer science|information fusion|information visualization|interactive visualization|linked data visualization|visual analytics|visualization|applied mathematics|data and information visualization|data science|deep learning|image representation|scientific visualization|data modeling|machine vision|visual data mining,https://openalex.org/W1522734439|https://openalex.org/W2954996726|https://openalex.org/W3005680577
https://openalex.org/W1663973292,Pattern Recognition and Machine Learning,"Pattern Recognition and Machine Learning

The <i>Journal of Electronic Imaging</i> (JEI), copublished bimonthly with the Society for Imaging Science and Technology, publishes peer-reviewed papers that cover research applications in all areas electronic imaging science technology.

statistical pattern recognition, pattern recognition application, pattern recognition, temporal pattern recognition, computer science, machine learning, machine learning research, unsupervised machine learning, data science, image analysis",2007,30241,statistical pattern recognition|pattern recognition application|pattern recognition|temporal pattern recognition|computer science|machine learning|machine learning research|unsupervised machine learning|data science|image analysis,https://openalex.org/W1903029394
https://openalex.org/W2124776405,Neural Networks: A Comprehensive Foundation,"Neural Networks: A Comprehensive Foundation

From the Publisher:
This book represents most comprehensive treatment available of neural networks from an engineering perspective. Thorough, well-organized, and completely up to date, it examines all important aspects this emerging technology, including learning process, back-propagation learning, radial-basis function networks, self-organizing systems, modular temporal processing neurodynamics, VLSI implementation networks. Written in a concise fluid manner, by foremost textbook author, make material more accessible, is ideal for professional engineers graduate students entering exciting field. Computer experiments, problems, worked examples, bibliography, photographs, illustrations reinforce key concepts.

computer science, machine learning, comprehensive foundation, neural networks, neural computation, deep learning, neural network (machine learning), neuronal network",1998,30166,computer science|machine learning|comprehensive foundation|neural networks|neural computation|deep learning|neural network (machine learning)|neuronal network,https://openalex.org/W2097308346|https://openalex.org/W2116341502|https://openalex.org/W2153233077
https://openalex.org/W2250539671,Glove: Global Vectors for Word Representation,"Glove: Global Vectors for Word Representation

Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using arithmetic, but the origin these has remained opaque. We analyze make explicit model properties needed such to emerge word vectors. The result is a new global logbilinear regression that combines advantages two major families literature: matrix factorization local context window methods. Our efficiently leverages statistical information by training only on nonzero elements word-word cooccurrence matrix, rather than entire sparse or individual windows large corpus. produces with meaningful substructure, as evidenced its performance 75% recent analogy task. It also outperforms related models similarity tasks named entity recognition.

word embeddings, language resource, computer science, linguistics, computational linguistics, semantic representation, information fusion, language, semantic evaluation, vector space model, word representation, image representation, machine translation, language model, global vectors, deep learning, distributional semantics, text mining, natural language processing, large language model",2014,29891,word embeddings|language resource|computer science|linguistics|computational linguistics|semantic representation|information fusion|language|semantic evaluation|vector space model|word representation|image representation|machine translation|language model|global vectors|deep learning|distributional semantics|text mining|natural language processing|large language model,https://openalex.org/W2896457183|https://openalex.org/W2954996726|https://openalex.org/W2970641574
https://openalex.org/W2896457183,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding

We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent models, BERT is designed to pre-train deep bidirectional representations unlabeled text by jointly conditioning on both left and right context in all layers. As result, the pre-trained can be fine-tuned with just one additional output layer create state-of-the-art models wide range of tasks, such as question answering inference, without substantial task-specific architecture modifications. conceptually simple empirically powerful. It obtains results eleven natural processing including pushing GLUE score 80.5% (7.7% point absolute improvement), MultiNLI accuracy 86.7% (4.6% SQuAD v1.1 Test F1 93.2 (1.5 improvement) v2.0 83.1 (5.1 improvement).

computer science, language model, natural language processing, language, language engineering, computational linguistics, deep bidirectional transformers, deep learning, machine translation, language understanding",2018,29822,computer science|language model|natural language processing|language|language engineering|computational linguistics|deep bidirectional transformers|deep learning|machine translation|language understanding,https://openalex.org/W3035524453|https://openalex.org/W2970641574
https://openalex.org/W2161969291,Histograms of Oriented Gradients for Human Detection,"Histograms of Oriented Gradients for Human Detection

We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient descriptors, we show experimentally that grids histograms oriented (HOG) descriptors significantly outperform detection. influence each stage computation on performance, concluding fine-scale gradients, fine orientation binning, relatively coarse spatial high-quality local contrast normalization in overlapping descriptor blocks are all important good results. The new approach gives near-perfect separation original MIT pedestrian database, so introduce more challenging dataset containing over 1800 annotated images with large range pose variations backgrounds.

pattern recognition, computer science, image analysis, feature detection, object detection, data science, image representation, computational imaging, motion detection, localization, oriented gradients, human detection, machine vision, digital image processing, object tracking, object recognition, computer vision, geography, multimedia retrieval, biometrics",2005,28834,pattern recognition|computer science|image analysis|feature detection|object detection|data science|image representation|computational imaging|motion detection|localization|oriented gradients|human detection|machine vision|digital image processing|object tracking|object recognition|computer vision|geography|multimedia retrieval|biometrics,https://openalex.org/W2963037989|https://openalex.org/W2102605133|https://openalex.org/W2963351448|https://openalex.org/W2565639579|https://openalex.org/W2150066425|https://openalex.org/W2168356304|https://openalex.org/W2549139847|https://openalex.org/W2109255472|https://openalex.org/W2954996726|https://openalex.org/W2016053056
https://openalex.org/W2618530766,ImageNet classification with deep convolutional neural networks,"ImageNet classification with deep convolutional neural networks

We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in ImageNet LSVRC-2010 contest into 1000 different classes. On test data, we achieved top-1 and top-5 error rates of 37.5% 17.0%, respectively, which is considerably better than previous state-of-the-art. The network, has 60 parameters 650,000 neurons, consists five layers, some are followed by max-pooling three fully connected layers with final 1000-way softmax. To make training faster, used non-saturating neurons very efficient GPU implementation convolution operation. reduce overfitting employed recently developed regularization method called ""dropout"" that proved be effective. also entered variant this model ILSVRC-2012 competition winning rate 15.3%, compared 26.2% second-best entry.

computer science, data classification, machine learning, intelligent classification, automatic classification, image analysis, convolutional neural network, biomedical imaging, data science, image representation, computational imaging, deep learning, machine learning research, digital image processing, medical image computing, imagenet classification, health science, neural network (machine learning), image classification",2017,28416,computer science|data classification|machine learning|intelligent classification|automatic classification|image analysis|convolutional neural network|biomedical imaging|data science|image representation|computational imaging|deep learning|machine learning research|digital image processing|medical image computing|imagenet classification|health science|neural network (machine learning)|image classification,https://openalex.org/W639708223|https://openalex.org/W2963163009|https://openalex.org/W1832693441|https://openalex.org/W2109255472|https://openalex.org/W2395611524|https://openalex.org/W2954996726|https://openalex.org/W1885185971|https://openalex.org/W2508457857|https://openalex.org/W1901616594|https://openalex.org/W2402144811
https://openalex.org/W1903029394,Fully convolutional networks for semantic segmentation,"Fully convolutional networks for semantic segmentation

Convolutional networks are powerful visual models that yield hierarchies of features. We show convolutional by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build ""fully convolutional"" take input arbitrary size and produce correspondingly-sized output with efficient inference learning. define detail space fully networks, explain their application spatially dense prediction tasks, draw connections prior models. adapt contemporary classification (AlexNet [20], VGG net [31], GoogLeNet [32]) into transfer learned representations fine-tuning [3] segmentation task. then a skip architecture combines information from deep, coarse layer appearance shallow, fine accurate detailed segmentations. network achieves PASCAL VOC (20% relative improvement 62.2% mean IU on 2012), NYUDv2, SIFT Flow, while takes less than one fifth second for typical image.

pattern recognition, computer science, machine learning, image segmentation, image analysis, information fusion, convolutional neural network, convolutional networks, cognitive science, data science, computational imaging, scene understanding, deep learning, machine learning research, machine vision, semantic segmentation, medical image computing, feature extraction, computer vision, scene analysis",2015,28292,pattern recognition|computer science|machine learning|image segmentation|image analysis|information fusion|convolutional neural network|convolutional networks|cognitive science|data science|computational imaging|scene understanding|deep learning|machine learning research|machine vision|semantic segmentation|medical image computing|feature extraction|computer vision|scene analysis,https://openalex.org/W2194775991|https://openalex.org/W2963446712|https://openalex.org/W639708223|https://openalex.org/W2183341477|https://openalex.org/W2963150697|https://openalex.org/W2953106684|https://openalex.org/W2963351448|https://openalex.org/W2565639579|https://openalex.org/W2752782242|https://openalex.org/W2962793481|https://openalex.org/W2412782625|https://openalex.org/W2963073614|https://openalex.org/W2963881378|https://openalex.org/W2613718673|https://openalex.org/W2962858109|https://openalex.org/W2560023338|https://openalex.org/W2963420686|https://openalex.org/W2549139847|https://openalex.org/W2340897893|https://openalex.org/W3018757597|https://openalex.org/W2395611524|https://openalex.org/W2954996726|https://openalex.org/W3035524453|https://openalex.org/W2962914239|https://openalex.org/W2963125010
https://openalex.org/W2105934661,A New Approach to Linear Filtering and Prediction Problems,"A New Approach to Linear Filtering and Prediction Problems

The classical filtering and prediction problem is re-examined using the Bode-Shannon representation of random processes “state-transition” method analysis dynamic systems. New results are: (1) formulation methods solution apply without modification to stationary nonstationary statistics growing-memory infinite-memory filters. (2) A nonlinear difference (or differential) equation derived for covariance matrix optimal estimation error. From this co-efficients linear filter are obtained further calculations. (3) shown be dual noise-free regulator problem. new developed here applied two well-known problems, confirming extending earlier results. discussion largely self-contained proceeds from first principles; basic concepts theory reviewed in Appendix.

computer science, filtering technique, prediction problems, machine learning, applied mathematics, information filtering system, machine learning research",1960,27514,computer science|filtering technique|prediction problems|machine learning|applied mathematics|information filtering system|machine learning research,https://openalex.org/W2019207321
https://openalex.org/W2121863487,Reinforcement Learning: An Introduction,"Reinforcement Learning: An Introduction

Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries maximize total amount reward it receives when interacting with complex, uncertain environment. In Learning, Richard Sutton and Andrew Barto provide clear simple account key ideas algorithms reinforcement learning. Their discussion ranges from history field's intellectual foundations recent developments applications. The only necessary mathematical background familiarity elementary concepts probability. book divided into three parts. Part I defines problem terms Markov decision processes. II provides basic solution methods: dynamic programming, Monte Carlo methods, temporal-difference III presents unified view methods incorporates neural networks, eligibility traces, planning; two final chapters present case studies consider future

computer science, artificial intelligence, deep reinforcement learning, sequential decision making, machine learning, reinforcement learning, deep learning, machine learning research",2005,27415,computer science|artificial intelligence|deep reinforcement learning|sequential decision making|machine learning|reinforcement learning|deep learning|machine learning research,https://openalex.org/W2964043796
https://openalex.org/W2171074980,A Simplex Method for Function Minimization,"A Simplex Method for Function Minimization

A method is described for the minimization of a function n variables, which depends on comparison values at (n + 1) vertices general simplex, followed by replacement vertex with highest value another point. The simplex adapts itself to local landscape, and contracts final minimum. shown be effective computationally compact. procedure given estimation Hessian matrix in neighbourhood minimum, needed statistical problems.

computer science, function minimization, mathematical optimization, simplex method, applied mathematics",1965,26799,computer science|function minimization|mathematical optimization|simplex method|applied mathematics,https://openalex.org/W3103145119
https://openalex.org/W2963037989,"You Only Look Once: Unified, Real-Time Object Detection","You Only Look Once: Unified, Real-Time Object Detection

We present YOLO, a new approach to object detection. Prior work on detection repurposes classifiers perform Instead, we frame as regression problem spatially separated bounding boxes and associated class probabilities. A single neural network predicts probabilities directly from full images in one evaluation. Since the whole pipeline is network, it can be optimized end-to-end performance. Our unified architecture extremely fast. base YOLO model processes real-time at 45 frames per second. smaller version of Fast an astounding 155 second while still achieving double mAP other detectors. Compared state-of-the-art systems, makes more localization errors but less likely predict false positives background. Finally, learns very general representations objects. It outperforms methods, including DPM R-CNN, when generalizing natural domains like artwork.

image analysis, pattern recognition, computer science, computational imaging, information fusion, object tracking, scene understanding, computer vision, machine learning, feature detection, motion detection, object detection, real-time object detection, data science, deep learning, image representation, machine vision",2016,26723,image analysis|pattern recognition|computer science|computational imaging|information fusion|object tracking|scene understanding|computer vision|machine learning|feature detection|motion detection|object detection|real-time object detection|data science|deep learning|image representation|machine vision,https://openalex.org/W2963351448|https://openalex.org/W2570343428|https://openalex.org/W3018757597
https://openalex.org/W2145023731,A Computational Approach to Edge Detection,"A Computational Approach to Edge Detection

This paper describes a computational approach to edge detection. The success of the depends on definition comprehensive set goals for computation points. These must be precise enough delimit desired behavior detector while making minimal assumptions about form solution. We define detection and localization criteria class edges, present mathematical forms these as functionals operator impulse response. A third criterion is then added ensure that has only one response single edge. use in numerical optimization derive detectors several common image features, including step edges. On specializing analysis we find there natural uncertainty principle between performance, which are two main goals. With this shape optimal at any scale. simple approximate implementation edges marked maxima gradient magnitude Gaussian-smoothed image. extend using operators widths cope with different signal-to-noise ratios general method, called feature synthesis, fine-to-coarse integration information from scales. Finally show performance improves considerably point spread function extended along

computational imaging, edge detection, computer science, edge computing, detection technique",1986,26409,computational imaging|edge detection|computer science|edge computing|detection technique,https://openalex.org/W2177274842
https://openalex.org/W2011301426,Matplotlib: A 2D Graphics Environment,"Matplotlib: A 2D Graphics Environment

Matplotlib is a 2D graphics package used for Python application development, interactive scripting,and publication-quality image generation across user interfaces and operating systems

computer science, interactive visualization, graphic interface, graphics, computational visualization, computer graphic, visualization, interactive computer graphic, graphics environment, visualization (graphics)",2007,26177,computer science|interactive visualization|graphic interface|graphics|computational visualization|computer graphic|visualization|interactive computer graphic|graphics environment|visualization (graphics),https://openalex.org/W3099878876|https://openalex.org/W3103145119
https://openalex.org/W639708223,Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks,"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks

State-of-the-art object detection networks depend on region proposal algorithms to hypothesize locations. Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these networks, exposing computation as a bottleneck. In this work, we introduce Region Proposal Network(RPN) that shares full-image convolutional features with network, thus enabling nearly cost-free proposals. An RPN is fully network simultaneously predicts bounds objectness scores at each position. The trained end-to-end generate high-quality proposals, which are used by for detection. We further merge into single sharing their features-using recently popular terminology neural 'attention' mechanisms, component tells unified where look. For very deep VGG-16 model [3], our system has frame rate 5 fps (including all steps) GPU, while achieving state-of-the-art accuracy PASCAL VOC 2007, 2012, MS COCO datasets only 300 proposals per image. ILSVRC 2015 competitions, Faster foundations 1st-place winning entries in several tracks. Code been made publicly available.

pattern recognition, computer science, machine learning, image analysis, information fusion, cognitive science, object detection, data science, computational imaging, scene understanding, localization, deep learning, machine vision, region proposal networks, object tracking, object recognition, computer vision, scene analysis, vehicular technology",2017,26058,pattern recognition|computer science|machine learning|image analysis|information fusion|cognitive science|object detection|data science|computational imaging|scene understanding|localization|deep learning|machine vision|region proposal networks|object tracking|object recognition|computer vision|scene analysis|vehicular technology,https://openalex.org/W2963037989|https://openalex.org/W639708223|https://openalex.org/W2570343428|https://openalex.org/W2963091558|https://openalex.org/W2395611524
https://openalex.org/W2102605133,Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation,"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation

Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable algorithm improves mean average precision (mAP) by more than 30% relative to previous best result 2012 -- achieving mAP of 53.3%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) bottom-up region proposals order localize segment objects (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed domain-specific fine-tuning, yields significant performance boost. Since CNNs, call our method R-CNN: Regions CNN features. We also present experiments provide insight into what network learns, revealing rich hierarchy Source code complete system available at http://www.cs.berkeley.edu/~rbg/rcnn.

pattern recognition, computer science, machine learning, fuzzy set, image analysis, information fusion, accurate object detection, feature detection, cognitive science, object detection, data science, object categorization, computational imaging, localization, deep learning, machine vision, rich feature hierarchies, semantic segmentation, object recognition, computer vision, scene analysis",2014,24628,pattern recognition|computer science|machine learning|fuzzy set|image analysis|information fusion|accurate object detection|feature detection|cognitive science|object detection|data science|object categorization|computational imaging|localization|deep learning|machine vision|rich feature hierarchies|semantic segmentation|object recognition|computer vision|scene analysis,https://openalex.org/W2194775991|https://openalex.org/W1686810756|https://openalex.org/W2097117768|https://openalex.org/W1903029394|https://openalex.org/W2963037989|https://openalex.org/W639708223|https://openalex.org/W2183341477|https://openalex.org/W1536680647|https://openalex.org/W2963150697|https://openalex.org/W2953106684|https://openalex.org/W2963351448|https://openalex.org/W2565639579|https://openalex.org/W2412782625|https://openalex.org/W1677182931|https://openalex.org/W2613718673|https://openalex.org/W2962858109|https://openalex.org/W2549139847|https://openalex.org/W2340897893|https://openalex.org/W2109255472|https://openalex.org/W2295107390|https://openalex.org/W3018757597|https://openalex.org/W1522734439|https://openalex.org/W2954996726|https://openalex.org/W3035524453|https://openalex.org/W2963524571|https://openalex.org/W2964153729|https://openalex.org/W2963125010|https://openalex.org/W2016053056
https://openalex.org/W1631356911,<i>Quantum Computation and Quantum Information</i>,"<i>Quantum Computation and Quantum Information</i>

First Page

computer science, quantum algorithm, quantum technology, quantum science, quantum logic, quantum computing, quantum computation, quantum information science",2002,24469,computer science|quantum algorithm|quantum technology|quantum science|quantum logic|quantum computing|quantum computation|quantum information science,
https://openalex.org/W2124026197,Features and development of <i>Coot</i>,"Features and development of <i>Coot</i>

Coot is a molecular-graphics application for model building and validation of biological macromolecules. The program displays electron-density maps atomic models allows manipulations such as idealization, real-space refinement, manual rotation/translation, rigid-body fitting, ligand search, solvation, mutations, rotamers Ramachandran idealization. Furthermore, tools are provided well interfaces to external programs graphics. software designed be easy learn novice users, which achieved by ensuring that common tasks 'discoverable' through familiar user-interface elements (menus toolbars) or intuitive behaviour (mouse controls). Recent developments have focused on providing expert with customisable key bindings, extensions an extensive scripting interface. under rapid development, but has already very widespread use within the crystallographic community. current state presented, description facilities available some underlying methods employed.

computer science",2010,24375,computer science,
https://openalex.org/W2125055259,C4.5: Programs for Machine Learning,"C4.5: Programs for Machine Learning

From the Publisher:
Classifier systems play a major role in machine learning and knowledge-based systems, Ross Quinlan's work on ID3 C4.5 is widely acknowledged to have made some of most significant contributions their development. This book complete guide system as implemented C for UNIX environment. It contains comprehensive system's use , source code (about 8,800 lines), implementation notes. The sample datasets are also available 3.5-inch floppy diskette Sun workstation.

C4.5 starts with large sets cases belonging known classes. cases, described by any mixture nominal numeric properties, scrutinized patterns that allow classes be reliably discriminated. These then expressed models, form decision trees or if-then rules, can used classify new emphasis making models understandable well accurate. has been applied successfully tasks involving tens thousands hundreds properties. from simple core methods shows how they elaborated extended deal typical problems such missing data over hitting. Advantages disadvantages approach discussed illustrated several case studies.

This software should interest developers classification-based intelligent students expert courses.

pattern recognition, computer science, computational learning theory, supervised learning, machine learning tool, machine learning, data science, computational intelligence, deep learning, statistics, knowledge discovery, machine learning research, automatic classification, automated machine learning, data mining",1992,23706,pattern recognition|computer science|computational learning theory|supervised learning|machine learning tool|machine learning|data science|computational intelligence|deep learning|statistics|knowledge discovery|machine learning research|automatic classification|automated machine learning|data mining,https://openalex.org/W1484413656|https://openalex.org/W2112076978|https://openalex.org/W2113242816
https://openalex.org/W2183341477,Rethinking the Inception Architecture for Computer Vision,"Rethinking the Inception Architecture for Computer Vision

Convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety tasks. Since 2014 very deep convolutional started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend translate immediate quality tasks (as long as enough labeled data is provided training), efficiency low parameter count still enabling factors use cases such mobile big-data scenarios. Here we exploring ways scale up that aim utilizing added computation efficiently possible by suitably factorized convolutions aggressive regularization. We benchmark our methods on ILSVRC 2012 classification challenge validation set demonstrate over art: 21:2% top-1 5:6% top-5 error single frame evaluation using network with 5 billion multiply-adds per inference less than 25 million parameters. With an ensemble 4 models multi-crop evaluation, report 3:5% 17:3% 3:6% official test set.

image analysis, computational imaging, computer science, artificial intelligence, object recognition, scene understanding, computer vision, machine learning, feature detection, inception architecture, object detection, deep learning, image representation, vision recognition, machine vision",2016,23508,image analysis|computational imaging|computer science|artificial intelligence|object recognition|scene understanding|computer vision|machine learning|feature detection|inception architecture|object detection|deep learning|image representation|vision recognition|machine vision,https://openalex.org/W2963446712|https://openalex.org/W2752782242|https://openalex.org/W2531409750|https://openalex.org/W2963420686|https://openalex.org/W2549139847|https://openalex.org/W2612445135|https://openalex.org/W3018757597|https://openalex.org/W2963125010|https://openalex.org/W2963857521
https://openalex.org/W2099471712,GAN（Generative Adversarial Nets）,"GAN（Generative Adversarial Nets）

We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: model G that captures the data distribution, and discriminative D estimates probability sample came from training rather than G. The procedure is to maximize of making mistake. This corresponds minimax two-player game. In space arbitrary functions D, unique solution exists, with recovering distribution equal ½ everywhere. case where are defined by multilayer perceptrons, entire system can be trained backpropagation. There no need any Markov chains or unrolled approximate inference networks during either generation samples. Experiments demonstrate potential through qualitative quantitative evaluation generated

adversarial machine learning, computer science, generative adversarial nets, generative adversarial network, machine learning, generative ai, neural network (machine learning)",2017,23283,adversarial machine learning|computer science|generative adversarial nets|generative adversarial network|machine learning|generative ai|neural network (machine learning),https://openalex.org/W2962793481|https://openalex.org/W2963073614|https://openalex.org/W2963470893|https://openalex.org/W2953384591|https://openalex.org/W2125389028|https://openalex.org/W2954996726|https://openalex.org/W3035524453|https://openalex.org/W2173520492|https://openalex.org/W3096831136|https://openalex.org/W3005680577
https://openalex.org/W2033943395,User Acceptance of Computer Technology: A Comparison of Two Theoretical Models,"User Acceptance of Computer Technology: A Comparison of Two Theoretical Models

Computer systems cannot improve organizational performance if they aren't used. Unfortunately, resistance to end-user by managers and professionals is a widespread problem. To better predict, explain, increase user acceptance, we need understand why people accept or reject computers. This research addresses the ability predict peoples' computer acceptance from measure of their intentions, explain intentions in terms attitudes, subjective norms, perceived usefulness, ease use, related variables. In longitudinal study 107 users, use specific system, measured after one-hour introduction were correlated 0.35 with system 14 weeks later. The intention-usage correlation was 0.63 at end this time period. Perceived usefulness strongly influenced explaining more than half variance weeks. had small but significant effect on as well, although subsided over time. Attitudes only partially mediated effects these beliefs intentions. Subjective norms no These results suggest possibility simple powerful models determinants practical value for evaluating guiding managerial interventions aimed reducing problem underutilized technology.

computer science, human-computer interaction, information technology, technology, model comparison, user acceptance, computer technology, user experience, technology adoption, psychology, technology acceptance model, user perception, theoretical models",1989,22273,computer science|human-computer interaction|information technology|technology|model comparison|user acceptance|computer technology|user experience|technology adoption|psychology|technology acceptance model|user perception|theoretical models,https://openalex.org/W1980569376|https://openalex.org/W2126512988
https://openalex.org/W3118608800,Learning Multiple Layers of Features from Tiny Images,"Learning Multiple Layers of Features from Tiny Images

In this work we describe how to train a multi-layer generative model of natural images. We use dataset millions tiny colour images, described in the next section. This has been attempted by several groups but without success. The models on which focus are RBMs (Restricted Boltzmann Machines) and DBNs (Deep Belief Networks). These learn interesting-looking filters, show more useful classifier than raw pixels. labeled subset that have collected call CIFAR-10 dataset.

image analysis, computational imaging, computer science, feature learning, computer vision, machine learning, tiny images, feature fusion, multiple layers, data science, knowledge discovery, deep learning, image representation, few-shot learning, machine vision, digital image processing, multiple instance learning",2009,21388,image analysis|computational imaging|computer science|feature learning|computer vision|machine learning|tiny images|feature fusion|multiple layers|data science|knowledge discovery|deep learning|image representation|few-shot learning|machine vision|digital image processing|multiple instance learning,https://openalex.org/W2194775991|https://openalex.org/W2163605009|https://openalex.org/W2963446712|https://openalex.org/W2095705004|https://openalex.org/W2618530766|https://openalex.org/W2102605133|https://openalex.org/W2099471712|https://openalex.org/W2752782242|https://openalex.org/W2963420686|https://openalex.org/W3094502228|https://openalex.org/W2549139847|https://openalex.org/W1904365287|https://openalex.org/W2963857521|https://openalex.org/W3005680577
https://openalex.org/W4250955649,Compressed sensing,"Compressed sensing

Suppose x is an unknown vector in Ropf <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">m</sup> (a digital image or signal); we plan to measure n general linear functionals of and then reconstruct. If known be compressible by transform coding with a transform, reconstruct via the nonlinear procedure defined here, number measurements can dramatically smaller than size m. Thus, certain natural classes images m pixels need only n=O(m xmlns:xlink=""http://www.w3.org/1999/xlink"">1/4</sup> log xmlns:xlink=""http://www.w3.org/1999/xlink"">5/2</sup> (m)) nonadaptive nonpixel samples for faithful recovery, as opposed usual pixel samples. More specifically, suppose has sparse representation some orthonormal basis (e.g., wavelet, Fourier) tight frame curvelet, Gabor)-so coefficients belong lscr <sub xmlns:xlink=""http://www.w3.org/1999/xlink"">p</sub> ball 0<ples1. The N most important that expansion allow reconstruction xmlns:xlink=""http://www.w3.org/1999/xlink"">2</sub> error O(N xmlns:xlink=""http://www.w3.org/1999/xlink"">1/2-1</sup> p/). It possible design n=O(Nlog(m)) allowing accuracy comparable attainable direct knowledge coefficients. Moreover, good approximation those extracted from solving program-Basis Pursuit signal processing. have character ""random"" combinations basis/frame elements. Our results use notions optimal n-widths, information-based complexity. We estimate Gel'fand n-widths balls high-dimensional Euclidean space case 0<ples1, give criterion identifying near- subspaces n-widths. show ""most"" are near-optimal, convex optimization (Basis Pursuit) near-optimal way extract information derived these

lossy compression, model compression, computer science, sensor, signal processing, compressive sensing, digital signal processing, quantum sensing, signal reconstruction",2006,20722,lossy compression|model compression|computer science|sensor|signal processing|compressive sensing|digital signal processing|quantum sensing|signal reconstruction,https://openalex.org/W2119667497|https://openalex.org/W2129638195
https://openalex.org/W2041902442,Computer Simulation of Liquids,"Computer Simulation of Liquids

Abstract This book provides a practical guide to molecular dynamics and Monte Carlo simulation techniques used in the modelling of simple complex liquids. Computer is an essential tool studying chemistry physics condensed matter, complementing reinforcing both experiment theory. Simulations provide detailed information about structure dynamics, understand many fluid systems that play key role our daily lives: polymers, gels, colloidal suspensions, liquid crystals, biological membranes, glasses. The second edition this pioneering aims explain how programs work, use them, interpret results, with examples latest research rapidly evolving field. Accompanying Fortran Python practical, hands-on, illustrations ideas text.

computer science, fluid flow, computer simulation, simulation modelling, fluid dynamics, numerical simulation, fluid mechanics, computational fluid dynamic",2017,20607,computer science|fluid flow|computer simulation|simulation modelling|fluid dynamics|numerical simulation|fluid mechanics|computational fluid dynamic,https://openalex.org/W2021520922
https://openalex.org/W2044465660,Textural Features for Image Classification,"Textural Features for Image Classification

Texture is one of the important characteristics used in identifying objects or regions interest an image, whether image be a photomicrograph, aerial photograph, satellite image. This paper describes some easily computable textural features based on gray-tone spatial dependancies, and illustrates their application category-identification tasks three different kinds data: photomicrographs five sandstones, 1:20 000 panchromatic photographs eight land-use categories, Earth Resources Technology Satellite (ERTS) multispecial imagery containing seven categories. We use two decision rules: for which are convex polyhedra (a piecewise linear rule), rectangular parallelpipeds min-max rule). In each experiment data set was divided into parts, training test set. Test identification accuracy 89 percent photomicrographs, 82 photographic imagery, 83 imagery. These results indicate that probably have general applicability wide variety image-classification applications.

image analysis, pattern recognition, computer science, computational imaging, content-based image retrieval, image classification, object recognition, computer vision, multimedia retrieval, feature detection, deep learning, image representation, machine learning research, texture analysis, textural features, machine vision, digital image processing",1973,20414,image analysis|pattern recognition|computer science|computational imaging|content-based image retrieval|image classification|object recognition|computer vision|multimedia retrieval|feature detection|deep learning|image representation|machine learning research|texture analysis|textural features|machine vision|digital image processing,https://openalex.org/W2174661749
https://openalex.org/W2132984323,A theory for multiresolution signal decomposition: the wavelet representation,"A theory for multiresolution signal decomposition: the wavelet representation

Multiresolution representations are effective for analyzing the information content of images. The properties operator which approximates a signal at given resolution were studied. It is shown that difference between approximation resolutions 2/sup j+1/ and j/ (where j an integer) can be extracted by decomposing this on wavelet orthonormal basis L/sup 2/(R/sup n/), vector space measurable, square-integrable n-dimensional functions. In 2/(R), family functions built dilating translating unique function psi (x). This decomposition defines orthogonal multiresolution representation called representation. computed with pyramidal algorithm based convolutions quadrature mirror filters. Wavelet lies spatial Fourier domains. For images, differentiates several orientations. application to data compression in image coding, texture discrimination fractal analysis discussed.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>

image analysis, pattern recognition, computer science, computational imaging, information fusion, signal processing, compressive sensing, speech processing, multiresolution signal decomposition, digital signal processing, multidimensional signal processing, applied mathematics, wavelet representation, wavelet, statistical signal processing, wavelet theory, signal reconstruction",1989,20237,image analysis|pattern recognition|computer science|computational imaging|information fusion|signal processing|compressive sensing|speech processing|multiresolution signal decomposition|digital signal processing|multidimensional signal processing|applied mathematics|wavelet representation|wavelet|statistical signal processing|wavelet theory|signal reconstruction,https://openalex.org/W1996021349
https://openalex.org/W1536680647,Fast R-CNN,"Fast R-CNN

This paper proposes a Fast Region-based Convolutional Network method (Fast R-CNN) for object detection. R-CNN builds on previous work to efficiently classify proposals using deep convolutional networks. Compared work, employs several innovations improve training and testing speed while also increasing detection accuracy. trains the very VGG16 network 9x faster than R-CNN, is 213x at test-time, achieves higher mAP PASCAL VOC 2012. SPPnet, 3x faster, tests 10x more accurate. implemented in Python C++ (using Caffe) available under open-source MIT License https://github.com/rbgirshick/fast-rcnn.

computational imaging, machine vision, natural language processing, neural network (machine learning), cognitive science, computer science, recurrent neural network, convolutional neural network, machine learning, deep reinforcement learning, machine learning research, object detection, deep learning, data science, object recognition, image analysis",2015,20208,computational imaging|machine vision|natural language processing|neural network (machine learning)|cognitive science|computer science|recurrent neural network|convolutional neural network|machine learning|deep reinforcement learning|machine learning research|object detection|deep learning|data science|object recognition|image analysis,https://openalex.org/W2194775991|https://openalex.org/W2963037989|https://openalex.org/W639708223|https://openalex.org/W2963150697|https://openalex.org/W2963351448|https://openalex.org/W2565639579|https://openalex.org/W2412782625|https://openalex.org/W2570343428|https://openalex.org/W1677182931|https://openalex.org/W2549139847|https://openalex.org/W2340897893|https://openalex.org/W3018757597|https://openalex.org/W3035524453
https://openalex.org/W1678356000,Greedy function approximation: A gradient boosting machine.,"Greedy function approximation: A gradient boosting machine.

Function estimation/approximation is viewed from the perspective of numerical optimization in function space, rather than parameter space. A connection made between stagewise additive expansions and steepest-descent minimization. general gradient descent “boosting” paradigm developed for based on any fitting criterion.Specific algorithms are presented least-squares, least absolute deviation, Huber-M loss functions regression, multiclass logistic likelihood classification. Special enhancements derived particular case where individual components regression trees, tools interpreting such “TreeBoost” models presented. Gradient boosting trees produces competitive, highly robust, interpretable procedures both classification, especially appropriate mining less clean data. Connections this approach methods Freund Shapire Friedman, Hastie Tibshirani discussed.

computational learning theory, computer science, supervised learning, mathematical optimization, machine learning, reinforcement learning, greedy function approximation",2001,20204,computational learning theory|computer science|supervised learning|mathematical optimization|machine learning|reinforcement learning|greedy function approximation,
https://openalex.org/W1587026990,ggplot2: Elegant Graphics for Data Analysis,"ggplot2: Elegant Graphics for Data Analysis

This book describes ggplot2, a new data visualization package for R that uses the insights from Leland Wilkisons Grammar of Graphics to create powerful and flexible system creating graphics. With its easy to: produce handsome, publication-quality plots, with automatic legends created plot specification superpose multiple layers (points, lines, maps, tiles, box plots name few) different sources, automatically adjusted common scales add customisable smoothers use modelling capabilities R, such as loess, linear models, generalised additive models robust regression save any ggplot2 (or part thereof) later modification or reuse custom themes capture in-house journal style requirements, can easily be applied approach your graph visual perspective, thinking about how each component is represented on final plot. will useful everyone who has struggled displaying their in an informative attractive way. You need some basic knowledge (i.e. you should able get into R), but mini-language specifically tailored producing graphics, youll learn everything book. After reading this graphics customized precisely problems,and find it out head screen page.

computer science, interactive visualization, graphics, elegant graphics, data analysis, data science, statistical software, visual analytics, graphical analysis",2009,20158,computer science|interactive visualization|graphics|elegant graphics|data analysis|data science|statistical software|visual analytics|graphical analysis,
https://openalex.org/W2121044470,A Simple Sequentially Rejective Multiple Test Procedure,"A Simple Sequentially Rejective Multiple Test Procedure

This paper presents a simple and widely ap- plicable multiple test procedure of the sequentially rejective type, i.e. hypotheses are rejected one at tine until no further rejections can be done. It is shown that has prescribed level significance protection against error first kind for any combination true hypotheses. The power properties number possible applications also discussed.

statistical hypothesis test, computer science, software testing, machine learning, statistics, test derivation",1979,20009,statistical hypothesis test|computer science|software testing|machine learning|statistics|test derivation,
https://openalex.org/W2963150697,Mask R-CNN,"Mask R-CNN

We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating high-quality segmentation mask each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding branch predicting parallel with the existing bounding box recognition. is simple to train adds only small overhead running at 5 fps. Moreover, easy generalize other tasks, e.g., allowing us estimate human poses same framework. show top results all three tracks of COCO suite challenges, including segmentation, bounding-box detection, person keypoint detection. Without tricks, outperforms existing, single-model entries on every task, 2016 challenge winners. hope our effective will serve as solid baseline help ease future research instance-level Code be made available.

human identification, biomedical imaging, pattern recognition, automatic classification, computational imaging, information fusion, machine vision, mask r-cnn, neural network (machine learning), cognitive science, computer science, convolutional neural network, machine learning, feature detection, object detection, deep learning, data science, image analysis",2017,19893,human identification|biomedical imaging|pattern recognition|automatic classification|computational imaging|information fusion|machine vision|mask r-cnn|neural network (machine learning)|cognitive science|computer science|convolutional neural network|machine learning|feature detection|object detection|deep learning|data science|image analysis,https://openalex.org/W2963351448|https://openalex.org/W2565639579|https://openalex.org/W3138516171|https://openalex.org/W2549139847|https://openalex.org/W2963091558|https://openalex.org/W3018757597|https://openalex.org/W3035524453
https://openalex.org/W1836465849,Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift,"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift

Training Deep Neural Networks is complicated by the fact that distribution of each layer's inputs changes during training, as parameters previous layers change. This slows down training requiring lower learning rates and careful parameter initialization, makes it notoriously hard to train models with saturating nonlinearities. We refer this phenomenon internal covariate shift, address problem normalizing layer inputs. Our method draws its strength from making normalization a part model architecture performing for mini-batch. Batch Normalization allows us use much higher be less about initialization. It also acts regularizer, in some cases eliminating need Dropout. Applied state-of-the-art image classification model, achieves same accuracy 14 times fewer steps, beats original significant margin. Using an ensemble batch-normalized networks, we improve upon best published result on ImageNet classification: reaching 4.9% top-5 validation error (and 4.8% test error), exceeding human raters.

neural network (machine learning), internal covariate shift, batch normalization, computer science, machine learning, deep learning, data science",2015,19668,neural network (machine learning)|internal covariate shift|batch normalization|computer science|machine learning|deep learning|data science,https://openalex.org/W2194775991|https://openalex.org/W2963446712|https://openalex.org/W2183341477|https://openalex.org/W2752782242|https://openalex.org/W2963073614|https://openalex.org/W2570343428|https://openalex.org/W1677182931|https://openalex.org/W2531409750|https://openalex.org/W2560023338|https://openalex.org/W2963420686|https://openalex.org/W2963470893|https://openalex.org/W2549139847|https://openalex.org/W2963091558|https://openalex.org/W3035524453|https://openalex.org/W2963524571|https://openalex.org/W2508457857|https://openalex.org/W2963125010|https://openalex.org/W1895577753
https://openalex.org/W2059020082,<i>ORTEP</i>-3 for Windows - a version of<i>ORTEP</i>-III with a Graphical User Interface (GUI),"<i>ORTEP</i>-3 for Windows - a version of<i>ORTEP</i>-III with a Graphical User Interface (GUI)

Computer Program Abstracts The category provides a rapid means of communicating up-to-date information concerning both new programs or systems and significant updates to existing ones. Following normal submission, Abstract will be reviewed by one two members the IUCr Commission on Crystallographic Computing. It should not exceed 500 words in length follow standard format given page 189 June 1985 issue Journal [J. Appl. CrysL (1985). 18, 189190] World Wide Web at http://www.iucr. ac. uk/journals/jac/software/. Lists software presented and~or Applied Crystallography are available above address, together with about availability where this is known. J. App/. (1997). 30, 565 ORTEP-3 for Windows version ORTEP-III Graphical User Interface (GUI)

computer science, human-computer interaction, user interface, graphic interface, computer graphic, graphical user interface, user interface design, visual interface, systems engineering, virtual reality, computer engineering",1997,19656,computer science|human-computer interaction|user interface|graphic interface|computer graphic|graphical user interface|user interface design|visual interface|systems engineering|virtual reality|computer engineering,https://openalex.org/W1990170643
https://openalex.org/W2033819227,Multiple View Geometry in Computer Vision,"Multiple View Geometry in Computer Vision

A basic problem in computer vision is to understand the structure of a real world scene given several images it. Techniques for solving this are taken from projective geometry and photogrammetry. Here, authors cover geometric principles their algebraic representation terms camera projection matrices, fundamental matrix trifocal tensor. The theory methods computation these entities discussed with examples, as use reconstruction scenes multiple images. new edition features an extended introduction covering key ideas book (which itself has been updated additional examples appendices) significant results which have appeared since first edition. Comprehensive background material provided, so readers familiar linear algebra numerical can estimation algorithms presented, implement directly book.

computer science, 3d vision, multi-view geometry, computer vision, multiple view geometry",2004,19601,computer science|3d vision|multi-view geometry|computer vision|multiple view geometry,https://openalex.org/W2177274842
https://openalex.org/W1554663460,Neural networks for pattern recognition,"Neural networks for pattern recognition

From the Publisher:
This is first comprehensive treatment of feed-forward neural networks from perspective statistical pattern recognition. After introducing basic concepts, book examines techniques for modelling probability density functions and properties merits multi-layer perceptron radial basis function network models. Also covered are various forms error functions, principal algorithms minimalization, learning generalization in networks, Bayesian their applications. Designed as a text, with over 100 exercises, this fully up-to-date work will benefit anyone involved fields computation

image analysis, pattern recognition, computer science, convolutional neural network, neural architecture search, machine learning, recurrent neural network, sparse neural network, cognitive science, temporal pattern recognition, data science, computational intelligence, deep learning, neural networks, machine learning research, neural network (machine learning), machine vision",1994,19427,image analysis|pattern recognition|computer science|convolutional neural network|neural architecture search|machine learning|recurrent neural network|sparse neural network|cognitive science|temporal pattern recognition|data science|computational intelligence|deep learning|neural networks|machine learning research|neural network (machine learning)|machine vision,https://openalex.org/W2194775991|https://openalex.org/W1746819321|https://openalex.org/W2131774270|https://openalex.org/W2117812871|https://openalex.org/W2116341502|https://openalex.org/W2153233077
https://openalex.org/W2891378911,PRISMA Extension for Scoping Reviews (PRISMA-ScR): Checklist and Explanation,"PRISMA Extension for Scoping Reviews (PRISMA-ScR): Checklist and Explanation

Scoping reviews, a type of knowledge synthesis, follow systematic approach to map evidence on topic and identify main concepts, theories, sources, gaps. Although more scoping reviews are being done, their methodological reporting quality need improvement. This document presents the PRISMA-ScR (Preferred Reporting Items for Systematic Meta-Analyses extension Reviews) checklist explanation. The was developed by 24-member expert panel 2 research leads following published guidance from EQUATOR (Enhancing QUAlity Transparency Of health Research) Network. final contains 20 essential items optional items. authors provide rationale an example good each item. intent is help readers (including researchers, publishers, commissioners, policymakers, care providers, guideline developers, patients or consumers) develop greater understanding relevant terminology, core key report reviews.

reliability, computer science, content analysis, model verification, machine learning, verification, selective separation, evaluation protocol, prisma extension",2018,19183,reliability|computer science|content analysis|model verification|machine learning|verification|selective separation|evaluation protocol|prisma extension,
https://openalex.org/W2953106684,Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks,"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks

State-of-the-art object detection networks depend on region proposal algorithms to hypothesize locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these networks, exposing computation as a bottleneck. In this work, we introduce Region Proposal Network (RPN) that shares full-image convolutional features with network, thus enabling nearly cost-free proposals. An RPN is fully network simultaneously predicts bounds objectness scores at each position. The trained end-to-end generate high-quality proposals, which are used by for detection. We further merge into single sharing their features---using recently popular terminology neural 'attention' mechanisms, component tells unified where look. For very deep VGG-16 model, our system has frame rate 5fps (including all steps) GPU, while achieving state-of-the-art accuracy PASCAL VOC 2007, 2012, MS COCO datasets only 300 proposals per image. ILSVRC 2015 competitions, Faster foundations 1st-place winning entries in several tracks. Code been made publicly available.

vehicular technology, computer science, deep learning, pattern recognition, information fusion, machine vision, object detection, scene understanding, object recognition, region proposal networks, computational imaging, machine learning, localization, data science, computer vision, cognitive science, object tracking, scene analysis, image analysis",2015,18973,vehicular technology|computer science|deep learning|pattern recognition|information fusion|machine vision|object detection|scene understanding|object recognition|region proposal networks|computational imaging|machine learning|localization|data science|computer vision|cognitive science|object tracking|scene analysis|image analysis,https://openalex.org/W2194775991|https://openalex.org/W2963037989|https://openalex.org/W2963351448|https://openalex.org/W2565639579|https://openalex.org/W2752782242|https://openalex.org/W2412782625|https://openalex.org/W2963163009|https://openalex.org/W2570343428|https://openalex.org/W2963420686|https://openalex.org/W2549139847|https://openalex.org/W2340897893|https://openalex.org/W2612445135|https://openalex.org/W2954996726|https://openalex.org/W3035524453|https://openalex.org/W2963524571|https://openalex.org/W2963125010
https://openalex.org/W2764347725,Quantum computation and quantum information,"Quantum computation and quantum information

No abstract available.

computer science, quantum technology, quantum science, quantum logic, quantum information, quantum computing, quantum communication, quantum mechanics, quantum computation, quantum information science",2001,18307,computer science|quantum technology|quantum science|quantum logic|quantum information|quantum computing|quantum communication|quantum mechanics|quantum computation|quantum information science,
https://openalex.org/W1965324089,System Identification: Theory for the User,"System Identification: Theory for the User

Das Buch behandelt die Systemidentifizierung in dem theoretischen Bereich, der direkte Auswirkungen auf Verstaendnis und praktische Anwendung verschiedenen Verfahren zur Identifizierung hat. Da ...

system safety, complex system, computer science, control system, engineering, system identification, automatic identification, systems modeling, identification method, systems engineering, automatic control, system theory, system science, system diagnosis",1987,18225,system safety|complex system|computer science|control system|engineering|system identification|automatic identification|systems modeling|identification method|systems engineering|automatic control|system theory|system science|system diagnosis,https://openalex.org/W2019207321
https://openalex.org/W2122410182,Artificial intelligence: a modern approach,"Artificial intelligence: a modern approach

The long-anticipated revision of this #1 selling book offers the most comprehensive, state art introduction to theory and practice artificial intelligence for modern applications. Intelligent Agents. Solving Problems by Searching. Informed Search Methods. Game Playing. Agents that Reason Logically. First-order Logic. Building a Knowledge Base. Inference in First-Order Logical Reasoning Systems. Practical Planning. Planning Acting. Uncertainty. Probabilistic Making Simple Decisions. Complex Learning from Observations. with Neural Networks. Reinforcement Learning. Communicate. Communication English. Perception. Robotics. For computer professionals, linguists, cognitive scientists interested intelligence.

automated reasoning, industrial artificial intelligence, applied artificial intelligence, intelligent computing, computational intelligence, computer science, machine learning, artificial intelligence, intelligent systems",1995,18219,automated reasoning|industrial artificial intelligence|applied artificial intelligence|intelligent computing|computational intelligence|computer science|machine learning|artificial intelligence|intelligent systems,
https://openalex.org/W2059334100,Structural Equations with Latent Variables.,"Structural Equations with Latent Variables.

Model Notation, Covariances, and Path Analysis. Causality Causal Models. Structural Equation Models with Observed Variables. The Consequences of Measurement Error. Models: Relation Between Latent Confirmatory Factor General Model, Part I: Variable Combined. II: Extensions. Appendices. Distribution Theory. References. Index.

computer science, latent modeling, matrix factorization, latent variable model, structural equations, latent variables",1991,18179,computer science|latent modeling|matrix factorization|latent variable model|structural equations|latent variables,
https://openalex.org/W2296616510,Compressed sensing,"Compressed sensing

Suppose x is an unknown vector in Ropfm (a digital image or signal); we plan to measure n general linear functionals of and then reconstruct. If known be compressible by transform coding with a transform, reconstruct via the nonlinear procedure defined here, number measurements can dramatically smaller than size m. Thus, certain natural classes images m pixels need only n=O(m1/4log5/2(m)) nonadaptive nonpixel samples for faithful recovery, as opposed usual pixel samples. More specifically, suppose has sparse representation some orthonormal basis (e.g., wavelet, Fourier) tight frame curvelet, Gabor)-so coefficients belong lscrp ball 0<ples1. The N most important that expansion allow reconstruction lscr2 error O(N1/2-1p/). It possible design n=O(Nlog(m)) allowing accuracy comparable attainable direct knowledge coefficients. Moreover, good approximation those extracted from solving program-Basis Pursuit signal processing. have character random combinations basis/frame elements. Our results use notions optimal n-widths, information-based complexity. We estimate Gel'fand n-widths balls high-dimensional Euclidean space case 0<ples1, give criterion identifying near- subspaces n-widths. show are near-optimal, convex optimization (Basis Pursuit) near-optimal way extract information derived these

lossy compression, model compression, computer science, sensor, signal processing, compressive sensing, digital signal processing, quantum sensing, signal reconstruction",2004,17953,lossy compression|model compression|computer science|sensor|signal processing|compressive sensing|digital signal processing|quantum sensing|signal reconstruction,https://openalex.org/W2119667497|https://openalex.org/W2129131372|https://openalex.org/W2164452299|https://openalex.org/W2129638195
https://openalex.org/W2963351448,Focal Loss for Dense Object Detection,"Focal Loss for Dense Object Detection

The highest accuracy object detectors to date are based on a two-stage approach popularized by R-CNN, where classifier is applied sparse set of candidate locations. In contrast, one-stage that over regular, dense sampling possible locations have the potential be faster and simpler, but trailed thus far. this paper, we investigate why case. We discover extreme foreground-background class imbalance encountered during training central cause. propose address reshaping standard cross entropy loss such it down-weights assigned well-classified examples. Our novel Focal Loss focuses hard examples prevents vast number easy negatives from overwhelming detector training. To evaluate effectiveness our loss, design train simple call RetinaNet. results show when trained with focal RetinaNet able match speed previous while surpassing all existing state-of-the-art detectors.

digital image processing, computer science, deep learning, pattern recognition, focal loss, information fusion, machine vision, object detection, image representation, scene understanding, object recognition, computational imaging, dense object detection, localization, data science, computer vision, cognitive science, multi-view geometry, object tracking, image analysis",2017,17900,digital image processing|computer science|deep learning|pattern recognition|focal loss|information fusion|machine vision|object detection|image representation|scene understanding|object recognition|computational imaging|dense object detection|localization|data science|computer vision|cognitive science|multi-view geometry|object tracking|image analysis,https://openalex.org/W3018757597
https://openalex.org/W2133990480,The WEKA data mining software,"The WEKA data mining software

More than twelve years have elapsed since the first public release of WEKA. In that time, software has been rewritten entirely from scratch, evolved substantially and now accompanies a text on data mining [35]. These days, WEKA enjoys widespread acceptance in both academia business, an active community, downloaded more 1.4 million times being placed Source-Forge April 2000. This paper provides introduction to workbench, reviews history project, and, light recent 3.6 stable release, briefly discusses what added last version (Weka 3.4) released 2003.

data management, computer science, data science, knowledge discovery, statistics, data stream mining, statistical software, data mining",2009,17625,data management|computer science|data science|knowledge discovery|statistics|data stream mining|statistical software|data mining,
https://openalex.org/W2565639579,Feature Pyramid Networks for Object Detection,"Feature Pyramid Networks for Object Detection

Feature pyramids are a basic component in recognition systems for detecting objects at different scales. But pyramid representations have been avoided recent object detectors that based on deep convolutional networks, partially because they slow to compute and memory intensive. In this paper, we exploit the inherent multi-scale, pyramidal hierarchy of networks construct feature with marginal extra cost. A top-down architecture lateral connections is developed building high-level semantic maps all This architecture, called Pyramid Network (FPN), shows significant improvement as generic extractor several applications. Using Faster R-CNN system, our method achieves state-of-the-art single-model results COCO detection benchmark without bells whistles, surpassing existing entries including those from 2016 challenge winners. addition, can run 5 FPS GPU thus practical accurate solution multi-scale detection. Code will be made publicly available.

image analysis, pattern recognition, computer science, feature pyramid networks, computer vision, machine learning, feature detection, object detection, object categorization, deep learning, image representation, feature construction, machine vision, feature (computer vision)",2017,17369,image analysis|pattern recognition|computer science|feature pyramid networks|computer vision|machine learning|feature detection|object detection|object categorization|deep learning|image representation|feature construction|machine vision|feature (computer vision),https://openalex.org/W2963150697|https://openalex.org/W2963351448|https://openalex.org/W3138516171|https://openalex.org/W2963091558|https://openalex.org/W3018757597|https://openalex.org/W3035524453
https://openalex.org/W2036149274,"Structural equation modeling with AMOS: basic concepts, applications, and programming","Structural equation modeling with AMOS: basic concepts, applications, and programming

Contents: Part I: Introduction. Structural Equation Models: The Basics. Using the EQS Program. II: Single-Group Analyses. Application 1: Testing for Factorial Validity of a Theoretical Construct (First-Order CFA Model). 2: Scores From Measuring Instrument 3: from (Second-Order 4: Causal Structure. III: Multiple-Group 5: Invariance Instrument. 6: 7: Latent Mean Differences 8: IV: Other Important Topics. 9: Validity: Multitrait-Multimethod Model. 10: Change Over Time: Growth Curve 11: Within- and Between-Level Variance: Multilevel

computer science, structural equation, systems modeling, applied mathematics, mathematical programming, basic concepts, modeling and simulation, applied mathematical modelling",2000,17082,computer science|structural equation|systems modeling|applied mathematics|mathematical programming|basic concepts|modeling and simulation|applied mathematical modelling,
https://openalex.org/W2128880918,Geneious Basic: An integrated and extendable desktop software platform for the organization and analysis of sequence data,"Geneious Basic: An integrated and extendable desktop software platform for the organization and analysis of sequence data

Abstract Summary: The two main functions of bioinformatics are the organization and analysis biological data using computational resources. Geneious Basic has been designed to be an easy-to-use flexible desktop software application framework for data, with a focus on molecular sequences related types. It integrates numerous industry-standard discovery tools, interactive visualizations generate publication-ready images. One key contribution researchers in life sciences is public programming interface (API) that affords ability leverage existing platform virtually unlimited extension customization. result increase speed quality development computation tools sciences, due functionality graphical user available developer through API. represents ideal community components integrate their own specific requirements discovery, visualization data. Availability implementation: Binaries API freely download at http://www.geneious.com/basic, implemented Java supported Linux, Apple OSX MS Windows. also from Bio-Linux package repository http://nebc.nerc.ac.uk/news/geneiousonbl. Contact: peter@biomatters.com

computer science, molecular biology, bioinformatics, sequence data, geneious basic, data science, statistical software, computational genomics, computational biology, genomics, machine learning research, sequence alignment, genome biology, sequence analysis, clustering, phylogenetics, genome sequencing, genome analysis, molecular informatics",2012,16959,computer science|molecular biology|bioinformatics|sequence data|geneious basic|data science|statistical software|computational genomics|computational biology|genomics|machine learning research|sequence alignment|genome biology|sequence analysis|clustering|phylogenetics|genome sequencing|genome analysis|molecular informatics,
https://openalex.org/W2122825543,Regularization and Variable Selection Via the Elastic Net,"Regularization and Variable Selection Via the Elastic Net

We propose the elastic net, a new regularization and variable selection method. Real world data simulation study show that net often outperforms lasso, while enjoying similar sparsity of representation. In addition, encourages grouping effect, where strongly correlated predictors tend to be in or out model together. The is particularly useful when number (p) much bigger than observations (n). By contrast, lasso not very satisfactory method p≫n case. An algorithm called LARS-EN proposed for computing paths efficiently, like LARS does lasso.

computer science, regularization (mathematics), variable selection, elastic net",2005,16957,computer science|regularization (mathematics)|variable selection|elastic net,https://openalex.org/W1998025025
https://openalex.org/W2752782242,Squeeze-and-Excitation Networks,"Squeeze-and-Excitation Networks

Convolutional neural networks are built upon the convolution operation, which extracts informative features by fusing spatial and channel-wise information together within local receptive fields. In order to boost representational power of a network, several recent approaches have shown benefit enhancing encoding. this work, we focus on channel relationship propose novel architectural unit, term ""Squeeze-and-Excitation"" (SE) block, that adaptively recalibrates feature responses explicitly modelling interdependencies between channels. We demonstrate stacking these blocks together, can construct SENet architectures generalise extremely well across challenging datasets. Crucially, find SE produce significant performance improvements for existing state-of-the-art deep at minimal additional computational cost. SENets formed foundation our ILSVRC 2017 classification submission won first place significantly reduced top-5 error 2.251%, achieving ~25% relative improvement over winning entry 2016. Code models available https://github.com/hujie-frank/SENet.

computer science, information fusion, convolutional neural network, squeeze-and-excitation networks, electrical engineering, quantum machine learning, neuroimaging, neuroscience, recurrent neural network, sparse neural network, systems neuroscience, neural computation, computational neuroscience, computational intelligence, machine learning research, neural network (machine learning), shift detection",2018,16843,computer science|information fusion|convolutional neural network|squeeze-and-excitation networks|electrical engineering|quantum machine learning|neuroimaging|neuroscience|recurrent neural network|sparse neural network|systems neuroscience|neural computation|computational neuroscience|computational intelligence|machine learning research|neural network (machine learning)|shift detection,https://openalex.org/W2963125010
https://openalex.org/W2949117887,Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift,"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift

Training Deep Neural Networks is complicated by the fact that distribution of each layer's inputs changes during training, as parameters previous layers change. This slows down training requiring lower learning rates and careful parameter initialization, makes it notoriously hard to train models with saturating nonlinearities. We refer this phenomenon internal covariate shift, address problem normalizing layer inputs. Our method draws its strength from making normalization a part model architecture performing for mini-batch. Batch Normalization allows us use much higher be less about initialization. It also acts regularizer, in some cases eliminating need Dropout. Applied state-of-the-art image classification model, achieves same accuracy 14 times fewer steps, beats original significant margin. Using an ensemble batch-normalized networks, we improve upon best published result on ImageNet classification: reaching 4.9% top-5 validation error (and 4.8% test error), exceeding human raters.

machine learning, computer science, batch normalization, internal covariate shift, data science, deep learning, neural network (machine learning)",2015,16638,machine learning|computer science|batch normalization|internal covariate shift|data science|deep learning|neural network (machine learning),https://openalex.org/W2963073614|https://openalex.org/W2963881378|https://openalex.org/W2570343428|https://openalex.org/W1677182931|https://openalex.org/W3094502228|https://openalex.org/W2271840356|https://openalex.org/W2953384591|https://openalex.org/W2612445135|https://openalex.org/W2173248099|https://openalex.org/W3018757597|https://openalex.org/W2954996726|https://openalex.org/W2963524571|https://openalex.org/W2508457857|https://openalex.org/W2963125010|https://openalex.org/W2173520492|https://openalex.org/W2402144811|https://openalex.org/W2279098554|https://openalex.org/W1895577753|https://openalex.org/W3005680577
https://openalex.org/W2962793481,Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks,"Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks

Image-to-image translation is a class of vision and graphics problems where the goal to learn mapping between an input image output using training set aligned pairs. However, for many tasks, paired data will not be available. We present approach learning translate from source domain X target Y in absence examples. Our G : → such that distribution images G(X) indistinguishable adversarial loss. Because this highly under-constrained, we couple it with inverse F introduce cycle consistency loss push F(G(X)) ≈ (and vice versa). Qualitative results are presented on several tasks does exist, including collection style transfer, object transfiguration, season photo enhancement, etc. Quantitative comparisons against prior methods demonstrate superiority our approach.

digital image processing, biomedical imaging, unpaired image-to-image translation, computer science, deep learning, machine translation, adversarial machine learning, cycle-consistent adversarial networks, image representation, human image synthesis, computational imaging, machine learning, domain adaptation, generative adversarial network, data science, computer vision, cognitive science, synthetic image generation, image communication, image analysis",2017,16550,digital image processing|biomedical imaging|unpaired image-to-image translation|computer science|deep learning|machine translation|adversarial machine learning|cycle-consistent adversarial networks|image representation|human image synthesis|computational imaging|machine learning|domain adaptation|generative adversarial network|data science|computer vision|cognitive science|synthetic image generation|image communication|image analysis,
https://openalex.org/W2164598857,Rapid object detection using a boosted cascade of simple features,"Rapid object detection using a boosted cascade of simple features

This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high rates. work distinguished by three key contributions. The first the introduction new image representation called ""integral image"" allows features used our detector to be computed very quickly. second algorithm, based on AdaBoost, selects small number critical from larger set yields efficient classifiers. third contribution method combining increasingly more complex classifiers in ""cascade"" background regions quickly discarded while spending computation promising object-like regions. cascade can viewed as an specific focus-of-attention mechanism unlike previous approaches provides statistical guarantees that are unlikely contain interest. In domain face system rates comparable best systems. Used real-time applications, runs at 15 frames per without resorting differencing or skin color detection.

computer science, simple features, computer vision, feature detection, rapid object detection, object detection, machine vision",2005,16429,computer science|simple features|computer vision|feature detection|rapid object detection|object detection|machine vision,https://openalex.org/W1536680647|https://openalex.org/W2963351448|https://openalex.org/W1989702938
https://openalex.org/W2157331557,Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation,"Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation

Kyunghyun Cho, Bart van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2014.

knowledge discovery, word embeddings, computer science, recurrent neural network, language model, machine learning research, deep learning, sequence modelling, natural language processing, machine translation, rnn encoder-decoder, language learning, machine learning, linguistics, data science, computational linguistics, statistical machine translation, neural machine translation, convolutional neural network, phrase representations",2014,16242,knowledge discovery|word embeddings|computer science|recurrent neural network|language model|machine learning research|deep learning|sequence modelling|natural language processing|machine translation|rnn encoder-decoder|language learning|machine learning|linguistics|data science|computational linguistics|statistical machine translation|neural machine translation|convolutional neural network|phrase representations,https://openalex.org/W2964308564|https://openalex.org/W1902237438|https://openalex.org/W1895577753
https://openalex.org/W2412782625,"DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs","DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs

In this work we address the task of semantic image segmentation with Deep Learning and make three main contributions that are experimentally shown to have substantial practical merit. First, highlight convolution upsampled filters, or 'atrous convolution', as a powerful tool in dense prediction tasks. Atrous allows us explicitly control resolution at which feature responses computed within Convolutional Neural Networks. It also effectively enlarge field view filters incorporate larger context without increasing number parameters amount computation. Second, propose atrous spatial pyramid pooling (ASPP) robustly segment objects multiple scales. ASPP probes an incoming convolutional layer sampling rates effective fields-of-views, thus capturing well Third, improve localization object boundaries by combining methods from DCNNs probabilistic graphical models. The commonly deployed combination max-pooling downsampling achieves invariance but has toll on accuracy. We overcome final DCNN fully connected Conditional Random Field (CRF), is both qualitatively quantitatively performance. Our proposed ""DeepLab"" system sets new state-of-art PASCAL VOC-2012 task, reaching 79.7 percent mIOU test set, advances results other datasets: PASCAL-Context, PASCAL-Person-Part, Cityscapes. All our code made publicly available online.

computer science, deep convolutional nets, machine learning, atrous convolution, image segmentation, image analysis, convolutional neural network, biomedical imaging, cognitive science, data science, image representation, computational imaging, scene understanding, deep learning, semantic image segmentation, machine vision, digital image processing, medical image computing, scene interpretation, computer vision, scene analysis",2018,16224,computer science|deep convolutional nets|machine learning|atrous convolution|image segmentation|image analysis|convolutional neural network|biomedical imaging|cognitive science|data science|image representation|computational imaging|scene understanding|deep learning|semantic image segmentation|machine vision|digital image processing|medical image computing|scene interpretation|computer vision|scene analysis,https://openalex.org/W2963163009|https://openalex.org/W2560023338|https://openalex.org/W3018757597|https://openalex.org/W3035524453
https://openalex.org/W2963163009,MobileNetV2: Inverted Residuals and Linear Bottlenecks,"MobileNetV2: Inverted Residuals and Linear Bottlenecks

In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of art performance models on multiple tasks and benchmarks as well across spectrum different model sizes. We also efficient ways applying these to object detection in novel framework call SSDLite. Additionally, demonstrate how build semantic segmentation through reduced form DeepLabv3 which Mobile DeepLabv3. is based an inverted residual structure where shortcut connections are between thin bottleneck layers. The intermediate expansion layer uses lightweight depthwise convolutions filter features source non-linearity. find it important remove non-linearities narrow layers order maintain representational power. provide intuition led design. Finally, our approach allows decoupling input/output domains from expressiveness transformation, provides convenient for further analysis. measure ImageNet [1] classification, COCO [2], VOC image [3]. evaluate trade-offs accuracy, number operations measured by multiply-adds (MAdd), actual latency, parameters.

temporal complexity, linear bottlenecks, computer science, machine learning, inverted residuals",2018,15965,temporal complexity|linear bottlenecks|computer science|machine learning|inverted residuals,https://openalex.org/W3018757597
https://openalex.org/W273955616,Classification and Regression by randomForest,"Classification and Regression by randomForest

Recently there has been a lot of interest in “ensemble learning” — methods that generate many classifiers and aggregate their results. Two well-known are boosting (see, e.g., Shapire et al., 1998) bagging Breiman (1996) classification trees. In boosting, successive trees give extra weight to points incorrectly predicted by earlier predictors. the end, weighted vote is taken for prediction. bagging, do not depend on each independently constructed using bootstrap sample data set. simple majority (2001) proposed random forests, which add an additional layer randomness bagging. addition constructing tree different data, forests change how or regression constructed. standard trees, node split best among all variables. forest, subset predictors randomly chosen at node. This somewhat counterintuitive strategy turns out perform very well compared other classifiers, including discriminant analysis, support vector machines neural networks, robust against overfitting (Breiman, 2001). addition, it user-friendly sense only two parameters (the number variables forest), usually sensitive values. The randomForest package provides R interface Fortran programs Cutler (available http://www.stat.berkeley.edu/ users/breiman/). article brief introduction usage features functions.

pattern recognition, computer science, supervised learning, statistical learning theory, classifier system, statistical inference, clustering, machine learning, data science, knowledge discovery, learning classifier system, statistics, machine learning research, classification method, data mining",2007,15963,pattern recognition|computer science|supervised learning|statistical learning theory|classifier system|statistical inference|clustering|machine learning|data science|knowledge discovery|learning classifier system|statistics|machine learning research|classification method|data mining,https://openalex.org/W1831050183
https://openalex.org/W2062024414,Ten lectures on wavelets,"Ten lectures on wavelets

Introduction Preliminaries and notation The what, why, how of wavelets continuous wavelet transform Discrete transforms: Frames Time-frequency density orthonormal bases Orthonormal multiresolutional analysis compactly supported More about the regularity Symmetry for Characterization functional spaces by means Generalizations tricks References Indexes.

wavelet theory, wavelet, computer science, signal processing",1992,15933,wavelet theory|wavelet|computer science|signal processing,https://openalex.org/W2034139177|https://openalex.org/W2151693816|https://openalex.org/W2158940042|https://openalex.org/W2130660124
https://openalex.org/W2170120409,Numerical recipes in C,"Numerical recipes in C

Note: Includes bibliographical references, 3 appendixes and 2 indexes.- Diskette v 2.06, 3.5''[1.44M] for IBM PC, PS/2 compatibles [DOS] Reference Record created on 2004-09-07, modified 2016-08-08

computer science, numerical computation, numerical mathematics, numerical method for partial differential equation, applied mathematics, numerical algorithm, numerical analysis, numerical recipes, numerical simulation",1994,15924,computer science|numerical computation|numerical mathematics|numerical method for partial differential equation|applied mathematics|numerical algorithm|numerical analysis|numerical recipes|numerical simulation,https://openalex.org/W1746819321|https://openalex.org/W2121016876
https://openalex.org/W2964308564,Neural Machine Translation by Jointly Learning to Align and Translate,"Neural Machine Translation by Jointly Learning to Align and Translate

Abstract: Neural machine translation is a recently proposed approach to translation. Unlike the traditional statistical translation, neural aims at building single network that can be jointly tuned maximize performance. The models for often belong family of encoder-decoders and consists an encoder encodes source sentence into fixed-length vector from which decoder generates In this paper, we conjecture use bottleneck in improving performance basic encoder-decoder architecture, propose extend by allowing model automatically (soft-)search parts are relevant predicting target word, without having form these as hard segment explicitly. With new approach, achieve comparable existing state-of-the-art phrase-based system on task English-to-French Furthermore, qualitative analysis reveals (soft-)alignments found agree well with our intuition.

computer science, linguistics, transfer learning, natural language processing, language, neural machine translation, machine learning, neural computation, computational intelligence, deep learning, machine learning research, machine translation, neural network (machine learning), computer-assisted translation",2015,15258,computer science|linguistics|transfer learning|natural language processing|language|neural machine translation|machine learning|neural computation|computational intelligence|deep learning|machine learning research|machine translation|neural network (machine learning)|computer-assisted translation,https://openalex.org/W2130942839|https://openalex.org/W1902237438|https://openalex.org/W1895577753
https://openalex.org/W2963073614,Image-to-Image Translation with Conditional Adversarial Networks,"Image-to-Image Translation with Conditional Adversarial Networks

We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These not only learn the mapping from input image output image, but also loss function train this mapping. This makes it possible apply same generic approach problems that traditionally would require very different formulations. demonstrate is effective at synthesizing photos label maps, reconstructing objects edge and colorizing images, among other tasks. Moreover, since release of pi×2pi× software associated with paper, hundreds twitter users have posted their own artistic experiments using our system. As community, we no longer hand-engineer functions, work suggests can achieve reasonable results without handengineering functions either.

computer science, conditional adversarial networks, machine learning, multimodal translation, synthetic image generation, image analysis, data science, image representation, machine translation, image-to-image translation, computational imaging, adversarial machine learning, image communication, deep learning, machine learning research, digital image processing, computer vision, neural machine translation, human image synthesis",2017,15243,computer science|conditional adversarial networks|machine learning|multimodal translation|synthetic image generation|image analysis|data science|image representation|machine translation|image-to-image translation|computational imaging|adversarial machine learning|image communication|deep learning|machine learning research|digital image processing|computer vision|neural machine translation|human image synthesis,https://openalex.org/W2962785568
https://openalex.org/W2045596260,Efficient pseudopotentials for plane-wave calculations,"Efficient pseudopotentials for plane-wave calculations

We present a simple procedure to generate first-principles norm-conserving pseudopotentials, which are designed be smooth and therefore save computational resources when used with plane-wave basis. found that these pseudopotentials extremely efficient for the cases where expansion has slow convergence, in particular, systems containing first-row elements, transition metals, rare-earth elements. The wide applicability of exemplified calculations copper, zinc blende, diamond, \ensuremath{\alpha}-quartz, rutile, cerium.

computer science, efficient pseudopotentials, applied mathematics, plane-wave calculations, computational electromagnetics, applied physics, harmonic analysis",1991,15209,computer science|efficient pseudopotentials|applied mathematics|plane-wave calculations|computational electromagnetics|applied physics|harmonic analysis,https://openalex.org/W2041902442
https://openalex.org/W2019207321,ANFIS: adaptive-network-based fuzzy inference system,"ANFIS: adaptive-network-based fuzzy inference system

The architecture and learning procedure underlying ANFIS (adaptive-network-based fuzzy inference system) is presented, which a system implemented in the framework of adaptive networks. By using hybrid procedure, proposed can construct an input-output mapping based on both human knowledge (in form if-then rules) stipulated data pairs. In simulation, employed to model nonlinear functions, identify components on-line control system, predict chaotic time series, all yielding remarkable results. Comparisons with artificial neural networks earlier work modeling are listed discussed. Other extensions promising applications automatic signal processing also suggested.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>

computer science, artificial intelligence, inference, fuzzy logic, fuzzy modeling, fuzzy pattern recognition, machine learning, fuzzy optimization, cognitive science, fuzzy computing, data science, network analysis, fuzzy expert system, neural network (machine learning), fuzzy system, fuzzy set",1993,15030,computer science|artificial intelligence|inference|fuzzy logic|fuzzy modeling|fuzzy pattern recognition|machine learning|fuzzy optimization|cognitive science|fuzzy computing|data science|network analysis|fuzzy expert system|neural network (machine learning)|fuzzy system|fuzzy set,
https://openalex.org/W2124386111,Object recognition from local scale-invariant features,"Object recognition from local scale-invariant features

An object recognition system has been developed that uses a new class of local image features. The features are invariant to scaling, translation, and rotation, partially illumination changes affine or 3D projection. These share similar properties with neurons in inferior temporal cortex used for primate vision. Features efficiently detected through staged filtering approach identifies stable points scale space. Image keys created allow geometric deformations by representing blurred gradients multiple orientation planes at scales. as input nearest neighbor indexing method candidate matches. Final verification each match is achieved finding low residual least squares solution the unknown model parameters. Experimental results show robust can be cluttered occluded images computation time under 2 seconds.

pattern recognition, computer science, local scale-invariant features, object recognition",1999,14977,pattern recognition|computer science|local scale-invariant features|object recognition,https://openalex.org/W2963037989|https://openalex.org/W2177274842|https://openalex.org/W2131846894|https://openalex.org/W2057175746
https://openalex.org/W2121947440,Normalized cuts and image segmentation,"Normalized cuts and image segmentation

We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies image data, our aims at extracting global impression of an image. treat segmentation as graph partitioning criterion, normalized cut, segmenting graph. The cut criterion measures both total dissimilarity between different groups well similarity within groups. show that efficient computational technique based generalized eigenvalue can be used to optimize this criterion. applied static images, motion sequences, found results very encouraging.

computer science, computer vision, image segmentation, data normalization",2000,14761,computer science|computer vision|image segmentation|data normalization,https://openalex.org/W2118246710|https://openalex.org/W2143516773|https://openalex.org/W2165232124
https://openalex.org/W2136922672,A Fast Learning Algorithm for Deep Belief Nets,"A Fast Learning Algorithm for Deep Belief Nets

We show how to use “complementary priors” eliminate the explaining-away effects that make inference difficult in densely connected belief nets have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm can learn deep, directed networks one layer at time, provided top two layers form an undirected associative memory. The is used initialize slower learning procedure fine-tunes weights using contrastive version of wake-sleep algorithm. After fine-tuning, network with three forms very good generative model joint distribution handwritten digit images and their labels. This gives better classification than best discriminative algorithms. low-dimensional manifolds on which digits lie are modeled by long ravines free-energy landscape top-level memory, it easy explore these connections display what memory has mind.

computer science, fast learning algorithm, deep belief nets, unsupervised machine learning, machine learning, computational intelligence, deep learning, neural network (machine learning)",2006,14752,computer science|fast learning algorithm|deep belief nets|unsupervised machine learning|machine learning|computational intelligence|deep learning|neural network (machine learning),https://openalex.org/W2095705004|https://openalex.org/W2099471712|https://openalex.org/W1533861849|https://openalex.org/W2025768430|https://openalex.org/W1983364832|https://openalex.org/W2158899491|https://openalex.org/W3005680577
https://openalex.org/W2009310436,A comprehensive set of sequence analysis programs for the VAX,"A comprehensive set of sequence analysis programs for the VAX

The University of Wisconsin Genetics Computer Group (UWGCG) has been organized to develop computational tools for the analysis and publication biological sequence data.A group programs that will interact with each other developed Digital Equipment Corporation VAX computer using VMS operating system.The available conditions transfer are described. DESIGN PRINCIPLESUWGCG program design is based on ""software tools"" approach Kernighan Plauger(l).Each performs a simple function easy use.The can be used independently in different combinations so

computer science, sequence analysis, next-generation sequencing, program analysis, sequence modelling, machine learning research, comprehensive set, sequence analysis programs, bioinformatics",1984,14749,computer science|sequence analysis|next-generation sequencing|program analysis|sequence modelling|machine learning research|comprehensive set|sequence analysis programs|bioinformatics,
https://openalex.org/W2963881378,SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation,"SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation

We present a novel and practical deep fully convolutional neural network architecture for semantic pixel-wise segmentation termed SegNet. This core trainable engine consists of an encoder network, corresponding decoder followed by classification layer. The the is topologically identical to 13 layers in VGG16 [1] . role map low resolution feature maps full input classification. novelty SegNet lies manner which upsamples its lower map(s). Specifically, uses pooling indices computed max-pooling step perform non-linear upsampling. eliminates need learning upsample. upsampled are sparse then convolved with filters produce dense maps. compare our proposed widely adopted FCN [2] also well known DeepLab-LargeFOV [3] , DeconvNet [4] architectures. comparison reveals memory versus accuracy trade-off involved achieving good performance. was primarily motivated scene understanding applications. Hence, it designed be efficient both terms computational time during inference. It significantly smaller number parameters than other competing architectures can trained end-to-end using stochastic gradient descent. performed controlled benchmark on road scenes SUN RGB-D indoor tasks. These quantitative assessments show that provides performance competitive inference most memory-wise as compared provide Caffe implementation web demo at http://mi.eng.cam.ac.uk/projects/segnet/.

image analysis, pattern recognition, computer science, computational imaging, medical image computing, autoencoders, convolutional neural network, scene understanding, computer vision, machine learning, scene analysis, cognitive science, data science, deep learning, image representation, machine learning research, image segmentation, machine vision",2017,14516,image analysis|pattern recognition|computer science|computational imaging|medical image computing|autoencoders|convolutional neural network|scene understanding|computer vision|machine learning|scene analysis|cognitive science|data science|deep learning|image representation|machine learning research|image segmentation|machine vision,https://openalex.org/W2412782625|https://openalex.org/W2560023338|https://openalex.org/W2340897893|https://openalex.org/W2279098554
https://openalex.org/W1614298861,Efficient Estimation of Word Representations in Vector Space,"Efficient Estimation of Word Representations in Vector Space

We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality these is measured in a word similarity task, and the results are compared to previously best performing techniques based on different types neural networks. observe improvements accuracy at much lower computational cost, i.e. it takes less than day learn high vectors 1.6 billion set. Furthermore, we show that provide state-of-the-art performance our test set measuring syntactic semantic similarities.

word representations, natural language processing, computer science, efficient estimation, vector space",2013,14484,word representations|natural language processing|computer science|efficient estimation|vector space,https://openalex.org/W2250539671|https://openalex.org/W2271840356|https://openalex.org/W1895577753
https://openalex.org/W2570343428,"YOLO9000: Better, Faster, Stronger","YOLO9000: Better, Faster, Stronger

We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 categories. First we propose various improvements to the YOLO method, both novel and drawn from prior work. The improved model, YOLOv2, is state-of-the-art on standard tasks like PASCAL VOC COCO. Using novel, multi-scale training method same YOLOv2 model run at varying sizes, offering an easy tradeoff between speed accuracy. At 67 FPS, gets 76.8 mAP 2007. 40 78.6 mAP, outperforming methods Faster RCNN with ResNet SSD while still running significantly faster. Finally jointly train classification. this YOLO9000 simultaneously COCO dataset ImageNet classification dataset. Our joint allows predict detections for classes dont have labelled data. validate our approach task. 19.7 validation set despite only having data 44 of 200 classes. On 156 not in COCO, 16.0 mAP. predicts more than different categories, all real-time.

computer science, intelligent computing, mobile computing, technology, soft computing, deep learning, next generation computing, parallel computing, scientific computing, high performance computer architecture, computer engineering",2017,14465,computer science|intelligent computing|mobile computing|technology|soft computing|deep learning|next generation computing|parallel computing|scientific computing|high performance computer architecture|computer engineering,https://openalex.org/W2963351448|https://openalex.org/W2963163009|https://openalex.org/W3018757597
https://openalex.org/W1677182931,Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification,"Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification

Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier networks image classification from two aspects. First, propose a Parametric Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, derive robust initialization method particularly considers nonlinearities. This enables us to train extremely deep models directly scratch investigate deeper or wider network architectures. Based on learnable advanced initialization, achieve 4.94% top-5 test error ImageNet 2012 dataset. is 26% relative improvement over ILSVRC 2014 winner (GoogLeNet, 6.66% [33]). To our knowledge, result first surpass reported human-level performance (5.1%, [26])

digital image processing, sparse neural network, imagenet classification, computer science, machine learning research, deep learning, machine vision, adversarial machine learning, image representation, human-level performance, human image synthesis, computational imaging, geometric learning, machine learning, data science, computer vision, cognitive science, computational intelligence, convolutional neural network, image analysis",2015,14420,digital image processing|sparse neural network|imagenet classification|computer science|machine learning research|deep learning|machine vision|adversarial machine learning|image representation|human-level performance|human image synthesis|computational imaging|geometric learning|machine learning|data science|computer vision|cognitive science|computational intelligence|convolutional neural network|image analysis,https://openalex.org/W2194775991|https://openalex.org/W2963446712|https://openalex.org/W2183341477|https://openalex.org/W1836465849|https://openalex.org/W2752782242|https://openalex.org/W2949117887|https://openalex.org/W2963881378|https://openalex.org/W2963420686|https://openalex.org/W2963470893|https://openalex.org/W2549139847|https://openalex.org/W2963091558|https://openalex.org/W3018757597|https://openalex.org/W2962914239|https://openalex.org/W2508457857|https://openalex.org/W2242218935|https://openalex.org/W2279098554
https://openalex.org/W2053186076,Nonlinear Dimensionality Reduction by Locally Linear Embedding,"Nonlinear Dimensionality Reduction by Locally Linear Embedding

Many areas of science depend on exploratory data analysis and visualization. The need to analyze large amounts multivariate raises the fundamental problem dimensionality reduction: how discover compact representations high-dimensional data. Here, we introduce locally linear embedding (LLE), an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings inputs. Unlike clustering methods for local reduction, LLE maps its inputs into a single global coordinate system lower dimensionality, optimizations do not involve minima. By exploiting symmetries reconstructions, is able learn structure nonlinear manifolds, such as those generated by images faces or documents text.

computer science, dimensionality reduction, nonlinear analysis, machine learning, applied mathematics, machine learning research, nonlinear dimensionality reduction",2000,14350,computer science|dimensionality reduction|nonlinear analysis|machine learning|applied mathematics|machine learning research|nonlinear dimensionality reduction,https://openalex.org/W2187089797|https://openalex.org/W2097308346|https://openalex.org/W2153233077
https://openalex.org/W2166559705,Mining association rules between sets of items in large databases,"Mining association rules between sets of items in large databases

We are given a large database of customer transactions. Each transaction consists items purchased by in visit. present an efficient algorithm that generates all significant association rules between the database. The incorporates buffer management and novel estimation pruning techniques. also results applying this to sales data obtained from retailing company, which shows effectiveness algorithm.

information retrieval, large databases, clustering, knowledge discovery, data mining, database, knowledge graph, association rule, computer science, large-scale datasets, frequent pattern mining, pattern discovery, pattern mining, data science",1993,14349,information retrieval|large databases|clustering|knowledge discovery|data mining|database|knowledge graph|association rule|computer science|large-scale datasets|frequent pattern mining|pattern discovery|pattern mining|data science,https://openalex.org/W1484413656
https://openalex.org/W1563088657,An Introduction to Support Vector Machines and Other Kernel-based Learning Methods,"An Introduction to Support Vector Machines and Other Kernel-based Learning Methods

This is the first comprehensive introduction to Support Vector Machines (SVMs), a generation learning system based on recent advances in statistical theory. SVMs deliver state-of-the-art performance real-world applications such as text categorisation, hand-written character recognition, image classification, biosequences analysis, etc., and are now established one of standard tools for machine data mining. Students will find book both stimulating accessible, while practitioners be guided smoothly through material required good grasp theory its applications. The concepts introduced gradually accessible self-contained stages, presentation rigorous thorough. Pointers relevant literature web sites containing software ensure that it forms an ideal starting point further study. Equally, associated site guide updated literature, new applications, on-line software.

kernel method, computer science, support vector machine, machine learning, vector machines, algorithmic learning",2000,14285,kernel method|computer science|support vector machine|machine learning|vector machines|algorithmic learning,
https://openalex.org/W2163352848,Multiresolution gray-scale and rotation invariant texture classification with local binary patterns,"Multiresolution gray-scale and rotation invariant texture classification with local binary patterns

Presents a theoretically very simple, yet efficient, multiresolution approach to gray-scale and rotation invariant texture classification based on local binary patterns nonparametric discrimination of sample prototype distributions. The method is recognizing that certain patterns, termed ""uniform,"" are fundamental properties image their occurrence histogram proven be powerful feature. We derive generalized operator presentation allows for detecting the ""uniform"" any quantization angular space spatial resolution presents combining multiple operators analysis. proposed robust in terms variations since is, by definition, against monotonic transformation gray scale. Another advantage computational simplicity as can realized with few operations small neighborhood lookup table. Experimental results demonstrate good achieved statistics simple patterns.

image analysis, pattern recognition, computer science, image classification, hierarchical classification, computer vision, local binary patterns, multiresolution gray-scale, object categorization, deep learning, texture analysis, machine vision, digital image processing",2002,14282,image analysis|pattern recognition|computer science|image classification|hierarchical classification|computer vision|local binary patterns|multiresolution gray-scale|object categorization|deep learning|texture analysis|machine vision|digital image processing,https://openalex.org/W2177274842|https://openalex.org/W2163808566
https://openalex.org/W2148534890,Inference from Iterative Simulation Using Multiple Sequences,"Inference from Iterative Simulation Using Multiple Sequences

The Gibbs sampler, the algorithm of Metropolis and similar iterative simulation methods are potentially very helpful for summarizing multivariate distributions. Used naively, however, can give misleading answers. Our simple generally applicable to output any simulation; they designed researchers primarily interested in science underlying data models analyzing, rather than probability theory simulations themselves. recommended strategy is use several independent sequences, with starting points sampled from an overdispersed distribution. At each step simulation, we obtain, univariate estimand interest, a distributional estimate how much sharper might become if were continued indefinitely. Because our focus on applied inference Bayesian posterior distributions real problems, which often tend toward normality after transformations marginalization, derive results as normal-theory approximations exact inference, conditional observed simulations. illustrated random-effects mixture model experimental measurements reaction times normal schizophrenic patients.

computer science, inference, iterative simulation, simulation methodology, multiple sequences",1992,14112,computer science|inference|iterative simulation|simulation methodology|multiple sequences,https://openalex.org/W2577537660
https://openalex.org/W2156186849,New directions in cryptography,"New directions in cryptography

Two kinds of contemporary developments in cryptography are examined. Widening applications teleprocessing have given rise to a need for new types cryptographic systems, which minimize the secure key distribution channels and supply equivalent written signature. This paper suggests ways solve these currently open problems. It also discusses how theories communication computation beginning provide tools problems long standing.

computer science, cryptographic hardware, cryptography, cryptanalysis, cryptographic protocol, cryptographic technology, cryptographic protection, cryptographic primitive, financial cryptography",1976,13691,computer science|cryptographic hardware|cryptography|cryptanalysis|cryptographic protocol|cryptographic technology|cryptographic protection|cryptographic primitive|financial cryptography,https://openalex.org/W1996360405|https://openalex.org/W4232836212|https://openalex.org/W2108834246|https://openalex.org/W3038067977
https://openalex.org/W4300402905,Parallel Distributed Processing,"Parallel Distributed Processing

What makes people smarter than computers? These volumes by a pioneering neurocomputing group suggest that the answer lies in massively parallel architecture of human mind. They describe new theory cognition called connectionism is challenging idea symbolic computation has traditionally been at center debate theoretical discussions about The authors' assumes mind composed great number elementary units connected neural network. Mental processes are interactions between these which excite and inhibit each other rather sequential operations. In this context, knowledge can no longer be thought as stored localized structures; instead, it consists connections pairs distributed throughout Volume 1 lays foundations exciting processing, while 2 applies to specific issues cognitive science neuroscience, with chapters describing models aspects perception, memory, language, thought.

distributed system, parallel processing, computer science, distributed data processing, distributed computing, distributed processing, parallel computing, distributed query processing",1986,13688,distributed system|parallel processing|computer science|distributed data processing|distributed computing|distributed processing|parallel computing|distributed query processing,https://openalex.org/W2101927907|https://openalex.org/W2116341502
https://openalex.org/W2138451337,Eigenfaces for Recognition,"Eigenfaces for Recognition

We have developed a near-real-time computer system that can locate and track subject's head, then recognize the person by comparing characteristics of face to those known individuals. The computational approach taken in this is motivated both physiology information theory, as well practical requirements performance accuracy. Our treats recognition problem an intrinsically two-dimensional (2-D) rather than requiring recovery three-dimensional geometry, taking advantage fact faces are normally upright thus may be described small set 2-D characteristic views. functions projecting images onto feature space spans significant variations among images. features ""eigenfaces,"" because they eigenvectors (principal components) faces; do not necessarily correspond such eyes, ears, noses. projection operation characterizes individual weighted sum eigenface features, so particular it necessary only compare these weights Some advantages our provides for ability learn later new unsupervised manner, easy implement using neural network architecture.

image analysis, pattern recognition, computer science, computational imaging, character recognition, machine learning, applied mathematics, data science, spectral theory, deep learning, image representation, machine learning research, facial recognition system, human identification, machine vision, digital image processing, facial expression recognition, face detection",1991,13623,image analysis|pattern recognition|computer science|computational imaging|character recognition|machine learning|applied mathematics|data science|spectral theory|deep learning|image representation|machine learning research|facial recognition system|human identification|machine vision|digital image processing|facial expression recognition|face detection,https://openalex.org/W2121647436|https://openalex.org/W2129812935|https://openalex.org/W2057175746|https://openalex.org/W1989702938|https://openalex.org/W2163808566|https://openalex.org/W2152826865|https://openalex.org/W2098693229
https://openalex.org/W2341171179,Dynamic Programming,"Dynamic Programming

From the Publisher:
An introduction to mathematical theory of multistage decision processes, this text takes a functional equation approach discovery optimum policies. Written by leading developer such policies, it presents series methods, uniqueness and existence theorems, examples for solving relevant equations. The examines optimal inventory equation, bottleneck problems in production new formalism calculus variation, strategies behind games, Markovian processes. Each chapter concludes with problem set that Eric V. Denardo Yale University, his informative introduction, calls rich lode applications research topics. 1957 edition. 37 figures.

computer science, dynamic programming, mathematical optimization, dynamic programming language, mathematical programming, optimization problem, programming language, program analysis, dynamic optimization",1957,13552,computer science|dynamic programming|mathematical optimization|dynamic programming language|mathematical programming|optimization problem|programming language|program analysis|dynamic optimization,https://openalex.org/W2121863487|https://openalex.org/W2119567691|https://openalex.org/W2107726111
https://openalex.org/W2109364787,A new optimizer using particle swarm theory,"A new optimizer using particle swarm theory

The optimization of nonlinear functions using particle swarm methodology is described. Implementations two paradigms are discussed and compared, including a recently developed locally oriented paradigm. Benchmark testing both described, applications, neural network training robot task learning, proposed. Relationships between artificial life evolutionary computation reviewed.

computer science, artificial intelligence, particle method, global optimization, simulation optimization, mathematical optimization, fuzzy optimization, applied mathematics, vector space model, evolutionary computation, particle swarm theory, modeling and simulation, reinforcement learning, intelligent optimization, swarm intelligence, design optimization, computational optimization, multiagent system",2002,13482,computer science|artificial intelligence|particle method|global optimization|simulation optimization|mathematical optimization|fuzzy optimization|applied mathematics|vector space model|evolutionary computation|particle swarm theory|modeling and simulation|reinforcement learning|intelligent optimization|swarm intelligence|design optimization|computational optimization|multiagent system,
https://openalex.org/W2965373594,RoBERTa: A Robustly Optimized BERT Pretraining Approach,"RoBERTa: A Robustly Optimized BERT Pretraining Approach

Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training computationally expensive, often done on private datasets of sizes, and, as we will show, hyperparameter choices have impact the final results. We present a replication study BERT (Devlin et al., 2019) that carefully measures many key hyperparameters and training data size. find was significantly undertrained, can match or exceed every published after it. Our best achieves state-of-the-art results GLUE, RACE SQuAD. These highlight importance previously overlooked design choices, raise questions about source recently reported improvements. release our models code.

pattern recognition, computer science, artificial intelligence, information fusion, transfer learning, clustering, applied mathematics, machine learning, multilingual pretraining, data science, knowledge discovery, deep learning, nlp task, machine learning research, knowledge management, retrieval augmented generation",2019,13458,pattern recognition|computer science|artificial intelligence|information fusion|transfer learning|clustering|applied mathematics|machine learning|multilingual pretraining|data science|knowledge discovery|deep learning|nlp task|machine learning research|knowledge management|retrieval augmented generation,https://openalex.org/W2970641574
https://openalex.org/W1532325895,Introduction to information retrieval,"Introduction to information retrieval

Class-tested and coherent, this groundbreaking new textbook teaches web-era information retrieval, including web search the related areas of text classification clustering from basic concepts. Written a computer science perspective by three leading experts in field, it gives an up-to-date treatment all aspects design implementation systems for gathering, indexing, searching documents; methods evaluating systems; introduction to use machine learning on collections. All important ideas are explained using examples figures, making perfect introductory courses retrieval advanced undergraduates graduate students science. Based feedback extensive classroom experience, book has been carefully structured order make teaching more natural effective. Although originally designed as primary or undergraduate course will also create buzz researchers professionals alike.

interactive information retrieval, information retrieval, intelligent information retrieval, information science, knowledge retrieval, search technology, computer science, collaborative information retrieval",2009,13354,interactive information retrieval|information retrieval|intelligent information retrieval|information science|knowledge retrieval|search technology|computer science|collaborative information retrieval,
https://openalex.org/W2613718673,Faster R-CNN: towards real-time object detection with region proposal networks,"Faster R-CNN: towards real-time object detection with region proposal networks

State-of-the-art object detection networks depend on region proposal algorithms to hypothesize locations. Advances like SPPnet [7] and Fast R-CNN [5] have reduced the running time of these networks, exposing computation as a bottleneck. In this work, we introduce Region Proposal Network (RPN) that shares full-image convolutional features with network, thus enabling nearly cost-free proposals. An RPN is fully-convolutional network simultaneously predicts bounds objectness scores at each position. RPNs are trained end-to-end generate high-quality proposals, which used by for detection. With simple alternating optimization, can be share features. For very deep VGG-16 model [19], our system has frame rate 5fps (including all steps) GPU, while achieving state-of-the-art accuracy PASCAL VOC 2007 (73.2% mAP) 2012 (70.4% using 300 proposals per image. Code available https://github.com/ShaoqingRen/faster_rcnn.

computer science, information fusion, vehicular technology, scene analysis, cognitive science, data science, deep learning, pattern recognition, machine learning, computer vision, object recognition, computational imaging, object detection, scene understanding, object tracking, region proposal networks, machine vision, image analysis, localization",2015,13298,computer science|information fusion|vehicular technology|scene analysis|cognitive science|data science|deep learning|pattern recognition|machine learning|computer vision|object recognition|computational imaging|object detection|scene understanding|object tracking|region proposal networks|machine vision|image analysis|localization,https://openalex.org/W2194775991|https://openalex.org/W2963150697|https://openalex.org/W2963351448|https://openalex.org/W2565639579|https://openalex.org/W2752782242|https://openalex.org/W2412782625|https://openalex.org/W2963163009|https://openalex.org/W2963420686|https://openalex.org/W2549139847|https://openalex.org/W2340897893|https://openalex.org/W3018757597|https://openalex.org/W3035524453|https://openalex.org/W2963524571|https://openalex.org/W2963125010
https://openalex.org/W1576818901,Genetic Programming: On the Programming of Computers by Means of Natural Selection,"Genetic Programming: On the Programming of Computers by Means of Natural Selection

Background on genetic algorithms, LISP, and programming hierarchical problem-solving introduction to automatically-defined functions - the two-boxes problem problems that straddle breakeven point for computational effort Boolean parity determining architecture of program lawnmower bumblebee increasing benefits ADFs as are scaled up finding an impulse response function artificial ant San Mateo trail obstacle-avoiding robot minesweeper automatic discovery detectors letter recognition flushes four-of-a-kinds in a pinochle deck biochemistry molecular biology prediction transmembrane domains proteins omega loops lookahead version evolutionary selection evolution primitives sufficiency terminals closure simultaneous architecture, primitive functions, terminals, sufficiency, role representation lens effect. Appendices: list special symbols type fonts default parameters computer implementation annotated bibliography electronic mailing public repository.

genetic algorithm, computer science, artificial intelligence, computational science, evolutionary design, genetic programming, evolutionary biology, evolutionary computation, genetic improvement programming, computational biology, genetic variation, natural computing, evolutionary application, genetic engineering, evolutionary programming, computational optimization, genetics",1992,13230,genetic algorithm|computer science|artificial intelligence|computational science|evolutionary design|genetic programming|evolutionary biology|evolutionary computation|genetic improvement programming|computational biology|genetic variation|natural computing|evolutionary application|genetic engineering|evolutionary programming|computational optimization|genetics,
https://openalex.org/W2150593711,Least squares quantization in PCM,"Least squares quantization in PCM

It has long been realized that in pulse-code modulation (PCM), with a given ensemble of signals to handle, the quantum values should be spaced more closely voltage regions where signal amplitude is likely fall. shown by Panter and Dite that, limit as number quanta becomes infinite, asymptotic fractional density per unit vary one-third power probability amplitudes. In this paper corresponding result for any finite derived; is, necessary conditions are found associated quantization intervals an optimum scheme must satisfy. The optimization criterion used average noise minimum. obtained here goes over into become large. quautization schemes <tex xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">2^{b}</tex> quanta, xmlns:xlink=""http://www.w3.org/1999/xlink"">b=1,2, \cdots, 7</tex> , numerically Gaussian Laplacian distribution

quantitative science study, image analysis, computer science, least squares quantization, sparse representation, quantification, computational imaging, machine learning research, principal component analysis, statistics, applied mathematics, quantization (signal processing)",1982,13153,quantitative science study|image analysis|computer science|least squares quantization|sparse representation|quantification|computational imaging|machine learning research|principal component analysis|statistics|applied mathematics|quantization (signal processing),https://openalex.org/W2118246710
https://openalex.org/W4211049957,Gaussian Processes for Machine Learning,"Gaussian Processes for Machine Learning

A comprehensive and self-contained introduction to Gaussian processes, which provide a principled, practical, probabilistic approach learning in kernel machines. processes (GPs) GPs have received increased attention the machine-learning community over past decade, this book provides long-needed systematic unified treatment of theoretical practical aspects machine learning. The is self-contained, targeted at researchers students applied statistics. deals with supervised-learning problem for both regression classification, includes detailed algorithms. wide variety covariance (kernel) functions are presented their properties discussed. Model selection discussed from Bayesian classical perspective. Many connections other well-known techniques statistics discussed, including support-vector machines, neural networks, splines, regularization relevance vector machines others. Theoretical issues curves PAC-Bayesian framework treated, several approximation methods large datasets contains illustrative examples exercises, code available on Web. Appendixes mathematical background discussion Markov processes.

statistical learning theory, computer science, gaussian process, machine learning",2005,13137,statistical learning theory|computer science|gaussian process|machine learning,https://openalex.org/W2150066425
https://openalex.org/W3099878876,Array programming with NumPy,"Array programming with NumPy

Abstract Array programming provides a powerful, compact and expressive syntax for accessing, manipulating operating on data in vectors, matrices higher-dimensional arrays. NumPy is the primary array library Python language. It has an essential role research analysis pipelines fields as diverse physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance economics. For example, was important part of software stack used discovery gravitational waves 1 first imaging black hole 2 . Here we review how few fundamental concepts lead to simple powerful paradigm organizing, exploring analysing scientific data. foundation upon which ecosystem constructed. so pervasive that several projects, targeting audiences with specialized needs, have developed their own NumPy-like interfaces objects. Owing its central position ecosystem, increasingly acts interoperability layer between such computation libraries and, together application interface (API), flexible framework support next decade industrial analysis.

computer science, array computing, digital signal processing, array processing, applied mathematics, parallel computing, numerical simulation, scientific computing, computational optimization, computer engineering",2020,13120,computer science|array computing|digital signal processing|array processing|applied mathematics|parallel computing|numerical simulation|scientific computing|computational optimization|computer engineering,
https://openalex.org/W1996360405,A method for obtaining digital signatures and public-key cryptosystems,"A method for obtaining digital signatures and public-key cryptosystems

An encryption method is presented with the novel property that publicly revealing an key does not thereby reveal corresponding decryption key. This has two important consequences: Couriers or other secure means are needed to transmit keys, since a message can be enciphered using revealed by intended recipient. Only he decipher message, only knows A “signed” privately held Anyone verify this signature Signatures cannot forged, and signer later deny validity of his signature. obvious applications in “electronic mail” funds transfer” systems. encrypted representing it as number M, raising M specified power e, then taking remainder when result divided product, n , large secret prime numbers p q. Decryption similar; different, secret, d used, where e * = 1(mod (p - 1) (q 1)). The security system rests part on difficulty factoring published divisor, .

computer science, cryptography, public key infrastructure, digital signature, data security, public-key cryptosystems, authentication authorization, cryptosystem",1983,13098,computer science|cryptography|public key infrastructure|digital signature|data security|public-key cryptosystems|authentication authorization|cryptosystem,https://openalex.org/W2108834246|https://openalex.org/W2168676717|https://openalex.org/W2031533839
https://openalex.org/W1492221128,Adaptive Filter Theory,"Adaptive Filter Theory

Background and Overview. 1. Stochastic Processes Models. 2. Wiener Filters. 3. Linear Prediction. 4. Method of Steepest Descent. 5. Least-Mean-Square Adaptive 6. Normalized 7. Transform-Domain Sub-Band 8. Least Squares. 9. Recursive Least-Square 10. Kalman Filters as the Unifying Bases for RLS 11. Square-Root 12. Order-Recursive 13. Finite-Precision Effects. 14. Tracking Time-Varying Systems. 15. Using Infinite-Duration Impulse Response Structures. 16. Blind Deconvolution. 17. Back-Propagation Learning. Epilogue. Appendix A. Complex Variables. B. Differentiation with Respect to a Vector. C. Lagrange Multipliers. D. Estimation Theory. E. Eigenanalysis. F. Rotations Reflections. G. Wishart Distribution. Glossary. Abbreviations. Principal Symbols. Bibliography. Index.

computer science, filter (signal processing), spatial filtering, theoretical computer science, adaptive algorithm, adaptive filter, applied mathematics, filter design, adaptive filter theory",1986,13062,computer science|filter (signal processing)|spatial filtering|theoretical computer science|adaptive algorithm|adaptive filter|applied mathematics|filter design|adaptive filter theory,https://openalex.org/W2019207321
https://openalex.org/W3017143921,Pattern classification and scene analysis,"Pattern classification and scene analysis

Provides a unified, comprehensive and up-to-date treatment of both statistical descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing pictorial data, spatial filtering, shape description perspective transformations, projective invariants, linguistic procedures, artificial intelligence techniques scene analysis.

image analysis, pattern recognition, computer science, computational imaging, image classification, statistical pattern recognition, scene understanding, pattern classification, computer vision, machine learning, scene analysis, data science, spatial analysis, knowledge discovery, pattern analysis, machine learning research, machine vision",1973,12979,image analysis|pattern recognition|computer science|computational imaging|image classification|statistical pattern recognition|scene understanding|pattern classification|computer vision|machine learning|scene analysis|data science|spatial analysis|knowledge discovery|pattern analysis|machine learning research|machine vision,https://openalex.org/W2112796928|https://openalex.org/W2121863487|https://openalex.org/W2163352848|https://openalex.org/W2121647436|https://openalex.org/W1746819321|https://openalex.org/W2067191022|https://openalex.org/W2087347434|https://openalex.org/W2117812871|https://openalex.org/W2048679005
https://openalex.org/W2034139177,A Practical Guide to Wavelet Analysis,"A Practical Guide to Wavelet Analysis

A practical step-by-step guide to wavelet analysis is given, with examples taken from time series of the El Niño–Southern Oscillation (ENSO). The includes a comparison windowed Fourier transform, choice an appropriate basis function, edge effects due finite-length series, and relationship between scale frequency. New statistical significance tests for power spectra are developed by deriving theoretical white red noise processes using these establish levels confidence intervals. It shown that smoothing in or can be used increase spectrum. Empirical formulas given effect on Extensions such as filtering, Hovmöller, cross-wavelet spectra, coherence described. give quantitative measure changes ENSO variance interdecadal timescales. Using new datasets extend back 1871, Niño3 sea surface temperature Southern index show significantly higher during 1880–1920 1960–90, lower 1920–60, well possible 15-yr modulation variance. Hovmöller level pressure shows significant variations 2–8-yr both longitude time.

image analysis, pattern recognition, computer science, computational imaging, speech processing, digital signal processing, computer vision, applied mathematics, multimodal signal processing, waveform analysis, wavelet, statistical signal processing, statistics, wave theory, wavelet theory, practical guide, machine vision",1998,12936,image analysis|pattern recognition|computer science|computational imaging|speech processing|digital signal processing|computer vision|applied mathematics|multimodal signal processing|waveform analysis|wavelet|statistical signal processing|statistics|wave theory|wavelet theory|practical guide|machine vision,
https://openalex.org/W2531409750,Xception: Deep Learning with Depthwise Separable Convolutions,"Xception: Deep Learning with Depthwise Separable Convolutions

We present an interpretation of Inception modules in convolutional neural networks as being intermediate step in-between regular convolution and the depthwise separable operation (a followed by a pointwise convolution). In this light, can be understood module with maximally large number towers. This observation leads us to propose novel deep network architecture inspired Inception, where have been replaced convolutions. show that architecture, dubbed Xception, slightly outperforms V3 on ImageNet dataset (which was designed for), significantly larger image classification comprising 350 million images 17,000 classes. Since Xception has same parameters V3, performance gains are not due increased capacity but rather more efficient use model parameters.

image analysis, computer science, convolutional neural network, depthwise separable convolutions, machine learning, deep learning",2017,12835,image analysis|computer science|convolutional neural network|depthwise separable convolutions|machine learning|deep learning,https://openalex.org/W2752782242|https://openalex.org/W2963163009|https://openalex.org/W2963420686|https://openalex.org/W2963125010
https://openalex.org/W1506342804,Iterative Methods for Sparse Linear Systems,"Iterative Methods for Sparse Linear Systems

Preface 1. Background in linear algebra 2. Discretization of partial differential equations 3. Sparse matrices 4. Basic iterative methods 5. Projection 6. Krylov subspace Part I 7. II 8. Methods related to the normal 9. Preconditioned iterations 10. Preconditioning techniques 11. Parallel implementations 12. preconditioners 13. Multigrid 14. Domain decomposition Bibliography Index.

computer science, graph theory, parameter identification, machine learning, applied mathematics, numerical linear algebra, sparse linear systems, sparse representation, numerical analysis, machine learning research, iterative methods, computational science",2003,12786,computer science|graph theory|parameter identification|machine learning|applied mathematics|numerical linear algebra|sparse linear systems|sparse representation|numerical analysis|machine learning research|iterative methods|computational science,
https://openalex.org/W2130942839,Sequence to Sequence Learning with Neural Networks,"Sequence to Sequence Learning with Neural Networks

Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets available, they cannot be used to map sequences sequences. In this paper, we present a general end-to-end approach sequence makes minimal assumptions the structure. Our method uses multilayered Long Short-Term Memory (LSTM) input vector of fixed dimensionality, and then another deep LSTM decode target from vector. main result is an English French translation task WMT'14 dataset, translations produced by achieve BLEU score 34.8 entire test set, where LSTM's was penalized out-of-vocabulary words. Additionally, did not difficulty long sentences. For comparison, phrase-based SMT system achieves 33.3 same dataset. When rerank 1000 hypotheses aforementioned system, its increases 36.5, which close previous best task. The also learned sensible phrase sentence representations sensitive word order relatively invariant active passive voice. Finally, found reversing words in all source sentences (but sentences) improved markedly, because doing so introduced many short term dependencies between made optimization problem easier.

neural networks, knowledge discovery, sparse neural network, neural network (machine learning), sequential learning, computer science, recurrent neural network, deep reinforcement learning, machine learning research, deep learning, sequence modelling, machine vision, natural language processing, natural language generation, machine learning, data science, neural computation, cognitive science, computational intelligence",2014,12686,neural networks|knowledge discovery|sparse neural network|neural network (machine learning)|sequential learning|computer science|recurrent neural network|deep reinforcement learning|machine learning research|deep learning|sequence modelling|machine vision|natural language processing|natural language generation|machine learning|data science|neural computation|cognitive science|computational intelligence,https://openalex.org/W2271840356|https://openalex.org/W1902237438|https://openalex.org/W1895577753
https://openalex.org/W2122111042,Nearest neighbor pattern classification,"Nearest neighbor pattern classification

The nearest neighbor decision rule assigns to an unclassified sample point the classification of a set previously classified points. This is independent underlying joint distribution on points and their classifications, hence probability error <tex xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">R</tex> such must be at least as great Bayes xmlns:xlink=""http://www.w3.org/1999/xlink"">R^{\ast}</tex> --the minimum over all rules taking structure into account. However, in large analysis, we will show xmlns:xlink=""http://www.w3.org/1999/xlink"">M</tex> -category case that xmlns:xlink=""http://www.w3.org/1999/xlink"">R^{\ast} \leq R R^{\ast}(2 --MR^{\ast}/(M-1))</tex> , where these bounds are tightest possible, for suitably smooth distributions. Thus any number categories, bounded above by twice error. In this sense, it may said half information infinite contained neighbor.

pattern recognition, computer science, data classification, machine learning, clustering, knowledge discovery, machine learning research, classification method, pattern mining",1967,12557,pattern recognition|computer science|data classification|machine learning|clustering|knowledge discovery|machine learning research|classification method|pattern mining,
https://openalex.org/W2962858109,Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization,"Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization

We propose a technique for producing `visual explanations' decisions from large class of Convolutional Neural Network (CNN)-based models, making them more transparent. Our approach - Gradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients any target concept (say logits `dog' or even caption), flowing into final convolutional layer to produce coarse localization map highlighting important regions in image predicting concept. Unlike previous approaches, Grad- CAM is applicable wide variety CNN model-families: (1) CNNs with fully-connected layers (e.g. VGG), (2) used structured outputs captioning), (3) tasks multi-modal inputs visual question answering) reinforcement learning, without architectural changes re-training. combine Grad-CAM existing fine-grained visualizations create high-resolution class-discriminative visualization, Guided Grad-CAM, and apply it classification, captioning, answering (VQA) including ResNet-based architectures. In context classification our (a) lend insights failure modes these models (showing that seemingly unreasonable predictions have reasonable explanations), (b) outperform methods on ILSVRC-15 weakly-supervised task, (c) are faithful underlying model, (d) help achieve model generalization by identifying dataset bias. For captioning VQA, show non-attention based can localize inputs. Finally, we design conduct human studies measure if explanations users establish appropriate trust deep networks helps untrained successfully discern `stronger' network `weaker' one when both make identical predictions. code available at https: //github.com/ramprs/grad-cam/ along demo CloudCV [2] video youtu.be/COjUB9Izk6E.

computer science, vision language model, machine learning, visual science, image analysis, information visualization, visualization, feature detection, cognitive science, data science, computational imaging, scene understanding, deep networks, localization, deep learning, machine vision, visual explanations, visual question answering, interactive visualization, computer vision, gradient-based localization",2017,12443,computer science|vision language model|machine learning|visual science|image analysis|information visualization|visualization|feature detection|cognitive science|data science|computational imaging|scene understanding|deep networks|localization|deep learning|machine vision|visual explanations|visual question answering|interactive visualization|computer vision|gradient-based localization,
https://openalex.org/W2167667767,A flexible new technique for camera calibration,"A flexible new technique for camera calibration

We propose a flexible technique to easily calibrate camera. It only requires the camera observe planar pattern shown at few (at least two) different orientations. Either or can be freely moved. The motion need not known. Radial lens distortion is modeled. proposed procedure consists of closed-form solution, followed by nonlinear refinement based on maximum likelihood criterion. Both computer simulation and real data have been used test very good results obtained. Compared with classical techniques which use expensive equipment such as two three orthogonal planes, easy flexible. advances 3D vision one more step from laboratory environments world use.

computer science, calibration, computer vision, camera calibration",2000,12438,computer science|calibration|computer vision|camera calibration,https://openalex.org/W2167667767
https://openalex.org/W2950577311,Efficient Estimation of Word Representations in Vector Space,"Efficient Estimation of Word Representations in Vector Space

We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality these is measured in a word similarity task, and the results are compared to previously best performing techniques based on different types neural networks. observe improvements accuracy at much lower computational cost, i.e. it takes less than day learn high vectors 1.6 billion set. Furthermore, we show that provide state-of-the-art performance our test set measuring syntactic semantic similarities.

computer science, efficient estimation, vector space, natural language processing, word representations",2013,12371,computer science|efficient estimation|vector space|natural language processing|word representations,https://openalex.org/W2493916176|https://openalex.org/W2953384591|https://openalex.org/W2125389028|https://openalex.org/W2964153729|https://openalex.org/W2402144811|https://openalex.org/W3005680577
https://openalex.org/W2149992227,The variant call format and VCFtools,"The variant call format and VCFtools

Abstract Summary: The variant call format (VCF) is a generic for storing DNA polymorphism data such as SNPs, insertions, deletions and structural variants, together with rich annotations. VCF usually stored in compressed manner can be indexed fast retrieval of variants from range positions on the reference genome. was developed 1000 Genomes Project, has also been adopted by other projects UK10K, dbSNP NHLBI Exome Project. VCFtools software suite that implements various utilities processing files, including validation, merging, comparing provides general Perl API. Availability: http://vcftools.sourceforge.net Contact: rd@sanger.ac.uk

computer science, variant call format",2011,12237,computer science|variant call format,https://openalex.org/W2099085143
https://openalex.org/W4295312788,"PyTorch: An Imperative Style, High-Performance Deep Learning Library","PyTorch: An Imperative Style, High-Performance Deep Learning Library

Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine library that shows these two goals are in fact compatible: it provides an imperative and Pythonic programming style supports code as model, makes debugging easy consistent with other popular scientific computing libraries, while remaining efficient supporting hardware accelerators such GPUs. In this paper, we detail the principles drove implementation of how they reflected its architecture. We emphasize every aspect regular Python program under full control user. also explain careful pragmatic key components runtime enables them to work together achieve compelling performance. demonstrate efficiency individual subsystems, well overall speed several common benchmarks.

imperative style, natural language processing, computer science, machine learning, large language model, deep learning",2019,11899,imperative style|natural language processing|computer science|machine learning|large language model|deep learning,
https://openalex.org/W2964015378,Semi-Supervised Classification with Graph Convolutional Networks,"Semi-Supervised Classification with Graph Convolutional Networks

We present a scalable approach for semi-supervised learning on graph-structured data that is based an efficient variant of convolutional neural networks which operate directly graphs. motivate the choice our architecture via localized first-order approximation spectral graph convolutions. Our model scales linearly in number edges and learns hidden layer representations encode both local structure features nodes. In experiments citation knowledge dataset we demonstrate outperforms related methods by significant margin.

graph theory, pattern recognition, semi-supervised classification, neural network (machine learning), semi-supervised learning, data classification, graph neural network, computer science, graph processing, graph convolutional networks, machine learning, machine learning research, graph analysis, deep learning, data science",2016,11848,graph theory|pattern recognition|semi-supervised classification|neural network (machine learning)|semi-supervised learning|data classification|graph neural network|computer science|graph processing|graph convolutional networks|machine learning|machine learning research|graph analysis|deep learning|data science,
https://openalex.org/W2091579301,The Sciences of the Artificial,"The Sciences of the Artificial

Continuing his exploration of the organization complexity and science design, this new edition Herbert Simon's classic work on artificial intelligence adds a chapter that sorts out current themes tools -- chaos, adaptive systems, genetic algorithms for analyzing complex systems. There are updates throughout book as well. These take into account important advances in cognitive psychology design while confirming extending book's basic thesis: physical symbol system has necessary sufficient means intelligent action. The Economic Reality also been revised to reflect change emphasis thinking about respective roles organizations markets economic

computer science, artificial intelligence, artificial system, technology, artificial society, systems engineering, artificial consciousness, intelligent robotic system, artificial organ, artificial bee, artificial life, synthetic agent",1969,11827,computer science|artificial intelligence|artificial system|technology|artificial society|systems engineering|artificial consciousness|intelligent robotic system|artificial organ|artificial bee|artificial life|synthetic agent,
https://openalex.org/W2121647436,Eigenfaces vs. Fisherfaces: recognition using class specific linear projection,"Eigenfaces vs. Fisherfaces: recognition using class specific linear projection

We develop a face recognition algorithm which is insensitive to large variation in lighting direction and facial expression. Taking pattern classification approach, we consider each pixel an image as coordinate high-dimensional space. take advantage of the observation that images particular face, under varying illumination but fixed pose, lie 3D linear subspace high dimensional space-if Lambertian surface without shadowing. However, since faces are not truly surfaces do indeed produce self-shadowing, will deviate from this subspace. Rather than explicitly modeling deviation, linearly project into manner discounts those regions with deviation. Our projection method based on Fisher's discriminant produces well separated classes low-dimensional subspace, even severe expressions. The eigenface technique, another projecting space low has similar computational requirements. Yet, extensive experimental results demonstrate proposed ""Fisherface"" error rates lower technique for tests Harvard Yale databases.

image analysis, pattern recognition, computer science, computational imaging, object recognition, computer vision, machine learning, numerical linear algebra, image representation, 3d object recognition, machine learning research, facial recognition system, machine vision, face detection, facial expression recognition",1997,11826,image analysis|pattern recognition|computer science|computational imaging|object recognition|computer vision|machine learning|numerical linear algebra|image representation|3d object recognition|machine learning research|facial recognition system|machine vision|face detection|facial expression recognition,https://openalex.org/W2121647436|https://openalex.org/W2129812935|https://openalex.org/W1989702938
https://openalex.org/W1746819321,Gaussian Processes for Machine Learning,"Gaussian Processes for Machine Learning

A comprehensive and self-contained introduction to Gaussian processes, which provide a principled, practical, probabilistic approach learning in kernel machines. processes (GPs) GPs have received increased attention the machine-learning community over past decade, this book provides long-needed systematic unified treatment of theoretical practical aspects machine learning. The is self-contained, targeted at researchers students applied statistics. deals with supervised-learning problem for both regression classification, includes detailed algorithms. wide variety covariance (kernel) functions are presented their properties discussed. Model selection discussed from Bayesian classical perspective. Many connections other well-known techniques statistics discussed, including support-vector machines, neural networks, splines, regularization relevance vector machines others. Theoretical issues curves PAC-Bayesian framework treated, several approximation methods large datasets contains illustrative examples exercises, code available on Web. Appendixes mathematical background discussion Markov processes.

machine learning, computer science, gaussian process, statistical learning theory",2005,11808,machine learning|computer science|gaussian process|statistical learning theory,https://openalex.org/W2150066425
https://openalex.org/W1766888123,Discrete-Time Signal Processing,"Discrete-Time Signal Processing

For senior/graduate-level courses in Discrete-Time Signal Processing. THE definitive, authoritative text on DSP -- ideal for those with an introductory-level knowledge of signals and systems. Written by prominent, pioneers, it provides thorough treatment the fundamental theorems properties discrete-time linear systems, filtering, sampling, Fourier Analysis. By focusing general universal concepts signal processing, remains vital relevant to new challenges arising field --without limiting itself specific technologies relatively short life spans.

computer science, statistical signal processing, discrete-time signal processing, signal processing",1989,11804,computer science|statistical signal processing|discrete-time signal processing|signal processing,
https://openalex.org/W2031611770,FastTree 2 – Approximately Maximum-Likelihood Trees for Large Alignments,"FastTree 2 – Approximately Maximum-Likelihood Trees for Large Alignments

We recently described FastTree, a tool for inferring phylogenies alignments with up to hundreds of thousands sequences. Here, we describe improvements FastTree that improve its accuracy without sacrificing scalability.Where 1 used nearest-neighbor interchanges (NNIs) and the minimum-evolution criterion tree, 2 adds subtree-pruning-regrafting (SPRs) maximum-likelihood NNIs. uses heuristics restrict search better trees estimates rate evolution each site (the ""CAT"" approximation). Nevertheless, both simulated genuine alignments, is slightly more accurate than standard implementation NNIs (PhyML 3 default settings). Although not quite as methods use SPRs, most splits disagree are poorly supported, large 100-1,000 times faster. inferred topology likelihood-based local support values 237,882 distinct 16S ribosomal RNAs on desktop computer in 22 hours 5.8 gigabytes memory.FastTree allows inference huge alignments. freely available at http://www.microbesonline.org/fasttree.

pattern recognition, computer science, maximum-likelihood trees, parameter identification, machine learning, automatic classification, image analysis, high-dimensional statistics, information fusion, treebanks, hierarchical classification, data science, large alignments, deep learning, machine learning research, sequence alignment, machine vision, applied mathematics, knowledge discovery",2010,11801,pattern recognition|computer science|maximum-likelihood trees|parameter identification|machine learning|automatic classification|image analysis|high-dimensional statistics|information fusion|treebanks|hierarchical classification|data science|large alignments|deep learning|machine learning research|sequence alignment|machine vision|applied mathematics|knowledge discovery,
https://openalex.org/W1821462560,Distilling the Knowledge in a Neural Network,"Distilling the Knowledge in a Neural Network

A very simple way to improve the performance of almost any machine learning algorithm is train many different models on same data and then average their predictions. Unfortunately, making predictions using a whole ensemble cumbersome may be too computationally expensive allow deployment large number users, especially if individual are neural nets. Caruana his collaborators have shown that it possible compress knowledge in an into single model which much easier deploy we develop this approach further compression technique. We achieve some surprising results MNIST show can significantly acoustic heavily used commercial system by distilling model. also introduce new type composed one or more full specialist learn distinguish fine-grained classes confuse. Unlike mixture experts, these trained rapidly parallel.

computer science, knowledge representation and reasoning, machine learning, neural network, knowledge distillation, neural network (machine learning)",2015,11760,computer science|knowledge representation and reasoning|machine learning|neural network|knowledge distillation|neural network (machine learning),https://openalex.org/W2531409750|https://openalex.org/W2612445135|https://openalex.org/W2963125010|https://openalex.org/W2963857521
https://openalex.org/W2038721957,WordNet: An Electronic Lexical Database,"WordNet: An Electronic Lexical Database

Part 1 The lexical database: nouns in WordNet, George A. Miller modifiers Katherine J. a semantic network of English verbs, Christiane Fellbaum design and implementation the WordNet database searching software, Randee I. Tengi. 2: automated discovery relations, Marti Hearst representing verb alterations Karen T. Kohl et al formalization by methods relational concept analysis, Uta E. Priss. 3 Applications WordNet: building concordances, Shari Landes performance confidence annotation task, class-based probabilities, Philip Resnik combining local context similarity for word sense identification, Claudia Leacock Martin Chodorow using text retrieval, Ellen M. Voorhees chains as representations detection correction malapropisms, Graeme Hirst David St-Onge temporal indexing through chaining, Reem Al-Halimi Rick Kazman COLOR-X - knowledge from conceptual modelling, J.F.M. Burg R.P. van de Riet processing on an extended Sanda Harabagiu Dan I Moldovan appendix obtaining WordNet.

computer science, computational lexicology, electronic library, computational linguistics, lexical resource, lexicography, electronic lexical database, lexicon, thesaurus management, corpus linguistics",2000,11729,computer science|computational lexicology|electronic library|computational linguistics|lexical resource|lexicography|electronic lexical database|lexicon|thesaurus management|corpus linguistics,https://openalex.org/W2160660844|https://openalex.org/W2097726431
https://openalex.org/W4294214983,Interrater reliability: the kappa statistic,"Interrater reliability: the kappa statistic

The kappa statistic is frequently used to test interrater reliability. importance of rater reliability lies in the fact that it represents extent which data collected study are correct representations variables measured. Measurement collectors (raters) assign same score variable called While there have been a variety methods measure reliability, traditionally was measured as percent agreement, calculated number agreement scores divided by total scores. In 1960, Jacob Cohen critiqued use due its inability account for chance agreement. He introduced Cohen's kappa, developed possibility raters actually guess on at least some uncertainty. Like most correlation statistics, can range from -1 +1. one commonly statistics has limitations. Judgments about what level should be acceptable health research questioned. suggested interpretation may too lenient related studies because implies low 0.41 might acceptable. Kappa and compared, levels both demanded healthcare suggested.

computer science, personality assessment, uncertainty analysis, machine learning, human reliability, quality of life, intellectual disability, physiological measurement, kappa statistic, interrater reliability, biostatistics, statistics, performance evaluation, reliability, interobserver agreement, performance measure, performance assessment, reliability analysis, reliability engineering",2012,11635,computer science|personality assessment|uncertainty analysis|machine learning|human reliability|quality of life|intellectual disability|physiological measurement|kappa statistic|interrater reliability|biostatistics|statistics|performance evaluation|reliability|interobserver agreement|performance measure|performance assessment|reliability analysis|reliability engineering,
https://openalex.org/W2138825607,Image processing with ImageJ,"Image processing with ImageJ

Wayne Rasband of NIH has created ImageJ, an open source Java-written program that is now at version 1.31 and used for many imaging applications, including those span the gamut from skin analysis to neuroscience. ImageJ in public domain runs on any operating system (OS). easy use can do manipulations. A very large knowledgeable group makes up user community ImageJ. Topics covered are abilities; cross platform; image formats support as June 2004; extensions, macros plug-ins; library. reports tens thousands downloads a rate about 24,000 per month currently. read most widely significant biomedical images. Manipulations supported read/write files operations separate pixels, regions, entire images, volumes (stacks ImageJ). Basic include convolution, edge detection, Fourier transform, histogram particle analyses, editing color manipulation, more advanced operations, well visualization. For assistance using users e-mail each other, base highly will answer requests mailing list. thorough manual with examples illustrations been written by Tony Collins Wright Cell Imaging Facility Toronto Western Research Institute available, along other listed resources, via Web.

image analysis, computational imaging, computer science, image processing, image restoration, computer vision, image manipulation, image sequence analysis, image representation, image classification, digital image processing",2004,11532,image analysis|computational imaging|computer science|image processing|image restoration|computer vision|image manipulation|image sequence analysis|image representation|image classification|digital image processing,
https://openalex.org/W3138516171,Swin Transformer: Hierarchical Vision Transformer using Shifted Windows,"Swin Transformer: Hierarchical Vision Transformer using Shifted Windows

This paper presents a new vision Transformer, called Swin that capably serves as general-purpose backbone for computer vision. Challenges in adapting Transformer from language to arise differences between the two domains, such large variations scale of visual entities and high resolution pixels images compared words text. To address these differences, we propose hierarchical whose representation is computed with Shifted windows. The shifted windowing scheme brings greater efficiency by limiting self-attention computation non-overlapping local windows while also allowing cross-window connection. architecture has flexibility model at various scales linear computational complexity respect image size. These qualities make it compatible broad range tasks, including classification (87.3 top-1 accuracy on ImageNet-1K) dense prediction tasks object detection (58.7 box AP 51.1 mask COCO test-dev) semantic segmentation (53.5 mIoU ADE20K val). Its performance surpasses previous state-of-the-art margin +2.7 +2.6 COCO, +3.2 ADE20K, demonstrating potential Transformer-based models backbones. design window approach prove beneficial all-MLP architectures. code are publicly available https://github.com/microsoft/Swin-Transformer.

computer vision, swin transformer, computer science, image manipulation, hierarchical vision transformer",2021,11529,computer vision|swin transformer|computer science|image manipulation|hierarchical vision transformer,
https://openalex.org/W2150220236,"Software survey: VOSviewer, a computer program for bibliometric mapping","Software survey: VOSviewer, a computer program for bibliometric mapping

We present VOSviewer, a freely available computer program that we have developed for constructing and viewing bibliometric maps. Unlike most programs are used mapping, VOSviewer pays special attention to the graphical representation of The functionality is especially useful displaying large maps in an easy-to-interpret way. paper consists three parts. In first part, overview VOSviewer's provided. second technical implementation specific parts discussed. Finally, third ability handle demonstrated by using construct display co-citation map 5,000 major scientific journals.

computer science, bibliometric mapping, bibliometrics, survey methodology, citation graph, citation analysis, informetrics, social science, data science, scholarly communication, information retrieval, digital scholarship, research library, scientific communication, computer program, text mining, scientometrics, clustering, knowledge discovery, altmetrics",2009,11469,computer science|bibliometric mapping|bibliometrics|survey methodology|citation graph|citation analysis|informetrics|social science|data science|scholarly communication|information retrieval|digital scholarship|research library|scientific communication|computer program|text mining|scientometrics|clustering|knowledge discovery|altmetrics,
https://openalex.org/W2129288307,A New Two-Constant Equation of State,"A New Two-Constant Equation of State

ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTA New Two-Constant Equation of StateDing-Yu Peng and Donald B. RobinsonCite this: Ind. Eng. Chem. Fundamen. 1976, 15, 1, 59–64Publication Date (Print):February 1976Publication History Published online1 May 2002Published inissue 1 February 1976https://pubs.acs.org/doi/10.1021/i160057a011https://doi.org/10.1021/i160057a011research-articleACS PublicationsRequest reuse permissionsArticle Views21168Altmetric-Citations9849LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum full text article downloads since November 2008 (both PDF HTML) across all institutions individuals. These metrics regularly updated to reflect usage leading up last few days.Citations number other articles citing this article, calculated by Crossref daily. Find more information about citation counts.The Altmetric Attention Score is a quantitative measure attention that research has received online. Clicking on donut icon will load page at altmetric.com with additional details score social media presence for given article. how calculated. Share Add toView InAdd Full Text ReferenceAdd Description ExportRISCitationCitation abstractCitation referencesMore Options onFacebookTwitterWechatLinked InRedditEmail Other access options Get e-Alerts

computer science, state space search",1976,11323,computer science|state space search,
https://openalex.org/W1832693441,Convolutional Neural Networks for Sentence Classification,"Convolutional Neural Networks for Sentence Classification

We report on a series of experiments with convolutional neural networks (CNN) trained top pre-trained word vectors for sentence-level classification tasks.We show that simple CNN little hyperparameter tuning and static achieves excellent results multiple benchmarks.Learning task-specific through fine-tuning offers further gains in performance.We additionally propose modification to the architecture allow use both vectors.The models discussed herein improve upon state art 4 out 7 tasks, which include sentiment analysis question classification.

knowledge discovery, nlp task, neural network (machine learning), sequential learning, computer science, machine learning research, deep learning, neuroscience, natural language processing, machine translation, semantic interpretation, text processing, sentence classification, machine learning, neural computation, cognitive science, computational intelligence, semantic evaluation, convolutional neural network",2014,11322,knowledge discovery|nlp task|neural network (machine learning)|sequential learning|computer science|machine learning research|deep learning|neuroscience|natural language processing|machine translation|semantic interpretation|text processing|sentence classification|machine learning|neural computation|cognitive science|computational intelligence|semantic evaluation|convolutional neural network,
https://openalex.org/W1533861849,Understanding the difficulty of training deep feedforward neural networks,"Understanding the difficulty of training deep feedforward neural networks

Whereas before 2006 it appears that deep multilayer neural networks were not successfully trained, since then several algorithms have been shown to train them, with experimental results showing the superiority of deeper vs less architectures. All these obtained new initialization or training mechanisms. Our objective here is understand better why standard gradient descent from random doing so poorly networks, recent relative successes and help design in future. We first observe influence non-linear activations functions. find logistic sigmoid activation unsuited for because its mean value, which can drive especially top hidden layer into saturation. Surprisingly, we saturated units move out saturation by themselves, albeit slowly, explaining plateaus sometimes seen when networks. a non-linearity saturates often be beneficial. Finally, study how gradients vary across layers during training, idea may more difficult singular values Jacobian associated each are far 1. Based on considerations, propose scheme brings substantially faster convergence. 1 Deep Neural Networks learning methods aim at feature hierarchies features higher levels hierarchy formed composition lower level features. They include Appearing Proceedings 13 International Conference Artificial Intelligence Statistics (AISTATS) 2010, Chia Laguna Resort, Sardinia, Italy. Volume 9 JMLR: WC Weston et al., 2008). Much attention has recently devoted them (see (Bengio, 2009) review), their theoretical appeal, inspiration biology human cognition, empirical success vision (Ranzato 2007; Larochelle Vincent 2008) natural language processing (NLP) (Collobert & Weston, 2008; Mnih Hinton, 2009). Theoretical reviewed discussed Bengio (2009), suggest order learn kind complicated functions represent high-level abstractions (e.g. vision, language, other AI-level tasks), one need Most architecture models turned supervised but schemes different classical feedforward (Rumelhart 1986). Why working much than gradient-based optimization criterion? Part answer found analyses effect unsupervised pretraining (Erhan 2009), acts as regularizer initializes parameters “better” basin attraction procedure, corresponding an apparent local minimum generalization. But earlier work (Bengio 2007) had even purely greedy layer-wise procedure would give results. So instead focusing what pre-training semi-supervised criteria bring architectures, focus analyzing going wrong good old (but deep) analysis driven investigative experiments monitor (watching units) gradients, iterations. also evaluate effects choices function (with might affect saturation) (since particular form drastic impact).

machine learning, computer science, artificial intelligence, deep learning, neural network (machine learning), learning problem, neural computation",2010,11314,machine learning|computer science|artificial intelligence|deep learning|neural network (machine learning)|learning problem|neural computation,https://openalex.org/W2194775991|https://openalex.org/W1836465849|https://openalex.org/W1677182931
https://openalex.org/W4232836212,A method for obtaining digital signatures and public-key cryptosystems,"A method for obtaining digital signatures and public-key cryptosystems

An encryption method is presented with the novel property that publicly revealing an key does not thereby reveal corresponding decryption key. This has two important consequences: (1) Couriers or other secure means are needed to transmit keys, since a message can be enciphered using revealed by intented recipient. Only he decipher message, only knows (2) A “signed” privately held Anyone verify this signature Signatures cannot forged, and signer later deny validity of his signature. obvious applications in “electronic mail” funds transfer” systems. encrypted representing it as number M, raising M specified power e, then taking remainder when result divided product, n , large secret primer numbers p q. Decryption similar; different, secret, d used, where e * ≡ 1(mod (p - 1) (q 1)). The security system rests part on difficulty factoring published divisor, .

authentication authorization, data security, cryptosystem, public key infrastructure, computer science, digital signature, public-key cryptosystems, cryptography",1978,11291,authentication authorization|data security|cryptosystem|public key infrastructure|computer science|digital signature|public-key cryptosystems|cryptography,https://openalex.org/W2108834246|https://openalex.org/W3038067977|https://openalex.org/W2168676717|https://openalex.org/W2031533839
https://openalex.org/W2118877769,An Iterative Image Registration Technique with an Application to Stereo Vision,"An Iterative Image Registration Technique with an Application to Stereo Vision

Image registration finds a variety of applications in computer vision. Unfortunately, traditional image techniques tend to be costly. We present new technique that makes use the spatial intensity gradient images find good match using type Newton-Raphson iteration. Our is taster because it examines far fewer potential matches between than existing Furthermore, this can generalized handle rotation, scaling and shearing. show how our adapted tor stereo vision system.

stereoscopic processing, computer science, digital image processing, image registration",1981,11189,stereoscopic processing|computer science|digital image processing|image registration,https://openalex.org/W2130103520
https://openalex.org/W2158266834,WebLogo: A Sequence Logo Generator: Figure 1,"WebLogo: A Sequence Logo Generator: Figure 1

WebLogo generates sequence logos, graphical representations of the patterns within a multiple alignment. Sequence logos provide richer and more precise description similarity than consensus sequences can rapidly reveal significant features alignment otherwise difficult to perceive. Each logo consists stacks letters, one stack for each position in sequence. The overall height indicates conservation at that (measured bits), whereas symbols reflects relative frequency corresponding amino or nucleic acid position. has been enhanced recently with additional options, convenient highly configurable generator. A command line interface complete, open source code are available local installation customization.

image analysis, pattern recognition, computer science, information visualization, sequence design, computer graphic, visualization, data and information visualization, computational linguistics, image sequence analysis, image representation, sequence modelling, sequence logo generator, feature construction, computer-generated imagery, design",2004,11169,image analysis|pattern recognition|computer science|information visualization|sequence design|computer graphic|visualization|data and information visualization|computational linguistics|image sequence analysis|image representation|sequence modelling|sequence logo generator|feature construction|computer-generated imagery|design,https://openalex.org/W2158266834
https://openalex.org/W2061171222,An algorithm for the machine calculation of complex Fourier series,"An algorithm for the machine calculation of complex Fourier series

An efficient method for the calculation of interactions a 2m factorial experiment was introduced by Yates and is widely known his name.The generalization to 3m given Box et al. [1].Good [2] generalized these methods gave elegant algorithms which one class applications Fourier series.In their full generality, Good's are applicable certain problems in must multiply an JV-vector JV X N matrix can be factored into m sparse matrices, where proportional log JV.This results procedure requiring number operations rather than JV2.These applied here complex series.They useful situations data points is, or chosen be, highly composite number.The algorithm derived presented different form.Attention choice JV.It also shown how special advantage obtained use binary computer with = entire performed within array storage locations used coefficients.Consider problem calculating series

complex fourier series, machine calculation, computer science",1965,11115,complex fourier series|machine calculation|computer science,https://openalex.org/W2041902442
https://openalex.org/W2560023338,Pyramid Scene Parsing Network,"Pyramid Scene Parsing Network

Scene parsing is challenging for unrestricted open vocabulary and diverse scenes. In this paper, we exploit the capability of global context information by different-region-based aggregation through our pyramid pooling module together with proposed scene network (PSPNet). Our prior representation effective to produce good quality results on task, while PSPNet provides a superior framework pixel-level prediction. The approach achieves state-of-the-art performance various datasets. It came first in ImageNet challenge 2016, PASCAL VOC 2012 benchmark Cityscapes benchmark. A single yields new record mIoU accuracy 85.4% 80.2% Cityscapes.

image analysis, pattern recognition, computer science, computational imaging, structure from motion, scene interpretation, scene understanding, multi-view geometry, computer vision, scene analysis, multimedia retrieval, data science, systems engineering, deep learning, image representation, machine learning research, machine vision, digital image processing",2017,11099,image analysis|pattern recognition|computer science|computational imaging|structure from motion|scene interpretation|scene understanding|multi-view geometry|computer vision|scene analysis|multimedia retrieval|data science|systems engineering|deep learning|image representation|machine learning research|machine vision|digital image processing,
https://openalex.org/W2047968138,Visualization and analysis of atomistic simulation data with OVITO–the Open Visualization Tool,"Visualization and analysis of atomistic simulation data with OVITO–the Open Visualization Tool

The Open Visualization Tool (OVITO) is a new 3D visualization software designed for post-processing atomistic data obtained from molecular dynamics or Monte Carlo simulations. Unique analysis, editing and animations functions are integrated into its easy-to-use graphical user interface. written in object-oriented C++, controllable via Python scripts easily extendable through plug-in It distributed as open-source can be downloaded the website http://ovito.sourceforge.net/.

computer science, information visualization, interactive visualization, computational visualization, visualization, data and information visualization, data science, systems engineering, open science, atomistic simulation data, scientific visualization, computational model",2009,11081,computer science|information visualization|interactive visualization|computational visualization|visualization|data and information visualization|data science|systems engineering|open science|atomistic simulation data|scientific visualization|computational model,
https://openalex.org/W2160337655,A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking,"A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking

Increasingly, for many application areas, it is becoming important to include elements of nonlinearity and non-Gaussianity in order model accurately the underlying dynamics a physical system. Moreover, typically crucial process data on-line as arrives, both from point view storage costs well rapid adaptation changing signal characteristics. In this paper, we review optimal suboptimal Bayesian algorithms nonlinear/non-Gaussian tracking problems, with focus on particle filters. Particle filters are sequential Monte Carlo methods based mass (or ""particle"") representations probability densities, which can be applied any state-space generalize traditional Kalman filtering methods. Several variants filter such SIR, ASIR, RPF introduced within generic framework importance sampling (SIS) algorithm. These discussed compared standard EKF through an illustrative example.

image analysis, shift detection, computer science, nonlinear system identification, nonlinear system, object tracking, parameter identification, particle filters, computer vision, machine learning, applied mathematics, bayesian analysis, moving object tracking, statistics, nonlinear dynamic, machine vision, nonlinear science",2002,10947,image analysis|shift detection|computer science|nonlinear system identification|nonlinear system|object tracking|parameter identification|particle filters|computer vision|machine learning|applied mathematics|bayesian analysis|moving object tracking|statistics|nonlinear dynamic|machine vision|nonlinear science,
https://openalex.org/W2990138404,Advances in Neural Information Processing Systems 19,"Advances in Neural Information Processing Systems 19

Papers from the 2006 flagship meeting on neural computation, with contributions physicists, neuroscientists, mathematicians, statisticians, and computer scientists. The annual Neural Information Processing Systems (NIPS) conference is computation machine learning. It draws a diverse group of attendees—physicists, scientists—interested in theoretical applied aspects modeling, simulating, building neural-like or intelligent systems. presentations are interdisciplinary, algorithms, learning theory, cognitive science, neuroscience, brain imaging, vision, speech signal processing, reinforcement learning, applications. Only twenty-five percent papers submitted accepted for presentation at NIPS, so quality exceptionally high. This volume contains presented December meeting, held Vancouver. Bradford Books imprint

computer science, artificial intelligence, machine learning, neural science, recurrent neural network, data science, neural computation, deep learning, computational intelligence, machine learning research, neural network (machine learning), neural information",2007,10917,computer science|artificial intelligence|machine learning|neural science|recurrent neural network|data science|neural computation|deep learning|computational intelligence|machine learning research|neural network (machine learning)|neural information,
https://openalex.org/W2067191022,Mean shift: a robust approach toward feature space analysis,"Mean shift: a robust approach toward feature space analysis

A general non-parametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module an old pattern recognition procedure: mean shift. For discrete data, we prove convergence recursive shift procedure nearest stationary point underlying density function and, thus, its utility detecting modes density. relation Nadaraya-Watson estimator from kernel regression robust M-estimators; location also established. Algorithms two low-level vision tasks discontinuity-preserving smoothing image segmentation - are described as applications. In these algorithms, only user-set parameter resolution analysis, either gray-level or color images accepted input. Extensive experimental results illustrate their excellent performance.

pattern recognition, computer science, machine learning, feature space analysis, mean shift, image analysis, information fusion, structure from motion, feature detection, data science, feature (computer vision), computational imaging, robust feature, deep learning, computational statistic, machine learning research, shift detection, machine vision, computer vision, applied mathematics",2002,10781,pattern recognition|computer science|machine learning|feature space analysis|mean shift|image analysis|information fusion|structure from motion|feature detection|data science|feature (computer vision)|computational imaging|robust feature|deep learning|computational statistic|machine learning research|shift detection|machine vision|computer vision|applied mathematics,https://openalex.org/W2118246710
https://openalex.org/W2102258543,Ad hoc On-Demand Distance Vector (AODV) Routing,"Ad hoc On-Demand Distance Vector (AODV) Routing

The Ad hoc On-Demand Distance Vector (AODV) routing protocol is intended for use by mobile nodes in an ad network. It offers quick adaptation to dynamic link conditions, low processing and memory overhead, network utilization, determines unicast routes destinations within the uses destination sequence numbers ensure loop freedom at all times (even face of anomalous delivery control messages), avoiding problems (such as counting infinity) associated with classical distance vector protocols.

network routing algorithm, computer science, mobile computing, wireless network, wireless communication, routing protocol, control optimization, route planning, ad hoc network, route choice",2003,10779,network routing algorithm|computer science|mobile computing|wireless network|wireless communication|routing protocol|control optimization|route planning|ad hoc network|route choice,
https://openalex.org/W1484413656,Fast algorithms for mining association rules,"Fast algorithms for mining association rules

We consider the problem of discovering association rules between items in a large database sales transactions. present two new algorithms for solving thii that are fundamentally different from known algorithms. Empirical evaluation shows these outperform by factors ranging three small problems to more than an order magnitude problems. also show how best features proposed can be combined into hybrid algorithm, called AprioriHybrid. Scale-up experiments AprioriHybrid scales linearly with number has excellent scale-up properties respect transaction size and database.

computer science, pattern discovery, association rule, machine learning, knowledge discovery, frequent pattern mining, rule induction, data mining, pattern mining",1998,10779,computer science|pattern discovery|association rule|machine learning|knowledge discovery|frequent pattern mining|rule induction|data mining|pattern mining,
https://openalex.org/W2150066425,Are we ready for autonomous driving? The KITTI vision benchmark suite,"Are we ready for autonomous driving? The KITTI vision benchmark suite

Today, visual recognition systems are still rarely employed in robotics applications. Perhaps one of the main reasons for this is lack demanding benchmarks that mimic such scenarios. In paper, we take advantage our autonomous driving platform to develop novel challenging tasks stereo, optical flow, odometry/SLAM and 3D object detection. Our recording equipped with four high resolution video cameras, a Velodyne laser scanner state-of-the-art localization system. comprise 389 stereo flow image pairs, odometry sequences 39.2 km length, more than 200k annotations captured cluttered scenarios (up 15 cars 30 pedestrians visible per image). Results from algorithms reveal methods ranking on established datasets as Middlebury perform below average when being moved outside laboratory real world. goal reduce bias by providing difficulties computer vision community. available online at: www.cvlibs.net/datasets/kitti.

image analysis, autonomous driving, computer science, vision recognition, vehicular technology, autonomous navigation, computer vision, machine learning, robot learning, cognitive science, advanced driver-assistance system, automatic control, deep learning, intelligent vehicle, robotics, machine vision, vision robotics, computer engineering",2012,10754,image analysis|autonomous driving|computer science|vision recognition|vehicular technology|autonomous navigation|computer vision|machine learning|robot learning|cognitive science|advanced driver-assistance system|automatic control|deep learning|intelligent vehicle|robotics|machine vision|vision robotics|computer engineering,https://openalex.org/W2963881378
https://openalex.org/W2100556411,A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems,"A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems

We consider the class of iterative shrinkage-thresholding algorithms (ISTA) for solving linear inverse problems arising in signal/image processing. This methods, which can be viewed as an extension classical gradient algorithm, is attractive due to its simplicity and thus adequate large-scale even with dense matrix data. However, such methods are also known converge quite slowly. In this paper we present a new fast algorithm (FISTA) preserves computational ISTA but global rate convergence proven significantly better, both theoretically practically. Initial promising numerical results wavelet-based image deblurring demonstrate capabilities FISTA shown faster than by several orders magnitude.

mathematics, computer science, mathematical optimization, applied mathematics, inverse problems, numerical analysis, computational optimization, linear inverse problems, sublinear algorithm",2009,10653,mathematics|computer science|mathematical optimization|applied mathematics|inverse problems|numerical analysis|computational optimization|linear inverse problems|sublinear algorithm,https://openalex.org/W2145962650
https://openalex.org/W2034707435,Estimation and Hypothesis Testing of Cointegration Vectors in Gaussian Vector Autoregressive Models,"Estimation and Hypothesis Testing of Cointegration Vectors in Gaussian Vector Autoregressive Models

This paper contains the likelihood analysis of vector autoregressive models allowing for cointegration. The author derives ratio test cointegrating rank and finds it asymptotic distribution. He shows that maximum estimator relations can be found by reduced regression structural hypotheses about these relations. distribution is mixed Gaussian, inference on relation to conducted using Chi( squared) Copyright 1991 Econometric Society.

computer science, high-dimensional statistics, econometrics, statistical methodology, econometric method, applied statistics, hypothesis testing, cointegration vectors, source apportionment, data science, computational statistic, statistics, time series, machine learning research, statistical model",1991,10627,computer science|high-dimensional statistics|econometrics|statistical methodology|econometric method|applied statistics|hypothesis testing|cointegration vectors|source apportionment|data science|computational statistic|statistics|time series|machine learning research|statistical model,
https://openalex.org/W2128272608,A model of saliency-based visual attention for rapid scene analysis,"A model of saliency-based visual attention for rapid scene analysis

A visual attention system, inspired by the behavior and neuronal architecture of early primate is presented. Multiscale image features are combined into a single topographical saliency map. dynamical neural network then selects attended locations in order decreasing saliency. The system breaks down complex problem scene understanding rapidly selecting, computationally efficient manner, conspicuous to be analyzed detail.

computer science, vision recognition, information fusion, scene analysis, scene interpretation, cognitive science, vision language model, data science, deep learning, pattern recognition, machine learning, computer vision, computational imaging, scene understanding, rapid scene analysis, saliency-based visual attention, machine vision, image analysis, image representation",1998,10626,computer science|vision recognition|information fusion|scene analysis|scene interpretation|cognitive science|vision language model|data science|deep learning|pattern recognition|machine learning|computer vision|computational imaging|scene understanding|rapid scene analysis|saliency-based visual attention|machine vision|image analysis|image representation,https://openalex.org/W2752782242|https://openalex.org/W2164598857|https://openalex.org/W2963420686|https://openalex.org/W2130660124
https://openalex.org/W2097571405,An Introduction to Genetic Algorithms,"An Introduction to Genetic Algorithms

Genetic algorithms have been used in science and engineering as adaptive for solving practical problems computational models of natural evolutionary systems. This brief, accessible introduction describes some the most interesting research field also enables readers to implement experiment with genetic on their own. It focuses depth a small set important topics—particularly machine learning, scientific modeling, artificial life—and reviews broad span research, including work Mitchell her colleagues. The descriptions applications modeling projects stretch beyond strict boundaries computer include dynamical systems theory, game molecular biology, ecology, population genetics, underscoring exciting ""general purpose"" nature search methods that can be employed across disciplines. An Introduction Algorithms is students researchers any discipline. includes many thought exercises build reinforce reader's understanding text. first chapter introduces terminology two provocative detail. second third chapters look at use learning (computer programs, data analysis prediction, neural networks) (interactions among evolution, culture; sexual selection; ecosystems; activity). Several approaches theory are discussed fourth chapter. fifth takes up implementation, last poses currently unanswered questions surveys prospects future computation. Bradford Books imprint

evolutionary multimodal optimization, computer science, genetic algorithm, genetic programming, mathematical optimization, evolutionary computation, genetic improvement programming, intelligent optimization, genetic engineering, computational optimization, genetics",1998,10559,evolutionary multimodal optimization|computer science|genetic algorithm|genetic programming|mathematical optimization|evolutionary computation|genetic improvement programming|intelligent optimization|genetic engineering|computational optimization|genetics,
https://openalex.org/W2087347434,A training algorithm for optimal margin classifiers,"A training algorithm for optimal margin classifiers

A training algorithm that maximizes the margin between patterns and decision boundary is presented. The technique applicable to a wide variety of classification functions, including Perceptrons, polynomials, Radial Basis Functions. effective number parameters adjusted automatically match complexity problem. solution expressed as linear combination supporting patterns. These are subset closest boundary. Bounds on generalization performance based leave-one-out method VC-dimension given. Experimental results optical character recognition problems demonstrate good obtained when compared with other learning algorithms.

computer science, optimal margin classifiers, machine learning, automatic classification, training algorithm",1992,10516,computer science|optimal margin classifiers|machine learning|automatic classification|training algorithm,https://openalex.org/W2112796928|https://openalex.org/W2118585731
https://openalex.org/W2017108196,The VideoToolbox software for visual psychophysics: transforming numbers into movies,"The VideoToolbox software for visual psychophysics: transforming numbers into movies

The VideoToolbox is a free collection of two hundred C subroutines for Macintosh computers that calibrates and controls the computer-display interface to create accurately specified visual stimuli. High-level platform-independent languages like MATLAB are best creating numbers describe desired images. Low-level, computer-specific routines control hardware transforms those into movie. Transcending particular computer language, we discuss nature interface, how calibrate it.

image analysis, computer science, visual reasoning, visual psychophysics, affective computing, scene understanding, video hallucination, cognitive science, film, visual system, video interpretation, visual perception, visual science, visual processing, videotoolbox software",1997,10505,image analysis|computer science|visual reasoning|visual psychophysics|affective computing|scene understanding|video hallucination|cognitive science|film|visual system|video interpretation|visual perception|visual science|visual processing|videotoolbox software,
https://openalex.org/W2099574482,Ad-hoc on-demand distance vector routing,"Ad-hoc on-demand distance vector routing

An ad-hoc network is the cooperative engagement of a collection mobile nodes without required intervention any centralized access point or existing infrastructure. We present Ad-hoc On Demand Distance Vector Routing (AODV), novel algorithm for operation such networks. Each host operates as specialized router, and routes are obtained needed (i.e., on-demand) with little no reliance on periodic advertisements. Our new routing quite suitable dynamic self starting network, by users wishing to utilize AODV provides loop-free even while repairing broken links. Because protocol does not require global advertisements, demand overall bandwidth available substantially less than in those protocols that do necessitate Nevertheless we can still maintain most advantages basic distance vector mechanisms. show our scales large populations form also include an evaluation methodology simulation results verify algorithm.

network routing algorithm, computer science, wireless network, routing protocol, route planning, network routing, ad hoc network",1999,10466,network routing algorithm|computer science|wireless network|routing protocol|route planning|network routing|ad hoc network,
https://openalex.org/W1990170643,<i>WinGX</i>and<i>ORTEP for Windows</i>: an update,"<i>WinGX</i>and<i>ORTEP for Windows</i>: an update

The WinGX suite provides a complete set of programs for the treatment small-molecule single-crystal diffraction data, from data reduction and processing, structure solution, model refinement visualization, metric analysis molecular geometry crystal packing, to final report preparation in form CIF. It includes several well known pieces software repository when original authors no longer wish to, or are unable maintain them. also menu items execute external software, such as SIR SHELX suites programs. program ORTEP Windows graphical user interface (GUI) classic program, which is illustration anisotropic displacement ellipsoids. GUI code input capabilities wide variety file formats, extra functionality calculations ray-traced outputs. have been distributed over internet about 15 years, this article describes some more modern features

computer science, browser user interface, technology, graphic interface",2012,10409,computer science|browser user interface|technology|graphic interface,
https://openalex.org/W2071637551,APACHE II-A Severity of Disease Classification System,"APACHE II-A Severity of Disease Classification System

Knaus, William A. MD; Draper, Elizabeth RN, MS; Wagner, Douglas P. PhD; Zimmerman, Jack E. MD Author Information

disease classification, disease assessment, medical image computing, bioinformatics, biostatistics, biomedical informatics, diagnostic system, disease detection, health informatics, computer science, diagnosis, machine learning, classification method, data science, apache ii-a severity, disease classification system, image analysis",1986,10402,disease classification|disease assessment|medical image computing|bioinformatics|biostatistics|biomedical informatics|diagnostic system|disease detection|health informatics|computer science|diagnosis|machine learning|classification method|data science|apache ii-a severity|disease classification system|image analysis,
https://openalex.org/W2128765501,Low-density parity-check codes,"Low-density parity-check codes

A low-density parity-check code is a specified by matrix with the following properties: each column contains small fixed number <tex xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">j \geq 3</tex> of l's and row xmlns:xlink=""http://www.w3.org/1999/xlink"">k &gt; j</tex> l's. The typical minimum distance these codes increases linearly block length for rate xmlns:xlink=""http://www.w3.org/1999/xlink"">j</tex> . When used maximum likelihood decoding on sufficiently quiet binary-input symmetric channel, probability error decreases exponentially simple but nonoptimum scheme operating directly from channel posteriori probabilities described. Both equipment complexity data-handling capacity in bits per second this decoder increase approximately length. For low rate, using binary shown to decrease at least root Some experimental results show that actual much smaller than theoretical bound.

computer science, algebraic coding theory, electrical engineering, error correction code, low-density parity-check codes",1962,10395,computer science|algebraic coding theory|electrical engineering|error correction code|low-density parity-check codes,https://openalex.org/W2137813581
https://openalex.org/W2166244948,"First-principles simulation: ideas, illustrations and the CASTEP code","First-principles simulation: ideas, illustrations and the CASTEP code

First-principles simulation, meaning density-functional theory calculations with plane waves and pseudopotentials, has become a prized technique in condensed-matter theory. Here I look at the basics of suject, give brief review theory, examining strengths weaknesses its implementation, illustrating some ways simulators approach problems through small case study. also discuss why how modern software design methods have been used writing completely new modular version CASTEP code.

computer science, first-principles simulation, modeling and simulation, simulation methodology, castep code",2002,10374,computer science|first-principles simulation|modeling and simulation|simulation methodology|castep code,
https://openalex.org/W4297775537,MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications,"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications

We present a class of efficient models called MobileNets for mobile and embedded vision applications. are based on streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. introduce two simple global hyper-parameters efficiently trade off between latency accuracy. These allow the model builder choose right sized their application constraints problem. extensive experiments resource accuracy tradeoffs show strong performance compared other popular ImageNet classification. then demonstrate effectiveness across wide range applications use cases including object detection, finegrain classification, face attributes large scale geo-localization.

computer vision, mobile sensing, machine vision, neural network (machine learning), motion detection, cognitive science, computational intelligence, computer science, convolutional neural network, machine learning, feature detection, machine learning research, object detection, deep learning, data science, mobile vision applications, image analysis",2017,10304,computer vision|mobile sensing|machine vision|neural network (machine learning)|motion detection|cognitive science|computational intelligence|computer science|convolutional neural network|machine learning|feature detection|machine learning research|object detection|deep learning|data science|mobile vision applications|image analysis,https://openalex.org/W2752782242|https://openalex.org/W2963163009|https://openalex.org/W2531409750|https://openalex.org/W2963420686|https://openalex.org/W2963125010
https://openalex.org/W1996109622,"Petri nets: Properties, analysis and applications","Petri nets: Properties, analysis and applications

Starts with a brief review of the history and application areas considered in literature. The author then proceeds introductory modeling examples, behavioral structural properties, three methods analysis, subclasses Petri nets their analysis. In particular, one section is devoted to marked graphs, concurrent system model most amenable Introductory discussions on stochastic performance modeling, high-level logic programming, are provided. Also included recent results reachability criteria. Suggestions provided for further reading many subject nets.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>

complex system, computer science, systems biology, stochastic petri net, applied mathematics, petri net, modeling and simulation, network analysis, deep learning, neural network (machine learning)",1989,10283,complex system|computer science|systems biology|stochastic petri net|applied mathematics|petri net|modeling and simulation|network analysis|deep learning|neural network (machine learning),
https://openalex.org/W2104846640,An application-specific protocol architecture for wireless microsensor networks,"An application-specific protocol architecture for wireless microsensor networks

Networking together hundreds or thousands of cheap microsensor nodes allows users to accurately monitor a remote environment by intelligently combining the data from individual nodes. These networks require robust wireless communication protocols that are energy efficient and provide low latency. We develop analyze low-energy adaptive clustering hierarchy (LEACH), protocol architecture for combines ideas energy-efficient cluster-based routing media access with application-specific aggregation achieve good performance in terms system lifetime, latency, application-perceived quality. LEACH includes new, distributed cluster formation technique enables self-organization large numbers nodes, algorithms adapting clusters rotating head positions evenly distribute load among all techniques enable signal processing save resources. Our results show can improve lifetime an order magnitude compared general-purpose multihop approaches.

computer science, mobile computing, application-specific protocol architecture, wireless communication, wireless sensor system, wireless microsensor networks, systems engineering, wireless sensor network, protocol analysis, computer engineering",2002,10263,computer science|mobile computing|application-specific protocol architecture|wireless communication|wireless sensor system|wireless microsensor networks|systems engineering|wireless sensor network|protocol analysis|computer engineering,
https://openalex.org/W2150297520,Tree View: An application to display phylogenetic trees on personal computers,"Tree View: An application to display phylogenetic trees on personal computers

TreeView is a simple, easy to use phylogenetic tree viewing utility that runs under both MacOS (on Apple Macintosh computers) and Microsoft Windows on Intel based computers, the two most common personal computers used by biologists. Some phylogeny programs, such as PAUP (Swofford, 1993) MacClade (Maddison Maddison, 1992) already provide excellent drawing printing facilities, however at present these programs are restricted computers. Furthermore, they require user load data set before any trees can be displayed which inconvenient if simply wants view trees. More portable DRAWGRAM DRAWTREE in PHYLIP package (Felsenstein, run but make little, of graphical interface features available those operating systems. native application either or enables standard fonts installed their machine, printer, supports relevant graphics format (PICT metafile) for creating files pasting pictures other applications via clipboard. The program also file operations, 'drag drop' whereby dragging file's icon onto opens file. read range formats (see below) display styles (Fig. 1). Additional information, edge lengths internal node labels displayed. order terminal taxa altered, rerooted. If contains more than one each turn. save variety formats, so it move between different formats.

computer science, phylogeny comparison, scene interpretation, evolutionary biology, biology, phylogenetics, systematics, tree view, phylogenetic trees, object orientation, personal computers, bioinformatics",1996,10263,computer science|phylogeny comparison|scene interpretation|evolutionary biology|biology|phylogenetics|systematics|tree view|phylogenetic trees|object orientation|personal computers|bioinformatics,
https://openalex.org/W4247053599,Fast and accurate long-read alignment with Burrows–Wheeler transform,"Fast and accurate long-read alignment with Burrows–Wheeler transform

Abstract Motivation: Many programs for aligning short sequencing reads to a reference genome have been developed in the last 2 years. Most of them are very efficient but inefficient or not applicable &amp;gt;200 bp because algorithms heavily and specifically tuned queries with low error rate. However, some platforms already produce longer others expected become available soon. For reads, hashing-based software such as BLAT SSAHA2 remain only choices. Nonetheless, these methods substantially slower than short-read aligners terms aligned bases per unit time. Results: We designed implemented new algorithm, Burrows-Wheeler Aligner's Smith-Waterman Alignment (BWA-SW), align long sequences up 1 Mb against large sequence database (e.g. human genome) few gigabytes memory. The algorithm is accurate SSAHA2, more BLAT, several tens times faster both. Availability: http://bio-bwa.sourceforge.net Contact: rd@sanger.ac.uk

burrows-wheeler transform, computer science, long-read alignment, long-read sequencing",2010,10212,burrows-wheeler transform|computer science|long-read alignment|long-read sequencing,
https://openalex.org/W1959608418,Auto-Encoding Variational Bayes,"Auto-Encoding Variational Bayes

Abstract: How can we perform efficient inference and learning in directed probabilistic models, the presence of continuous latent variables with intractable posterior distributions, large datasets? We introduce a stochastic variational algorithm that scales to datasets and, under some mild differentiability conditions, even works case. Our contributions is two-fold. First, show reparameterization lower bound yields estimator be straightforwardly optimized using standard gradient methods. Second, for i.i.d. per datapoint, made especially by fitting an approximate model (also called recognition model) proposed estimator. Theoretical advantages are reflected experimental results.

bayesian analysis, computer science, auto-encoding variational bayes, variational analysis",2014,10146,bayesian analysis|computer science|auto-encoding variational bayes|variational analysis,https://openalex.org/W2099471712|https://openalex.org/W2962793481
https://openalex.org/W3103145119,SciPy 1.0: fundamental algorithms for scientific computing in Python,"SciPy 1.0: fundamental algorithms for scientific computing in Python

SciPy is an open-source scientific computing library for the Python programming language. Since its initial release in 2001, has become a de facto standard leveraging algorithms Python, with over 600 unique code contributors, thousands of dependent packages, 100,000 repositories and millions downloads per year. In this work, we provide overview capabilities development practices 1.0 highlight some recent technical developments.

computer science, algorithmic development, fundamental algorithms, scientific computing, computational optimization, computational science",2020,10060,computer science|algorithmic development|fundamental algorithms|scientific computing|computational optimization|computational science,
https://openalex.org/W2229412420,Marching cubes: A high resolution 3D surface construction algorithm,"Marching cubes: A high resolution 3D surface construction algorithm

We present a new algorithm, called marching cubes, that creates triangle models of constant density surfaces from 3D medical data. Using divide-and-conquer approach to generate inter-slice connectivity, we create case table defines topology. The algorithm processes the data in scan-line order and calculates vertices using linear interpolation. find gradient original data, normalize it, use it as basis for shading models. detail images produced generated surface is result maintaining information Results computed tomography (CT), magnetic resonance (MR), single-photon emission (SPECT) illustrate quality functionality cubes. also discuss improvements decrease processing time add solid modeling capabilities.

computational geometry, geometry processing, 3d printing, surface construction algorithm, numerical simulation, 3d modeling, computer science, computer-aided design, geometric modeling, 3d reconstruction, surface modeling, deformation, finite element method",1987,9945,computational geometry|geometry processing|3d printing|surface construction algorithm|numerical simulation|3d modeling|computer science|computer-aided design|geometric modeling|3d reconstruction|surface modeling|deformation|finite element method,https://openalex.org/W2124026197
https://openalex.org/W2116040950,Active contours without edges,"Active contours without edges

We propose a new model for active contours to detect objects in given image, based on techniques of curve evolution, Mumford-Shah (1989) functional segmentation and level sets. Our can whose boundaries are not necessarily defined by the gradient. minimize an energy which be seen as particular case minimal partition problem. In set formulation, problem becomes ""mean-curvature flow""-like evolving contour, will stop desired boundary. However, stopping term does depend gradient classical contour models, but is instead related image. give numerical algorithm using finite differences. Finally, we present various experimental results some examples snakes methods applicable. Also, initial anywhere interior automatically detected.

image analysis, computational imaging, computer science, edge detection, computer vision, geometry processing, image segmentation, active contours, digital image processing, inpainting, computational geometry",2001,9906,image analysis|computational imaging|computer science|edge detection|computer vision|geometry processing|image segmentation|active contours|digital image processing|inpainting|computational geometry,
https://openalex.org/W2147800946,Backpropagation Applied to Handwritten Zip Code Recognition,"Backpropagation Applied to Handwritten Zip Code Recognition

The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such integrated into a backpropagation network through architecture network. approach has been successfully applied recognition handwritten zip code digits provided U.S. Postal Service. A single learns entire operation, going normalized image character final classification.

pattern recognition, computer science, natural language processing, character recognition, text recognition, machine learning, deep learning, automatic classification, zip code recognition",1989,9899,pattern recognition|computer science|natural language processing|character recognition|text recognition|machine learning|deep learning|automatic classification|zip code recognition,https://openalex.org/W2194775991|https://openalex.org/W2112796928|https://openalex.org/W1686810756|https://openalex.org/W2097117768|https://openalex.org/W2963446712|https://openalex.org/W2095705004|https://openalex.org/W1903029394|https://openalex.org/W639708223|https://openalex.org/W2102605133|https://openalex.org/W1536680647|https://openalex.org/W2963150697|https://openalex.org/W2953106684|https://openalex.org/W2963351448|https://openalex.org/W2565639579|https://openalex.org/W1677182931|https://openalex.org/W2613718673|https://openalex.org/W3094502228|https://openalex.org/W2549139847|https://openalex.org/W2963091558|https://openalex.org/W2109255472|https://openalex.org/W2395611524|https://openalex.org/W1885185971|https://openalex.org/W3035524453|https://openalex.org/W3099206234|https://openalex.org/W2117812871|https://openalex.org/W2279098554
https://openalex.org/W2054141820,Matrix Factorization Techniques for Recommender Systems,"Matrix Factorization Techniques for Recommender Systems

As the Netflix Prize competition has demonstrated, matrix factorization models are superior to classic nearest neighbor techniques for producing product recommendations, allowing incorporation of additional information such as implicit feedback, temporal effects, and confidence levels.

computer science, ranking algorithm, machine learning, recommender system, cold-start problem, data science, deep learning, matrix factorization, machine learning research, principal component analysis, information retrieval, matrix factorization techniques, data mining",2009,9886,computer science|ranking algorithm|machine learning|recommender system|cold-start problem|data science|deep learning|matrix factorization|machine learning research|principal component analysis|information retrieval|matrix factorization techniques|data mining,
https://openalex.org/W2963420686,Squeeze-and-Excitation Networks,"Squeeze-and-Excitation Networks

The central building block of convolutional neural networks (CNNs) is the convolution operator, which enables to construct informative features by fusing both spatial and channel-wise information within local receptive fields at each layer. A broad range prior research has investigated component this relationship, seeking strengthen representational power a CNN enhancing quality encodings throughout its feature hierarchy. In work, we focus instead on channel relationship propose novel architectural unit, term ""Squeeze-and-Excitation"" (SE) block, that adaptively recalibrates responses explicitly modelling interdependencies between channels. We show these blocks can be stacked together form SENet architectures generalise extremely effectively across different datasets. further demonstrate SE bring significant improvements in performance for existing state-of-the-art CNNs slight additional computational cost. Squeeze-and-Excitation Networks formed foundation our ILSVRC 2017 classification submission won first place reduced top-5 error 2.251 percent, surpassing winning entry 2016 relative improvement -25 percent. Models code are available https://github.com/hujie-frank/SENet.

computer science, information fusion, convolutional neural network, squeeze-and-excitation networks, electrical engineering, quantum machine learning, neuroimaging, neuroscience, recurrent neural network, sparse neural network, systems neuroscience, neural computation, computational neuroscience, computational intelligence, machine learning research, neural network (machine learning), shift detection",2020,9879,computer science|information fusion|convolutional neural network|squeeze-and-excitation networks|electrical engineering|quantum machine learning|neuroimaging|neuroscience|recurrent neural network|sparse neural network|systems neuroscience|neural computation|computational neuroscience|computational intelligence|machine learning research|neural network (machine learning)|shift detection,https://openalex.org/W3018757597|https://openalex.org/W2963125010
https://openalex.org/W2963470893,Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network,"Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network

Despite the breakthroughs in accuracy and speed of single image super-resolution using faster deeper convolutional neural networks, one central problem remains largely unsolved: how do we recover finer texture details when super-resolve at large upscaling factors? The behavior optimization-based methods is principally driven by choice objective function. Recent work has focused on minimizing mean squared reconstruction error. resulting estimates have high peak signal-to-noise ratios, but they are often lacking high-frequency perceptually unsatisfying sense that fail to match fidelity expected higher resolution. In this paper, present SRGAN, a generative adversarial network (GAN) for (SR). To our knowledge, it first framework capable inferring photo-realistic natural images 4x factors. achieve this, propose perceptual loss function which consists an content loss. pushes solution manifold discriminator trained differentiate between super-resolved original images. addition, use motivated similarity instead pixel space. Our deep residual able textures from heavily downsampled public benchmarks. An extensive mean-opinion-score (MOS) test shows hugely significant gains quality SRGAN. MOS scores obtained with SRGAN closer those high-resolution than any state-of-the-art method.

image analysis, computational imaging, computer science, super-resolution imaging, computer vision, machine learning, generative adversarial network, generative ai, single-image super-resolution, deep learning, image representation, synthetic image generation, machine vision, digital image processing",2017,9742,image analysis|computational imaging|computer science|super-resolution imaging|computer vision|machine learning|generative adversarial network|generative ai|single-image super-resolution|deep learning|image representation|synthetic image generation|machine vision|digital image processing,https://openalex.org/W2962793481|https://openalex.org/W2963073614|https://openalex.org/W2954996726|https://openalex.org/W2962785568
https://openalex.org/W2128016314,The Human Genome Browser at UCSC,"The Human Genome Browser at UCSC

As vertebrate genome sequences near completion and research refocuses to their analysis, the issue of effective annotation display becomes critical. A mature web tool for rapid reliable any requested portion at scale, together with several dozen aligned tracks, is provided http://genome.ucsc.edu . This browser displays assembly contigs gaps, mRNA expressed sequence tag alignments, multiple gene predictions, cross-species homologies, single nucleotide polymorphisms, sequence-tagged sites, radiation hybrid data, transposon repeats, more as a stack coregistered tracks. Text sequence-based searches provide quick precise access region specific interest. Secondary links from individual features lead details supplementary off-site databases. One-half tracks are computed University California, Santa Cruz publicly available data; collaborators worldwide rest. Users can stably add own custom educational or purposes. The conceptual technical framework browser, its underlying MYSQL database, overall use described. site currently serves over 50,000 pages per day 3000 different users.

genomics, knowledge discovery, reference genome, bioinformatics, biomedical informatics, human genome browser, high throughput sequencing, genome analysis, computer science, human genetics, genome editing, next-generation sequencing, genome sequencing, genome biology",2002,9715,genomics|knowledge discovery|reference genome|bioinformatics|biomedical informatics|human genome browser|high throughput sequencing|genome analysis|computer science|human genetics|genome editing|next-generation sequencing|genome sequencing|genome biology,https://openalex.org/W2108234281
https://openalex.org/W3094502228,An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale,"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale

While the Transformer architecture has become de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used replace certain components of networks while keeping their overall structure place. We show that this reliance on CNNs not necessary and a pure transformer directly sequences image patches can perform very well classification tasks. When pre-trained large amounts data transferred multiple mid-sized small recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision (ViT) attains excellent results compared state-of-the-art requiring substantially fewer computational resources train.

image analysis, pattern recognition, computer science, image classification, image search, natural language processing, image communication, image retrieval, text recognition, computer vision, machine learning, feature detection, data science, multimedia information processing, image representation, machine learning research, machine vision, image recognition",2020,9670,image analysis|pattern recognition|computer science|image classification|image search|natural language processing|image communication|image retrieval|text recognition|computer vision|machine learning|feature detection|data science|multimedia information processing|image representation|machine learning research|machine vision|image recognition,https://openalex.org/W3138516171
https://openalex.org/W1969761972,R: A Language for Data Analysis and Graphics,"R: A Language for Data Analysis and Graphics

Abstract In this article we discuss our experience designing and implementing a statistical computing language. developing new language, sought to combine what felt were useful features from two existing computer languages. We feel that the language provides advantages in areas of portability, computational efficiency, memory management, scoping.

data and information visualization, visual analytics, graphical analysis, data analysis, computer science, interactive visualization, data science, graphics, information visualization, visual data mining, data analytics",1996,9648,data and information visualization|visual analytics|graphical analysis|data analysis|computer science|interactive visualization|data science|graphics|information visualization|visual data mining|data analytics,https://openalex.org/W3099878876
https://openalex.org/W2158196600,Multimodel Inference,"Multimodel Inference

The model selection literature has been generally poor at reflecting the deep foundations of Akaike information criterion (AIC) and making appropriate comparisons to Bayesian (BIC). There is a clear philosophy, sound based in theory, rigorous statistical foundation for AIC. AIC can be justified as using “savvy” prior on models that function sample size number parameters. Furthermore, BIC derived non-Bayesian result. Therefore, arguments about versus cannot from Bayes frequentist perspective. philosophical context what assumed reality, approximating models, intent model-based inference should determine whether or used. Various facets such multimodel are presented here, particularly methods averaging.

computer science, inference, machine learning, multimodal signal processing, multimodel inference",2004,9609,computer science|inference|machine learning|multimodal signal processing|multimodel inference,
https://openalex.org/W1655990431,The Design and Analysis of Computer Algorithms,"The Design and Analysis of Computer Algorithms

From the Publisher:
With this text, you gain an understanding of fundamental concepts algorithms, very heart computer science. It introduces basic data structures and programming techniques often used in efficient algorithms. Covers use lists, push-down stacks, queues, trees, graphs. Later chapters go into sorting, searching graphing string-matching Schonhage-Strassen integer-multiplication algorithm. Provides numerous graded exercises at end each chapter.


0201000296B04062001

computational complexity, computer science, algorithm design, algorithm engineering, theoretical computer science, theory of computation, applied mathematics, analysis of algorithm, computer algorithms, algorithm implementation, computational optimization, computational science, computer engineering",1974,9596,computational complexity|computer science|algorithm design|algorithm engineering|theoretical computer science|theory of computation|applied mathematics|analysis of algorithm|computer algorithms|algorithm implementation|computational optimization|computational science|computer engineering,https://openalex.org/W2156186849|https://openalex.org/W2080267935|https://openalex.org/W2000359198
https://openalex.org/W2006617902,pROC: an open-source package for R and S+ to analyze and compare ROC curves,"pROC: an open-source package for R and S+ to analyze and compare ROC curves

Receiver operating characteristic (ROC) curves are useful tools to evaluate classifiers in biomedical and bioinformatics applications. However, conclusions often reached through inconsistent use or insufficient statistical analysis. To support researchers their ROC analysis we developed pROC, a package for R S+ that contains set of displaying, analyzing, smoothing comparing user-friendly, object-oriented flexible interface. With data previously imported into the environment, pROC builds includes functions computing confidence intervals, tests total partial area under curve points different classifiers, methods curves. Intermediary final results visualised user-friendly interfaces. A case study based on published clinical biomarker shows how perform typical with pROC. is specifically dedicated It proposes multiple compare curves, particular areas curve, allowing proper interpretation. available two versions: programming language graphical user interface software. accessible at http://expasy.org/tools/pROC/ GNU General Public License. also distributed CRAN CSAN public repositories, facilitating its installation.

computer science, model comparison, roc curves, principal component analysis, statistical software, open-source package",2011,9586,computer science|model comparison|roc curves|principal component analysis|statistical software|open-source package,
https://openalex.org/W2171960770,Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions,"Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions

This paper presents an overview of the field recommender systems and describes current generation recommendation methods that are usually classified into following three main categories: content-based, collaborative, hybrid approaches. also various limitations discusses possible extensions can improve capabilities make applicable to even broader range applications. These include, among others, improvement understanding users items, incorporation contextual information process, support for multicriteria ratings, a provision more flexible less intrusive types recommendations.

computer science, machine learning, ranking algorithm, recommender system, data science, collaborative filtering, possible extensions, online information, data mining, conversational recommender system, human-computer interaction, information retrieval, systems engineering, deep learning, natural language processing, information filtering system, knowledge discovery, learning to rank, next generation",2005,9581,computer science|machine learning|ranking algorithm|recommender system|data science|collaborative filtering|possible extensions|online information|data mining|conversational recommender system|human-computer interaction|information retrieval|systems engineering|deep learning|natural language processing|information filtering system|knowledge discovery|learning to rank|next generation,
https://openalex.org/W2168356304,Object Detection with Discriminatively Trained Part-Based Models,"Object Detection with Discriminatively Trained Part-Based Models

We describe an object detection system based on mixtures of multiscale deformable part models. Our is able to represent highly variable classes and achieves state-of-the-art results in the PASCAL challenges. While models have become quite popular, their value had not been demonstrated difficult benchmarks such as data sets. relies new methods for discriminative training with partially labeled data. combine a margin-sensitive approach data-mining hard negative examples formalism we call latent SVM. A SVM reformulation MI--SVM terms variables. semiconvex, problem becomes convex once information specified positive examples. This leads iterative algorithm that alternates between fixing values optimizing objective function.

image analysis, pattern recognition, computer science, object recognition, scene understanding, computer vision, machine learning, part-based models, object detection, object categorization, deep learning, machine vision",2010,9559,image analysis|pattern recognition|computer science|object recognition|scene understanding|computer vision|machine learning|part-based models|object detection|object categorization|deep learning|machine vision,https://openalex.org/W2963037989|https://openalex.org/W639708223|https://openalex.org/W2102605133|https://openalex.org/W1536680647|https://openalex.org/W2565639579|https://openalex.org/W2150066425|https://openalex.org/W2340897893|https://openalex.org/W2109255472
https://openalex.org/W2557283755,Deep Learning,"Deep Learning

Deep learning is a form of machine that enables computers to learn from experience and understand the world in terms hierarchy concepts. Because computer gathers knowledge experience, there no need for human operator formally specify all needs. The concepts allows complicated by building them out simpler ones; graph these hierarchies would be many layers deep. This book introduces broad range topics deep learning. text offers mathematical conceptual background, covering relevant linear algebra, probability theory information theory, numerical computation, It describes techniques used practitioners industry, including feedforward networks, regularization, optimization algorithms, convolutional sequence modeling, practical methodology; it surveys such applications as natural language processing, speech recognition, vision, online recommendation systems, bioinformatics, videogames. Finally, research perspectives, theoretical factor models, autoencoders, representation learning, structured probabilistic Monte Carlo methods, partition function, approximate inference, generative models. Learning can undergraduate or graduate students planning careers either industry research, software engineers who want begin using their products platforms. A website supplementary material both readers instructors.

supervised learning, neural computation, neural network (machine learning), computer science, machine learning, machine learning research, deep learning",2016,9537,supervised learning|neural computation|neural network (machine learning)|computer science|machine learning|machine learning research|deep learning,https://openalex.org/W2242218935
https://openalex.org/W2164418313,TCS: a computer program to estimate gene genealogies,"TCS: a computer program to estimate gene genealogies

Phylogenies are extremely useful tools, not only for establishing genealogical relationships among a group of organisms or their parts (e.g. genes), but also variety research once the phylogenies estimated. In recent review, Pagel (1999) eloquently outline number uses phylogenetic information from discovery drug resistance to reconstructing common ancestor all life. have been used predict future trends in infectious disease ( Bush et al. 1999 ) and even offered as evidence court law Vogel 1997). Yet they accurate. Estimating genes at population level presents difficulties traditional methods phylogeny reconstruction. These such parsimony, neighbour-joining, maximum-likelihood make assumptions that invalid level. For example, these assume ancestral haplotypes no longer population, yet coalescent theory predicts will be most frequent sequences sampled study Watterson & Guess 1977; Donnelly Tavaré 1986; Crandall Templeton 1993). Traditional require reasonably large numbers variable characters accurately reconstruct Huelsenbeck Hillis 1993) studies typically lack variation. Also, recombination is real possibility does occur. The failure incorporate reconstruction can lead grave errors resulting estimated phylogeny. combination effects parsimony infer cumbersome amount parsimonious trees with resolution set over one billion human mitochondrial DNA (mtDNA), Excoffier Smouse 1994). neighbour-joining confident Bandelt 1995 ). Therefore, an alternative approach needed provide accurate estimates gene genealogies take into account phenomena addressed by methods. Multiple groups looked network representations Dress 1992; 1992 ; 1994; Fitch Networks allow naturally often-times nonbifurcating associated divergences. method (1992) (TCS) has extensively restriction site nucleotide sequence data when divergences low Georgiadis 1994 Routman Gerber 1996; Hedin 1997; Schaal 1998 Viláet , Gómez-Zurita 2000). TCS estimate span wide range divergence Fitzpatrick Benabib 1997 nested analysis procedure partition structure history 1998) explore phylogeographic diversity Johnson Jordon 2000; Turner 2000 this note, we announce availability new software package, TCS, using . opens files either nexus Maddison phylip Felsenstein 1991) sequential format. Sequences should collapsed frequency incorporated output. program collapses calculates frequencies sample. haplotype outgroup probabilities, which correlate age Castelloe An absolute distance matrix then calculated pairwise comparisons haplotypes. probability [as defined equations 6, 7, 8] differences until exceeds 0.95. mutational just before 95% cut-off maximum connections between pairs justified 'parsimony' criterion. made plausible solutions. outputs sequences, matrix, probabilities steps beyond cut-off, test listing missing intermediates generated, graph output file containing Fig. 1). This opened freeware VGJ 1.0.3 http://www.eng.auburn.edu/department/cse/research/graphdrawing/graphdrawing.html; distributed under terms GNU General Public License, Version 2), packaged algorithm. handle reasonable sequences. HTLV 69 length 725 bp took hour run Macintosh G3. Memory requirements low, less than 1 MB RAM. including executables Mac PC, documentation, Java source code, freely available our website, along host other programs genetic analyses: http://bioag.byu.edu/zoology/crandalllab/programs.htm. interface. connecting parsimoniously two indicated. Gaps treated 5th state data. edited arranged different algorithms. By double-clicking haplotype, some displayed, included weights. highest displayed square, while ovals. size square oval corresponds frequency. work was supported Alfred P. Sloan Foundation, Shannon Award National Institutes Health, NIH R01-HD34350.

gene genealogies, computer science, computational genomics, sequence analysis, biostatistics, genomics, computer program, bioinformatics",2000,9487,gene genealogies|computer science|computational genomics|sequence analysis|biostatistics|genomics|computer program|bioinformatics,
https://openalex.org/W2053289371,Numerical Recipes in FORTRAN,"Numerical Recipes in FORTRAN

Note: Includes bibliographical references and index.- Diskette v 2.04, 3.5'' (720k) for IBM PC, PS/2 compatibles [DOS] Reference Record created on 2004-09-07, modified 2016-08-08

computer science, numerical computation, numerical algorithm, numerical analysis, numerical recipes, numerical simulation",1988,9470,computer science|numerical computation|numerical algorithm|numerical analysis|numerical recipes|numerical simulation,
https://openalex.org/W2119667497,An Introduction To Compressive Sampling,"An Introduction To Compressive Sampling

Conventional approaches to sampling signals or images follow Shannon's theorem: the rate must be at least twice maximum frequency present in signal (Nyquist rate). In field of data conversion, standard analog-to-digital converter (ADC) technology implements usual quantized Shannon representation - is uniformly sampled above Nyquist rate. This article surveys theory compressive sampling, also known as compressed sensing CS, a novel sensing/sampling paradigm that goes against common wisdom acquisition. CS asserts one can recover certain and from far fewer samples measurements than traditional methods use.

computer science, high-dimensional statistics, sampling, compressive sensing, statistical inference, machine learning, applied mathematics, data compression, sparse representation, statistics, machine learning research",2008,9325,computer science|high-dimensional statistics|sampling|compressive sensing|statistical inference|machine learning|applied mathematics|data compression|sparse representation|statistics|machine learning research,
https://openalex.org/W4297734170,Neural Machine Translation by Jointly Learning to Align and Translate,"Neural Machine Translation by Jointly Learning to Align and Translate

Neural machine translation is a recently proposed approach to translation. Unlike the traditional statistical translation, neural aims at building single network that can be jointly tuned maximize performance. The models for often belong family of encoder-decoders and consists an encoder encodes source sentence into fixed-length vector from which decoder generates In this paper, we conjecture use bottleneck in improving performance basic encoder-decoder architecture, propose extend by allowing model automatically (soft-)search parts are relevant predicting target word, without having form these as hard segment explicitly. With new approach, achieve comparable existing state-of-the-art phrase-based system on task English-to-French Furthermore, qualitative analysis reveals (soft-)alignments found agree well with our intuition.

transfer learning, neural computation, natural language processing, machine translation, computer-assisted translation, neural network (machine learning), computational intelligence, computer science, neural machine translation, machine learning, linguistics, language, deep learning, machine learning research",2014,9323,transfer learning|neural computation|natural language processing|machine translation|computer-assisted translation|neural network (machine learning)|computational intelligence|computer science|neural machine translation|machine learning|linguistics|language|deep learning|machine learning research,https://openalex.org/W1895577753
https://openalex.org/W2051051926,Quantum cryptography based on Bell’s theorem,"Quantum cryptography based on Bell’s theorem

Practical application of the generalized Bell's theorem in so-called key distribution process cryptography is reported. The proposed scheme based on Bohm's version Einstein-Podolsky-Rosen gedanken experiment and used to test for eavesdropping.

computer science, quantum algorithm, quantum security, quantum science, cryptography, quantum computing, quantum communication, applied mathematics, quantum mechanics, quantum cryptography, quantum key distribution, quantum information science, quantum entanglement",1991,9308,computer science|quantum algorithm|quantum security|quantum science|cryptography|quantum computing|quantum communication|applied mathematics|quantum mechanics|quantum cryptography|quantum key distribution|quantum information science|quantum entanglement,https://openalex.org/W3038067977
https://openalex.org/W1583837637,Proceedings of the 24th international conference on Machine learning,"Proceedings of the 24th international conference on Machine learning

This volume contains the papers accepted to 24th International Conference on Machine Learning (ICML 2007), which was held at Oregon State University in Corvalis, Oregon, from June 20th 24th, 2007. ICML is annual conference of Society (IMLS), and provides a venue for presentation discussion current research field machine learning. These proceedings can also be found online at: http://www.machinelearning.org. year there were 522 submissions ICML. There very thorough review process, each paper reviewed by three program committee (PC) members. Authors able respond initial reviews, PC members could then modify their reviews based discussions content this author response. For first time two periods led senior (SPC), one just before after submission responses. At end second period, SPC gave recommendations provided summary papers. Also time, authors asked submit list changes with final papers, checked SPCs ensure that reviewer comments had been addressed. Apart length restrictions compressed frame, process resembles many journal publications. In total, 150 year, including small number initially conditionally accepted, yielding an overall acceptance rate 29%. attracts learning researchers around globe. The geographically distributed as follows: 66 US, 32 Europe, 19 China or Hong Kong, 11 Canada, 6 India, 5 Australia Japan, 3 Israel, 1 Korea, Russia Taiwan. addition main includes both talk poster paper, included workshops 8 tutorials topics are currently broad interest. We extremely pleased have David Heckerman (Microsoft Research), Joshua Tenenbaum (Massachussetts Institute Technology), Bernhard Schölkopf (Max Planck Biological Cybernetics) invited speakers year. Thanks sponsorship Journal, we award outstanding student prizes. fortunate co-located Inductive Logic Programming (ILP 2007). ILP joint sessions day

adversarial machine learning, pattern recognition, computer science, computational learning theory, supervised learning, machine learning tool, unsupervised machine learning, machine learning, data science, computational intelligence, deep learning, knowledge discovery, machine learning research, neural network (machine learning), data mining",2007,9301,adversarial machine learning|pattern recognition|computer science|computational learning theory|supervised learning|machine learning tool|unsupervised machine learning|machine learning|data science|computational intelligence|deep learning|knowledge discovery|machine learning research|neural network (machine learning)|data mining,
https://openalex.org/W2129812935,Robust Face Recognition via Sparse Representation,"Robust Face Recognition via Sparse Representation

We consider the problem of automatically recognizing human faces from frontal views with varying expression and illumination, as well occlusion disguise. cast recognition one classifying among multiple linear regression models argue that new theory sparse signal representation offers key to addressing this problem. Based on a computed by l{1}-minimization, we propose general classification algorithm for (image-based) object recognition. This framework provides insights into two crucial issues in face recognition: feature extraction robustness occlusion. For extraction, show if sparsity is properly harnessed, choice features no longer critical. What critical, however, whether number sufficiently large correctly computed. Unconventional such downsampled images random projections perform just conventional Eigenfaces Laplacianfaces, long dimension space surpasses certain threshold, predicted representation. can handle errors due corruption uniformly exploiting fact these are often respect standard (pixel) basis. The helps predict how much choose training maximize conduct extensive experiments publicly available databases verify efficacy proposed corroborate above claims.

image analysis, pattern recognition, computer science, computational imaging, object recognition, feature learning, feature extraction, computer vision, machine learning, feature detection, data science, sparse representation, deep learning, image representation, machine vision, robust face recognition",2009,9264,image analysis|pattern recognition|computer science|computational imaging|object recognition|feature learning|feature extraction|computer vision|machine learning|feature detection|data science|sparse representation|deep learning|image representation|machine vision|robust face recognition,
https://openalex.org/W2146292423,The NumPy Array: A Structure for Efficient Numerical Computation,"The NumPy Array: A Structure for Efficient Numerical Computation

In the Python world, NumPy arrays are standard representation for numerical data. Here, we show how these enable efficient implementation of computations in a high-level language. Overall, three techniques applied to improve performance: vectorizing calculations, avoiding copying data memory, and minimizing operation counts. We first present array structure, then use it computation, finally share with other libraries.

computer science, efficient numerical computation, array computing, numerical computation, parameter identification, parallel computing, scientific computing, numerical mathematics, computational mathematics, systems engineering, numerical analysis, numerical simulation, computational optimization, computational engineering, numpy array, numerical method for partial differential equation, applied mathematics, numerical algorithm, computational science",2011,9244,computer science|efficient numerical computation|array computing|numerical computation|parameter identification|parallel computing|scientific computing|numerical mathematics|computational mathematics|systems engineering|numerical analysis|numerical simulation|computational optimization|computational engineering|numpy array|numerical method for partial differential equation|applied mathematics|numerical algorithm|computational science,https://openalex.org/W2101234009|https://openalex.org/W3099878876|https://openalex.org/W3103145119
https://openalex.org/W1924770834,Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling,"Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling

In this paper we compare different types of recurrent units in neural networks (RNNs). Especially, focus on more sophisticated that implement a gating mechanism, such as long short-term memory (LSTM) unit and recently proposed gated (GRU). We evaluate these the tasks polyphonic music modeling speech signal modeling. Our experiments revealed advanced are indeed better than traditional tanh units. Also, found GRU to be comparable LSTM.

computer science, sequence modeling, neuroimaging, neuroscience, machine learning, recurrent neural network, sequential learning, sparse neural network, data science, neural computation, deep learning, computational intelligence, machine learning research, sequence modelling, neural network (machine learning), empirical evaluation",2014,9208,computer science|sequence modeling|neuroimaging|neuroscience|machine learning|recurrent neural network|sequential learning|sparse neural network|data science|neural computation|deep learning|computational intelligence|machine learning research|sequence modelling|neural network (machine learning)|empirical evaluation,
https://openalex.org/W1484040084,Graph Theory with Applications,"Graph Theory with Applications

(1977). Graph Theory with Applications. Journal of the Operational Research Society: Vol. 28, Volume issue 1, pp. 237-238.

geometric graph theory, computer science, graph theory, structural graph theory, applied mathematics, extremal graph theory, probabilistic graph theory, network analysis, network science, applied physics, algebraic graph theory",1976,9193,geometric graph theory|computer science|graph theory|structural graph theory|applied mathematics|extremal graph theory|probabilistic graph theory|network analysis|network science|applied physics|algebraic graph theory,
https://openalex.org/W1555915743,Computer Architecture: A Quantitative Approach,"Computer Architecture: A Quantitative Approach

This best-selling title, considered for over a decade to be essential reading every serious student and practitioner of computer design, has been updated throughout address the most important trends facing designers today. In this edition, authors bring their trademark method quantitative analysis not only high-performance desktop machine but also design embedded server systems. They have illustrated principles with designs from all three these domains, including examples consumer electronics, multimedia Web technologies, computing.

computer science, system architecture, computer architecture, systems engineering, architecture",1989,9177,computer science|system architecture|computer architecture|systems engineering|architecture,
https://openalex.org/W2122646361,Anomaly detection,"Anomaly detection

Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly techniques have specifically developed for certain domains, while others are more generic. This survey tries to provide a structured comprehensive overview of the on detection. We grouped existing into different categories based underlying approach adopted by each technique. For category we identified key assumptions, which used differentiate between normal anomalous behavior. When applying given technique particular domain, these assumptions can be as guidelines assess effectiveness in domain. category, basic technique, then show how variants template provides easier succinct understanding belonging category. Further, identify advantages disadvantages also discussion computational complexity since it issue real hope this will better directions done topic, one area applied domains they were not intended begin with.

anomaly detection, pattern recognition, computer science, outlier detection",2009,9131,anomaly detection|pattern recognition|computer science|outlier detection,https://openalex.org/W2963857521
https://openalex.org/W2154053567,"Feature selection based on mutual information criteria of max-dependency, max-relevance, and min-redundancy","Feature selection based on mutual information criteria of max-dependency, max-relevance, and min-redundancy

Feature selection is an important problem for pattern classification systems. We study how to select good features according the maximal statistical dependency criterion based on mutual information. Because of difficulty in directly implementing condition, we first derive equivalent form, called minimal-redundancy-maximal-relevance (mRMR), first-order incremental feature selection. Then, present a two-stage algorithm by combining mRMR and other more sophisticated selectors (e.g., wrappers). This allows us compact set superior at very low cost. perform extensive experimental comparison our methods using three different classifiers (naive Bayes, support vector machine, linear discriminate analysis) four data sets (handwritten digits, arrhythmia, NCI cancer cell lines, lymphoma tissues). The results confirm that leads promising improvement accuracy.

image analysis, pattern recognition, computer science, computational imaging, model comparison, feature learning, feature engineering, clustering, machine learning, mutual information criteria, data science, machine learning research, feature construction, combinatorial optimization, feature selection, information retrieval",2005,9117,image analysis|pattern recognition|computer science|computational imaging|model comparison|feature learning|feature engineering|clustering|machine learning|mutual information criteria|data science|machine learning research|feature construction|combinatorial optimization|feature selection|information retrieval,
https://openalex.org/W2146842127,De-noising by soft-thresholding,"De-noising by soft-thresholding

Donoho and Johnstone (1994) proposed a method for reconstructing an unknown function f on [0,1] from noisy data d/sub i/=f(t/sub i/)+/spl sigma/z/sub i/, i=0, ..., n-1,t/sub i/=i/n, where the z/sub i/ are independent identically distributed standard Gaussian random variables. The reconstruction f/spl circ/*/sub n/ is defined in wavelet domain by translating all empirical coefficients of d toward 0 amount /spl sigma//spl middot//spl radic/(2log (n)/n). authors prove two results about this type estimator. [Smooth]: with high probability at least as smooth f, any wide variety smoothness measures. [Adapt]: estimator comes nearly close mean square to measurable can come, uniformly over balls each broad scales classes. These properties unprecedented several ways. present proof these develops new facts abstract statistical inference its connection optimal recovery model.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>

digital signal processing, soft computing, computer science, noise reduction",1995,9081,digital signal processing|soft computing|computer science|noise reduction,https://openalex.org/W2097073572
https://openalex.org/W2099085143,Second-generation PLINK: rising to the challenge of larger and richer datasets,"Second-generation PLINK: rising to the challenge of larger and richer datasets

PLINK 1 is a widely used open-source C/C++ toolset for genome-wide association studies (GWAS) and research in population genetics. However, the steady accumulation of data from imputation whole-genome sequencing has exposed strong need even faster more scalable implementations key functions. In addition, GWAS population-genetic now frequently contain probabilistic calls, phase information, and/or multiallelic variants, none which can be represented by 1's primary format. To address these issues, we are developing second-generation codebase PLINK. The first major release this codebase, 1.9, introduces extensive use bit-level parallelism, O(sqrt(n))-time/constant-space Hardy-Weinberg equilibrium Fisher's exact tests, many other algorithmic improvements. combination, changes accelerate most operations 1-4 orders magnitude, allow program to handle datasets too large fit RAM. This will followed 2.0, introduce (a) new format capable efficiently representing probabilities, phase, (b) extensions functions account types information. versions offer dramatic improvements performance compatibility. For time, users without access high-end computing resources perform several essential analyses feature-rich very genetic coming into use.

computer science, benchmark datasets, data integration, real-time data, richer datasets, large-scale datasets, missing data, machine learning, data heterogeneity, data-driven science, data science, deep learning, statistics, machine learning research, scientific data, second-generation plink, big data",2015,9075,computer science|benchmark datasets|data integration|real-time data|richer datasets|large-scale datasets|missing data|machine learning|data heterogeneity|data-driven science|data science|deep learning|statistics|machine learning research|scientific data|second-generation plink|big data,
https://openalex.org/W2142238829,SExtractor: Software for source extraction,"SExtractor: Software for source extraction

We present the automated techniques we have developed for new software that optimally detects, deblends, measures and classifies sources from astronomical images: SExtractor (Source Extractor ). show a very reliable star/galaxy separation can be achieved on most images using neural network trained with simulated images. Salient features of include its ability to work large images, minimal human intervention, deal wide variety object shapes magnitudes. It is therefore particularly suited analysis extragalactic surveys.

computer science, source extraction",1996,9066,computer science|source extraction,
https://openalex.org/W2160547390,$rm K$-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation,"$rm K$-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation

In recent years there has been a growing interest in the study of sparse representation signals. Using an overcomplete dictionary that contains prototype signal-atoms, signals are described by linear combinations these atoms. Applications use many and include compression, regularization inverse problems, feature extraction, more. Recent activity this field concentrated mainly on pursuit algorithms decompose with respect to given dictionary. Designing dictionaries better fit above model can be done either selecting one from prespecified set transforms or adapting training Both techniques have considered, but topic is largely still open. paper we propose novel algorithm for order achieve signal representations. Given signals, seek leads best each member set, under strict sparsity constraints. We present new method-the K-SVD algorithm-generalizing K-means clustering process. iterative method alternates between coding examples based current process updating atoms data. The update columns combined representations, thereby accelerating convergence. flexible work any (e.g., basis pursuit, FOCUSS, matching pursuit). analyze demonstrate its results both synthetic tests applications real image data

image analysis, pattern recognition, computer science, computational imaging, dimensionality reduction, compressive sensing, natural language processing, hierarchical classification, clustering, applied mathematics, data science, sparse representation, image representation, machine learning research, feature construction, overcomplete dictionaries, computational science",2006,8999,image analysis|pattern recognition|computer science|computational imaging|dimensionality reduction|compressive sensing|natural language processing|hierarchical classification|clustering|applied mathematics|data science|sparse representation|image representation|machine learning research|feature construction|overcomplete dictionaries|computational science,https://openalex.org/W1885185971
https://openalex.org/W2024165284,Tensor Decompositions and Applications,"Tensor Decompositions and Applications

This survey provides an overview of higher-order tensor decompositions, their applications, and available software. A is a multidimensional or N-way array. Decompositions tensors (i.e., arrays with $N \geq 3$) have applications in psycho-metrics, chemometrics, signal processing, numerical linear algebra, computer vision, analysis, data mining, neuroscience, graph elsewhere. Two particular decompositions can be considered to extensions the matrix singular value decomposition: CANDECOMP/PARAFAC (CP) decomposes as sum rank-one tensors, Tucker decomposition form principal component analysis. There are many other including INDSCAL, PARAFAC2, CANDELINC, DEDICOM, PARATUCK2 well nonnegative variants all above. The Toolbox, Tensor Multilinear Engine examples software packages for working tensors.

mathematics, computational imaging, computer science, dimensionality reduction, linear algebra, operator theory, parameter identification, tensor decompositions, matrix analysis, computer vision, low-rank approximation, applied mathematics, numerical linear algebra, spectral theory, machine learning research, feature construction, computational geometry",2009,8929,mathematics|computational imaging|computer science|dimensionality reduction|linear algebra|operator theory|parameter identification|tensor decompositions|matrix analysis|computer vision|low-rank approximation|applied mathematics|numerical linear algebra|spectral theory|machine learning research|feature construction|computational geometry,
https://openalex.org/W4388297464,Neural Networks for Pattern Recognition,"Neural Networks for Pattern Recognition

Abstract This book provides the first comprehensive treatment of feed-forward neural networks from perspective statistical pattern recognition. After introducing basic concepts recognition, describes techniques for modelling probability density functions, and discusses properties relative merits multi-layer perceptron radial basis function network models. It also motivates use various forms error reviews principal algorithms minimization. As well as providing a detailed discussion learning generalization in networks, covers important topics data processing, feature extraction, prior knowledge. The concludes with an extensive Bayesian their applications to networks.

neural networks, pattern recognition, machine vision, neural architecture search, sparse neural network, neural network (machine learning), temporal pattern recognition, cognitive science, computational intelligence, computer science, recurrent neural network, convolutional neural network, machine learning, machine learning research, deep learning, data science, image analysis",1995,8927,neural networks|pattern recognition|machine vision|neural architecture search|sparse neural network|neural network (machine learning)|temporal pattern recognition|cognitive science|computational intelligence|computer science|recurrent neural network|convolutional neural network|machine learning|machine learning research|deep learning|data science|image analysis,https://openalex.org/W2194775991|https://openalex.org/W2131774270
https://openalex.org/W2549139847,Aggregated Residual Transformations for Deep Neural Networks,"Aggregated Residual Transformations for Deep Neural Networks

We present a simple, highly modularized network architecture for image classification. Our is constructed by repeating building block that aggregates set of transformations with the same topology. simple design results in homogeneous, multi-branch has only few hyper-parameters to set. This strategy exposes new dimension, which we call cardinality (the size transformations), as an essential factor addition dimensions depth and width. On ImageNet-1K dataset, empirically show even under restricted condition maintaining complexity, increasing able improve classification accuracy. Moreover, more effective than going deeper or wider when increase capacity. models, named ResNeXt, are foundations our entry ILSVRC 2016 task secured 2nd place. further investigate ResNeXt on ImageNet-5K COCO detection set, also showing better its ResNet counterpart. The code models publicly available online.

computer science, machine learning, deep neural networks, neural computation, deep learning, residual transformations, neural network (machine learning)",2017,8913,computer science|machine learning|deep neural networks|neural computation|deep learning|residual transformations|neural network (machine learning),https://openalex.org/W2963150697|https://openalex.org/W2752782242|https://openalex.org/W2963163009|https://openalex.org/W3138516171|https://openalex.org/W2963420686|https://openalex.org/W2963091558|https://openalex.org/W3018757597|https://openalex.org/W3035524453|https://openalex.org/W2963125010
https://openalex.org/W2080267935,Graph-Based Algorithms for Boolean Function Manipulation,"Graph-Based Algorithms for Boolean Function Manipulation

In this paper we present a new data structure for representing Boolean functions and an associated set of manipulation algorithms. Functions are represented by directed, acyclic graphs in manner similar to the representations introduced Lee [1] Akers [2], but with further restrictions on ordering decision variables graph. Although function requires, worst case, graph size exponential number arguments, many encountered typical applications have more reasonable representation. Our algorithms time complexity proportional sizes being operated on, hence quite efficient as long do not grow too large. We experimental results from applying these problems logic design verification that demonstrate practicality our approach.

computer science, graph theory, boolean function manipulation, graph algorithm, boolean function, graph-based algorithms",1986,8830,computer science|graph theory|boolean function manipulation|graph algorithm|boolean function|graph-based algorithms,
https://openalex.org/W2157009395,MEME SUITE: tools for motif discovery and searching,"MEME SUITE: tools for motif discovery and searching

The MEME Suite web server provides a unified portal for online discovery and analysis of sequence motifs representing features such as DNA binding sites protein interaction domains. popular motif algorithm is now complemented by the GLAM2 which allows containing gaps. Three scanning algorithms—MAST, FIMO GLAM2SCAN—allow numerous databases discovered GLAM2. Transcription factor (including those using MEME) can be compared with in many database Tomtom. further analyzed putative function association Gene Ontology (GO) terms motif-GO term tool GOMO. output contains LOGOS each motif, well buttons to allow conveniently submitted algorithms (MAST, Tomtom), or GOMO, analysis. similarly GLAM2SCAN rerunning different parameters. All motif-based tools are implemented services via Opal. Source code, binaries freely available noncommercial use at http://meme.nbcr.net.

pattern recognition, computer science, pattern discovery, link analysis, sequence motif, molecular biology, bioinformatics, systems biology, combinatorial pattern matching, information retrieval, genomics, meme suite, pattern mining, web search, clustering, multimedia retrieval, motif discovery, knowledge discovery, memetic computing, molecular informatics",2009,8794,pattern recognition|computer science|pattern discovery|link analysis|sequence motif|molecular biology|bioinformatics|systems biology|combinatorial pattern matching|information retrieval|genomics|meme suite|pattern mining|web search|clustering|multimedia retrieval|motif discovery|knowledge discovery|memetic computing|molecular informatics,
https://openalex.org/W2151693816,Matching pursuits with time-frequency dictionaries,"Matching pursuits with time-frequency dictionaries

The authors introduce an algorithm, called matching pursuit, that decomposes any signal into a linear expansion of waveforms are selected from redundant dictionary functions. These chosen in order to best match the structures. Matching pursuits general procedures compute adaptive representations. With Gabor functions pursuit defines time-frequency transform. They derive energy distribution plane, which does not include interference terms, unlike Wigner and Cohen class distributions. A isolates structures coherent with respect given dictionary. An application pattern extraction noisy signals is described. compare decomposition over optimized wavepacket orthonormal basis, algorithm Coifman Wickerhauser see (IEEE Trans. Informat. Theory, vol. 38, Mar. 1992).< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>

computer science, hierarchical classification, signal processing, time-frequency dictionaries",1993,8777,computer science|hierarchical classification|signal processing|time-frequency dictionaries,https://openalex.org/W1678356000|https://openalex.org/W2160547390
https://openalex.org/W2078146328,Fully optimized contracted Gaussian basis sets for atoms Li to Kr,"Fully optimized contracted Gaussian basis sets for atoms Li to Kr

Various contracted Gaussian basis sets for atoms up to Kr are presented which have been determined by optimizing atomic self-consistent field ground state energies with respect all set parameters, i.e., orbital exponents and contraction coefficients.

computer science, engineering optimization, density functional theory, energy minimization, combinatorial evolution, control optimization, mathematical optimization, applied mathematics, numerical linear algebra, computational chemistry, quantum optimization algorithm, sparse representation, structure elucidation, applied physics, optical properties, computational optimization, computational science",1992,8775,computer science|engineering optimization|density functional theory|energy minimization|combinatorial evolution|control optimization|mathematical optimization|applied mathematics|numerical linear algebra|computational chemistry|quantum optimization algorithm|sparse representation|structure elucidation|applied physics|optical properties|computational optimization|computational science,
https://openalex.org/W2120772351,Jalview Version 2—a multiple sequence alignment editor and analysis workbench,"Jalview Version 2—a multiple sequence alignment editor and analysis workbench

Abstract Summary: Jalview Version 2 is a system for interactive WYSIWYG editing, analysis and annotation of multiple sequence alignments. Core features include keyboard mouse-based views alignment overviews, linked structure display with Jmol. available in two forms: lightweight Java applet use web applications, powerful desktop application that employs services alignment, secondary prediction the retrieval alignments, sequences, structures from public databases any DAS 1.53 compliant or server. Availability: The Desktop JalviewLite are made freely under GPL, can be downloaded www.jalview.org Contact: g.j.barton@dundee.ac.uk

computer science, sequence analysis, sequence modelling, analysis workbench, sequence alignment, bioinformatics",2009,8733,computer science|sequence analysis|sequence modelling|analysis workbench|sequence alignment|bioinformatics,
https://openalex.org/W2061326496,Coding Algorithms for Defining Comorbidities in ICD-9-CM and ICD-10 Administrative Data,"Coding Algorithms for Defining Comorbidities in ICD-9-CM and ICD-10 Administrative Data

Implementation of the International Statistical Classification Disease and Related Health Problems, 10th Revision (ICD-10) coding system presents challenges for using administrative data. Recognizing this, we conducted a multistep process to develop ICD-10 algorithms define Charlson Elixhauser comorbidities in data assess performance resulting algorithms.ICD-10 were developed by ""translation"" ICD-9-CM codes constituting Deyo's (for comorbidities) Elixhauser's physicians' assessment face-validity selected codes. The carefully developing also produced modified enhanced comorbidities. We then used on in-patients aged 18 years older hospital discharge from Canadian health region comorbidity frequencies mortality prediction achieved original algorithms, new algorithms.Among 56,585 patients 58,805 data, 17 30 remained generally similar across algorithms. either matched or outperformed Deyo predicting in-hospital mortality. C-statistic was 0.842 algorithm, 0.860 0.859 0.868 0.870 algorithm 0.878 algorithm.These newly produce estimates prevalence may outperform existing

health informatics, data management, computer science, pattern recognition, information fusion, algebraic coding theory, data coding, dimensionality reduction, differential diagnosis, comorbidity, epidemiology, biomedical informatics, public health",2005,8720,health informatics|data management|computer science|pattern recognition|information fusion|algebraic coding theory|data coding|dimensionality reduction|differential diagnosis|comorbidity|epidemiology|biomedical informatics|public health,
https://openalex.org/W2970971581,"PyTorch: An Imperative Style, High-Performance Deep Learning Library","PyTorch: An Imperative Style, High-Performance Deep Learning Library

Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine library that shows these two goals are in fact compatible: it was designed from first principles to support an imperative and Pythonic programming style supports code as model, makes debugging easy consistent with other popular scientific computing libraries, while remaining efficient supporting hardware accelerators such GPUs. In this paper, we detail the drove implementation of how they reflected its architecture. We emphasize every aspect regular Python program under full control user. also explain careful pragmatic key components runtime enables them work together achieve compelling performance. demonstrate efficiency individual subsystems, well overall speed several commonly used benchmarks.

imperative style, natural language processing, computer science, machine learning, large language model, deep learning",2019,8716,imperative style|natural language processing|computer science|machine learning|large language model|deep learning,https://openalex.org/W3099878876
https://openalex.org/W2999905431,Advances in Neural Information Processing Systems 14,"Advances in Neural Information Processing Systems 14

The proceedings of the 2001 Neural Information Processing Systems (NIPS) Conference. annual conference on is flagship neural computation. interdisciplinary, with contributions in algorithms, learning theory, cognitive science, neuroscience, vision, speech and signal processing, reinforcement control, implementations, diverse applications. Only about 30 percent papers submitted are accepted for presentation at NIPS, so quality exceptionally high. These contain all that were presented conference. Bradford Books imprint

computer science, artificial intelligence, machine learning, neural science, neural computation, computational intelligence, deep learning, machine learning research, neural network (machine learning), intelligent information processing, neural information",2002,8662,computer science|artificial intelligence|machine learning|neural science|neural computation|computational intelligence|deep learning|machine learning research|neural network (machine learning)|intelligent information processing|neural information,https://openalex.org/W2116341502
https://openalex.org/W2125910575,Gephi: An Open Source Software for Exploring and Manipulating Networks,"Gephi: An Open Source Software for Exploring and Manipulating Networks

Gephi is an open source software for graph and network analysis. It uses a 3D render engine to display large networks in real-time speed up the exploration. A flexible multi-task architecture brings new possibilities work with complex data sets produce valuable visual results. We present several key features of context interactive exploration interpretation networks. provides easy broad access allows spatializing, filtering, navigating, manipulating clustering. Finally, by presenting dynamic Gephi, we highlight aspects visualization.

complex system, computer science, graph theory, social network analysis, network theory, networked system design, network dynamic, network analysis, network science, community structure",2009,8652,complex system|computer science|graph theory|social network analysis|network theory|networked system design|network dynamic|network analysis|network science|community structure,
https://openalex.org/W2963091558,Non-local Neural Networks,"Non-local Neural Networks

Both convolutional and recurrent operations are building blocks that process one local neighborhood at a time. In this paper, we present non-local as generic family of for capturing long-range dependencies. Inspired by the classical means method in computer vision, our operation computes response position weighted sum features all positions. This block can be plugged into many vision architectures. On task video classification, even without any bells whistles, models compete or outperform current competition winners on both Kinetics Charades datasets. static image recognition, improve object detection/segmentation pose estimation COCO suite tasks. Code is available https://github.com/facebookresearch/video-nonlocal-net .

computer science, non-local neural networks, machine learning, neural computation, neural network (machine learning), neuronal network",2018,8614,computer science|non-local neural networks|machine learning|neural computation|neural network (machine learning)|neuronal network,https://openalex.org/W3138516171|https://openalex.org/W3094502228
https://openalex.org/W2114296561,A view of cloud computing,"A view of cloud computing

Clearing the clouds away from true potential and obstacles posed by this computing capability.

computer science, cloud computing architecture, information technology, cloud computing, cloud data management, cloud resource management, cloud-based integration, distributed cloud",2010,8565,computer science|cloud computing architecture|information technology|cloud computing|cloud data management|cloud resource management|cloud-based integration|distributed cloud,https://openalex.org/W2416799949
https://openalex.org/W2271840356,TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems,"TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems

TensorFlow is an interface for expressing machine learning algorithms, and implementation executing such algorithms. A computation expressed using can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices as phones tablets up to large-scale distributed systems hundreds machines thousands computational GPU cards. The system flexible used express including training inference algorithms deep neural network models, it has been conducting research deploying into production across more than dozen areas computer science other fields, speech recognition, vision, robotics, information retrieval, natural language processing, geographic extraction, drug discovery. This paper describes the that we have built at Google. API reference were released open-source package under Apache 2.0 license in November, 2015 are available www.tensorflow.org.

distributed system, computer science, heterogeneous computing, large-scale machine, machine learning",2016,8543,distributed system|computer science|heterogeneous computing|large-scale machine|machine learning,https://openalex.org/W2412782625|https://openalex.org/W3099878876|https://openalex.org/W2963524571|https://openalex.org/W2630837129
https://openalex.org/W2122683221,"DAVID: Database for Annotation, Visualization, and Integrated Discovery","DAVID: Database for Annotation, Visualization, and Integrated Discovery

Functional annotation of differentially expressed genes is a necessary and critical step in the analysis microarray data. The distributed nature biological knowledge frequently requires researchers to navigate through numerous web-accessible databases gathering information one gene at time. A more judicious approach provide query-based access an integrated database that disseminates biologically rich across large datasets displays graphic summaries functional information.Database for Annotation, Visualization, Integrated Discovery (DAVID; http://www.david.niaid.nih.gov) addresses this need via four web-based modules: 1) Annotation Tool - rapidly appends descriptive data from several public lists genes; 2) GoCharts assigns Gene Ontology categories based on user selected classifications term specificity level; 3) KeggCharts KEGG metabolic processes enables users view context biochemical pathway maps; 4) DomainCharts groups according PFAM conserved protein domains.Analysis results graphical remain dynamically linked primary external repositories, thereby furnishing in-depth as well broad-based coverage. functionality provided by DAVID accelerates genome-scale facilitating transition collection meaning.

clustering, knowledge discovery, annotation tool, data and information visualization, integrated discovery, bioinformatics database, computer science, discovery technique, data science, information visualization, interactive data exploration",2003,8542,clustering|knowledge discovery|annotation tool|data and information visualization|integrated discovery|bioinformatics database|computer science|discovery technique|data science|information visualization|interactive data exploration,
https://openalex.org/W2340897893,The Cityscapes Dataset for Semantic Urban Scene Understanding,"The Cityscapes Dataset for Semantic Urban Scene Understanding

Visual understanding of complex urban street scenes is an enabling factor for a wide range applications. Object detection has benefited enormously from large-scale datasets, especially in the context deep learning. For semantic scene understanding, however, no current dataset adequately captures complexity real-world scenes. To address this, we introduce Cityscapes, benchmark suite and to train test approaches pixel-level instance-level labeling. Cityscapes comprised large, diverse set stereo video sequences recorded streets 50 different cities. 5000 these images have high quality annotations, 20 000 additional coarse annotations enable methods that leverage large volumes weakly-labeled data. Crucially, our effort exceeds previous attempts terms size, annotation richness, variability, complexity. Our accompanying empirical study provides in-depth analysis characteristics, as well performance evaluation several state-of-the-art based on benchmark.

computer science, urban informatics, urban planning, urban ecology, deep learning, information fusion, semantic urban scene, urban modelling, urbanism, image representation, geography, scene understanding, urban geography, computational imaging, scene interpretation, localization, data science, scene analysis, image analysis",2016,8538,computer science|urban informatics|urban planning|urban ecology|deep learning|information fusion|semantic urban scene|urban modelling|urbanism|image representation|geography|scene understanding|urban geography|computational imaging|scene interpretation|localization|data science|scene analysis|image analysis,https://openalex.org/W2962793481|https://openalex.org/W2412782625|https://openalex.org/W2963073614|https://openalex.org/W2963881378|https://openalex.org/W2560023338|https://openalex.org/W3035524453
https://openalex.org/W2493916176,Enriching Word Vectors with Subword Information,"Enriching Word Vectors with Subword Information

Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Popular models that learn such representations ignore the morphology of words, by assigning a distinct vector to each word. This is limitation, especially languages with vocabularies and rare words. In this paper, we propose new approach based skipgram model, where represented as bag character n-grams. A representation associated n-gram; words being sum these representations. Our method fast, allowing train quickly allows us compute did not appear in training data. We evaluate our nine different languages, both similarity analogy By comparing recently proposed morphological show vectors achieve state-of-the-art performance

word embeddings, computer science, linguistics, keyword extraction, text mining, language model, natural language processing, topic model, semantic evaluation, terminology extraction, computational linguistics, knowledge discovery, nlp task, machine learning research, word vectors, information retrieval, subword information",2017,8508,word embeddings|computer science|linguistics|keyword extraction|text mining|language model|natural language processing|topic model|semantic evaluation|terminology extraction|computational linguistics|knowledge discovery|nlp task|machine learning research|word vectors|information retrieval|subword information,
https://openalex.org/W2162598825,Performance analysis of the IEEE 802.11 distributed coordination function,"Performance analysis of the IEEE 802.11 distributed coordination function

The IEEE has standardized the 802.11 protocol for wireless local area networks. primary medium access control (MAC) technique of is called distributed coordination function (DCF). DCF a carrier sense multiple with collision avoidance (CSMA/CA) scheme binary slotted exponential backoff. This paper provides simple, but nevertheless extremely accurate, analytical model to compute throughput, in assumption finite number terminals and ideal channel conditions. proposed analysis applies both packet transmission schemes employed by DCF, namely, basic RTS/CTS mechanisms. In addition, it also combination two schemes, which packets longer than given threshold are transmitted according mechanism. By means model, we provide an extensive throughput performance evaluation mechanisms protocol.

distributed system, computer science, wireless network, wireless communication, communication, networked system design, advanced networking, coordination model, coordination function, systems engineering, communications system, swarm intelligence, telecommunication network, distributed coordination, wireless cooperative network",2000,8502,distributed system|computer science|wireless network|wireless communication|communication|networked system design|advanced networking|coordination model|coordination function|systems engineering|communications system|swarm intelligence|telecommunication network|distributed coordination|wireless cooperative network,
https://openalex.org/W1996672843,The Minimalist Program,"The Minimalist Program

A classic work that situates linguistic theory in the broader cognitive sciences, formulating and developing minimalist program. In his foundational book, The Minimalist Program, published 1995, Noam Chomsky offered a significant contribution to generative tradition linguistics. This twentieth-anniversary edition reissues this with new preface by author. four essays, attempts situate essays progressively approach theory. Building on of principles parameters and, particular, economy derivation representation, framework takes Universal Grammar as providing unique computational system, derivations driven morphological properties, which syntactic variation languages is also restricted. Within theoretical framework, expressions are generated optimally efficient must satisfy conditions hold interface levels, only levels representation. provide instructions two types performance systems, articulatory-perceptual conceptual-intentional. All conditions, then, express properties these reflecting interpretive requirements language keeping very restricted conceptual resources. edition, emphasizes developed book subsequent program, not With built pursuits from earliest days grammar formulate research program had far-reaching implications for field.

computer science, theory of computation, programming language theory, program evaluation, logic in computer science, theoretical computer science, critical theory, declarative programming, minimalist program, computer engineering, complexity reduction, abstract interpretation, active control, systems engineering, automatic control, computational optimization, mathematical programming, program analysis, miniaturization",1992,8439,computer science|theory of computation|programming language theory|program evaluation|logic in computer science|theoretical computer science|critical theory|declarative programming|minimalist program|computer engineering|complexity reduction|abstract interpretation|active control|systems engineering|automatic control|computational optimization|mathematical programming|program analysis|miniaturization,
https://openalex.org/W4213009331,Introduction to Information Retrieval,"Introduction to Information Retrieval

Class-tested and coherent, this textbook teaches classical web information retrieval, including search the related areas of text classification clustering from basic concepts. It gives an up-to-date treatment all aspects design implementation systems for gathering, indexing, searching documents; methods evaluating systems; introduction to use machine learning on collections. All important ideas are explained using examples figures, making it perfect introductory courses in retrieval advanced undergraduates graduate students computer science. Based feedback extensive classroom experience, book has been carefully structured order make teaching more natural effective. Slides additional exercises (with solutions lecturers) also available through book's supporting website help course instructors prepare their lectures.

computer science, information science, knowledge retrieval, intelligent information retrieval, interactive information retrieval, collaborative information retrieval, information retrieval, search technology",2008,8436,computer science|information science|knowledge retrieval|intelligent information retrieval|interactive information retrieval|collaborative information retrieval|information retrieval|search technology,
https://openalex.org/W2109255472,Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition,"Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition

Existing deep convolutional neural networks (CNNs) require a fixed-size (e.g., 224 × 224) input image. This requirement is ""artificial"" and may reduce the recognition accuracy for images or sub-images of an arbitrary size/scale. In this work, we equip with another pooling strategy, ""spatial pyramid pooling"", to eliminate above requirement. The new network structure, called SPP-net, can generate fixed-length representation regardless image Pyramid also robust object deformations. With these advantages, SPP-net should in general improve all CNN-based classification methods. On ImageNet 2012 dataset, demonstrate that boosts variety CNN architectures despite their different designs. Pascal VOC 2007 Caltech101 datasets, achieves state-of-the-art results using single full-image no fine-tuning. power significant detection. Using compute feature maps from entire only once, then pool features regions (sub-images) representations training detectors. method avoids repeatedly computing features. processing test images, our 24-102 faster than R-CNN method, while achieving better comparable on 2007. Large Scale Visual Recognition Challenge (ILSVRC) 2014, methods rank #2 detection #3 among 38 teams. manuscript introduces improvement made competition.

computer science, machine learning, visual recognition, image analysis, information fusion, convolutional neural network, feature detection, cognitive science, data science, object categorization, image representation, vision recognition, computational imaging, deep convolutional networks, deep learning, spatial pyramid pooling, machine learning research, machine vision, digital image processing, computer vision, geometric learning",2015,8381,computer science|machine learning|visual recognition|image analysis|information fusion|convolutional neural network|feature detection|cognitive science|data science|object categorization|image representation|vision recognition|computational imaging|deep convolutional networks|deep learning|spatial pyramid pooling|machine learning research|machine vision|digital image processing|computer vision|geometric learning,https://openalex.org/W2963037989|https://openalex.org/W639708223|https://openalex.org/W1536680647|https://openalex.org/W2560023338|https://openalex.org/W3018757597
https://openalex.org/W2953384591,TensorFlow: A system for large-scale machine learning,"TensorFlow: A system for large-scale machine learning

TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. uses dataflow graphs to represent computation, shared state, the operations mutate state. It maps nodes of graph across many machines cluster, within multiple computational devices, including multicore CPUs, general-purpose GPUs, custom designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility application developer: whereas previous ""parameter server"" designs management state built into system, enables developers experiment with novel optimizations training algorithms. supports variety applications, particularly strong support for inference on deep neural networks. Several Google services use production, we have released it an open-source project, has become widely used research. In this paper, describe model contrast existing systems, demonstrate compelling performance achieves several real-world applications.

systems engineering, massive data processing, automated machine learning, large ai model, algorithmic learning, computer science, large-scale datasets, machine learning, machine learning research, large-scale machine learning, data science",2016,8380,systems engineering|massive data processing|automated machine learning|large ai model|algorithmic learning|computer science|large-scale datasets|machine learning|machine learning research|large-scale machine learning|data science,https://openalex.org/W3099878876
https://openalex.org/W2132216432,"<i>EXPGUI</i>, a graphical user interface for<i>GSAS</i>","<i>EXPGUI</i>, a graphical user interface for<i>GSAS</i>

A description and justification of the EXPGUI program is presented. This implements a graphical user interface shell for GSAS single-crystal Rietveld package. Use Tcl/Tk scripting language allows to be platform independent. Also included synopsis how implemented.

intelligent user interface, computer science, human-computer interaction, mobile computing, user interface, graphics, graphic interface, touch user interface, computer graphic, graphical user interface, mobile interface, user interface design, visual interface, systems engineering, user experience, interaction design, adaptive user interface, computer engineering",2001,8366,intelligent user interface|computer science|human-computer interaction|mobile computing|user interface|graphics|graphic interface|touch user interface|computer graphic|graphical user interface|mobile interface|user interface design|visual interface|systems engineering|user experience|interaction design|adaptive user interface|computer engineering,
https://openalex.org/W2130416410,Markov Chain Monte Carlo in Practice,"Markov Chain Monte Carlo in Practice

In a family study of breast cancer, epidemiologists in Southern California increase the power for detecting gene-environment interaction. Gambia, helps vaccination program reduce incidence Hepatitis B carriage. Archaeologists Austria place Bronze Age site its true temporal location on calendar scale. And France,

markov chain monte carlo, computer science, stochastic process, monte carlo",1995,8249,markov chain monte carlo|computer science|stochastic process|monte carlo,
https://openalex.org/W2119567691,Markov Decision Processes: Discrete Stochastic Dynamic Programming.,"Markov Decision Processes: Discrete Stochastic Dynamic Programming.

From the Publisher:
The past decade has seen considerable theoretical and applied research on Markov decision processes, as well growing use of these models in ecology, economics, communications engineering, other fields where outcomes are uncertain sequential decision-making processes needed. A timely response to this increased activity, Martin L. Puterman's new work provides a uniquely up-to-date, unified, rigorous treatment theoretical, computational, process models. It discusses all major directions field, highlights many significant applications models, explores numerous important topics that have previously been neglected or given cursory coverage literature. Decision Processes focuses primarily infinite horizon discrete time with spaces while also examining arbitrary state spaces, finite continuous-time The book is organized around optimality criteria, using common framework centered (Bellman) equation for presenting results. results presented theorem-proof format elaborated through both discussion examples, including not available any book. two-state model, Chapter 3, analyzed repeatedly throughout demonstrates algorithms. covers recent advances such areas countable space average reward criterion, constrained risk sensitive criteria. several received little no attention books, modified policy iteration, multichain optimality. In addition, Bibliographic Remarks section each chapter comments relevant historic

dynamic programming, computer science, stochastic optimization, stochastic dynamic, markov decision process, dynamic optimization, stochastic process",1995,8246,dynamic programming|computer science|stochastic optimization|stochastic dynamic|markov decision process|dynamic optimization|stochastic process,https://openalex.org/W2107726111
https://openalex.org/W1548802052,Independent Component Analysis,"Independent Component Analysis

In this chapter, we discuss a statistical generative model called independent component analysis. It is basically proper probabilistic formulation of the ideas underpinning sparse coding. shows how coding can be interpreted as providing Bayesian prior, and answers some questions which were not properly answered in framework.

spectral theory, multidimensional analysis, network analysis, functional data analysis, biostatistics, high-dimensional statistics, statistics, information fusion, mixture analysis, source separation, independent component analysis, principal component analysis, computer science, computational statistic, functional analysis, image analysis",2004,8223,spectral theory|multidimensional analysis|network analysis|functional data analysis|biostatistics|high-dimensional statistics|statistics|information fusion|mixture analysis|source separation|independent component analysis|principal component analysis|computer science|computational statistic|functional analysis|image analysis,https://openalex.org/W2154053567
https://openalex.org/W2117228865,ORB: An efficient alternative to SIFT or SURF,"ORB: An efficient alternative to SIFT or SURF

Feature matching is at the base of many computer vision problems, such as object recognition or structure from motion. Current methods rely on costly descriptors for detection and matching. In this paper, we propose a very fast binary descriptor based BRIEF, called ORB, which rotation invariant resistant to noise. We demonstrate through experiments how ORB two orders magnitude faster than SIFT, while performing well in situations. The efficiency tested several real-world applications, including patch-tracking smart phone.

pattern recognition, computer science, machine learning, geometry processing, image analysis, information fusion, structure from motion, data science, computational imaging, partial evaluation, localization, numerical simulation, machine vision, point cloud processing, digital image processing, 3d computer vision, computer vision, applied mathematics, efficient alternative",2011,8195,pattern recognition|computer science|machine learning|geometry processing|image analysis|information fusion|structure from motion|data science|computational imaging|partial evaluation|localization|numerical simulation|machine vision|point cloud processing|digital image processing|3d computer vision|computer vision|applied mathematics|efficient alternative,
https://openalex.org/W2612445135,MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications,"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications

We present a class of efficient models called MobileNets for mobile and embedded vision applications. are based on streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. introduce two simple global hyper-parameters efficiently trade off between latency accuracy. These allow the model builder choose right sized their application constraints problem. extensive experiments resource accuracy tradeoffs show strong performance compared other popular ImageNet classification. then demonstrate effectiveness across wide range applications use cases including object detection, finegrain classification, face attributes large scale geo-localization.

image analysis, computer science, computer vision, machine learning, computational intelligence, motion detection, feature detection, mobile sensing, object detection, neural network (machine learning), machine learning research, convolutional neural network, data science, deep learning, mobile vision applications, machine vision, cognitive science",2017,8181,image analysis|computer science|computer vision|machine learning|computational intelligence|motion detection|feature detection|mobile sensing|object detection|neural network (machine learning)|machine learning research|convolutional neural network|data science|deep learning|mobile vision applications|machine vision|cognitive science,https://openalex.org/W2752782242|https://openalex.org/W2963163009|https://openalex.org/W2963420686|https://openalex.org/W3018757597
https://openalex.org/W2962862931,A Unified Approach to Interpreting Model Predictions,"A Unified Approach to Interpreting Model Predictions

Understanding why a model makes certain prediction can be as crucial the prediction's accuracy in many applications. However, highest for large modern datasets is often achieved by complex models that even experts struggle to interpret, such ensemble or deep learning models, creating tension between and interpretability. In response, various methods have recently been proposed help users interpret predictions of but it unclear how these are related when one method preferable over another. To address this problem, we present unified framework interpreting predictions, SHAP (SHapley Additive exPlanations). assigns each feature an importance value particular prediction. Its novel components include: (1) identification new class additive measures, (2) theoretical results showing there unique solution with set desirable properties. The unifies six existing methods, notable because several recent lack Based on insights from unification, show improved computational performance and/or better consistency human intuition than previous approaches.

predictive analytics, interpretation technique, interpretation, model analysis, forecasting, computer science, prediction modelling, predictive modeling, machine learning, model predictions, machine learning research, theoretical prediction, data science, statistical model",2017,8170,predictive analytics|interpretation technique|interpretation|model analysis|forecasting|computer science|prediction modelling|predictive modeling|machine learning|model predictions|machine learning research|theoretical prediction|data science|statistical model,
https://openalex.org/W1491178396,"Compilers: Principles, Techniques, and Tools","Compilers: Principles, Techniques, and Tools

1 Introduction 1.1 Language Processors 1.2 The Structure of a Compiler 1.3 Evolution Programming Languages 1.4 Science Building 1.5 Applications Technology 1.6 Basics 1.7 Summary Chapter 1.8 References for 2 A Simple Syntax-Directed Translator 2.1 2.2 Syntax Definition 2.3 Translation 2.4 Parsing 2.5 Expressions 2.6 Lexical Analysis 2.7 Symbol Tables 2.8 Intermediate Code Generation 2.9 3 3.1 Role the Analyzer 3.2 Input Buffering 3.3 Specification Tokens 3.4 Recognition 3.5 Lexical-Analyzer Generator Lex 3.6 Finite Automata 3.7 From Regular to 3.8 Design 3.9 Optimization DFA-Based Pattern Matchers 3.10 3.11 4 4.1 4.2 Context-Free Grammars 4.3 Writing Grammar 4.4 Top-Down 4.5 Bottom-Up 4.6 LR Parsing: 4.7 More Powerful Parsers 4.8 Using Ambiguous 4.9 Parser Generators 4.10 4.11 5 5.1 Definitions 5.2 Evaluation Orders SDD's 5.3 5.4 Schemes 5.5 Implementing L-Attributed 5.6 5.7 6 Intermediate-Code 6.1 Variants Trees 6.2 Three-Address 6.3 Types and Declarations 6.4 6.5 Type Checking 6.6 Control Flow 6.7 Backpatching 6.8 Switch-Statements 6.9 Procedures 6.10 6.11 7 Run-Time Environments 7.1 Storage Organization 7.2 Stack Allocation Space 7.3 Access Nonlocal Data on 7.4 Heap Management 7.5 Garbage Collection 7.6 Trace-Based 7.7 Short-Pause 7.8 Advanced Topics in 7.9 7.10 8 8.1 Issues 8.2 Target 8.3 Addresses 8.4 Basic Blocks Graphs 8.5 8.6 8.7 Peephole 8.8 Register Assignment 8.9 Instruction Selection by Tree Rewriting 8.10 Optimal 8.11 Dynamic Code-Generation 8.12 8.13 9 Machine-Independent Optimizations 9.1 Principal Sources 9.2 Data-Flow 9.3 Foundations 9.4 Constant Propagation 9.5 Partial-Redundancy Elimination 9.6 Loops 9.7 Region-Based 9.8 Symbolic 9.9 9.10 10 Instruction-Level Parallelism 10.1 Processor Architectures 10.2 Code-Scheduling Constraints 10.3 Basic-Block Scheduling 10.4 Global 10.5 Software Pipelining 10.6 10.7 11 Optimizing Locality 11.1 Concepts 11.2 Matrix Multiply: An In-Depth Example 11.3 Iteration Spaces 11.4 Affine Array Indexes 11.5 Reuse 11.6 Data-Dependence 11.7 Finding Synchronization-Free 11.8 Synchronization Between Parallel 11.9 11.10 11.11 Other Uses Transforms 11.12 11.13 12 Interprocedural 12.1 12.2 Why Analysis? 12.3 Logical Representation 12.4 Pointer-Analysis Algorithm 12.5 Context-Insensitive 12.6 Context-Sensitive Pointer 12.7 Datalog Implementation BDD's 12.8 12.9 Complete Front End A.1 Source A.2 Main A.3 A.4 A.5 A.6 Jumping Boolean A.7 Statements A.8 A.9 Creating B Linearly Independent Solutions Index

compiler technology, computer science, computational engineering, software engineering, dynamic compilation, theory of computation, applied mathematics, numerical algorithm, system software, formal technique, software analysis, numerical analysis, program analysis, optimizing compiler, parallelizing compiler, statistical software, computational optimization, computer engineering",1986,8154,compiler technology|computer science|computational engineering|software engineering|dynamic compilation|theory of computation|applied mathematics|numerical algorithm|system software|formal technique|software analysis|numerical analysis|program analysis|optimizing compiler|parallelizing compiler|statistical software|computational optimization|computer engineering,
https://openalex.org/W2042281163,Item-based collaborative filtering recommendation algorithms,"Item-based collaborative filtering recommendation algorithms

Article Share on Item-based collaborative filtering recommendation algorithms Authors: Badrul Sarwar GroupLens Research Group/Army HPC Center, Department of Computer Science and Engineering, University Minnesota, Minneapolis, MN MNView Profile , George Karypis Joseph Konstan John Riedl Authors Info & Claims WWW '01: Proceedings the 10th international conference World Wide WebMay 2001 Pages 285–295https://doi.org/10.1145/371920.372071Online:01 April 2001Publication History 4,816citation29,749DownloadsMetricsTotal Citations4,816Total Downloads29,749Last 12 Months2,414Last 6 weeks183 Get Citation AlertsNew Alert added!This alert has been successfully added will be sent to:You notified whenever a record that you have chosen cited.To manage your preferences, click button below.Manage my Alerts New Alert!Please log in to account Save BinderSave BinderCreate BinderNameCancelCreateExport CitationPublisher SiteGet Access

computer science, recommender system, information filtering system, collaborative filtering, data mining",2001,8152,computer science|recommender system|information filtering system|collaborative filtering|data mining,https://openalex.org/W2171960770|https://openalex.org/W1971040550
https://openalex.org/W2074682976,Variable Selection via Nonconcave Penalized Likelihood and its Oracle Properties,"Variable Selection via Nonconcave Penalized Likelihood and its Oracle Properties

Variable selection is fundamental to high-dimensional statistical modeling, including nonparametric regression. Many approaches in use are stepwise procedures, which can be computationally expensive and ignore stochastic errors the variable process. In this article, penalized likelihood proposed handle these kinds of problems. The methods select variables estimate coefficients simultaneously. Hence they enable us construct confidence intervals for estimated parameters. distinguished from others that penalty functions symmetric, nonconcave on (0, ∞), have singularities at origin produce sparse solutions. Furthermore, should bounded by a constant reduce bias satisfy certain conditions yield continuous A new algorithm optimizing functions. ideas widely applicable. They readily applied variety parametric models such as generalized linear robust regression models. also easily modeling using wavelets splines. Rates convergence estimators established. with proper choice regularization parameters, we show perform well oracle procedure selection; namely, work if correct submodel were known. Our simulation shows newly compare favorably other techniques. standard error formulas tested accurate enough practical applications.

computer science, oracle properties, variable selection",2001,8091,computer science|oracle properties|variable selection,https://openalex.org/W2122825543
https://openalex.org/W2047417387,<scp>genepop</scp>’007: a complete re‐implementation of the <scp>genepop</scp> software for Windows and Linux,"<scp>genepop</scp>’007: a complete re‐implementation of the <scp>genepop</scp> software for Windows and Linux

This note summarizes developments of the genepop software since its first description in 1995, and particular those new to version 4.0: an extended input format, several estimators neighbourhood size under isolation by distance, confidence intervals for null allele frequency, less important extensions previous options. now runs Linux as well Windows, can be entirely controlled batch calls.

computer science, continual improvement process, genetic programming, genome editing, complete re-implementation",2008,8089,computer science|continual improvement process|genetic programming|genome editing|complete re-implementation,
https://openalex.org/W2165744313,Coordination of groups of mobile autonomous agents using nearest neighbor rules,"Coordination of groups of mobile autonomous agents using nearest neighbor rules

In a recent Physical Review Letters article, Vicsek et al. propose simple but compelling discrete-time model of n autonomous agents (i.e., points or particles) all moving in the plane with same speed different headings. Each agent's heading is updated using local rule based on average its own plus headings ""neighbors."" their paper, provide simulation results which demonstrate that nearest neighbor they are studying can cause to eventually move direction despite absence centralized coordination and fact each set neighbors change time as system evolves. This paper provides theoretical explanation for this observed behavior. addition, convergence derived several other similarly inspired models. The proves be graphic example switched linear stable, there does not exist common quadratic Lyapunov function.

mobile autonomous agents, computer science, nearest neighbor rules, active control, collective motion, clustering, swarm robotics, unmanned aerial vehicle, complex system, drone, automatic control, group decision, distributed coordination, multiagent system, group process, swarm intelligence, mobile agent, autonomous agent system",2003,8077,mobile autonomous agents|computer science|nearest neighbor rules|active control|collective motion|clustering|swarm robotics|unmanned aerial vehicle|complex system|drone|automatic control|group decision|distributed coordination|multiagent system|group process|swarm intelligence|mobile agent|autonomous agent system,
https://openalex.org/W2136145671,<tt>BLAT</tt>—The <tt>BLAST</tt>-Like Alignment Tool,"<tt>BLAT</tt>—The <tt>BLAST</tt>-Like Alignment Tool

Analyzing vertebrate genomes requires rapid mRNA/DNA and cross-species protein alignments. A new tool, BLAT, is more accurate 500 times faster than popular existing tools for alignments 50 at sensitivity settings typically used when comparing sequences. BLAT's speed stems from an index of all nonoverlapping K-mers in the genome. This fits inside RAM inexpensive computers, need only be computed once each genome assembly. BLAT has several major stages. It uses to find regions likely homologous query sequence. performs alignment between regions. stitches together these aligned (often exons) into larger (typically genes). Finally, revisits small internal exons possibly missed first stage adjusts large gap boundaries that have canonical splice sites where feasible. paper describes how was optimized. Effects on are explored various K-mer sizes, mismatch schemes, number required matches. compared with other programs test sets then genome-wide applications. http://genome.ucsc.edu hosts a web-based server human

image analysis, pattern recognition, computer science, information fusion, sequence analysis, clustering, data science, molecular biology, deep learning, network analysis, signal recognition, sequence alignment, representation analysis, sequence assembly",2002,8069,image analysis|pattern recognition|computer science|information fusion|sequence analysis|clustering|data science|molecular biology|deep learning|network analysis|signal recognition|sequence alignment|representation analysis|sequence assembly,https://openalex.org/W4247053599|https://openalex.org/W2128016314
https://openalex.org/W2295107390,Learning Deep Features for Discriminative Localization,"Learning Deep Features for Discriminative Localization

In this work, we revisit the global average pooling layer proposed in [13], and shed light on how it explicitly enables convolutional neural network (CNN) to have remarkable localization ability despite being trained imagelevel labels. While technique was previously as a means for regularizing training, find that actually builds generic localizable deep representation exposes implicit attention of CNNs an image. Despite apparent simplicity pooling, are able achieve 37.1% top-5 error object ILSVRC 2014 without training any bounding box annotation. We demonstrate variety experiments our is localize discriminative image regions just solving classification task1.

computer science, feature learning, machine learning, discriminative localization, localization, deep learning, automatic classification, deep features",2016,8054,computer science|feature learning|machine learning|discriminative localization|localization|deep learning|automatic classification|deep features,https://openalex.org/W2962858109
https://openalex.org/W2109488193,Scheduling Algorithms for Multiprogramming in a Hard-Real-Time Environment,"Scheduling Algorithms for Multiprogramming in a Hard-Real-Time Environment

The problem of multiprogram scheduling on a single processor is studied from the viewpoint characteristics peculiar to program functions that need guaranteed service. It shown an optimum fixed priority scheduler possesses upper bound utilization which may be as low 70 percent for large task sets. also full can achieved by dynamically assigning priorities basis their current deadlines. A combination these two techniques discussed.

computer science, hard-real-time environment, scheduling (computing)",1973,8049,computer science|hard-real-time environment|scheduling (computing),
https://openalex.org/W2098162425,An algorithm for suffix stripping,"An algorithm for suffix stripping

The automatic removal of suffixes from words in English is particular interest the field information retrieval. An algorithm for suffix stripping described, which has been implemented as a short, fast program BCPL. Although simple, it performs slightly better than much more elaborate system with compared. It effectively works by treating complex compounds made up simple suffixes, and removing number steps. In each step to depend upon form remaining stem, usually involves measure its syllable length.

computer science, terminology extraction, string-searching algorithm, suffix stripping, data mining, string processing",1980,8028,computer science|terminology extraction|string-searching algorithm|suffix stripping|data mining|string processing,https://openalex.org/W2158899491
https://openalex.org/W2162098634,Primer3—new capabilities and interfaces,"Primer3—new capabilities and interfaces

Polymerase chain reaction (PCR) is a basic molecular biology technique with multiplicity of uses, including deoxyribonucleic acid cloning and sequencing, functional analysis genes, diagnosis diseases, genotyping discovery genetic variants. Reliable primer design crucial for successful PCR, over decade, the open-source Primer3 software has been widely used design, often in high-throughput genomics applications. It also incorporated into numerous publicly available packages web services. During this period, we have greatly expanded Primer3's functionality. In article, describe current capabilities, emphasizing recent improvements. The most notable enhancements incorporate more accurate thermodynamic models process, both to improve melting temperature prediction reduce likelihood that primers will form hairpins or dimers. Additional include precise control placement—a change motivated partly by opportunities use whole-genome sequences specificity. We added features increase ease use, ability save re-use parameter settings require individual not be than one pair. made core code modular provided cleaner programming interfaces further integration other software. These improvements position continued genome-scale data decade ahead.

computer science, novel interface, user interface, interface science",2012,8020,computer science|novel interface|user interface|interface science,
https://openalex.org/W1985588649,"Glide: A New Approach for Rapid, Accurate Docking and Scoring. 1. Method and Assessment of Docking Accuracy","Glide: A New Approach for Rapid, Accurate Docking and Scoring. 1. Method and Assessment of Docking Accuracy

Unlike other methods for docking ligands to the rigid 3D structure of a known protein receptor, Glide approximates complete systematic search conformational, orientational, and positional space docked ligand. In this search, an initial rough positioning scoring phase that dramatically narrows is followed by torsionally flexible energy optimization on OPLS-AA nonbonded potential grid few hundred surviving candidate poses. The very best candidates are further refined via Monte Carlo sampling pose conformation; in some cases, crucial obtaining accurate pose. Selection uses model function combines empirical force-field-based terms. Docking accuracy assessed redocking from 282 cocrystallized PDB complexes starting conformationally optimized ligand geometries bear no memory correctly Errors geometry top-ranked less than 1 Å nearly half cases greater 2 only about one-third them. Comparisons published data rms deviations show twice as GOLD more FlexX having up 20 rotatable bonds. also found be recently described Surflex method.

computer science, aerospace engineering, ultra-low latency, low latency, accurate docking, machine learning, space exploration, dynamic positioning, feedback loop, active control, unmanned aircraft system, systems engineering, performance metric, performance evaluation, numerical simulation, drone, unmanned aerial vehicle",2004,7970,computer science|aerospace engineering|ultra-low latency|low latency|accurate docking|machine learning|space exploration|dynamic positioning|feedback loop|active control|unmanned aircraft system|systems engineering|performance metric|performance evaluation|numerical simulation|drone|unmanned aerial vehicle,
https://openalex.org/W2170102584,RADAR: an in-building RF-based user location and tracking system,"RADAR: an in-building RF-based user location and tracking system

The proliferation of mobile computing devices and local-area wireless networks has fostered a growing interest in location-aware systems services. In this paper we present RADAR, radio-frequency (RF)-based system for locating tracking users inside buildings. RADAR operates by recording processing signal strength information at multiple base stations positioned to provide overlapping coverage the area interest. It combines empirical measurements with propagation modeling determine user location thereby enable services applications. We experimental results that demonstrate ability estimate high degree accuracy.

location awareness, computer science, radar, localization, systems engineering, communications system, rf localization, location tracking, positioning system, indoor positioning system, wireless sensor network, computer engineering",2002,7969,location awareness|computer science|radar|localization|systems engineering|communications system|rf localization|location tracking|positioning system|indoor positioning system|wireless sensor network|computer engineering,
https://openalex.org/W2154652894,ROUGE: A Package for Automatic Evaluation of Summaries,"ROUGE: A Package for Automatic Evaluation of Summaries

ROUGE stands for Recall-Oriented Understudy Gisting Evaluation. It includes measures to automatically determine the quality of a summary by comparing it other (ideal) summaries created humans. The count number overlapping units such as n-gram, word sequences, and pairs between computer-generated be evaluated ideal This paper introduces four different measures: ROUGE-N, ROUGE-L, ROUGE-W, ROUGE-S included in summarization evaluation package their evaluations. Three them have been used Document Understanding Conference (DUC) 2004, large-scale sponsored NIST.

computer science, knowledge representation and reasoning, text mining, natural language processing, method validation, automated assessment, semantic evaluation, data science, entity summarization, program evaluation, machine learning research, automatic summarization, automatic annotation tool, information retrieval, knowledge management, automatic evaluation",2004,7904,computer science|knowledge representation and reasoning|text mining|natural language processing|method validation|automated assessment|semantic evaluation|data science|entity summarization|program evaluation|machine learning research|automatic summarization|automatic annotation tool|information retrieval|knowledge management|automatic evaluation,
https://openalex.org/W2101927907,An introduction to computing with neural nets,"An introduction to computing with neural nets

Artificial neural net models have been studied for many years in the hope of achieving human-like performance fields speech and image recognition. These are composed nonlinear computational elements operating parallel arranged patterns reminiscent biological nets. Computational or nodes connected via weights that typically adapted during use to improve performance. There has a recent resurgence field artificial nets caused by new topologies algorithms, analog VLSI implementation techniques, belief massive parallelism is essential high This paper provides an introduction reviewing six important can be used pattern classification. highly building blocks illustrate components design principles construct more complex systems. In addition describing these nets, major emphasis placed on exploring how some existing classification clustering algorithms performed using simple neuron-like components. Single-layer implement required Gaussian maximum-likelihood classifiers optimum minimum-error binary corrupted noise. More generally, decision regions any algorithm generated straightforward manner three-layer feed-forward

computer science, artificial intelligence, intelligent computing, neural nets, brain-like computing, machine learning, recurrent neural network, neural computation, computational intelligence, deep learning, machine learning research, neural network (machine learning)",1987,7900,computer science|artificial intelligence|intelligent computing|neural nets|brain-like computing|machine learning|recurrent neural network|neural computation|computational intelligence|deep learning|machine learning research|neural network (machine learning),
https://openalex.org/W2125389028,Conditional Generative Adversarial Nets,"Conditional Generative Adversarial Nets

Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of adversarial nets, which can be constructed by simply feeding data, y, wish condition on both generator and discriminator. We show that model generate MNIST digits conditioned class labels. also illustrate how could used learn multi-modal model, provide preliminary examples an application image tagging in demonstrate approach descriptive tags are not part training

adversarial machine learning, computer science, generative adversarial network, machine learning, generative model, generative ai, generative system, deep learning, machine learning research, neural network (machine learning)",2014,7898,adversarial machine learning|computer science|generative adversarial network|machine learning|generative model|generative ai|generative system|deep learning|machine learning research|neural network (machine learning),https://openalex.org/W2963073614
https://openalex.org/W1560724230,Learning with Kernels,"Learning with Kernels

A comprehensive introduction to Support Vector Machines and related kernel methods. In the 1990s, a new type of learning algorithm was developed, based on results from statistical theory: Machine (SVM). This gave rise class theoretically elegant machines that use central concept SVMs—-kernels—for number tasks. Kernel provide modular framework can be adapted different tasks domains by choice function base algorithm. They are replacing neural networks in variety fields, including engineering, information retrieval, bioinformatics. Learning with Kernels provides an SVMs Although book begins basics, it also includes latest research. It all concepts necessary enable reader equipped some basic mathematical knowledge enter world machine using well-founded yet easy-to-use algorithms understand apply powerful have been developed over last few years.

kernel method, computer science, computational learning theory, supervised learning, machine learning, neural computation, computational intelligence, deep learning, knowledge discovery, machine learning research, markov kernel, reproducing kernel method, neural network (machine learning)",2018,7885,kernel method|computer science|computational learning theory|supervised learning|machine learning|neural computation|computational intelligence|deep learning|knowledge discovery|machine learning research|markov kernel|reproducing kernel method|neural network (machine learning),https://openalex.org/W2153233077
https://openalex.org/W2560609797,PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation

Point cloud is an important type of geometric data structure. Due to its irregular format, most researchers transform such regular 3D voxel grids or collections images. This, however, renders unnecessarily voluminous and causes issues. In this paper, we design a novel neural network that directly consumes point clouds, which well respects the permutation invariance points in input. Our network, named PointNet, provides unified architecture for applications ranging from object classification, part segmentation, scene semantic parsing. Though simple, PointNet highly efficient effective. Empirically, it shows strong performance on par even better than state art. Theoretically, provide analysis towards understanding what has learnt why robust with respect input perturbation corruption.

pattern recognition, computer science, point sets, multi-view geometry, machine learning, visual science, image analysis, information fusion, scene modeling, cognitive science, data science, computational imaging, localization, deep learning, 3d object recognition, machine vision, 3d computer vision, 3d vision, computer vision",2017,7870,pattern recognition|computer science|point sets|multi-view geometry|machine learning|visual science|image analysis|information fusion|scene modeling|cognitive science|data science|computational imaging|localization|deep learning|3d object recognition|machine vision|3d computer vision|3d vision|computer vision,
https://openalex.org/W2131774270,Bidirectional recurrent neural networks,"Bidirectional recurrent neural networks

In the first part of this paper, a regular recurrent neural network (RNN) is extended to bidirectional (BRNN). The BRNN can be trained without limitation using input information just up preset future frame. This accomplished by training it simultaneously in positive and negative time direction. Structure procedure proposed are explained. regression classification experiments on artificial data, structure gives better results than other approaches. For real for phonemes from TIMIT database show same tendency. second shown how easily modified allow efficient estimation conditional posterior probability complete symbol sequences making any explicit assumption about shape distribution. part, data reported.

computer science, machine learning, recurrent neural network, neural computation, computational neuroscience, deep learning, neural network (machine learning)",1997,7843,computer science|machine learning|recurrent neural network|neural computation|computational neuroscience|deep learning|neural network (machine learning),https://openalex.org/W2964308564|https://openalex.org/W2143612262
https://openalex.org/W2159024459,k-ANONYMITY: A MODEL FOR PROTECTING PRIVACY,"k-ANONYMITY: A MODEL FOR PROTECTING PRIVACY

Consider a data holder, such as hospital or bank, that has privately held collection of person-specific, field structured data. Suppose the holder wants to share version with researchers. How can release its private scientific guarantees individuals who are subjects cannot be re-identified while remain practically useful? The solution provided in this paper includes formal protection model named k-anonymity and set accompanying policies for deployment. A provides if information each person contained distinguished from at least k-1 whose also appears release. This examines re-identification attacks realized on releases adhere unless respected. is important because it forms basis which real-world systems known Datafly, μ-Argus k-Similar provide privacy protection.

computer science, information technology, privacy issue, usable privacy, information policy, data privacy, privacy-preserving communication, privacy management, privacy system, privacy protection",2002,7838,computer science|information technology|privacy issue|usable privacy|information policy|data privacy|privacy-preserving communication|privacy management|privacy system|privacy protection,
https://openalex.org/W2056370875,Image Denoising by Sparse 3-D Transform-Domain Collaborative Filtering,"Image Denoising by Sparse 3-D Transform-Domain Collaborative Filtering

We propose a novel image denoising strategy based on an enhanced sparse representation in transform domain. The enhancement of the sparsity is achieved by grouping similar 2D fragments (e.g., blocks) into 3D data arrays which we call ""groups."" Collaborative Altering special procedure developed to deal with these groups. realize it using three successive steps: transformation group, shrinkage spectrum, and inverse transformation. result estimate that consists jointly filtered grouped blocks. By attenuating noise, collaborative filtering reveals even finest details shared blocks and, at same time, preserves essential unique features each individual block. are then returned their original positions. Because overlapping, for pixel, obtain many different estimates need be combined. Aggregation particular averaging exploited take advantage this redundancy. A significant improvement obtained specially Wiener filtering. An algorithm its efficient implementation presented full detail; extension color-image also developed. experimental results demonstrate computationally scalable achieves state-of-the-art performance terms both peak signal-to-noise ratio subjective visual quality.

digital image processing, computer vision, sparse representation, computational imaging, computer science, image denoising, image representation, image analysis",2007,7824,digital image processing|computer vision|sparse representation|computational imaging|computer science|image denoising|image representation|image analysis,https://openalex.org/W2963091558|https://openalex.org/W2508457857
https://openalex.org/W1519266993,MUSCLE: a multiple sequence alignment method with reduced time and space complexity.,"MUSCLE: a multiple sequence alignment method with reduced time and space complexity.

Abstract Background In a previous paper, we introduced MUSCLE, new program for creating multiple alignments of protein sequences, giving brief summary the algorithm and showing MUSCLE to achieve highest scores reported date on four alignment accuracy benchmarks. Here present more complete discussion algorithm, describing several previously unpublished techniques that improve biological / or computational complexity. We introduce option, MUSCLE-fast, designed high-throughput applications. also describe protocol evaluating objective functions align two profiles. Results compare speed with CLUSTALW, Progressive POA MAFFT script FFTNS1, fastest published known author. Accuracy is measured using benchmarks: BAliBASE, PREFAB, SABmark SMART. test three variants offer (MUSCLE default settings), (MUSCLE-fast), carefully chosen compromise between (MUSCLE-prog). find MUSCLE-fast be all sets, achieving average similar CLUSTALW in times are typically orders magnitude less. able 1,000 sequences length 282 21 seconds current desktop computer. Conclusions offers range options provide improved compared currently available programs. freely at http://www.drive5.com/muscle .

computer science, reduced time, sequence analysis, kinesiology, machine learning, biostatistics, deep learning, sequence assembly, sequence alignment, space complexity, bioinformatics",2004,7814,computer science|reduced time|sequence analysis|kinesiology|machine learning|biostatistics|deep learning|sequence assembly|sequence alignment|space complexity|bioinformatics,
https://openalex.org/W2091257550,The Grid 2: Blueprint for a New Computing Infrastructure,"The Grid 2: Blueprint for a New Computing Infrastructure

Preface Foreword 1. Grids in Context 2. Computational I Applications 3 Distributed Supercomputing 4 Real-Time Widely Instrumentation Systems 5 Data-Intensive Computing 6 Teleimmersion II Programming Tools 7 Application-Specific 8 Compilers, Languages, and Libraries 9 Object-Based Approaches 10 High-Performance Commodity III Services 11 The Globus Toolkit 12 Schedulers 13 High-Throughput Resource Management 14 Measurement 15 Performance Analysis Visualization 16 Security, Accounting, Assurance IV Infrastructure 17 Platforms 18 Network Protocols 19 Quality of Service 20 Operating Interfaces 21 22 Testbed Bridges from Research to Glossary Bibliography Contributor Biographies

computer science, infrastructure engineering, smart grid, technology, computational infrastructure, grid network, simulation infrastructure, computer architecture, modeling and simulation, grid computing, architecture, grid application, scalability, high performance computer architecture, cluster computing",1998,7787,computer science|infrastructure engineering|smart grid|technology|computational infrastructure|grid network|simulation infrastructure|computer architecture|modeling and simulation|grid computing|architecture|grid application|scalability|high performance computer architecture|cluster computing,https://openalex.org/W2154010459
https://openalex.org/W2118246710,SLIC Superpixels Compared to State-of-the-Art Superpixel Methods,"SLIC Superpixels Compared to State-of-the-Art Superpixel Methods

Computer vision applications have come to rely increasingly on superpixels in recent years, but it is not always clear what constitutes a good superpixel algorithm. In an effort understand the benefits and drawbacks of existing methods, we empirically compare five state-of-the-art algorithms for their ability adhere image boundaries, speed, memory efficiency, impact segmentation performance. We then introduce new algorithm, simple linear iterative clustering (SLIC), which adapts k-means approach efficiently generate superpixels. Despite its simplicity, SLIC adheres boundaries as well or better than previous methods. At same time, faster more efficient, improves performance, straightforward extend supervoxel generation.

image analysis, pattern recognition, computer science, computational imaging, super-resolution imaging, spatial filtering, computer vision, single-image super-resolution, slic superpixels, image representation, image resolution, shift detection, machine vision, digital image processing",2012,7770,image analysis|pattern recognition|computer science|computational imaging|super-resolution imaging|spatial filtering|computer vision|single-image super-resolution|slic superpixels|image representation|image resolution|shift detection|machine vision|digital image processing,
https://openalex.org/W2143612262,Speech recognition with deep recurrent neural networks,"Speech recognition with deep recurrent neural networks

Recurrent neural networks (RNNs) are a powerful model for sequential data. End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs sequence labelling problems where the input-output alignment is unknown. The combination of these with Long Short-term Memory RNN architecture has proved particularly fruitful, delivering state-of-the-art results in cursive handwriting recognition. However performance speech recognition so far been disappointing, better returned by deep feedforward networks. This paper investigates recurrent networks, which combine multiple levels representation that have effective flexible use long range context empowers RNNs. When trained end-to-end suitable regularisation, we find achieve test set error 17.7% on TIMIT phoneme benchmark, our knowledge best recorded score.

spoken language technology, linguistics, computer science, machine learning, language learning, speech recognition, acoustic modeling, neural network (machine learning), speaker recognition, recurrent neural network, deep learning, speech processing, speech communication, speech technology, voice recognition, cognitive science, language model",2013,7729,spoken language technology|linguistics|computer science|machine learning|language learning|speech recognition|acoustic modeling|neural network (machine learning)|speaker recognition|recurrent neural network|deep learning|speech processing|speech communication|speech technology|voice recognition|cognitive science|language model,https://openalex.org/W1832693441|https://openalex.org/W1924770834|https://openalex.org/W2963857521
https://openalex.org/W2170747616,CD-HIT: accelerated for clustering the next-generation sequencing data,"CD-HIT: accelerated for clustering the next-generation sequencing data

CD-HIT is a widely used program for clustering biological sequences to reduce sequence redundancy and improve the performance of other analyses. In response rapid increase in amount sequencing data produced by next-generation technologies, we have developed new accelerated with novel parallelization strategy some techniques allow efficient such datasets. Our tests demonstrated very good speedup derived from up ∼24 cores quasi-linear ∼8 cores. The enhanced capable handling large datasets much shorter time than previous versions.http://cd-hit.org.liwz@sdsc.eduSupplementary are available at Bioinformatics online.

computer science, computational genomics, clustering, machine learning, next-generation sequencing data, next-generation sequencing, biostatistics, data science, computational biology, genomics, large-scale datasets, high throughput sequencing, sequence alignment, bioinformatics",2012,7726,computer science|computational genomics|clustering|machine learning|next-generation sequencing data|next-generation sequencing|biostatistics|data science|computational biology|genomics|large-scale datasets|high throughput sequencing|sequence alignment|bioinformatics,
https://openalex.org/W2162915993,Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories,"Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories

This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting ""spatial pyramid"" is simple computationally efficient extension an orderless bag-of-features representation, it shows significantly improved performance challenging categorization tasks. Specifically, our proposed exceeds state art Caltech-101 database achieves high accuracy large fifteen natural categories. spatial pyramid framework also offers insights success several recently descriptions, including Torralba's ""gist"" Lowe's SIFT descriptors.

pattern recognition, computer science, spatial pyramid, machine learning, image analysis, information fusion, cognitive science, object detection, data science, image representation, computational imaging, scene understanding, localization, deep learning, machine vision, natural scene categories, object recognition, scene interpretation, computer vision, image classification",2006,7696,pattern recognition|computer science|spatial pyramid|machine learning|image analysis|information fusion|cognitive science|object detection|data science|image representation|computational imaging|scene understanding|localization|deep learning|machine vision|natural scene categories|object recognition|scene interpretation|computer vision|image classification,https://openalex.org/W1536680647|https://openalex.org/W2412782625|https://openalex.org/W2560023338|https://openalex.org/W2109255472|https://openalex.org/W2295107390|https://openalex.org/W3018757597|https://openalex.org/W1983364832
https://openalex.org/W2118020653,Machine learning in automated text categorization,"Machine learning in automated text categorization

The automated categorization (or classification) of texts into predefined categories has witnessed a booming interest in the last 10 years, due to increased availability documents digital form and ensuing need organize them. In research community dominant approach this problem is based on machine learning techniques: general inductive process automatically builds classifier by learning, from set preclassified documents, characteristics categories. advantages over knowledge engineering (consisting manual definition domain experts) are very good effectiveness, considerable savings terms expert labor power, straightforward portability different domains. This survey discusses main approaches text that fall within paradigm. We will discuss detail issues pertaining three problems, namely, document representation, construction, evaluation.

computer science, text mining, natural language processing, automated text categorization, machine learning, text segmentation, automatic classification, automated machine learning",2002,7691,computer science|text mining|natural language processing|automated text categorization|machine learning|text segmentation|automatic classification|automated machine learning,https://openalex.org/W2250539671|https://openalex.org/W2097726431
https://openalex.org/W2140199336,Overview of the H.264/AVC video coding standard,"Overview of the H.264/AVC video coding standard

H.264/AVC is newest video coding standard of the ITU-T Video Coding Experts Group and ISO/IEC Moving Picture Group. The main goals standardization effort have been enhanced compression performance provision a ""network-friendly"" representation addressing ""conversational"" (video telephony) ""nonconversational"" (storage, broadcast, or streaming) applications. has achieved significant improvement in rate-distortion efficiency relative to existing standards. This article provides an overview technical features H.264/AVC, describes profiles applications for standard, outlines history process.

video adaptation, computer science, video coding format, video quality",2003,7676,video adaptation|computer science|video coding format|video quality,https://openalex.org/W2146395539
https://openalex.org/W2165874743,On Spectral Clustering: Analysis and an algorithm,"On Spectral Clustering: Analysis and an algorithm

Despite many empirical successes of spectral clustering methods— algorithms that cluster points using eigenvectors matrices derived from the data—there are several unresolved issues. First. there a wide variety use in slightly different ways. Second, these have no proof they will actually compute reasonable clustering. In this paper, we present simple algorithm can be implemented few lines Matlab. Using tools matrix perturbation theory, analyze algorithm, and give conditions under which it expected to do well. We also show surprisingly good experimental results on number challenging problems.

computer science, dimensionality reduction, clustering, data science, spectral theory, spectral clustering, statistics, machine learning research, spectral analysis",2001,7646,computer science|dimensionality reduction|clustering|data science|spectral theory|spectral clustering|statistics|machine learning research|spectral analysis,https://openalex.org/W2097308346
https://openalex.org/W2107726111,Reinforcement Learning: A Survey,"Reinforcement Learning: A Survey

This paper surveys the field of reinforcement learning from a computer-science perspective. It is written to be accessible researchers familiar with machine learning. Both historical basis and broad selection current work are summarized. Reinforcement problem faced by an agent that learns behavior through trial-and-error interactions dynamic environment. The described here has resemblance in psychology, but differs considerably details use word ``reinforcement.'' discusses central issues learning, including trading off exploration exploitation, establishing foundations via Markov decision theory, delayed reinforcement, constructing empirical models accelerate making generalization hierarchy, coping hidden state. concludes survey some implemented systems assessment practical utility methods for

computer science, machine learning, deep reinforcement learning, reinforcement learning, artificial intelligence, sequential decision making, machine learning research, multi-agent learning, statistics, data science, deep learning",1996,7629,computer science|machine learning|deep reinforcement learning|reinforcement learning|artificial intelligence|sequential decision making|machine learning research|multi-agent learning|statistics|data science|deep learning,https://openalex.org/W2154929945
https://openalex.org/W2108834246,A public key cryptosystem and a signature scheme based on discrete logarithms,"A public key cryptosystem and a signature scheme based on discrete logarithms

A new signature scheme is proposed, together with an implementation of the Diffie-Hellman key distribution that achieves a public cryptosystem. The security both systems relies on difficulty computing discrete logarithms over finite fields.

computer science, information security, cryptography, computer security, information theoretic security, public key infrastructure, digital signature, data security, public key algorithm, public key cryptosystem, signature scheme, discrete logarithms, cryptosystem",1985,7606,computer science|information security|cryptography|computer security|information theoretic security|public key infrastructure|digital signature|data security|public key algorithm|public key cryptosystem|signature scheme|discrete logarithms|cryptosystem,https://openalex.org/W2031533839
https://openalex.org/W2173248099,Continuous control with deep reinforcement learning,"Continuous control with deep reinforcement learning

We adapt the ideas underlying success of Deep Q-Learning to continuous action domain. present an actor-critic, model-free algorithm based on deterministic policy gradient that can operate over spaces. Using same learning algorithm, network architecture and hyper-parameters, our robustly solves more than 20 simulated physics tasks, including classic problems such as cartpole swing-up, dexterous manipulation, legged locomotion car driving. Our is able find policies whose performance competitive with those found by a planning full access dynamics domain its derivatives. further demonstrate for many tasks learn end-to-end: directly from raw pixel inputs.

computer science, control system, stochastic control, real-time control, deep reinforcement learning, intelligent control, control optimization, robot learning, active control, neural computation, reinforcement learning, deep learning, automatic control, continuous control, learning control, neural network (machine learning)",2015,7589,computer science|control system|stochastic control|real-time control|deep reinforcement learning|intelligent control|control optimization|robot learning|active control|neural computation|reinforcement learning|deep learning|automatic control|continuous control|learning control|neural network (machine learning),
https://openalex.org/W2106334424,Multiobjective evolutionary algorithms: a comparative case study and the strength Pareto approach,"Multiobjective evolutionary algorithms: a comparative case study and the strength Pareto approach

Evolutionary algorithms (EAs) are often well-suited for optimization problems involving several, conflicting objectives. Since 1985, various evolutionary approaches to multiobjective have been developed that capable of searching multiple solutions concurrently in a single run. However, the few comparative studies different methods presented up now remain mostly qualitative and restricted approaches. In this paper, four EAs compared quantitatively where an extended 0/1 knapsack problem is taken as basis. Furthermore, we introduce new approach multicriteria optimization, strength Pareto EA (SPEA), combines several features previous unique manner. It characterized by (a) storing nondominated externally second, continuously updated population, (b) evaluating individual's fitness dependent on number external points dominate it, (c) preserving population diversity using dominance relationship, (d) incorporating clustering procedure order reduce set without destroying its characteristics. The proof-of-principle results obtained two artificial well larger problem, synthesis digital hardware-software multiprocessor system, suggest SPEA can be very effective sampling from along entire Pareto-optimal front distributing generated over tradeoff surface. Moreover, clearly outperforms other problem.

computer science, multiobjective evolutionary algorithms, comparative case study, evolutionary computation, case study",1999,7581,computer science|multiobjective evolutionary algorithms|comparative case study|evolutionary computation|case study,https://openalex.org/W2143381319
https://openalex.org/W2963207607,Explaining and Harnessing Adversarial Examples,"Explaining and Harnessing Adversarial Examples

Abstract: Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that perturbed input results in model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead primary cause of networks' vulnerability perturbation is their linear nature. This explanation supported new quantitative while giving first most intriguing fact about them: generalization across architectures training sets. Moreover, view yields a simple fast method generating examples. Using approach provide for training, we reduce test set error maxout network MNIST dataset.

adversarial machine learning, computer science, artificial intelligence, explainable ai, scene interpretation, machine learning, adversarial examples",2015,7573,adversarial machine learning|computer science|artificial intelligence|explainable ai|scene interpretation|machine learning|adversarial examples,https://openalex.org/W2954996726
https://openalex.org/W2154929945,Ant colony system: a cooperative learning approach to the traveling salesman problem,"Ant colony system: a cooperative learning approach to the traveling salesman problem

This paper introduces the ant colony system (ACS), a distributed algorithm that is applied to traveling salesman problem (TSP). In ACS, set of cooperating agents called ants cooperate find good solutions TSPs. Ants using an indirect form communication mediated by pheromone they deposit on edges TSP graph while building solutions. We study ACS running experiments understand its operation. The results show outperforms other nature-inspired algorithms such as simulated annealing and evolutionary computation, we conclude comparing ACS-3-opt, version augmented with local search procedure, some best performing for symmetric asymmetric

computer science, ant colony system, cooperative learning, salesman problem, ant colony optimization, multi-agent learning, multiagent system",1997,7559,computer science|ant colony system|cooperative learning|salesman problem|ant colony optimization|multi-agent learning|multiagent system,https://openalex.org/W2154929945
https://openalex.org/W2054692642,What Will 5G Be?,"What Will 5G Be?

What will 5G be? it not be is an incremental advance on 4G. The previous four generations of cellular technology have each been a major paradigm shift that has broken backward compatibility. Indeed, need to includes very high carrier frequencies with massive bandwidths, extreme base station and device densities, unprecedented numbers antennas. However, unlike the generations, also highly integrative: tying any new air interface spectrum together LTE WiFi provide universal high-rate coverage seamless user experience. To support this, core network reach levels flexibility intelligence, regulation rethought improved, energy cost efficiencies become even more critical considerations. This paper discusses all these topics, identifying key challenges for future research preliminary standardization activities, while providing comprehensive overview current literature, in particular papers appearing this special issue.

distributed system, next generation internet, computer science, mobile computing, technology, wireless network, wireless communication, 5g system, communication, 5g network slicing, mobile communication, field programmable gate array, internet of things, communications system, next generation computing, telecommunication network, cellular network, drone",2014,7549,distributed system|next generation internet|computer science|mobile computing|technology|wireless network|wireless communication|5g system|communication|5g network slicing|mobile communication|field programmable gate array|internet of things|communications system|next generation computing|telecommunication network|cellular network|drone,
https://openalex.org/W4311415873,Auto-Encoding Variational Bayes,"Auto-Encoding Variational Bayes

How can we perform efficient inference and learning in directed probabilistic models, the presence of continuous latent variables with intractable posterior distributions, large datasets? We introduce a stochastic variational algorithm that scales to datasets and, under some mild differentiability conditions, even works case. Our contributions are two-fold. First, show reparameterization lower bound yields estimator be straightforwardly optimized using standard gradient methods. Second, for i.i.d. per datapoint, made especially by fitting an approximate model (also called recognition model) proposed estimator. Theoretical advantages reflected experimental results.

computer science, bayesian analysis, auto-encoding variational bayes, variational analysis",2013,7544,computer science|bayesian analysis|auto-encoding variational bayes|variational analysis,https://openalex.org/W2962793481|https://openalex.org/W2962770929
https://openalex.org/W4233857083,Marching cubes: A high resolution 3D surface construction algorithm,"Marching cubes: A high resolution 3D surface construction algorithm

We present a new algorithm, called marching cubes , that creates triangle models of constant density surfaces from 3D medical data. Using divide-and-conquer approach to generate inter-slice connectivity, we create case table defines topology. The algorithm processes the data in scan-line order and calculates vertices using linear interpolation. find gradient original data, normalize it, use it as basis for shading models. detail images produced generated surface is result maintaining information Results computed tomography (CT), magnetic resonance (MR), single-photon emission (SPECT) illustrate quality functionality . also discuss improvements decrease processing time add solid modeling capabilities.

numerical simulation, geometric modeling, computer science, computational geometry, computer-aided design, geometry processing, 3d printing, finite element method, surface construction algorithm, deformation, surface modeling, 3d modeling, 3d reconstruction",1987,7537,numerical simulation|geometric modeling|computer science|computational geometry|computer-aided design|geometry processing|3d printing|finite element method|surface construction algorithm|deformation|surface modeling|3d modeling|3d reconstruction,https://openalex.org/W2124026197
https://openalex.org/W3018757597,YOLOv4: Optimal Speed and Accuracy of Object Detection,"YOLOv4: Optimal Speed and Accuracy of Object Detection

There are a huge number of features which said to improve Convolutional Neural Network (CNN) accuracy. Practical testing combinations such on large datasets, and theoretical justification the result, is required. Some operate certain models exclusively for problems exclusively, or only small-scale datasets; while some features, as batch-normalization residual-connections, applicable majority models, tasks, datasets. We assume that universal include Weighted-Residual-Connections (WRC), Cross-Stage-Partial-connections (CSP), Cross mini-Batch Normalization (CmBN), Self-adversarial-training (SAT) Mish-activation. use new features: WRC, CSP, CmBN, SAT, Mish activation, Mosaic data augmentation, DropBlock regularization, CIoU loss, combine them achieve state-of-the-art results: 43.5% AP (65.7% AP50) MS COCO dataset at realtime speed ~65 FPS Tesla V100. Source code https://github.com/AlexeyAB/darknet

image analysis, pattern recognition, computer science, object tracking, object recognition, real-time operation, computer vision, machine learning, object detection, data science, moving object tracking, deep learning, optimal speed, machine vision",2020,7532,image analysis|pattern recognition|computer science|object tracking|object recognition|real-time operation|computer vision|machine learning|object detection|data science|moving object tracking|deep learning|optimal speed|machine vision,https://openalex.org/W3138516171
https://openalex.org/W2006546769,The file drawer problem and tolerance for null results.,"The file drawer problem and tolerance for null results.

For any given research area, one cannot tell how many studies have been conducted but never reported. The extreme view of the file drawer problem is that journals are filled with 5% show Type I errors, while drawers 95% nonsignificant results. Quantitative procedures for computing tolerance filed and future null results reported illustrated, implications discussed. (15 ref) (PsycINFO Database Record (c) 2012 APA, all rights reserved)

computer science, file drawer problem",1979,7498,computer science|file drawer problem,
https://openalex.org/W2158940042,Ideal spatial adaptation by wavelet shrinkage,"Ideal spatial adaptation by wavelet shrinkage

SUMMARY With ideal spatial adaptation, an oracle furnishes information about how best to adapt a spatially variable estimator, whether piecewise constant, polynomial, knot spline, or bandwidth kernel, the unknown function. Estimation with aid of offers dramatic advantages over traditional linear estimation by nonadaptive kernels; however, it is priori unclear such performance can be obtained procedure relying on data alone. We describe new principle for spatially-adaptive estimation: selective wavelet reconstruction. show that variable-knot spline fits and piecewise-polynomial fits, when equipped select knots, are not dramatically more powerful than reconstruction oracle. develop practical adaptive method, RiskShrink, which works shrinkage empirical coefficients. RiskShrink mimics as well possible do so. A inequality in multivariate normal decision theory we call shows attained differs from at most factor approximately 2 log n, where n sample size. Moreover no estimator give better guarantee this. Within class procedures, essentially optimal. Relying only data, comes within polynomial variableknot methods In contrast, if could made function this denied access forced rely

digital image processing, space-time processing, pattern recognition, computational imaging, information fusion, neuroscience, wavelet shrinkage, digital signal processing, computer science, adaptation, domain adaptation, multimodal signal processing, wavelet, geography, spatial filtering, statistical signal processing, ideal spatial adaptation, image analysis",1994,7497,digital image processing|space-time processing|pattern recognition|computational imaging|information fusion|neuroscience|wavelet shrinkage|digital signal processing|computer science|adaptation|domain adaptation|multimodal signal processing|wavelet|geography|spatial filtering|statistical signal processing|ideal spatial adaptation|image analysis,https://openalex.org/W2034139177|https://openalex.org/W2074682976
https://openalex.org/W2099244020,Bilateral filtering for gray and color images,"Bilateral filtering for gray and color images

Bilateral filtering smooths images while preserving edges, by means of a nonlinear combination nearby image values. The method is noniterative, local, and simple. It combines gray levels or colors based on both their geometric closeness photometric similarity, prefers near values to distant in domain range. In contrast with filters that operate the three bands color separately, bilateral filter can enforce perceptual metric underlying CIE-Lab space, smooth preserve edges way tuned human perception. Also, standard filtering, produces no phantom along images, reduces where they appear original image.

image analysis, computational imaging, computer science, color correction, bilateral filtering, image enhancement, computer vision, machine learning, feature detection, image restoration, object detection, color images, machine vision, digital image processing",2002,7491,image analysis|computational imaging|computer science|color correction|bilateral filtering|image enhancement|computer vision|machine learning|feature detection|image restoration|object detection|color images|machine vision|digital image processing,https://openalex.org/W2067191022|https://openalex.org/W2963091558|https://openalex.org/W2097073572
https://openalex.org/W2395611524,Fully Convolutional Networks for Semantic Segmentation,"Fully Convolutional Networks for Semantic Segmentation

Convolutional networks are powerful visual models that yield hierarchies of features. We show convolutional by themselves, trained end-to-end, pixels-to-pixels, improve on the previous best result in semantic segmentation. Our key insight is to build ""fully convolutional"" take input arbitrary size and produce correspondingly-sized output with efficient inference learning. define detail space fully networks, explain their application spatially dense prediction tasks, draw connections prior models. adapt contemporary classification (AlexNet, VGG net, GoogLeNet) into transfer learned representations fine-tuning segmentation task. then a skip architecture combines information from deep, coarse layer appearance shallow, fine accurate detailed segmentations. achieve improved PASCAL VOC (30% relative improvement 67.2% mean IU 2012), NYUDv2, SIFT Flow, PASCAL-Context, while takes one tenth second for typical image.

pattern recognition, computer science, machine learning, image segmentation, image analysis, information fusion, convolutional neural network, convolutional networks, cognitive science, data science, computational imaging, scene understanding, deep learning, machine learning research, machine vision, semantic segmentation, medical image computing, feature extraction, computer vision, scene analysis",2017,7476,pattern recognition|computer science|machine learning|image segmentation|image analysis|information fusion|convolutional neural network|convolutional networks|cognitive science|data science|computational imaging|scene understanding|deep learning|machine learning research|machine vision|semantic segmentation|medical image computing|feature extraction|computer vision|scene analysis,
https://openalex.org/W2112076978,Experiments with a new boosting algorithm,"Experiments with a new boosting algorithm

In an earlier paper, we introduced a new boosting algorithm called AdaBoost which, theoretically, can be used to significantly reduce the error of any learning that con- sistently generates classifiers whose performance is little better than random guessing. We also related notion pseudo-loss which method for forcing multi-label concepts concentrate on labels are hardest discriminate. this describe experiments carried out assess how well with and without pseudo-loss, performs real problems. performed two sets experiments. The first set compared Breiman's bagging when aggregate various (including decision trees single attribute- value tests). methods collection machine-learning benchmarks. second experiments, studied in more detail using nearest-neighbor classifier OCR problem.

computational learning theory, computer science, machine learning, machine learning research",1996,7468,computational learning theory|computer science|machine learning|machine learning research,https://openalex.org/W1678356000|https://openalex.org/W2117812871|https://openalex.org/W2113242816|https://openalex.org/W1983364832
https://openalex.org/W1902237438,Effective Approaches to Attention-based Neural Machine Translation,"Effective Approaches to Attention-based Neural Machine Translation

An attentional mechanism has lately been used to improve neural machine translation (NMT) by selectively focusing on parts of the source sentence during translation.However, there little work exploring useful architectures for attention-based NMT.This paper examines two simple and effective classes mechanism: a global approach which always attends all words local one that only looks at subset time.We demonstrate effectiveness both approaches WMT tasks between English German in directions.With attention, we achieve significant gain 5.0 BLEU points over non-attentional systems already incorporate known techniques such as dropout.Our ensemble model using different attention yields new state-of-the-art result WMT'15 task with 25.9 points, an improvement 1.0 existing best system backed NMT n-gram reranker. 1

language learning, neural computation, natural language processing, machine translation, attention, cognitive science, computational intelligence, computer science, neural machine translation",2015,7464,language learning|neural computation|natural language processing|machine translation|attention|cognitive science|computational intelligence|computer science|neural machine translation,
https://openalex.org/W2135255848,A spreading-activation theory of semantic processing.,"A spreading-activation theory of semantic processing.

This paper presents a spreading-acti vation theory of human semantic processing, which can be applied to wide range recent experimental results. The is based on Quillian's memory search and preparation, or priming. In conjunction with this, several the miscondeptions concerning Qullian's are discussed. A number additional assumptions proposed for his in order apply it experiments. present shows how extended account results production experiments by Loftus, Juola Atkinson's multiple-category experiment, Conrad's sentence-verification experiments, categorization effect relatedness typicality Holyoak Glass, Rips, Shoben, Smith, Rosch. also provides critique Rips model judgments. Some years ago, Quillian1 (1962, 1967) processing that he tried implement computer simulations (Quillian, 1966) comprehension 1969). viewed as activation spreading from two more concept nodes network until an intersection was found. effects preparation (or priming) were explained terms node primed concept. Rather than explain data, designed show build structure into computer.

knowledge representation and reasoning, computer science, semantic representation, semantic similarity, semantic evaluation, semantics, semantic processing, semantic learning, spreading-activation theory, cognitive science, semantic parsing",1975,7433,knowledge representation and reasoning|computer science|semantic representation|semantic similarity|semantic evaluation|semantics|semantic processing|semantic learning|spreading-activation theory|cognitive science|semantic parsing,
https://openalex.org/W2143381319,MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition,"MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition

Decomposition is a basic strategy in traditional multiobjective optimization. However, it has not yet been widely used evolutionary This paper proposes algorithm based on decomposition (MOEA/D). It decomposes optimization problem into number of scalar subproblems and optimizes them simultaneously. Each subproblem optimized by only using information from its several neighboring subproblems, which makes MOEA/D have lower computational complexity at each generation than MOGLS nondominated sorting genetic II (NSGA-II). Experimental results demonstrated that with simple methods outperforms or performs similarly to NSGA-II 0-1 knapsack problems continuous problems. shown objective normalization can deal disparately-scaled objectives, an advanced method generate set very evenly distributed solutions for 3-objective test instances. The ability small population, the scalability sensitivity also experimentally investigated this paper.

evolutionary multimodal optimization, computer science, computational engineering, sequential algorithm, ensemble algorithm, control optimization, mathematical optimization, adaptive algorithm, evolutionary multi-criterion optimization, evolutionary computation, systems engineering, evolution-based method, multiobjective evolutionary algorithm, combinatorial optimization, design optimization, computer engineering",2007,7429,evolutionary multimodal optimization|computer science|computational engineering|sequential algorithm|ensemble algorithm|control optimization|mathematical optimization|adaptive algorithm|evolutionary multi-criterion optimization|evolutionary computation|systems engineering|evolution-based method|multiobjective evolutionary algorithm|combinatorial optimization|design optimization|computer engineering,
https://openalex.org/W2011208902,Entanglement of Formation of an Arbitrary State of Two Qubits,"Entanglement of Formation of an Arbitrary State of Two Qubits

The entanglement of a pure state pair quantum systems is defined as the entropy either member pair. formation mixed $\ensuremath{\rho}$ minimum average an ensemble states that represents \ensuremath{\rho}. An earlier paper conjectured explicit formula for binary objects (qubits) function their density matrix, and proved special states. present extends proof to arbitrary this system shows how construct entanglement-minimizing decompositions.

computer science, quantum algorithm, quantum technology, quantum science, quantum computing, quantum materials, quantum mechanics, quantum information science, quantum entanglement, arbitrary state",1998,7404,computer science|quantum algorithm|quantum technology|quantum science|quantum computing|quantum materials|quantum mechanics|quantum information science|quantum entanglement|arbitrary state,
https://openalex.org/W2166843422,Handbook of Genetic Algorithms,"Handbook of Genetic Algorithms

This book sets out to explain what genetic algorithms are and how they can be used solve real-world problems. The first objective is tackled by the editor, Lawrence Davis. remainder of turned over a series short review articles collection authors, each explaining have been applied problems in their own specific area interest. part introduces fundamental algorithm (GA), explains it has traditionally designed implemented shows basic technique may very simple numerical optimisation problem. then altered refined number ways, with effects change being measured comparison against performance original. In this way, reader provided an uncluttered introduction learns appreciate why certain variants GA become more popular than others scientific community. Davis stresses that choice suitable representation for problem hand key step applying GA, as selection techniques generating new solutions from old. He refreshingly open admitting much business adapting owes art science. It nice see terminology associated subject explained, author stressing field still active research. Few assumptions made about reader's mathematical background. second contains thirteen cameo descriptions algorithmic been, or being, diverse range Thus, one group authors modelling arms races between neighbouring countries (a non- linear, dynamical system), while another describes its use deciding design trade-offs military aircraft. My favourite rather charming account was scheduling Having attempted something sort Simulated Annealing, I found refreshing highlighting some had encountered, sweeping them under carpet so often done literature. editor points there standard tools available either play serious development work. Two these (GENESIS OOGA) described short, third book. As case nowadays, possible obtain diskette containing both systems sending your Visa card details (or $60) address USA.

genetic algorithm, computer science, genetic programming, computational genomics, evolutionary computation, combinatorial optimization, genetic engineering, computational optimization, genetics",1991,7379,genetic algorithm|computer science|genetic programming|computational genomics|evolutionary computation|combinatorial optimization|genetic engineering|computational optimization|genetics,https://openalex.org/W2152195021|https://openalex.org/W2109364787
https://openalex.org/W2964350391,"Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning","Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning

Very deep convolutional networks have been central to the largest advances in image recognition performance recent years. One example is Inception architecture that has shown achieve very good at relatively low computational cost. Recently, introduction of residual connections conjunction with a more traditional yielded state-of-the-art 2015 ILSVRC challenge; its was similar latest generation Inception-v3 network. This raises question: Are there any benefits combining architectures connections? Here we give clear empirical evidence training accelerates significantly. There also some outperforming similarly expensive without by thin margin. We present several new streamlined for both and non-residual networks. These variations improve single-frame on 2012 classification task further demonstrate how proper activation scaling stabilizes wide With an ensemble three one Inception-v4 networks, 3.08% top-5 error test set ImageNet (CLS) challenge.

image analysis, computer science, convolutional neural network, deep reinforcement learning, neuroscience, machine learning, generative adversarial network, recurrent neural network, residual connections, data science, neural computation, deep learning, machine learning research, neural network (machine learning)",2017,7372,image analysis|computer science|convolutional neural network|deep reinforcement learning|neuroscience|machine learning|generative adversarial network|recurrent neural network|residual connections|data science|neural computation|deep learning|machine learning research|neural network (machine learning),https://openalex.org/W2963420686
https://openalex.org/W2100115174,Fundamentals of digital image processing,"Fundamentals of digital image processing

Introduction. 1. Two Dimensional Systems and Mathematical Preliminaries. 2. Image Perception. 3. Sampling Quantization. 4. Transforms. 5. Representation by Stochastic Models. 6. Enhancement. 7. Filtering Restoration. 8. Analysis Computer Vision. 9. Reconstruction From Projections. 10. Data Compression.

image analysis, pattern recognition, computer science, computational imaging, computer vision, digital imaging, image representation, image denoising, digital image processing",1988,7370,image analysis|pattern recognition|computer science|computational imaging|computer vision|digital imaging|image representation|image denoising|digital image processing,
https://openalex.org/W1967073510,"Using SeDuMi 1.02, A Matlab toolbox for optimization over symmetric cones","Using SeDuMi 1.02, A Matlab toolbox for optimization over symmetric cones

Abstract SeDuMi is an add-on for MATLAB, which lets you solve optimization problems with linear, quadratic and semidefiniteness constraints. It possible to have complex valued data variables in SeDuMi. Moreover, large scale are solved efficiently, by exploiting sparsity. This paper describes how work this toolbox. Keywords: Symmetric conesemidefinite programmingsecond order cone programmingself-dualityMATLABSeDuMi *MATLAB a registered trademark of the The Mathworks, Inc. Notes

computer science, engineering optimization, matlab toolbox, convex optimization, global optimization, symmetric cones, mathematical optimization, applied mathematics, optimization problem, combinatorial optimization, conic optimization, design optimization, computational optimization, shape optimization",1999,7370,computer science|engineering optimization|matlab toolbox|convex optimization|global optimization|symmetric cones|mathematical optimization|applied mathematics|optimization problem|combinatorial optimization|conic optimization|design optimization|computational optimization|shape optimization,
https://openalex.org/W1998025025,Collinearity: a review of methods to deal with it and a simulation study evaluating their performance,"Collinearity: a review of methods to deal with it and a simulation study evaluating their performance

Collinearity refers to the non independence of predictor variables, usually in a regression‐type analysis. It is common feature any descriptive ecological data set and can be problem for parameter estimation because it inflates variance regression parameters hence potentially leads wrong identification relevant predictors statistical model. severe when model trained on from one region or time, predicted another with different unknown structure collinearity. To demonstrate reach collinearity ecology, we show how relationships among differ between biomes, change over spatial scales through time. Across disciplines, approaches addressing problems have been developed, ranging clustering predictors, threshold‐based pre‐selection, latent variable methods, shrinkage regularisation. Using simulated five predictor‐response increasing complexity eight levels compared ways address standard multiple machine‐learning approaches. We assessed performance each approach by testing its impact prediction new data. In extreme, tested whether methods were able identify true underlying relationship training dataset strong evaluating test without found that specifically designed collinearity, such as tree based models, did not outperform traditional GLM pre‐selection. Our results highlight value combination penalised (particularly ridge) pre‐selection omitted variables are considered final interpretation. However, all yielded degraded predictions under ‘folk lore’‐thresholds correlation coefficients |r| &gt;0.7 was an appropriate indicator begins severely distort subsequent prediction. The use understanding system pre‐analysis selection choice least sensitive reduce but cannot ultimately solve them.

computer science, simulation study, performance studies, modeling and simulation, systems engineering, case study, performance evaluation, performance comparison, experimental analysis",2012,7345,computer science|simulation study|performance studies|modeling and simulation|systems engineering|case study|performance evaluation|performance comparison|experimental analysis,
https://openalex.org/W3038067977,Quantum cryptography,"Quantum cryptography

Quantum cryptography could well be the first application of quantum mechanics at single-quantum level. The rapid progress in both theory and experiment recent years is reviewed, with emphasis on open questions technological issues.

computer science, quantum algorithm, quantum security, quantum science, cryptography, quantum computing, quantum communication, quantum cryptography, quantum key distribution, quantum information science",2002,7339,computer science|quantum algorithm|quantum security|quantum science|cryptography|quantum computing|quantum communication|quantum cryptography|quantum key distribution|quantum information science,
https://openalex.org/W1816720378,Lisrel 8: Structural Equation Modeling With the Simplis Command Language,"Lisrel 8: Structural Equation Modeling With the Simplis Command Language

This text introduces the SIMPLIS command language for structural equation modelling. It is written students and researchers with limited mathematical statistical training who need to use models analyze their data, those have tried but failed learn LISREL language. not a textbook on factor analysis, equations or latent variable models, although there are many examples of such in book. Rather, it assumed that reader already familiar basic ideas principles these types analyses techniques. The main objective demonstrate modelling can be done easily without technical jargon which has been associated. shifts focus away from question How do it, so concentrate question, What does all mean? Although makes easier specify carry out substantive specification interpretation remain same as

computer science, structural linguistics, structural equation, systems modeling, simulation language, structural optimization, logic in computer science, graph theory, systems biology, simulation modelling, modeling notation, simplis command language, model transformation language, active control, modeling and simulation, systems engineering, numerical simulation, computational engineering, complex modeling, mathematical programming",1993,7335,computer science|structural linguistics|structural equation|systems modeling|simulation language|structural optimization|logic in computer science|graph theory|systems biology|simulation modelling|modeling notation|simplis command language|model transformation language|active control|modeling and simulation|systems engineering|numerical simulation|computational engineering|complex modeling|mathematical programming,
https://openalex.org/W1522734439,Learning Spatiotemporal Features with 3D Convolutional Networks,"Learning Spatiotemporal Features with 3D Convolutional Networks

We propose a simple, yet effective approach for spatiotemporal feature learning using deep 3-dimensional convolutional networks (3D ConvNets) trained on large scale supervised video dataset. Our findings are three-fold: 1) 3D ConvNets more suitable compared to 2D ConvNets, 2) A homogeneous architecture with small 3x3x3 convolution kernels in all layers is among the best performing architectures and 3) learned features, namely C3D (Convolutional 3D), simple linear classifier outperform state-of-the-art methods 4 different benchmarks comparable current other 2 benchmarks. In addition, features compact: achieving 52.8% accuracy UCF101 dataset only 10 dimensions also very efficient compute due fast inference of ConvNets. Finally, they conceptually easy train use.

image analysis, computer science, convolutional neural network, structure from motion, convolutional networks, spatiotemporal features, computer vision, machine learning, spatio-temporal model, data science, deep learning, big spatiotemporal data analytics, machine vision, spatialtemporal reasoning",2015,7330,image analysis|computer science|convolutional neural network|structure from motion|convolutional networks|spatiotemporal features|computer vision|machine learning|spatio-temporal model|data science|deep learning|big spatiotemporal data analytics|machine vision|spatialtemporal reasoning,https://openalex.org/W2963091558|https://openalex.org/W2963524571
https://openalex.org/W2155482699,Training feedforward networks with the Marquardt algorithm,"Training feedforward networks with the Marquardt algorithm

The Marquardt algorithm for nonlinear least squares is presented and incorporated into the backpropagation training feedforward neural networks. tested on several function approximation problems, compared with a conjugate gradient variable learning rate algorithm. It found that much more efficient than either of other techniques when network contains no few hundred weights.

computer science, marquardt algorithm, feedforward networks, machine learning",1994,7302,computer science|marquardt algorithm|feedforward networks|machine learning,
https://openalex.org/W2159498975,Visual pattern recognition by moment invariants,"Visual pattern recognition by moment invariants

In this paper a theory of two-dimensional moment invariants for planar geometric figures is presented. A fundamental theorem established to relate such the well-known algebraic invariants. Complete systems under translation, similitude and orthogonal transformations are derived. Some general linear also included. Both theoretical formulation practical models visual pattern recognition based upon these discussed. simple simulation program together with its performance It shown that geometrical patterns alphabetical characters independently position, size orientation can be accomplished. indicated generalization possible include invariance parallel projection.

image analysis, pattern recognition, computer science, object recognition, computer vision, visual pattern recognition, cognitive science, temporal pattern recognition, visual perception, vision recognition, machine vision, moment invariants",1962,7298,image analysis|pattern recognition|computer science|object recognition|computer vision|visual pattern recognition|cognitive science|temporal pattern recognition|visual perception|vision recognition|machine vision|moment invariants,https://openalex.org/W2130660124
https://openalex.org/W2954996726,A survey on Image Data Augmentation for Deep Learning,"A survey on Image Data Augmentation for Deep Learning

Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these are heavily reliant big data to avoid overfitting. Overfitting refers the phenomenon when a network learns function with very high variance such as perfectly model training data. Unfortunately, application domains do not access data, medical image analysis. This survey focuses Data Augmentation, data-space solution problem of limited Augmentation encompasses suite techniques that enhance size and quality datasets better Learning models can be built using them. The augmentation algorithms discussed in this include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature augmentation, adversarial training, generative networks, style transfer, meta-learning. methods based GANs covered survey. In addition techniques, paper will briefly discuss other characteristics test-time resolution impact, final dataset size, curriculum learning. present existing for promising developments, meta-level decisions implementing Augmentation. Readers understand how improve performance their expand take advantage capabilities

computer science, data augmentation, feature extraction, machine learning, data science, deep learning, image data augmentation, machine learning research, digital image processing",2019,7298,computer science|data augmentation|feature extraction|machine learning|data science|deep learning|image data augmentation|machine learning research|digital image processing,
https://openalex.org/W2124181495,"The Jackknife, the Bootstrap and Other Resampling Plans","The Jackknife, the Bootstrap and Other Resampling Plans

The Jackknife Estimate of Bias Variance the Bootstrap Infinitesimal Delta Method and Influence Function Cross-Validation, Balanced Repeated Replications (Half-Sampling) Random Subsampling Nonparametric Confidence Intervals.

computer science, forecasting, bootstrap resampling, sampling, other resampling plans, machine learning, data science, model refinement, statistics, machine learning research",1982,7279,computer science|forecasting|bootstrap resampling|sampling|other resampling plans|machine learning|data science|model refinement|statistics|machine learning research,
https://openalex.org/W1565377632,Introduction to Data Mining,"Introduction to Data Mining

1 Introduction 1.1 What is Data Mining? 1.2 Motivating Challenges 1.3 The Origins of Mining 1.4 Tasks 1.5 Scope and Organization the Book 1.6 Bibliographic Notes 1.7 Exercises 2 2.1 Types 2.2 Quality 2.3 Preprocessing 2.4 Measures Similarity Dissimilarity 2.5 2.6 3 Exploring 3.1 Iris Set 3.2 Summary Statistics 3.3 Visualization 3.4 OLAP Multidimensional Analysis 3.5 3.6 4 Classification: Basic Concepts, Decision Trees, Model Evaluation 4.1 Preliminaries 4.2 General Approach to Solving a Classification Problem 4.3 Tree Induction 4.4 Overfitting 4.5 Evaluating Performance Classifier 4.6 Methods for Comparing Classifiers 4.7 4.8 5 Alternative Techniques 5.1 Rule-Based 5.2 Nearest-Neighbor 5.3 Bayesian 5.4 Artificial Neural Network (ANN) 5.5 Support Vector Machine (SVM) 5.6 Ensemble 5.7 Class Imbalance 5.8 Multiclass 5.9 5.10 6 Association Analysis: Concepts Algorithms 6.1 Definition 6.2 Frequent Itemset Generation 6.3 Rule 6.4 Compact Representation Itemsets 6.5 Generating 6.6 FP-Growth Algorithm 6.7 Patterns 6.8 Effect Skewed Distribution 6.9 6.10 7 Advanced 7.1 Handling Categorical Attributes 7.2 Continuous 7.3 Concept Hierarchy 7.4 Sequential 7.5 Subgraph 7.6 Infrequent 7.7 7.8 8 Cluster 8.1 Overview 8.2 K-means 8.3 Agglomerative Hierarchical Clustering 8.4 DBSCAN 8.5 8.6 8.7 9 Additional Issues 9.1 Characteristics Data, Clusters, 9.2 Prototype-Based 9.3 Density-Based 9.4 Graph-Based 9.5 Scalable 9.6 Which Algorithm? 9.7 9.8 10 Anomaly Detection 10.1 10.2 Statistical Approaches 10.3 Proximity-Based Outlier 10.4 10.5 Clustering-Based 10.6 10.7 Appendix A Linear Algebra B Dimensionality Reduction C Probability D Regression E Optimization Author Index Subject

predictive analytics, clustering, pattern recognition, knowledge discovery, optimization-based data mining, data mining, pattern mining, data stream mining, computer science, machine learning, frequent pattern mining, classification method, data science",2008,7266,predictive analytics|clustering|pattern recognition|knowledge discovery|optimization-based data mining|data mining|pattern mining|data stream mining|computer science|machine learning|frequent pattern mining|classification method|data science,https://openalex.org/W2122646361
https://openalex.org/W2097308346,Laplacian Eigenmaps for Dimensionality Reduction and Data Representation,"Laplacian Eigenmaps for Dimensionality Reduction and Data Representation

One of the central problems in machine learning and pattern recognition is to develop appropriate representations for complex data. We consider problem constructing a representation data lying on low-dimensional manifold embedded high-dimensional space. Drawing correspondence between graph Laplacian, Laplace Beltrami operator manifold, connections heat equation, we propose geometrically motivated algorithm representing The provides computationally efficient approach nonlinear dimensionality reduction that has locality-preserving properties natural connection clustering. Some potential applications illustrative examples are discussed.

computer science, parameter identification, data modeling, manifold learning, image analysis, information fusion, information visualization, visualization, vector space model, data science, image representation, computational imaging, dimensionality reduction, sparse representation, deep learning, machine learning research, laplacian eigenmaps, clustering, geography",2003,7253,computer science|parameter identification|data modeling|manifold learning|image analysis|information fusion|information visualization|visualization|vector space model|data science|image representation|computational imaging|dimensionality reduction|sparse representation|deep learning|machine learning research|laplacian eigenmaps|clustering|geography,https://openalex.org/W2145962650
https://openalex.org/W2134383396,An Algorithm for Vector Quantizer Design,"An Algorithm for Vector Quantizer Design

An efficient and intuitive algorithm is presented for the design of vector quantizers based either on a known probabilistic model or long training sequence data. The basic properties are discussed demonstrated by examples. Quite general distortion measures blocklengths allowed, as exemplified parameter ten-dimensional vectors arising in Linear Predictive Coded (LPC) speech compression with complicated measure LPC analysis that does not depend only error vector.

computer science, engineering, quantum algorithm, signal processing, vector quantizer design, vector processing, digital signal processing, numerical algorithm, vectorization, quantization (signal processing), digital image processing, quantification, computer engineering",1980,7244,computer science|engineering|quantum algorithm|signal processing|vector quantizer design|vector processing|digital signal processing|numerical algorithm|vectorization|quantization (signal processing)|digital image processing|quantification|computer engineering,
https://openalex.org/W3216401400,Praat: Doing Phonetics by Computer,"Praat: Doing Phonetics by Computer

Ear and Hearing: March 2011 - Volume 32 Issue 2 p 266 doi: 10.1097/AUD.0b013e31821473f7

computer science, linguistics, speech recognition, human-computer interaction, natural language processing, speech processing, language, spoken language processing, speech synthesis, computational linguistics, phonology, speech technology, speech communication, computer-assisted language learning, spoken language technology, phonetics",2011,7194,computer science|linguistics|speech recognition|human-computer interaction|natural language processing|speech processing|language|spoken language processing|speech synthesis|computational linguistics|phonology|speech technology|speech communication|computer-assisted language learning|spoken language technology|phonetics,
https://openalex.org/W2955425717,EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks

Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources available. In this paper, we systematically study model scaling identify that carefully balancing network depth, width, resolution can lead to performance. Based on observation, propose new method uniformly scales all dimensions of depth/width/resolution using simple yet highly effective compound coefficient. We demonstrate the effectiveness MobileNets ResNet. To go even further, use neural architecture search design baseline scale it obtain family models, called EfficientNets, which achieve much efficiency than previous ConvNets. particular, our EfficientNet-B7 achieves state-of-the-art 84.3% top-1 ImageNet, while being 8.4x smaller 6.1x faster inference best existing ConvNet. Our EfficientNets also transfer well CIFAR-100 (91.7%), Flowers (98.8%), 3 other learning datasets, with an order magnitude fewer parameters. Source code is https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.

neural scaling law, neural computation, neural network (machine learning), computer science, convolutional neural network, machine learning, rethinking model, machine learning research, deep learning, data science",2019,7184,neural scaling law|neural computation|neural network (machine learning)|computer science|convolutional neural network|machine learning|rethinking model|machine learning research|deep learning|data science,https://openalex.org/W3138516171|https://openalex.org/W3018757597
https://openalex.org/W2038669746,A Comparison of Three Methods for Selecting Values of Input Variables in the Analysis of Output from a Computer Code,"A Comparison of Three Methods for Selecting Values of Input Variables in the Analysis of Output from a Computer Code

Two types of sampling plans are examined as alternatives to simple random in Monte Carlo studies. These shown be improvements over with respect variance for a class estimators which includes the sample mean and empirical distribution function.

software engineering, applied mathematics, scientific computing, software analysis, computer code, computer engineering, code representation, program evaluation, computer analysis, computer science, software testing, numerical analysis, source code analysis, input-output analysis, static program analysis, program analysis, input variables",2000,7155,software engineering|applied mathematics|scientific computing|software analysis|computer code|computer engineering|code representation|program evaluation|computer analysis|computer science|software testing|numerical analysis|source code analysis|input-output analysis|static program analysis|program analysis|input variables,
https://openalex.org/W2160660844,Mining and summarizing customer reviews,"Mining and summarizing customer reviews

Merchants selling products on the Web often ask their customers to review that they have purchased and associated services. As e-commerce is becoming more popular, number of customer reviews a product receives grows rapidly. For popular product, can be in hundreds or even thousands. This makes it difficult for potential read them make an informed decision whether purchase product. It also manufacturer keep track manage opinions. manufacturer, there are additional difficulties because many merchant sites may sell same normally produces kinds products. In this research, we aim mine summarize all summarization task different from traditional text only features which expressed opinions positive negative. We do not by selecting subset rewrite some original sentences capture main points as classic summarization. Our performed three steps: (1) mining been commented customers; (2) identifying opinion each deciding sentence negative; (3) summarizing results. paper proposes several novel techniques perform these tasks. experimental results using sold online demonstrate effectiveness techniques.

consumer research, computer science, content analysis, community mining, text mining, web mining, data science, knowledge discovery, entity summarization, customer review, automatic summarization, information retrieval, data mining",2004,7155,consumer research|computer science|content analysis|community mining|text mining|web mining|data science|knowledge discovery|entity summarization|customer review|automatic summarization|information retrieval|data mining,https://openalex.org/W1832693441|https://openalex.org/W2097726431|https://openalex.org/W2970641574
https://openalex.org/W1885185971,Image Super-Resolution Using Deep Convolutional Networks,"Image Super-Resolution Using Deep Convolutional Networks

We propose a deep learning method for single image super-resolution (SR). Our directly learns an end-to-end mapping between the low/high-resolution images. The is represented as convolutional neural network (CNN) that takes low-resolution input and outputs high-resolution one. further show traditional sparse-coding-based SR methods can also be viewed network. But unlike handle each component separately, our jointly optimizes all layers. CNN has lightweight structure, yet demonstrates state-of-the-art restoration quality, achieves fast speed practical on-line usage. explore different structures parameter settings to achieve trade-offs performance speed. Moreover, we extend cope with three color channels simultaneously, better overall reconstruction quality.

computer science, high resolution, machine learning, image analysis, convolutional neural network, biomedical imaging, data science, image representation, computational imaging, deep convolutional networks, deep learning, image super-resolution, image resolution, machine vision, single-image super-resolution, digital image processing, medical image computing, super-resolution imaging, computer vision",2016,7136,computer science|high resolution|machine learning|image analysis|convolutional neural network|biomedical imaging|data science|image representation|computational imaging|deep convolutional networks|deep learning|image super-resolution|image resolution|machine vision|single-image super-resolution|digital image processing|medical image computing|super-resolution imaging|computer vision,https://openalex.org/W2963470893|https://openalex.org/W2242218935
https://openalex.org/W2165612380,A vector space model for automatic indexing,"A vector space model for automatic indexing

In a document retrieval, or other pattern matching environment where stored entities (documents) are compared with each incoming patterns (search requests), it appears that the best indexing (property) space is one entity lies as far away from others possible; in these circumstances value of an system may be expressible function density object space; particular, retrieval performance correlate inversely density. An approach based on computations used to choose optimum vocabulary for collection documents. Typical evaluation results shown, demonstating usefulness model.

computer science, data indexing, index system, automatic indexing, indexing technique, applied mathematics, vector space model, similarity search, machine learning research, information retrieval",1975,7127,computer science|data indexing|index system|automatic indexing|indexing technique|applied mathematics|vector space model|similarity search|machine learning research|information retrieval,https://openalex.org/W2118020653
https://openalex.org/W3035524453,Momentum Contrast for Unsupervised Visual Representation Learning,"Momentum Contrast for Unsupervised Visual Representation Learning

We present Momentum Contrast (MoCo) for unsupervised visual representation learning. From a perspective on contrastive learning as dictionary look-up, we build dynamic with queue and moving-averaged encoder. This enables building large consistent on-the-fly that facilitates MoCo provides competitive results under the common linear protocol ImageNet classification. More importantly, representations learned by transfer well to downstream tasks. can outperform its supervised pre-training counterpart in 7 detection/segmentation tasks PASCAL VOC, COCO, other datasets, sometimes surpassing it margins. suggests gap between has been largely closed many vision

computer science, vision language model, machine learning, visual science, image analysis, visual reasoning, visualization, cognitive science, data science, image representation, computational imaging, scene understanding, unsupervised machine learning, deep learning, machine learning research, machine vision, momentum contrast, visual question answering, computer vision",2020,7118,computer science|vision language model|machine learning|visual science|image analysis|visual reasoning|visualization|cognitive science|data science|image representation|computational imaging|scene understanding|unsupervised machine learning|deep learning|machine learning research|machine vision|momentum contrast|visual question answering|computer vision,https://openalex.org/W3094502228
https://openalex.org/W3113109455,<i>Introduction to Percolation Theory</i>,"<i>Introduction to Percolation Theory</i>

Share Icon Twitter Facebook Reddit LinkedIn Reprints and Permissions Cite Search Site Citation Dietrich Stauffer, Amnon Aharony, Sidney Redner; Introduction to Percolation Theory. Physics Today 1 April 1993; 46 (4): 64. https://doi.org/10.1063/1.2808877 Download citation file: Ris (Zotero) Reference Manager EasyBib Bookends Mendeley Papers EndNote RefWorks BibTex toolbar search Dropdown Menu input auto suggest filter your All ContentPhysics Advanced

critical phenomenon, computer science, numerical mathematics, chaotic mixing, diffusion, dynamical system, clustering, applied mathematics, discrete algorithm, entropy, nonlinear phenomenon, probabilistic graph theory, random graph, stochastic geometry, applied physics, statistical theory, nonlinear science, stochastic process",1993,7090,critical phenomenon|computer science|numerical mathematics|chaotic mixing|diffusion|dynamical system|clustering|applied mathematics|discrete algorithm|entropy|nonlinear phenomenon|probabilistic graph theory|random graph|stochastic geometry|applied physics|statistical theory|nonlinear science|stochastic process,
https://openalex.org/W2111030512,An introduction to cybernetics,"An introduction to cybernetics

Many workers in the biological sciencesphysiologists, psycholo- gists, sociologistsare interested cybernetics and would like to apply its methods techniques their own speciality.Many have, however, been prevented from taking up subject by an impression that use must be preceded a long study of elec- tronics advanced pure mathematics; for they have formed these subjects are inseparable.The author is convinced, this false.The basic ideas can treated without reference electronics, fundamentally simple; so although may necessary applications, great deal done, especially sciences, quite simple techniques, provided used with clear deep understanding principles involved.It author's belief if founded common-place well under- stood, then built carefully, step step, there no reason why worker only elementary mathematical knowledge should not achieve complete principles.With such he will able see exactly what further learn proceed further;and, particularly useful, safely ignore as being irrelevant his purpose.The book intended provide introduction.It starts well-understood concepts, proceeds, show how concepts made exact, developed until lead into feedback, stability, regulation, ultrastability, information, coding, noise, other cybernetic topics.Throughout mathematics required beyond algebra; particular, arguments nowhere depend on calculus (the few references it ignored harm, joins discussed, used).The illustrations examples mostly taken biological, rather than physical, sciences.Its overlap Design Brain small, two books almost independent.They are, intimately related, best complementary; each help illuminate other.Amplifying intelligence .. .

computer science, technology, biocybernetics, cyber-physical systems, cybernetics, agricultural cybernetics, computer engineering",1956,7074,computer science|technology|biocybernetics|cyber-physical systems|cybernetics|agricultural cybernetics|computer engineering,
https://openalex.org/W2107878631,Learning long-term dependencies with gradient descent is difficult,"Learning long-term dependencies with gradient descent is difficult

Recurrent neural networks can be used to map input sequences output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent perform tasks which the temporal contingencies present input/output span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem duration of dependencies captured increases. These results expose a trade-off between efficient by descent and latching on information periods. Based understanding this problem, alternatives standard are considered.

gradient descent, computer science, long-term dependencies, machine learning",1994,7064,gradient descent|computer science|long-term dependencies|machine learning,https://openalex.org/W2194775991|https://openalex.org/W2064675550|https://openalex.org/W2112796928|https://openalex.org/W2964308564|https://openalex.org/W2130942839|https://openalex.org/W1533861849|https://openalex.org/W2242218935
https://openalex.org/W2123845384,Space/time trade-offs in hash coding with allowable errors,"Space/time trade-offs in hash coding with allowable errors

In this paper trade-offs among certain computational factors in hash coding are analyzed. The paradigm problem considered is that of testing a series messages one-by-one for membership given set messages. Two new hash-coding methods examined and compared with particular conventional method. the size area (space), time required to identify message as nonmember (reject time), an allowable error frequency. intended reduce amount space contain hash-coded information from associated methods. reduction accomplished by exploiting possibility small fraction errors commission may be tolerable some applications, particular, applications which large data involved core resident consequently not feasible using such it envisaged overall performance could improved smaller conjunction and, when necessary, secondary perhaps time-consuming test “catch” An example discussed illustrates possible areas application Analysis demonstrates allowing number falsely identified members will permit much used without increasing reject time.

computer science, allowable errors, cryptography, hash coding, hash function",1970,7050,computer science|allowable errors|cryptography|hash coding|hash function,
https://openalex.org/W3127702745,The Logic of Scientific Discovery.,"The Logic of Scientific Discovery.

Described by the philosopher A.J. Ayer as a work of 'great originality and power', this book revolutionized contemporary thinking on science knowledge. Ideas such now legendary doctrine 'falsificationism' electrified scientific community, influencing even working scientists, well post-war philosophy. This astonishing ranks alongside The Open Society Its Enemies one Popper's most enduring books contains insights arguments that demand to be read day.

philosophy of science, computational logic, provenance analysis, scientific discovery, knowledge discovery, knowledge representation and reasoning, discovery research, history of logic, theory building, scientific communication, scientific data, computer science, logic in computer science, quantitative science study, mathematical logic, epistemology, data science, scientific computing",1959,7048,philosophy of science|computational logic|provenance analysis|scientific discovery|knowledge discovery|knowledge representation and reasoning|discovery research|history of logic|theory building|scientific communication|scientific data|computer science|logic in computer science|quantitative science study|mathematical logic|epistemology|data science|scientific computing,
https://openalex.org/W3099206234,FaceNet: A unified embedding for face recognition and clustering,"FaceNet: A unified embedding for face recognition and clustering

Despite significant recent advances in the field of face recognition [10, 14, 15, 17], implementing verification and efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns mapping from images compact Euclidean space where distances correspond measure offace similarity. Once has been produced, tasks such as recognition, clustering can be easily implemented using standard techniques with FaceNet embeddings asfeature vectors. Our method uses deep convolutional network trained optimize embedding itself, rather than an intermediate bottleneck layer previous learning To train, use triplets roughly aligned matching / non-matching patches generated novel online triplet mining method. The benefit our approach is much greater representational efficiency: achieve state-of-the-artface performance only 128-bytes perface. On widely used Labeled Faces Wild (LFW) dataset, system achieves new record accuracy 99.63%. YouTube DB it 95.12%. cuts error rate comparison best published result [15] by 30% on both datasets.

pattern recognition, computer science, machine learning, face recognition, image analysis, information fusion, feature detection, cognitive science, data science, image representation, computational imaging, deep learning, machine learning research, machine vision, unified embedding, object recognition, feature extraction, clustering, geometric learning, image classification",2015,7000,pattern recognition|computer science|machine learning|face recognition|image analysis|information fusion|feature detection|cognitive science|data science|image representation|computational imaging|deep learning|machine learning research|machine vision|unified embedding|object recognition|feature extraction|clustering|geometric learning|image classification,https://openalex.org/W2183341477|https://openalex.org/W2612445135|https://openalex.org/W2954996726|https://openalex.org/W2970641574|https://openalex.org/W3005680577
https://openalex.org/W1515851193,Introduction to Reinforcement Learning,"Introduction to Reinforcement Learning

From the Publisher:
In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear simple account of key ideas algorithms reinforcement learning. Their discussion ranges from history field's intellectual foundations to most recent developments applications. The only necessary mathematical background is familiarity with elementary concepts probability.

computer science, artificial intelligence, deep reinforcement learning, sequential decision making, control optimization, machine learning, markov decision process, reinforcement learning, learning control, multi-agent learning",1998,6998,computer science|artificial intelligence|deep reinforcement learning|sequential decision making|control optimization|machine learning|markov decision process|reinforcement learning|learning control|multi-agent learning,https://openalex.org/W2964043796
https://openalex.org/W2963684088,Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks,"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks

In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised CNNs received less attention. this work we hope to help bridge the gap between success of for and learning. We introduce a class called deep generative adversarial (DCGANs), that have certain architectural constraints, demonstrate they are strong candidate Training on various image datasets, show convincing evidence our pair learns hierarchy representations from object parts scenes both generator discriminator. Additionally, use learned features novel tasks - demonstrating their applicability as general representations.

digital image processing, computer science, machine learning research, deep learning, generative ai, machine vision, natural language processing, image representation, unsupervised representation, computational imaging, machine learning, generative adversarial network, image classification, data science, cognitive science, computational intelligence, dimensionality reduction, convolutional neural network, image analysis",2015,6973,digital image processing|computer science|machine learning research|deep learning|generative ai|machine vision|natural language processing|image representation|unsupervised representation|computational imaging|machine learning|generative adversarial network|image classification|data science|cognitive science|computational intelligence|dimensionality reduction|convolutional neural network|image analysis,https://openalex.org/W2962793481|https://openalex.org/W2963073614|https://openalex.org/W2963470893
https://openalex.org/W1533162639,Digital Image Processing Using MATLAB,"Digital Image Processing Using MATLAB

1. Introduction. 2. Fundamentals. 3. Intensity Transformations and Spatial Filtering. 4. Frequency Domain Processing. 5. Image Restoration. 6. Color 7. Wavelets. 8. Compression. 9. Morphological 10. Segmentation. 11. Representation Description. 12. Object Recognition.

computational imaging, computer science, digital image processing, digital imaging",2003,6967,computational imaging|computer science|digital image processing|digital imaging,
https://openalex.org/W2752908210,The Art of Computer Programming,"The Art of Computer Programming

""The Art of Computer Programming."" Nuclear Science and Engineering, 34(2), p. 198 Additional informationNotes on contributorsWilliam J. WorltonAbout the Reviewer: Mr. Worlton is a coordinator automatic data processing at Los Alamos Scientific Laboratory where he has been staff member since graduate studies Utah State University. His interests are in history computing, computer architecture, evaluation comparison systems

program synthesis, computer science, programming language, software design, software engineering, automatic programming, program analysis, programming language theory, computer engineering, system software, programming paradigm, programming style, mathematical programming, software analysis, computer programming",1968,6953,program synthesis|computer science|programming language|software design|software engineering|automatic programming|program analysis|programming language theory|computer engineering|system software|programming paradigm|programming style|mathematical programming|software analysis|computer programming,https://openalex.org/W2041902442
https://openalex.org/W2146395539,Overview of the High Efficiency Video Coding (HEVC) Standard,"Overview of the High Efficiency Video Coding (HEVC) Standard

High Efficiency Video Coding (HEVC) is currently being prepared as the newest video coding standard of ITU-T Experts Group and ISO/IEC Moving Picture Group. The main goal HEVC standardization effort to enable significantly improved compression performance relative existing standards-in range 50% bit-rate reduction for equal perceptual quality. This paper provides an overview technical features characteristics standard.

computer science, video transmission, video restoration, digital signal processing, video quality, multimedia signal processing, video coding format",2012,6907,computer science|video transmission|video restoration|digital signal processing|video quality|multimedia signal processing|video coding format,
https://openalex.org/W2129131372,Decoding by Linear Programming,"Decoding by Linear Programming

This paper considers a natural error correcting problem with real valued input/output. We wish to recover an input vector f/spl isin/R/sup n/ from corrupted measurements y=Af+e. Here, A is m by n (coding) matrix and e arbitrary unknown of errors. Is it possible f exactly the data y? prove that under suitable conditions on coding A, unique solution /spl lscr//sub 1/-minimization (/spl par/x/spl par//sub lscr/1/:=/spl Sigma//sub i/|x/sub i/|) min(g/spl n/) par/y - Ag/spl lscr/1/ provided support errors not too large, par/e/spl lscr/0/:=|{i:e/sub i/ ne/ 0}|/spl les//spl rho//spl middot/m for some rho/>0. In short, can be recovered solving simple convex optimization (which one recast as linear program). addition, numerical experiments suggest this recovery procedure works unreasonably well; even in situations where significant fraction output corrupted. work related finding sparse solutions vastly underdetermined systems equations. There are also connections recovering signals highly incomplete measurements. fact, results introduced improve our earlier work. Finally, underlying success 1/ crucial property we call uniform uncertainty principle shall describe detail.

linear programming, computer science, computational optimization, mathematical optimization, iterative decoding, numerical analysis, mathematical programming, combinatorial optimization, algebraic coding theory, applied mathematics",2005,6897,linear programming|computer science|computational optimization|mathematical optimization|iterative decoding|numerical analysis|mathematical programming|combinatorial optimization|algebraic coding theory|applied mathematics,https://openalex.org/W2119667497|https://openalex.org/W2164452299|https://openalex.org/W2129638195
https://openalex.org/W2121016876,Base-Calling of Automated Sequencer Traces Using<i>Phred.</i> I. Accuracy Assessment,"Base-Calling of Automated Sequencer Traces Using<i>Phred.</i> I. Accuracy Assessment

The availability of massive amounts DNA sequence information has begun to revolutionize the practice biology. As a result, current large-scale sequencing output, while impressive, is not adequate keep pace with growing demand and, in particular, far short what will be required obtain 3-billion-base human genome by target date 2005. To reach this goal, improved automation essential, and it particularly important that involvement data processing significantly reduced or eliminated. Progress respect require both accuracy software reliable measures reduce need for error correction make review more efficient. Here, we describe one step toward goal: base-calling program automated sequencer traces, phred, accuracy. phred appears first achieve lower rate than ABI software, averaging 40%–50% fewer errors sets examined independent position read, machine running conditions, chemistry.

automated sequencer traces, computer science, speech recognition, information fusion, sequence analysis, systems biology, clustering, machine learning, data science, computational biology, network analysis, machine learning research, high throughput sequencing, automated analysis, automated mining, sequence assembly",1998,6893,automated sequencer traces|computer science|speech recognition|information fusion|sequence analysis|systems biology|clustering|machine learning|data science|computational biology|network analysis|machine learning research|high throughput sequencing|automated analysis|automated mining|sequence assembly,https://openalex.org/W2119923823
https://openalex.org/W2164452299,Stable signal recovery from incomplete and inaccurate measurements,"Stable signal recovery from incomplete and inaccurate measurements

Abstract Suppose we wish to recover a vector x 0 ∈ ℝ 𝓂 (e.g., digital signal or image) from incomplete and contaminated observations y = A + e ; is an 𝓃 × matrix with far fewer rows than columns (𝓃 ≪ 𝓂) error term. Is it possible accurately based on the data ? To , consider solution # 𝓁 1 ‐regularization problem where ϵ size of term . We show that if obeys uniform uncertainty principle (with unit‐normed columns) sufficiently sparse, then within noise level As first example, suppose Gaussian random matrix; stable recovery occurs for almost all such 's provided number nonzeros about same order as observations. second instance, one observes few Fourier samples any set coefficients 𝓃/(log 6 In case vanishes, course exact, this work actually provides novel insights into exact phenomenon discussed in earlier papers. The methodology also explains why can very nearly approximately sparse signals. © 2006 Wiley Periodicals, Inc.

signal integrity, computer science, measurement, inaccurate measurements, signal processing, digital signal processing, statistical signal processing, stable signal recovery, signal reconstruction",2006,6884,signal integrity|computer science|measurement|inaccurate measurements|signal processing|digital signal processing|statistical signal processing|stable signal recovery|signal reconstruction,https://openalex.org/W2119667497|https://openalex.org/W2129812935
https://openalex.org/W2018044188,Design and Analysis of Computer Experiments,"Design and Analysis of Computer Experiments

Many scientific phenomena are now investigated by complex computer models or codes. A experiment is a number of runs the code with various inputs. feature many experiments that output deterministic--rerunning same inputs gives identical observations. Often, codes computationally expensive to run, and common objective an fit cheaper predictor data. Our approach model deterministic as realization stochastic process, thereby providing statistical basis for designing (choosing inputs) efficient prediction. With this model, estimates uncertainty predictions also available. Recent work in area reviewed, applications discussed, we demonstrate our methodology example.

optimal experimental design, computer science, experimental testing, experiment design, systems engineering, program analysis, computer experiments, experimental technology, scientific computing, experimental analysis, computer engineering",1989,6878,optimal experimental design|computer science|experimental testing|experiment design|systems engineering|program analysis|computer experiments|experimental technology|scientific computing|experimental analysis|computer engineering,https://openalex.org/W1746819321
https://openalex.org/W2110659753,Space-time block codes from orthogonal designs,"Space-time block codes from orthogonal designs

We introduce space-time block coding, a new paradigm for communication over Rayleigh fading channels using multiple transmit antennas. Data is encoded code and the data split into n streams which are simultaneously transmitted The received signal at each receive antenna linear superposition of signals perturbed by noise. Maximum-likelihood decoding achieved in simple way through decoupling from different antennas rather than joint detection. This uses orthogonal structure gives maximum-likelihood algorithm based only on processing receiver. Space-time codes designed to achieve maximum diversity order given number subject constraint having algorithm. classical mathematical framework designs applied construct codes. It shown that constructed this exist few sporadic values n. Subsequently, generalization provide both real complex constellations any These possible transmission rate arbitrary constellation such as PAM. For an PSK QAM, 1/2 specific cases two, three, four antennas, achieve, respectively, all, 3/4, 3/4 constellations. best tradeoff between delay also computed it many presented here optimal sense well.

computer science, space-time block codes, algebraic coding theory, orthogonal designs",1999,6873,computer science|space-time block codes|algebraic coding theory|orthogonal designs,
https://openalex.org/W2143516773,Fast approximate energy minimization via graph cuts,"Fast approximate energy minimization via graph cuts

Many tasks in computer vision involve assigning a label (such as disparity) to every pixel. A common constraint is that the labels should vary smoothly almost everywhere while preserving sharp discontinuities may exist, e.g., at object boundaries. These are naturally stated terms of energy minimization. The authors consider wide class energies with various smoothness constraints. Global minimization these functions NP-hard even simplest discontinuity-preserving case. Therefore, our focus on efficient approximation algorithms. We present two algorithms based graph cuts efficiently find local minimum respect types large moves, namely expansion moves and swap moves. can simultaneously change arbitrarily sets pixels. In contrast, many standard (including simulated annealing) use small where only one pixel changes its time. Our algorithm finds labeling within known factor global minimum, handles more general functions. Both allow important cases discontinuity energies. experimentally demonstrate effectiveness approach for image restoration, stereo motion. On real data ground truth, we achieve 98 percent accuracy.

computer science, energy minimization, graph theory, approximate energy minimization, graph cuts",2001,6872,computer science|energy minimization|graph theory|approximate energy minimization|graph cuts,
https://openalex.org/W2963524571,"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset","Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset

The paucity of videos in current action classification datasets (UCF-101 and HMDB-51) has made it difficult to identify good video architectures, as most methods obtain similar performance on existing small-scale benchmarks. This paper re-evaluates state-of-the-art architectures light the new Kinetics Human Action Video dataset. two orders magnitude more data, with 400 human classes over clips per class, is collected from realistic, challenging YouTube videos. We provide an analysis how fare task this dataset much improves smaller benchmark after pre-training Kinetics. also introduce a Two-Stream Inflated 3D ConvNet (I3D) that based 2D inflation: filters pooling kernels very deep image ConvNets are expanded into 3D, making possible learn seamless spatio-temporal feature extractors while leveraging successful ImageNet architecture designs even their parameters. show that, Kinetics, I3D models considerably improve upon classification, reaching 80.2% HMDB-51 97.9% UCF-101.

computer science, robot learning, information fusion, multimedia retrieval, action recognition, cognitive science, structure from motion, digital image processing, data science, pattern recognition, quo vadis, video understanding, machine learning, computer vision, machine vision, activity recognition, image analysis, motion detection, motion analysis, image representation",2017,6836,computer science|robot learning|information fusion|multimedia retrieval|action recognition|cognitive science|structure from motion|digital image processing|data science|pattern recognition|quo vadis|video understanding|machine learning|computer vision|machine vision|activity recognition|image analysis|motion detection|motion analysis|image representation,https://openalex.org/W2963091558
https://openalex.org/W2162273778,A Real-Time QRS Detection Algorithm,"A Real-Time QRS Detection Algorithm

We have developed a real-time algorithm for detection of the QRS complexes ECG signals. It reliably recognizes based upon digital analyses slope, amplitude, and width. A special bandpass filter reduces false detections caused by various types interference present in This filtering permits use low thresholds, thereby increasing sensitivity. The automatically adjusts thresholds parameters periodically to adapt such changes as morphology heart rate. For standard 24 h MIT/BIH arrhythmia database, this correctly detects 99.3 percent complexes.

automatic target recognition, computer science, real-time monitoring, computer vision, machine learning, detection technique, deep learning, machine vision",1985,6820,automatic target recognition|computer science|real-time monitoring|computer vision|machine learning|detection technique|deep learning|machine vision,
https://openalex.org/W2134295053,"Internet of Things: A Survey on Enabling Technologies, Protocols, and Applications","Internet of Things: A Survey on Enabling Technologies, Protocols, and Applications

This paper provides an overview of the Internet Things (IoT) with emphasis on enabling technologies, protocols, and application issues. The IoT is enabled by latest developments in RFID, smart sensors, communication protocols. basic premise to have sensors collaborate directly without human involvement deliver a new class applications. current revolution Internet, mobile, machine-to-machine (M2M) technologies can be seen as first phase IoT. In coming years, expected bridge diverse enable applications connecting physical objects together support intelligent decision making. starts providing horizontal Then, we give some technical details that pertain Compared other survey papers field, our objective provide more thorough summary most relevant protocols issues researchers developers get up speed quickly how different fit desired functionalities having go through RFCs standards specifications. We also key challenges presented recent literature related research work. Moreover, explore relation between emerging including big data analytics cloud fog computing. present need for better integration among services. Finally, detailed service use-cases illustrate

iot protocol, computer science, information technology, mobile computing, technology, wireless network, wireless communication, vehicular technology, web of thing, communication, internet of things, iot architecture, communications system, ubiquitous computing, communication security, iot communication, wireless sensor network, iot interoperability",2015,6777,iot protocol|computer science|information technology|mobile computing|technology|wireless network|wireless communication|vehicular technology|web of thing|communication|internet of things|iot architecture|communications system|ubiquitous computing|communication security|iot communication|wireless sensor network|iot interoperability,
https://openalex.org/W2124651399,Highly dynamic Destination-Sequenced Distance-Vector routing (DSDV) for mobile computers,"Highly dynamic Destination-Sequenced Distance-Vector routing (DSDV) for mobile computers

An ad-hoc network is the cooperative engagement of a collection Mobile Hosts without required intervention any centralized Access Point. In this paper we present an innovative design for operation such networks. The basic idea to operate each Host as specialized router, which periodically advertises its view interconnection topology with other within network. This amounts new sort routing protocol. We have investigated modifications Bellman-Ford mechanisms, specified by RIP [5], make it suitable dynamic and self-starting mechanism users wishing utilize ad hoc Our address some previous objections use Bellman-Ford, related poor looping properties algorithms in face broken links resulting time dependent nature describing between Hosts. Finally, describe ways network-layer can be modified provide MAC-layer support

systems engineering, trajectory planning, network routing, distributed system, computer engineering, networked system design, mobile computers, route planning, scalable routing, wireless sensor network, network routing algorithm, control optimization, computer science, drone, wireless communication, communications system, mobile computing, navigation",1994,6771,systems engineering|trajectory planning|network routing|distributed system|computer engineering|networked system design|mobile computers|route planning|scalable routing|wireless sensor network|network routing algorithm|control optimization|computer science|drone|wireless communication|communications system|mobile computing|navigation,
https://openalex.org/W2123442489,The Stanford CoreNLP Natural Language Processing Toolkit,"The Stanford CoreNLP Natural Language Processing Toolkit

Christopher Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven Bethard, David McClosky. Proceedings of 52nd Annual Meeting the Association for Computational Linguistics: System Demonstrations. 2014.

computer science, linguistics, knowledge representation and reasoning, keyword extraction, language model, natural language processing, natural language generation, natural language interface, syntactic parsing, computational linguistics, data science, knowledge discovery, deep learning, nlp task, machine learning research, machine translation, semantic parsing, spoken language technology",2014,6760,computer science|linguistics|knowledge representation and reasoning|keyword extraction|language model|natural language processing|natural language generation|natural language interface|syntactic parsing|computational linguistics|data science|knowledge discovery|deep learning|nlp task|machine learning research|machine translation|semantic parsing|spoken language technology,
https://openalex.org/W2053913299,Combinatorial Optimization: Algorithms and Complexity.,"Combinatorial Optimization: Algorithms and Complexity.

This clearly written , mathematically rigorous text includes a novel algorithmic exposition of the simplex method and also discusses Soviet ellipsoid algorithm for linear programming; efficient algorithms network flow, matching, spanning trees, matroids; theory NP-complete problems; approximation algorithms, local search heuristics NPcomplete problems, more. All chapters are supplemented by thoughtprovoking problems. A useful work graduate-level students with backgrounds in computer science, operations research, electrical engineering. Mathematicians wishing self-contained introduction need look no further.—American Mathematical Monthly. 1982 ed.

combinatorial optimization, optimization problem, computer science, mathematical optimization",1984,6757,combinatorial optimization|optimization problem|computer science|mathematical optimization,https://openalex.org/W2057175746
https://openalex.org/W2154010459,The Anatomy of the Grid: Enabling Scalable Virtual Organizations,"The Anatomy of the Grid: Enabling Scalable Virtual Organizations

“Grid” computing has emerged as an important new field, distinguished from conventional distributed by its focus on large-scale resource sharing, innovative applications, and, in some cases, high performance orientation. In this article, the authors define field. First, they review “Grid problem,” which is defined flexible, secure, coordinated sharing among dynamic collections of individuals, institutions, and resources—what referred to virtual organizations. such settings, unique authentication, authorization, access, discovery, other challenges are encountered. It class problem that addressed Grid technologies. Next, present extensible open architecture, protocols, services, application programming interfaces, software development kits categorized according their roles enabling sharing. The describe requirements believe any mechanisms must satisfy discuss importance defining a compact set intergrid protocols enable interoperability different systems. Finally, how technologies relate contemporary technologies, including enterprise integration, service provider, storage peer-to-peer computing. They maintain concepts complement have much contribute these approaches.

scalability, smart grid, grid system, grid computing, computer science, virtual organization, scalable computing, grid network",2001,6752,scalability|smart grid|grid system|grid computing|computer science|virtual organization|scalable computing|grid network,
https://openalex.org/W2129638195,Near-Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?,"Near-Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?

<para xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> Suppose we are given a vector &lt;emphasis&gt;&lt;formula formulatype=""inline""&gt; &lt;tex&gt;$f$&lt;/tex&gt;&lt;/formula&gt;&lt;/emphasis&gt; in class &lt;tex&gt;${\cal F} \subset{\BBR}^N$&lt;/tex&gt;&lt;/formula&gt;&lt;/emphasis&gt;, e.g., of digital signals or images. How many linear measurements do need to make about formulatype=""inline""&gt;&lt;tex&gt;$f$&lt;/tex&gt;&lt;/formula&gt;&lt;/emphasis&gt; be able recover formulatype=""inline""&gt;&lt;tex&gt;$f$&lt;/tex&gt; &lt;/formula&gt;&lt;/emphasis&gt; within precision &lt;tex&gt;$\epsilon$&lt;/tex&gt;&lt;/formula&gt;&lt;/emphasis&gt; the Euclidean formulatype=""inline""&gt;&lt;tex&gt;$(\ell_2)$&lt;/tex&gt;&lt;/formula&gt;&lt;/emphasis&gt; metric? This paper shows that if objects interest sparse fixed basis compressible, then it is possible reconstruct very high accuracy from small number random by solving simple program. More precisely, suppose formulatype=""inline""&gt;&lt;tex&gt;$n$&lt;/tex&gt;&lt;/formula&gt;&lt;/emphasis&gt;th largest entry formulatype=""inline""&gt;&lt;tex&gt;$\vert f\vert$&lt;/tex&gt;&lt;/formula&gt;&lt;/emphasis&gt; (or its coefficients basis) obeys f\vert _{(n)} \le R \cdot n^{-1/p}$&lt;/tex&gt;&lt;/formula&gt;&lt;/emphasis&gt;, where &lt;tex&gt;$R &gt; 0$&lt;/tex&gt;&lt;/formula&gt;&lt;/emphasis&gt; and &lt;tex&gt;$p 0$&lt;/tex&gt;&lt;/formula&gt;&lt;/emphasis&gt;. take formulatype=""inline""&gt;&lt;tex&gt;$y_k = \langle f, X_k\rangle, k 1, \ldots, K$&lt;/tex&gt; &lt;/formula&gt;&lt;/emphasis&gt;, &lt;tex&gt;$X_k$&lt;/tex&gt;&lt;/formula&gt;&lt;/emphasis&gt; &lt;tex&gt;$N$&lt;/tex&gt;&lt;/formula&gt;&lt;/emphasis&gt;-dimensional Gaussian vectors with independent standard normal entries. Then for each obeying decay estimate above some formulatype=""inline""&gt;&lt;tex&gt;$0 &lt; p 1$&lt;/tex&gt;&lt;/formula&gt;&lt;/emphasis&gt; overwhelming probability, our reconstruction &lt;tex&gt;$f^\sharp$&lt;/tex&gt;&lt;/formula&gt;&lt;/emphasis&gt;, defined as solution constraints f^\sharp, X_k \rangle$&lt;/tex&gt;&lt;/formula&gt;&lt;/emphasis&gt; minimal &lt;tex&gt;$\ell_1$&lt;/tex&gt;&lt;/formula&gt;&lt;/emphasis&gt; norm, &lt;emphasis&gt; &lt;formula formulatype=""display""&gt;&lt;tex&gt;$$ \Vert f - f^\sharp\Vert _{\ell_2} C_p (K/\log N)^{-r}, \quad r 1/p 1/2. $$&lt;/tex&gt; &lt;/formula&gt;&lt;/emphasis&gt;There sense which this result optimal; generally impossible obtain higher any set formulatype=""inline""&gt;&lt;tex&gt;$K$&lt;/tex&gt;&lt;/formula&gt;&lt;/emphasis&gt; whatsoever. The methodology extends various other measurement ensembles; example, show similar results hold one observes few randomly sampled Fourier &lt;/formula&gt;&lt;/emphasis&gt;. In fact, quite general require only two hypotheses on ensemble detailed. </para>

computer science, signal processing, near-optimal signal recovery, statistical signal processing, random projections",2006,6711,computer science|signal processing|near-optimal signal recovery|statistical signal processing|random projections,https://openalex.org/W2119667497|https://openalex.org/W2129812935|https://openalex.org/W2129131372|https://openalex.org/W2164452299
https://openalex.org/W2102625004,Adaptive background mixture models for real-time tracking,"Adaptive background mixture models for real-time tracking

A common method for real-time segmentation of moving regions in image sequences involves ""background subtraction"", or thresholding the error between an estimate without objects and current image. The numerous approaches to this problem differ type background model used procedure update model. This paper discusses modeling each pixel as a mixture Gaussians using on-line approximation Gaussian, distributions adaptive are then evaluated determine which most likely result from process. Each is classified based on whether Gaussian distribution represents it effectively considered part results stable, outdoor tracker reliably deals with lighting changes, repetitive motions clutter, long-term scene changes. system has been run almost continuously 16 months, 24 hours day, through rain snow.

image analysis, pattern recognition, computer science, information fusion, mixture analysis, motion analysis, scene modeling, computer vision, machine learning, scene analysis, motion detection, data science, systems engineering, deep learning, localization, machine vision, real-time tracking",2003,6709,image analysis|pattern recognition|computer science|information fusion|mixture analysis|motion analysis|scene modeling|computer vision|machine learning|scene analysis|motion detection|data science|systems engineering|deep learning|localization|machine vision|real-time tracking,https://openalex.org/W2145962650
https://openalex.org/W2127847431,A Rapid Bootstrap Algorithm for the RAxML Web Servers,"A Rapid Bootstrap Algorithm for the RAxML Web Servers

Despite recent advances achieved by application of high-performance computing methods and novel algorithmic techniques to maximum likelihood (ML)-based inference programs, the major computational bottleneck still consists in computation bootstrap support values. Conducting a probably insufficient number 100 (BS) analyses with current ML programs on large datasets—either respect taxa or base pairs—can easily require month run time. Therefore, we have developed, implemented, thoroughly tested rapid heuristics RAxML (Randomized Axelerated Maximum Likelihood) that are more than an order magnitude faster algorithms. These new can contribute resolving improve methodology phylogenetic analyses. Computational experiments assess performance relative accuracy these were conducted 22 diverse DNA AA (amino acid), single gene as well multigene, real-world alignments containing 125 up 7764 sequences. The standard BS (SBS) (RBS) values drawn best-scoring tree highly correlated show almost identical average weighted RF (Robinson-Foulds) distance between SBS- RBS-based consensus trees was smaller 6% all cases (average 4%). More importantly, RBS inferences 8 20 times 14.73) SBS 18 495 competing such PHYML GARLI. Moreover, this improvement increases alignment size. Finally, set two freely accessible Web servers for significantly improved version provide access 200-CPU cluster Vital-IT unit at Swiss Institute Bioinformatics 128-CPU CIPRES project San Diego Supercomputer Center. offer possibility conduct large-scale part community does not to, expertise use, resources.

computer science, bootstrap resampling, raxml web servers, rapid bootstrap algorithm",2008,6708,computer science|bootstrap resampling|raxml web servers|rapid bootstrap algorithm,https://openalex.org/W2031611770|https://openalex.org/W2951464304
https://openalex.org/W1985479415,Summarizing multiple aspects of model performance in a single diagram,"Summarizing multiple aspects of model performance in a single diagram

A diagram has been devised that can provide a concise statistical summary of how well patterns match each other in terms their correlation, root‐mean‐square difference, and the ratio variances. Although form this is general, it especially useful evaluating complex models, such as those used to study geophysical phenomena. Examples are given showing be summarize relative merits collection different models or track changes performance model modified. Methods suggested for indicating on these diagrams significance apparent differences degree which observational uncertainty unforced internal variability limit expected agreement between model‐simulated observed behaviors. The geometric relationship statistics plotted also provides some guidance devising skill scores appropriately weight among various measures pattern correspondence.

computer science, multiple aspects, single diagram, model performance, visualization, multi-modal summarization",2001,6693,computer science|multiple aspects|single diagram|model performance|visualization|multi-modal summarization,
https://openalex.org/W2914659449,Enumerative Combinatorics,"Enumerative Combinatorics

This book is the first of a two-volume basic introduction to enumerative combinatorics at level suitable for graduate students and research mathematicians. It concentrates on theory application generating functions, fundamental tool in combinatorics. The covers those parts greatest applicability other areas mathematics. four chapters are devoted an enumeration (suitable advanced undergraduates), sieve methods (including Principle Inclusion-Exclusion), partially ordered sets, rational functions. There large number exercises, almost all with solutions, which greatly augment text provide entry into many not covered directly. Graduate mathematicians who wish apply their work will find this authoritative reference.

mathematics, computational complexity, computer science, combinatorics, combinatorial theory, combinatorial problem, discrete algorithm, applied mathematics, discrete mathematics, set theory, combinatory analysis, combinatorial optimization, enumerative combinatorics, combinatorial method, algebraic combinatorics",1997,6690,mathematics|computational complexity|computer science|combinatorics|combinatorial theory|combinatorial problem|discrete algorithm|applied mathematics|discrete mathematics|set theory|combinatory analysis|combinatorial optimization|enumerative combinatorics|combinatorial method|algebraic combinatorics,
https://openalex.org/W2165558283,Multidimensional binary search trees used for associative searching,"Multidimensional binary search trees used for associative searching

This paper develops the multidimensional binary search tree (or k -d tree, where is dimensionality of space) as a data structure for storage information to be retrieved by associative searches. The defined and examples are given. It shown quite efficient in its requirements. A significant advantage this that single can handle many types queries very efficiently. Various utility algorithms developed; their proven average running times an n record file are: insertion, O (log ); deletion root, ( -1)/ random node, optimization (guarantees logarithmic performance searches), log ). Search given partial match with t keys specified [proven maximum time - )/ )] nearest neighbor [empirically observed ).] These performances far surpass best currently known these tasks. An algorithm presented any general intersection query. main focus theoretical. felt, however, trees could useful applications, potential uses

computer science, information retrieval, associative searching, information search",1975,6668,computer science|information retrieval|associative searching|information search,https://openalex.org/W2122646361
https://openalex.org/W2998216295,An introduction to variable and feature selection,"An introduction to variable and feature selection

Variable and feature selection have become the focus of much research in areas application for which datasets with tens or hundreds thousands variables are available. These include t...

image analysis, pattern recognition, computer science, high-dimensional statistics, feature learning, feature engineering, machine learning, feature detection, cognitive science, knowledge discovery, computational statistic, statistics, machine learning research, feature selection, statistical software, machine vision, feature (computer vision), model selection",2003,6666,image analysis|pattern recognition|computer science|high-dimensional statistics|feature learning|feature engineering|machine learning|feature detection|cognitive science|knowledge discovery|computational statistic|statistics|machine learning research|feature selection|statistical software|machine vision|feature (computer vision)|model selection,
https://openalex.org/W2155806125,ARB: a software environment for sequence data,"ARB: a software environment for sequence data

The ARB (from Latin arbor, tree) project was initiated almost 10 years ago. program package comprises a variety of directly interacting software tools for sequence database maintenance and analysis which are controlled by common graphical user interface. Although it initially designed ribosomal RNA data, can be used any nucleic amino acid data as well. A central contains processed (aligned) primary structure data. Any additional descriptive stored in fields assigned to the individual sequences or linked via local worldwide networks. phylogenetic tree visualized main window access visualization. import export, alignment, secondary editing, profile filter calculation, analyses, specific hybridization probe design evaluation other components analysis. Currently, is numerous working groups worldwide.

sequence analysis, computer science, sequence data",2004,6638,sequence analysis|computer science|sequence data,
https://openalex.org/W1510073064,Kernel Methods for Pattern Analysis,"Kernel Methods for Pattern Analysis

Kernel methods provide a powerful and unified framework for pattern discovery, motivating algorithms that can act on general types of data (e.g. strings, vectors or text) look relations rankings, classifications, regressions, clusters). The application areas range from neural networks recognition to machine learning mining. This book, developed lectures tutorials, fulfils two major roles: firstly it provides practitioners with large toolkit algorithms, kernels solutions ready use standard discovery problems in fields such as bioinformatics, text analysis, image analysis. Secondly an easy introduction students researchers the growing field kernel-based demonstrating examples how handcraft algorithm kernel new specific application, covering all necessary conceptual mathematical tools do so.

kernel method, pattern recognition, computer science, statistical pattern recognition, machine learning, applied mathematics, systems engineering, deep learning, markov kernel, machine learning research, pattern analysis, reproducing kernel method",2004,6626,kernel method|pattern recognition|computer science|statistical pattern recognition|machine learning|applied mathematics|systems engineering|deep learning|markov kernel|machine learning research|pattern analysis|reproducing kernel method,
https://openalex.org/W2177274842,A performance evaluation of local descriptors,"A performance evaluation of local descriptors

In this paper, we compare the performance of descriptors computed for local interest regions, as, example, extracted by Harris-Affine detector. Many different have been proposed in literature. It is unclear which are more appropriate and how their depends on region The should be distinctive at same time robust to changes viewing conditions as well errors Our evaluation uses criterion recall with respect precision carried out image transformations. We shape context, steerable filters, PCA-SIFT, differential invariants, spin images, SIFT, complex moment cross-correlation types regions. also propose an extension SIFT descriptor show that it outperforms original method. Furthermore, observe ranking mostly independent detector SIFT-based perform best. Moments filters best among low dimensional descriptors.

image analysis, pattern recognition, computer science, machine vision, content-based image retrieval, object recognition, image retrieval, computer vision, object detection, data science, deep learning, image representation, machine learning research, local descriptors, information retrieval, feature (computer vision)",2005,6605,image analysis|pattern recognition|computer science|machine vision|content-based image retrieval|object recognition|image retrieval|computer vision|object detection|data science|deep learning|image representation|machine learning research|local descriptors|information retrieval|feature (computer vision),https://openalex.org/W2161969291|https://openalex.org/W2163808566
https://openalex.org/W2130103520,Good features to track,"Good features to track

No feature-based vision system can work unless good features be identified and tracked from frame to frame. Although tracking itself is by large a solved problem, selecting that well correspond physical points in the world still hard. We propose feature selection criterion optimal construction because it based on how tracker works, monitoring method detect occlusions, disocclusions, do not world. These methods are new algorithm extends previous Newton-Raphson style search under affine image transformations. test performance with several simulations experiments.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>

pattern recognition, computer science, remote sensing, image analysis, information fusion, feature detection, data science, moving object tracking, feature (computer vision), localization, systems engineering, machine vision, digital image processing, object tracking, visual surveillance, computer vision, multimedia retrieval, good features, vehicular technology",1994,6599,pattern recognition|computer science|remote sensing|image analysis|information fusion|feature detection|data science|moving object tracking|feature (computer vision)|localization|systems engineering|machine vision|digital image processing|object tracking|visual surveillance|computer vision|multimedia retrieval|good features|vehicular technology,
https://openalex.org/W2964153729,Intriguing properties of neural networks,"Intriguing properties of neural networks

Abstract: Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is reason they succeed, it also causes them to learn uninterpretable solutions could counter-intuitive properties. In this paper we report two such 
First, find there no distinction between individual high level units random linear combinations units, according various methods unit analysis. It suggests space, rather than contains semantic information in layers networks. 
Second, deep input-output mappings fairly discontinuous a significant extend. We can cause network misclassify an image by applying certain imperceptible perturbation, which found maximizing network's prediction error. addition, specific nature these perturbations not artifact learning: same perturbation different network, was trained subset dataset, input.

computer science, convolutional neural network, neuroscience, machine learning, neural networks, neural computation, neural network (machine learning)",2014,6598,computer science|convolutional neural network|neuroscience|machine learning|neural networks|neural computation|neural network (machine learning),https://openalex.org/W2099471712|https://openalex.org/W2963857521
https://openalex.org/W2962914239,V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation,"V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation

Convolutional Neural Networks (CNNs) have been recently employed to solve problems from both the computer vision and medical image analysis fields. Despite their popularity, most approaches are only able process 2D images while data used in clinical practice consists of 3D volumes. In this work we propose an approach segmentation based on a volumetric, fully convolutional, neural network. Our CNN is trained end-to-end MRI volumes depicting prostate, learns predict for whole volume at once. We introduce novel objective function, that optimise during training, Dice coefficient. way can deal with situations where there strong imbalance between number foreground background voxels. To cope limited annotated available augment applying random non-linear transformations histogram matching. show our experimental evaluation achieves good performances challenging test requiring fraction processing time needed by other previous methods.

image segmentation, computed tomography, digital image processing, medical image computing, computer vision, radiology, biomedical imaging, computational imaging, machine vision, medical image analysis, biomedical engineering, medical imaging, computer science, digital medicine, convolutional neural network, machine learning, deep learning, 3d imaging",2016,6563,image segmentation|computed tomography|digital image processing|medical image computing|computer vision|radiology|biomedical imaging|computational imaging|machine vision|medical image analysis|biomedical engineering|medical imaging|computer science|digital medicine|convolutional neural network|machine learning|deep learning|3d imaging,
https://openalex.org/W2950635152,Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation,"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation

In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent networks (RNN). One encodes sequence symbols into fixed-length vector representation, and the other decodes representation another symbols. The encoder decoder proposed are jointly trained to maximize conditional probability target given source sequence. performance statistical machine translation system is empirically found improve by using probabilities phrase pairs computed as an additional feature in existing log-linear model. Qualitatively, show learns semantically syntactically meaningful linguistic phrases.

computer science, knowledge discovery, word embeddings, convolutional neural network, phrase representations, statistical machine translation, computational linguistics, data science, deep learning, language model, linguistics, machine learning, machine learning research, natural language processing, machine translation, rnn encoder-decoder, sequence modelling, neural machine translation, recurrent neural network, language learning",2014,6555,computer science|knowledge discovery|word embeddings|convolutional neural network|phrase representations|statistical machine translation|computational linguistics|data science|deep learning|language model|linguistics|machine learning|machine learning research|natural language processing|machine translation|rnn encoder-decoder|sequence modelling|neural machine translation|recurrent neural network|language learning,https://openalex.org/W2130942839|https://openalex.org/W1902237438
https://openalex.org/W2951464304,UFBoot2: Improving the Ultrafast Bootstrap Approximation,"UFBoot2: Improving the Ultrafast Bootstrap Approximation

The standard bootstrap (SBS), despite being computationally intensive, is widely used in maximum likelihood phylogenetic analyses. We recently proposed the ultrafast approximation (UFBoot) to reduce computing time while achieving more unbiased branch supports than SBS under mild model violations. UFBoot has been steadily adopted as an efficient alternative and other approaches. Here, we present UFBoot2, which substantially accelerates reduces risk of overestimating due polytomies or severe Additionally, UFBoot2 provides suitable resampling strategies for phylogenomic data. 778 times (median) faster 8.4 RAxML rapid on tested data sets. implemented IQ-TREE software package version 1.6 freely available at http://www.iqtree.org.

ultrafast bootstrap approximation, computer science, bootstrap resampling, approximation theory",2017,6528,ultrafast bootstrap approximation|computer science|bootstrap resampling|approximation theory,
https://openalex.org/W2172000360,A comparison of methods for multiclass support vector machines,"A comparison of methods for multiclass support vector machines

Support vector machines (SVMs) were originally designed for binary classification. How to effectively extend it multiclass classification is still an ongoing research issue. Several methods have been proposed where typically we construct a classifier by combining several classifiers. Some authors also that consider all classes at once. As computationally more expensive solve problems, comparisons of these using large-scale problems not seriously conducted. Especially solving SVM in one step, much larger optimization problem required so up now experiments are limited small data sets. In this paper give decomposition implementations two such ""all-together"" methods. We then compare their performance with three based on classifications: ""one-against-all,"" ""one-against-one,"" and directed acyclic graph (DAGSVM). Our indicate the ""one-against-one"" DAG suitable practical use than other Results show large considering once general need fewer support vectors.

kernel method, computer science, support vector machine, machine learning, applied mathematics, machine learning research",2002,6526,kernel method|computer science|support vector machine|machine learning|applied mathematics|machine learning research,https://openalex.org/W2154053567
https://openalex.org/W1991133427,Error bounds for convolutional codes and an asymptotically optimum decoding algorithm,"Error bounds for convolutional codes and an asymptotically optimum decoding algorithm

The probability of error in decoding an optimal convolutional code transmitted over a memoryless channel is bounded from above and below as function the constraint length code. For all but pathological channels bounds are asymptotically (exponentially) tight for rates <tex xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">R_{0}</tex> , computational cutoff rate sequential decoding. As performance codes shown to be superior that block same length, relative improvement increasing with rate. upper bound obtained specific probabilistic nonsequential algorithm which optimum whose bears certain similarities algorithms.

asymptotic analysis, iterative decoding, computer science, algebraic coding theory, digital signal processing, applied mathematics, convolutional codes, optimum decoding algorithm, computer engineering",1967,6524,asymptotic analysis|iterative decoding|computer science|algebraic coding theory|digital signal processing|applied mathematics|convolutional codes|optimum decoding algorithm|computer engineering,https://openalex.org/W2112796928|https://openalex.org/W2142384583
https://openalex.org/W2117812871,Pattern Recognition and Neural Networks,"Pattern Recognition and Neural Networks

This 1996 book is a reliable account of the statistical framework for pattern recognition and machine learning. With unparalleled coverage wealth case-studies this gives valuable insight into both theory enormously diverse applications (which can be found in remote sensing, astrophysics, engineering medicine, example). So that readers develop their skills understanding, many real data sets used are available from author's website: www.stats.ox.ac.uk/~ripley/PRbook/. For same reason, examples included to illustrate problems recognition. Unifying principles highlighted, author an overview state subject, making experienced researchers statistics, learning/artificial intelligence engineering. The clear writing style means also superb introduction non-specialists.

pattern recognition, computer science, convolutional neural network, machine learning, cognitive science, temporal pattern recognition, neural computation, neural networks, deep learning, machine learning research, neural network (machine learning)",1996,6461,pattern recognition|computer science|convolutional neural network|machine learning|cognitive science|temporal pattern recognition|neural computation|neural networks|deep learning|machine learning research|neural network (machine learning),https://openalex.org/W2194775991|https://openalex.org/W1663973292|https://openalex.org/W1678356000|https://openalex.org/W1746819321|https://openalex.org/W2057175746
https://openalex.org/W2095721433,An Alternative to Compactification,"An Alternative to Compactification

Conventional wisdom states that Newton's force law implies only four noncompact dimensions. We demonstrate this is not necessarily true in the presence of a nonfactorizable background geometry. The specific example we study single 3-brane embedded five show even without gap Kaluza-Klein spectrum, four-dimensional Newtonian and general relativistic gravity reproduced to more than adequate precision.

mathematics, geometry and topology, computer science, geometric topology, topology, topological property, applied mathematics, geometric analysis, set theory, mathematical analysis",1999,6461,mathematics|geometry and topology|computer science|geometric topology|topology|topological property|applied mathematics|geometric analysis|set theory|mathematical analysis,
https://openalex.org/W2124344619,Intelligent agents: theory and practice,"Intelligent agents: theory and practice

Abstract The concept of an agent has become important in both artificial intelligence (AT) and mainstream computer science. Our aim this paper is to point the reader at what we perceive be most theoretical practical issues associated with design construction intelligent agents. For convenience, divide these into three areas (though as will see, divisions are times somewhat arbitrary). Agent theory concerned question is, use mathematical formalisms for representing reasoning about properties architectures can thought software engineering models agents; researchers area primarily problem designing or hardware systems that satisfy specified by theorists. Finally, languages programming experimenting may embody principles proposed not intended serve a tutorial introduction all mentioned; hope instead simply identify issues, work elaborates on them. article includes short review current potential applications technology.

computer science, artificial intelligence, agent-based system, intelligent systems, intelligent agent, agent theory, agent decision-making, autonomous agent system, multiagent system",1995,6377,computer science|artificial intelligence|agent-based system|intelligent systems|intelligent agent|agent theory|agent decision-making|autonomous agent system|multiagent system,
https://openalex.org/W2508457857,Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising,"Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising

Discriminative model learning for image denoising has been recently attracting considerable attentions due to its favorable performance. In this paper, we take one step forward by investigating the construction of feed-forward convolutional neural networks (DnCNNs) embrace progress in very deep architecture, algorithm, and regularization method into denoising. Specifically, residual batch normalization are utilized speed up training process as well boost Different from existing discriminative models which usually train a specific additive white Gaussian noise (AWGN) at certain level, our DnCNN is able handle with unknown level (i.e., blind denoising). With strategy, implicitly removes latent clean hidden layers. This property motivates us single tackle several general tasks such denoising, super-resolution JPEG deblocking. Our extensive experiments demonstrate that can not only exhibit high effectiveness tasks, but also be efficiently implemented benefiting GPU computing.

image analysis, computational imaging, computer science, convolutional neural network, image restoration, computer vision, machine learning, deep cnn, gaussian denoiser, deep learning, deblurring, machine learning research, residual learning, image denoising, automatic classification, machine vision, digital image processing",2017,6359,image analysis|computational imaging|computer science|convolutional neural network|image restoration|computer vision|machine learning|deep cnn|gaussian denoiser|deep learning|deblurring|machine learning research|residual learning|image denoising|automatic classification|machine vision|digital image processing,
https://openalex.org/W2097726431,Opinion Mining and Sentiment Analysis,"Opinion Mining and Sentiment Analysis

An important part of our information-gathering behavior has always been to find out what other people think. With the growing availability and popularity opinion-rich resources such as online review sites personal blogs, new opportunities challenges arise can, do, actively use information technologies seek understand opinions others. The sudden eruption activity in area opinion mining sentiment analysis, which deals with computational treatment opinion, sentiment, subjectivity text, thus occurred at least a direct response surge interest systems that deal directly first-class object. Opinion Mining Sentiment Analysis covers techniques approaches promise enable opinion-oriented information-seeking systems. focus is on methods address raised by sentiment-aware applications, compared those are already present more traditional fact-based analysis. survey includes an enumeration various look general discusses categorization, extraction summarization. Finally, it moves beyond just technical issues, devoting significant attention broader implications development information-access services have: questions privacy, vulnerability manipulation, whether or not reviews can have measurable economic impact. To facilitate future work, discussion available resources, benchmark datasets, evaluation campaigns also provided. first comprehensive this vibrant research will be anyone

public opinion, argument mining, social medium data, knowledge discovery, disinformation detection, opinion aggregation, data mining, sentiment analysis, social medium mining, computer science, text mining, social media, content analysis, communication, data science, opinion mining",2008,6350,public opinion|argument mining|social medium data|knowledge discovery|disinformation detection|opinion aggregation|data mining|sentiment analysis|social medium mining|computer science|text mining|social media|content analysis|communication|data science|opinion mining,https://openalex.org/W2251939518
https://openalex.org/W2116661285,Muiltiobjective Optimization Using Nondominated Sorting in Genetic Algorithms,"Muiltiobjective Optimization Using Nondominated Sorting in Genetic Algorithms

In trying to solve multiobjective optimization problems, many traditional methods scalarize the objective vector into a single objective. those cases, obtained solution is highly sensitive weight used in scalarization process and demands that user have knowledge about underlying problem. Moreover, solving designers may be interested set of Pareto-optimal points, instead point. Since genetic algorithms (GAs) work with population it seems natural use GAs problems capture number solutions simultaneously. Although evaluated GA (VEGA) has been implemented by Schaffer tried algorithm bias toward some regions. this paper, we investigate Goldberg's notion nondominated sorting along niche speciation method find multiple points The proof-of-principle results on three others suggest proposed can extended higher dimensional more difficult problems. A suggestions for extension application are also discussed.

muiltiobjective optimization, genetic algorithm, computer science, nondominated sorting, mathematical optimization",1994,6337,muiltiobjective optimization|genetic algorithm|computer science|nondominated sorting|mathematical optimization,https://openalex.org/W2126105956|https://openalex.org/W2106334424
https://openalex.org/W2963125010,ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices,"ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices

We introduce an extremely computation-efficient CNN architecture named ShuffleNet, which is designed specially for mobile devices with very limited computing power (e.g., 10-150 MFLOPs). The new utilizes two operations, pointwise group convolution and channel shuffle, to greatly reduce computation cost while maintaining accuracy. Experiments on ImageNet classification MS COCO object detection demonstrate the superior performance of ShuffleNet over other structures, e.g. lower top-1 error (absolute 7.8%) than recent MobileNet [12] task, under budget 40 MFLOPs. On ARM-based device, achieves ~13× actual speedup AlexNet comparable

computer science, mobile computing, convolutional neural network, mobile learning, neural architecture search, machine learning, recurrent neural network, mobile devices, neural computation, deep learning, neural network (machine learning)",2018,6329,computer science|mobile computing|convolutional neural network|mobile learning|neural architecture search|machine learning|recurrent neural network|mobile devices|neural computation|deep learning|neural network (machine learning),https://openalex.org/W2752782242|https://openalex.org/W2963163009|https://openalex.org/W2963420686|https://openalex.org/W3018757597
https://openalex.org/W2131846894,Video Google: a text retrieval approach to object matching in videos,"Video Google: a text retrieval approach to object matching in videos

We describe an approach to object and scene retrieval which searches for localizes all the occurrences of a user outlined in video. The is represented by set viewpoint invariant region descriptors so that recognition can proceed successfully despite changes viewpoint, illumination partial occlusion. temporal continuity video within shot used track regions order reject unstable reduce effects noise descriptors. analogy with text implementation where matches on are pre-computed (using vector quantization), inverted file systems document rankings used. result retrieved immediate, returning ranked list key frames/shots manner Google. method illustrated matching two full length feature films.

computer science, information retrieval, video retrieval, video google",2003,6322,computer science|information retrieval|video retrieval|video google,https://openalex.org/W2109255472|https://openalex.org/W2117228865|https://openalex.org/W3035524453|https://openalex.org/W2177274842|https://openalex.org/W2016053056
https://openalex.org/W2963840672,Multi-Scale Context Aggregation by Dilated Convolutions,"Multi-Scale Context Aggregation by Dilated Convolutions

State-of-the-art models for semantic segmentation are based on adaptations of convolutional networks that had originally been designed image classification. However, dense prediction and classification structurally different. In this work, we develop a new network module is specifically prediction. The presented uses dilated convolutions to systematically aggregate multi-scale contextual information without losing resolution. architecture the fact support exponential expansion receptive field loss resolution or coverage. We show context increases accuracy state-of-the-art systems. addition, examine adaptation simplifying adapted can increase accuracy.

dilated convolutions, scene understanding, computer vision, machine vision, multi-scale context aggregation, natural language processing, computer science, convolutional neural network, machine learning, deep learning, data science, scene analysis, image analysis",2015,6319,dilated convolutions|scene understanding|computer vision|machine vision|multi-scale context aggregation|natural language processing|computer science|convolutional neural network|machine learning|deep learning|data science|scene analysis|image analysis,https://openalex.org/W2412782625|https://openalex.org/W2963881378|https://openalex.org/W2560023338|https://openalex.org/W2340897893|https://openalex.org/W2395611524
https://openalex.org/W2025768430,Extracting and composing robust features with denoising autoencoders,"Extracting and composing robust features with denoising autoencoders

Previous work has shown that the difficulties in learning deep generative or discriminative models can be overcome by an initial unsupervised step maps inputs to useful intermediate representations. We introduce and motivate a new training principle for of representation based on idea making learned representations robust partial corruption input pattern. This approach used train autoencoders, these denoising autoencoders stacked initialize architectures. The algorithm motivated from manifold information theoretic perspective model perspective. Comparative experiments clearly show surprising advantage corrupting pattern classification benchmark suite.

autoencoders, computer science, feature learning, robust feature, machine learning, deep learning, feature construction, image denoising",2008,6318,autoencoders|computer science|feature learning|robust feature|machine learning|deep learning|feature construction|image denoising,https://openalex.org/W2095705004|https://openalex.org/W2896457183|https://openalex.org/W2099471712|https://openalex.org/W1533861849|https://openalex.org/W3035524453
https://openalex.org/W2165232124,Clustering by Passing Messages Between Data Points,"Clustering by Passing Messages Between Data Points

Clustering data by identifying a subset of representative examples is important for processing sensory signals and detecting patterns in data. Such “exemplars” can be found randomly choosing an initial points then iteratively refining it, but this works well only if that choice close to good solution. We devised method called “affinity propagation,” which takes as input measures similarity between pairs points. Real-valued messages are exchanged until high-quality set exemplars corresponding clusters gradually emerges. used affinity propagation cluster images faces, detect genes microarray data, identify sentences manuscript, cities efficiently accessed airline travel. Affinity with much lower error than other methods, it did so less one-hundredth the amount time.

computer science, clustering, data points",2007,6317,computer science|clustering|data points,
https://openalex.org/W1898259180,Fuzzy Sets and Fuzzy Logic: Theory and Applications,"Fuzzy Sets and Fuzzy Logic: Theory and Applications

Fuzzy Sets and Logic is a true magnum opus. An enlargement of Sets, Uncertainty,
and Information—an earlier work Professor Klir Tina Folger—Fuzzy Logic
addresses practically every significant topic in the broad expanse union fuzzy set theory
and logic. To me remarkable achievement; it covers its vast
territory with impeccable authority, deep insight meticulous attention to detail.
To view proper perspective, necessary clarify point
of semantics which relates meanings sets logic.
A frequent source misunderstanding fias do interpretation The
problem that term logic has two different meanings. More specifically, narrow
sense, logic, FLn, logical system may be viewed as an extension generalization
of classical multivalued logics. But wider sense, FL^ almost synonymous
with theory sets. In this context, what important recognize that: (a) FLW much
broader than FLn subsumes one branches; (b) agenda very different
from agendas logics; (c) at juncture, is
usually used wide rather narrow effectively equating FLW
In Logic, interpreted sense close FLW. However,
to avoid misunderstanding, title refers both logic.
Underlying organization fundamental fact, namely,
that any field X Y can fuzzified by replacing concept crisp Y
by set. application basic fields such arithmetic, topology, graph theory, probability
theory fuzzification leads theory,
fuzzy probability FLn. Similarly, hi applied neural network
theory, stability pattern recognition mathematical programming, to
fuzzy network mathematical
programming. What gained through greater generality, higher expressive
power, enhanced ability model real-world problems and, most importantly, methodology for
exploiting tolerance for imprecision—a serves achieve tractability,

computer science, knowledge representation and reasoning, fuzzy logic, fuzzy modeling, fuzzy pattern recognition, fuzzy optimization, applied mathematics, fuzzy computing, fuzzy mathematics, set theory, logic in computer science, fuzzy system, fuzzy set",1995,6309,computer science|knowledge representation and reasoning|fuzzy logic|fuzzy modeling|fuzzy pattern recognition|fuzzy optimization|applied mathematics|fuzzy computing|fuzzy mathematics|set theory|logic in computer science|fuzzy system|fuzzy set,
https://openalex.org/W2145962650,Robust principal component analysis?,"Robust principal component analysis?

This article is about a curious phenomenon. Suppose we have data matrix, which the superposition of low-rank component and sparse component. Can recover each individually? We prove that under some suitable assumptions, it possible to both components exactly by solving very convenient convex program called Principal Component Pursuit; among all feasible decompositions, simply minimize weighted combination nuclear norm ℓ1 norm. suggests possibility principled approach robust principal analysis since our methodology results assert one can matrix even though positive fraction its entries are arbitrarily corrupted. extends situation where missing as well. discuss an algorithm for this optimization problem, present applications in area video surveillance, allows detection objects cluttered background, face recognition, offers way removing shadows specularities images faces.

image analysis, pattern recognition, computer science, high-dimensional statistics, robust feature, machine learning, applied mathematics, robust optimization, robust statistic, systems engineering, analytics, machine learning research, principal component analysis, computational optimization, multidimensional analysis",2011,6289,image analysis|pattern recognition|computer science|high-dimensional statistics|robust feature|machine learning|applied mathematics|robust optimization|robust statistic|systems engineering|analytics|machine learning research|principal component analysis|computational optimization|multidimensional analysis,
https://openalex.org/W1904365287,Improving neural networks by preventing co-adaptation of feature detectors,"Improving neural networks by preventing co-adaptation of feature detectors

When a large feedforward neural network is trained on small training set, it typically performs poorly held-out test data. This ""overfitting"" greatly reduced by randomly omitting half of the feature detectors each case. prevents complex co-adaptations in which detector only helpful context several other specific detectors. Instead, neuron learns to detect that generally for producing correct answer given combinatorially variety internal contexts must operate. Random ""dropout"" gives big improvements many benchmark tasks and sets new records speech object recognition.

adversarial machine learning, pattern recognition, computer science, convolutional neural network, transfer learning, feature learning, machine learning, feature detection, cognitive science, feature detectors, data science, neural computation, deep learning, computational intelligence, machine learning research, neural networks, neural network (machine learning)",2012,6272,adversarial machine learning|pattern recognition|computer science|convolutional neural network|transfer learning|feature learning|machine learning|feature detection|cognitive science|feature detectors|data science|neural computation|deep learning|computational intelligence|machine learning research|neural networks|neural network (machine learning),https://openalex.org/W2194775991|https://openalex.org/W2163605009|https://openalex.org/W2097117768|https://openalex.org/W2618530766|https://openalex.org/W2963037989|https://openalex.org/W2099471712|https://openalex.org/W1677182931|https://openalex.org/W1821462560|https://openalex.org/W1832693441|https://openalex.org/W2963091558|https://openalex.org/W2125389028
https://openalex.org/W2103282498,Quantum computation with quantum dots,"Quantum computation with quantum dots

We propose an implementation of a universal set one- and two-quantum-bit gates for quantum computation using the spin states coupled single-electron dots. Desired operations are effected by gating tunneling barrier between neighboring Several measures gate quality computed within recently derived master equation incorporating decoherence caused prototypical magnetic environment. Dot-array experiments that would provide initial demonstration desired nonequilibrium dynamics proposed.

computer science, quantum information science, quantum algorithm, quantum science, quantum logic, quantum technology, quantum computing, quantum engineering, quantum device, quantum programming, quantum computation, photonics, quantum dot",1998,6266,computer science|quantum information science|quantum algorithm|quantum science|quantum logic|quantum technology|quantum computing|quantum engineering|quantum device|quantum programming|quantum computation|photonics|quantum dot,
https://openalex.org/W2630837129,Rethinking Atrous Convolution for Semantic Image Segmentation,"Rethinking Atrous Convolution for Semantic Image Segmentation

In this work, we revisit atrous convolution, a powerful tool to explicitly adjust filter's field-of-view as well control the resolution of feature responses computed by Deep Convolutional Neural Networks, in application semantic image segmentation. To handle problem segmenting objects at multiple scales, design modules which employ convolution cascade or parallel capture multi-scale context adopting rates. Furthermore, propose augment our previously proposed Atrous Spatial Pyramid Pooling module, probes convolutional features with image-level encoding global and further boost performance. We also elaborate on implementation details share experience training system. The `DeepLabv3' system significantly improves over previous DeepLab versions without DenseCRF post-processing attains comparable performance other state-of-art models PASCAL VOC 2012 segmentation benchmark.

pattern recognition, computer science, machine learning, atrous convolution, image segmentation, information fusion, convolutional neural network, biomedical imaging, cognitive science, data science, image representation, computational imaging, scene understanding, deep learning, semantic image segmentation, machine vision, digital image processing, scene interpretation, computer vision, scene analysis",2017,6262,pattern recognition|computer science|machine learning|atrous convolution|image segmentation|information fusion|convolutional neural network|biomedical imaging|cognitive science|data science|image representation|computational imaging|scene understanding|deep learning|semantic image segmentation|machine vision|digital image processing|scene interpretation|computer vision|scene analysis,https://openalex.org/W2963163009
https://openalex.org/W2084652510,A fast quantum mechanical algorithm for database search,"A fast quantum mechanical algorithm for database search

Article Free Access Share on A fast quantum mechanical algorithm for database search Author: Lov K. Grover 3C-404A, AT&T Bell Labs, 600 Mountain Avenue, Murray Hill, NJ NJView Profile Authors Info & Claims STOC '96: Proceedings of the twenty-eighth annual ACM symposium Theory ComputingJuly 1996Pages 212–219https://doi.org/10.1145/237814.237866Published:01 July 1996Publication History 3,453citation12,253DownloadsMetricsTotal Citations3,453Total Downloads12,253Last 12 Months3,433Last 6 weeks400 Get Citation AlertsNew Alert added!This alert has been successfully added and will be sent to:You notified whenever a record that you have chosen cited.To manage your preferences, click button below.Manage my Alert!Please log in to account Save BinderSave BinderCreate New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF

quantum algorithm, discrete algorithm, quantum mechanics, quantum computing, database, information search, computer science, database search, numerical algorithm",1996,6259,quantum algorithm|discrete algorithm|quantum mechanics|quantum computing|database|information search|computer science|database search|numerical algorithm,
https://openalex.org/W1555563750,The Description Logic Handbook,"The Description Logic Handbook

Description logics are embodied in several knowledge-based systems and used to develop various real-life applications. Now paperback, The Logic Handbook provides a thorough account of the subject, covering all aspects research this field, namely: theory, implementation, Its appeal will be broad, ranging from more theoretically oriented readers, those with practically interests who need sound modern understanding knowledge representation based on description logics. As well as general revision throughout book, new edition presents chapter ontology languages for semantic web, an area great importance future development web. In sum, book serve unique resource can also self-study or reference artificial intelligence courses.

computer science, knowledge representation and reasoning, description logic handbook, description logic, logic in computer science",2007,6255,computer science|knowledge representation and reasoning|description logic handbook|description logic|logic in computer science,
https://openalex.org/W2122967269,"Scheduling: Theory, Algorithms, and Systems","Scheduling: Theory, Algorithms, and Systems

This book on scheduling covers theoretical models as well problems in the real world. Author Michael Pinedo also includes a CD that contains slide-shows from industry and movies dealing with implementations of systems. The consists three parts. first part focuses deterministic associated combinatorial problems. second probabilistic models. In this it is assumed processing times other problem data are not known advance. third deals practice. It heuristics popular practitioners discusses system design development issues. Each chapter series computational exercises. interest to theoreticians alike. Graduate students operations management, research, industrial engineering computer science will find be an accessible invaluable resource. Scheduling serve essential reference for professionals working manufacturing computing environments. Julius Schlesinger Professor Operations Management at New York University.

distributed system, computer science, cloud scheduling, operations research, theoretical computer science, theory of computation, project scheduling, scheduling (production processes), scheduling problem, applied mathematics, systems engineering, scheduling (computing), swarm intelligence, computational optimization",1996,6247,distributed system|computer science|cloud scheduling|operations research|theoretical computer science|theory of computation|project scheduling|scheduling (production processes)|scheduling problem|applied mathematics|systems engineering|scheduling (computing)|swarm intelligence|computational optimization,
https://openalex.org/W1534416612,Optimization by Vector Space Methods,"Optimization by Vector Space Methods

From the Publisher:
Engineers must make decisions regarding distribution of expensive resources in a manner that will be economically beneficial. This problem can realistically formulated and logically analyzed with optimization theory. book shows engineers how to use theory solve complex problems. Unifies large field few geometric principles. Covers functional analysis minimum mathematics. Contains problems relate applications book.

computer science, engineering optimization, global optimization, mathematical optimization, vector space methods, applied mathematics, vector space model, numerical analysis, combinatorial optimization, design optimization, computational optimization, computer engineering",1970,6246,computer science|engineering optimization|global optimization|mathematical optimization|vector space methods|applied mathematics|vector space model|numerical analysis|combinatorial optimization|design optimization|computational optimization|computer engineering,https://openalex.org/W2134383396|https://openalex.org/W2141224535
https://openalex.org/W2173520492,Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks,"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks

In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised CNNs received less attention. this work we hope to help bridge the gap between success of for and learning. We introduce a class called deep generative adversarial (DCGANs), that have certain architectural constraints, demonstrate they are strong candidate Training on various image datasets, show convincing evidence our pair learns hierarchy representations from object parts scenes both generator discriminator. Additionally, use learned features novel tasks - demonstrating their applicability as general representations.

computer science, generative ai, convolutional neural network, cognitive science, dimensionality reduction, unsupervised representation, image classification, digital image processing, data science, deep learning, machine learning, generative adversarial network, computational imaging, machine learning research, natural language processing, machine vision, image analysis, computational intelligence, image representation",2015,6233,computer science|generative ai|convolutional neural network|cognitive science|dimensionality reduction|unsupervised representation|image classification|digital image processing|data science|deep learning|machine learning|generative adversarial network|computational imaging|machine learning research|natural language processing|machine vision|image analysis|computational intelligence|image representation,https://openalex.org/W2962793481|https://openalex.org/W2963073614|https://openalex.org/W2954996726
https://openalex.org/W1511986666,Probabilistic graphical models : principles and techniques,"Probabilistic graphical models : principles and techniques

Most tasks require a person or an automated system to reason -- reach conclusions based on available information. The framework of probabilistic graphical models, presented in this book, provides general approach for task. is model-based, allowing interpretable models be constructed and then manipulated by reasoning algorithms. These can also learned automatically from data, the used cases where manually constructing model difficult even impossible. Because uncertainty inescapable aspect most real-world applications, book focuses which make explicit provide that are more faithful reality. Probabilistic Graphical Models discusses variety spanning Bayesian networks, undirected Markov discrete continuous extensions deal with dynamical systems relational data. For each class text describes three fundamental cornerstones: representation, inference, learning, presenting both basic concepts advanced techniques. Finally, considers use proposed causal decision making under uncertainty. main chapter detailed technical development key ideas. chapters include boxes additional material: skill boxes, describe techniques; case study discuss empirical related described text, including applications computer vision, robotics, natural language understanding, computational biology; concept present significant drawn material chapter. Instructors (and readers) group various combinations, core topics technically material, suit their particular needs.

computer science, statistical methodology, probabilistic graphical models, probabilistic programming, uncertainty analysis, statistical inference, probability theory, applied mathematics, predictive modeling, applied probability, bayesian analysis, probabilistic graph theory, probabilistic system, computational statistic, statistics, machine learning research, statistical model, graphical model",2009,6230,computer science|statistical methodology|probabilistic graphical models|probabilistic programming|uncertainty analysis|statistical inference|probability theory|applied mathematics|predictive modeling|applied probability|bayesian analysis|probabilistic graph theory|probabilistic system|computational statistic|statistics|machine learning research|statistical model|graphical model,
https://openalex.org/W2121606987,Near Shannon limit error-correcting coding and decoding: Turbo-codes. 1,"Near Shannon limit error-correcting coding and decoding: Turbo-codes. 1

A new class of convolutional codes called turbo-codes, whose performances in terms bit error rate (BER) are close to the Shannon limit, is discussed. The turbo-code encoder built using a parallel concatenation two recursive systematic codes, and associated decoder, feedback decoding rule, implemented as P pipelined identical elementary decoders.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>

digital signal processing, error correction code, computer science, algebraic coding theory",2002,6222,digital signal processing|error correction code|computer science|algebraic coding theory,https://openalex.org/W2137813581
https://openalex.org/W2126554879,Swarm Intelligence,"Swarm Intelligence

Social insects--ants, bees, termites, and wasps--can be viewed as powerful problem-solving systems with sophisticated collective intelligence. Composed of simple interacting agents, this intelligence lies in the networks interactions among individuals between environment. A fascinating subject, social insects are also a metaphor for artificial intelligence, problems they solve--finding food, dividing labor nestmates, building nests, responding to external challenges--have important counterparts engineering computer science. This book provides detailed look at models insect behavior how apply these design complex systems. The shows replace an emphasis on control, preprogramming, centralization designs featuring autonomy, emergence, distributed functioning. These proving immensely flexible robust, able adapt quickly changing environments continue functioning even when individual elements fail. In particular, exciting approach tremendous growth complexity software information. Swarm Intelligence draws up-to-date research from biology, neuroscience, robotics, operations research, graphics, each chapter is organized around particular biological example, which then used develop algorithm, multiagent system, or group robots. will invaluable resource broad range disciplines.

distributed system, distributed intelligence, computer science, artificial intelligence, intelligent computing, distributed artificial intelligence, intelligent systems, control optimization, swarm robotics, networked swarm, swarm dynamic, systems engineering, computational intelligence, swarm intelligence, neural network (machine learning), machine intelligence, multiagent system",1999,6219,distributed system|distributed intelligence|computer science|artificial intelligence|intelligent computing|distributed artificial intelligence|intelligent systems|control optimization|swarm robotics|networked swarm|swarm dynamic|systems engineering|computational intelligence|swarm intelligence|neural network (machine learning)|machine intelligence|multiagent system,
https://openalex.org/W2158733823,Random early detection gateways for congestion avoidance,"Random early detection gateways for congestion avoidance

The authors present random early detection (RED) gateways for congestion avoidance in packet-switched networks. gateway detects incipient by computing the average queue size. could notify connections of either dropping packets arriving at or setting a bit packet headers. When size exceeds threshold, drops marks each with certain probability, where exact probability is function RED keep low while allowing occasional bursts queue. During congestion, that notifies particular connection to reduce its window roughly proportional connection's share bandwidth through gateway. are designed accompany transport-layer control protocol such as TCP. has no bias against bursty traffic and avoids global synchronization many decreasing their same time. Simulations TCP/IP network used illustrate performance gateways.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>

early detection gateways, computer science, congestion avoidance, machine learning, early detection",1993,6216,early detection gateways|computer science|congestion avoidance|machine learning|early detection,
https://openalex.org/W2137813581,Factor graphs and the sum-product algorithm,"Factor graphs and the sum-product algorithm

Algorithms that must deal with complicated global functions of many variables often exploit the manner in which given factor as a product ""local"" functions, each depends on subset variables. Such factorization can be visualized bipartite graph we call graph, In this tutorial paper, present generic message-passing algorithm, sum-product operates graph. Following single, simple computational rule, algorithm computes-either exactly or approximately-various marginal derived from function. A wide variety algorithms developed artificial intelligence, signal processing, and digital communications specific instances including forward/backward Viterbi iterative ""turbo"" decoding Pearl's (1988) belief propagation for Bayesian networks, Kalman filter, certain fast Fourier transform (FFT) algorithms.

computer science, sum-product algorithm, graph theory, factor graphs",2001,6209,computer science|sum-product algorithm|graph theory|factor graphs,https://openalex.org/W2165232124
https://openalex.org/W2962770929,A Style-Based Generator Architecture for Generative Adversarial Networks,"A Style-Based Generator Architecture for Generative Adversarial Networks

We propose an alternative generator architecture for generative adversarial networks, borrowing from style transfer literature. The new leads to automatically learned, unsupervised separation of high-level attributes (e.g., pose and identity when trained on human faces) stochastic variation in the generated images freckles, hair), it enables intuitive, scale-specific control synthesis. improves state-of-the-art terms traditional distribution quality metrics, demonstrably better interpolation properties, also disentangles latent factors variation. To quantify disentanglement, we two new, automated methods that are applicable any architecture. Finally, introduce a highly varied high-quality dataset faces.

image analysis, pattern recognition, computer science, natural language processing, natural language generation, computer graphic, generative adversarial network, machine learning, generative ai, style transfer, architecture, deep learning, image representation, style-based generator architecture, synthetic image generation, design, procedural generation",2019,6186,image analysis|pattern recognition|computer science|natural language processing|natural language generation|computer graphic|generative adversarial network|machine learning|generative ai|style transfer|architecture|deep learning|image representation|style-based generator architecture|synthetic image generation|design|procedural generation,
https://openalex.org/W2057175746,Shape matching and object recognition using shape contexts,"Shape matching and object recognition using shape contexts

We present a novel approach to measuring similarity between shapes and exploit it for object recognition. In our framework, the measurement of is preceded by: (1) solving correspondences points on two shapes; (2) using estimate an aligning transform. order solve correspondence problem, we attach descriptor, shape context, each point. The context at reference point captures distribution remaining relative it, thus offering globally discriminative characterization. Corresponding similar will have contexts, enabling us as optimal assignment problem. Given correspondences, transformation that best aligns regularized thin-plate splines provide flexible class maps this purpose. dissimilarity computed sum matching errors corresponding points, together with term magnitude treat recognition in nearest-neighbor classification framework problem finding stored prototype maximally image. Results are presented silhouettes, trademarks, handwritten digits, COIL data set.

pattern recognition, computer science, object recognition, shape matching, shape contexts",2002,6174,pattern recognition|computer science|object recognition|shape matching|shape contexts,https://openalex.org/W2136922672|https://openalex.org/W2177274842|https://openalex.org/W2057175746
https://openalex.org/W1990911977,The vision of autonomic computing,"The vision of autonomic computing

A 2001 IBM manifesto observed that a looming software complexity crisis -caused by applications and environments number into the tens of millions lines code - threatened to halt progress in computing. The noted almost impossible difficulty managing current planned computing systems, which require integrating several heterogeneous corporate-wide systems extend Internet. Autonomic computing, perhaps most attractive approach solving this problem, creates can manage themselves when given high-level objectives from administrators. Systems according an administrator's goals. New components integrate as effortlessly new cell establishes itself human body. These ideas are not science fiction, but elements grand challenge create self-managing systems.

automation, autonomic computing, computer science, autonomic system",2003,6172,automation|autonomic computing|computer science|autonomic system,
https://openalex.org/W2021520922,CHARMM‐GUI: A web‐based graphical user interface for CHARMM,"CHARMM‐GUI: A web‐based graphical user interface for CHARMM

CHARMM is an academic research program used widely for macromolecular mechanics and dynamics with versatile analysis manipulation tools of atomic coordinates trajectories. CHARMM-GUI, http://www.charmm-gui.org, has been developed to provide a web-based graphical user interface generate various input files molecular systems facilitate standardize the usage common advanced simulation techniques in CHARMM. The web environment provides ideal platform build validate model system interactive fashion such that, if problem found through visual inspection, one can go back previous setup regenerate whole again. In this article, we describe currently available functional modules CHARMM-GUI Input Generator that form basis techniques. Future directions development project are also discussed briefly together other features website, as Archive Movie Gallery. © 2008 Wiley Periodicals, Inc. J Comput Chem,

user interface design, computer science, human-computer interaction, user interface",2008,6170,user interface design|computer science|human-computer interaction|user interface,
https://openalex.org/W2097073572,A Non-Local Algorithm for Image Denoising,"A Non-Local Algorithm for Image Denoising

We propose a new measure, the method noise, to evaluate and compare performance of digital image denoising methods. first compute analyze this noise for wide class algorithms, namely local smoothing filters. Second, we algorithm, nonlocal means (NL-means), based on averaging all pixels in image. Finally, present some experiments comparing NL-means algorithm

computational imaging, computer science, computer vision, image denoising, non-local algorithm, digital image processing",2005,6157,computational imaging|computer science|computer vision|image denoising|non-local algorithm|digital image processing,https://openalex.org/W2963073614|https://openalex.org/W2963091558|https://openalex.org/W2508457857
https://openalex.org/W1989702938,Face recognition,"Face recognition

As one of the most successful applications image analysis and understanding, face recognition has recently received significant attention, especially during past several years. At least two reasons account for this trend: first is wide range commercial law enforcement applications, second availability feasible technologies after 30 years research. Even though current machine systems have reached a certain level maturity, their success limited by conditions imposed many real applications. For example, images acquired in an outdoor environment with changes illumination and/or pose remains largely unsolved problem. In other words, are still far away from capability human perception system.This paper provides up-to-date critical survey still- video-based There underlying motivations us to write paper: provide review existing literature, offer some insights into studies faces. To comprehensive survey, we not only categorize techniques but also present detailed descriptions representative methods within each category. addition, relevant topics such as psychophysical studies, system evaluation, issues variation covered.

image analysis, pattern recognition, computer science, computational imaging, image classification, object recognition, feature extraction, automatic identification, computer vision, machine learning, biometrics, cognitive science, data science, image representation, face recognition, automatic classification, machine vision",2003,6149,image analysis|pattern recognition|computer science|computational imaging|image classification|object recognition|feature extraction|automatic identification|computer vision|machine learning|biometrics|cognitive science|data science|image representation|face recognition|automatic classification|machine vision,https://openalex.org/W2129812935|https://openalex.org/W2163808566
https://openalex.org/W2150687058,A grid-based Bader analysis algorithm without lattice bias,"A grid-based Bader analysis algorithm without lattice bias

A computational method for partitioning a charge density grid into Bader volumes is presented which efficient, robust, and scales linearly with the number of points. The algorithm follows steepest ascent paths along gradient from point to until maximum reached. In this paper, we describe how accurate off-lattice can be represented respect This improvement maintains efficient linear scaling an earlier version algorithm, eliminates tendency surfaces aligned directions. As assigns points maxima, subsequent are terminated when they reach previously assigned It grid-based approach gives its efficiency, allows analysis large grids generated plane-wave-based functional theory calculations.

computer science, algorithmic bias, lattice bias, mathematical optimization, grid optimization, applied mathematics, numerical analysis, analysis of algorithm",2009,6140,computer science|algorithmic bias|lattice bias|mathematical optimization|grid optimization|applied mathematics|numerical analysis|analysis of algorithm,
https://openalex.org/W2064853889,Mining frequent patterns without candidate generation,"Mining frequent patterns without candidate generation

Mining frequent patterns in transaction databases, time-series and many other kinds of databases has been studied popularly data mining research. Most the previous studies adopt an Apriori-like candidate set generation-and-test approach. However, generation is still costly, especially when there exist prolific and/or long patterns. In this study, we propose a novel pattern tree (FP-tree) structure, which extended prefix-tree structure for storing compressed, crucial information about patterns, develop efficient FP-tree-based method, FP-growth, complete by fragment growth. Efficiency achieved with three techniques: (1) large database compressed into highly condensed, much smaller avoids repeated scans, (2) our adopts growth method to avoid costly number sets, (3) partitioning-based, divide-and-conquer used decompose task tasks confined conditional dramatically reduces search space. Our performance study shows that FP-growth scalable both short order magnitude faster than Apriori algorithm also some recently reported new methods.

data mining, mining frequent patterns, computer science, candidate generation, frequent pattern mining, pattern mining",2000,6131,data mining|mining frequent patterns|computer science|candidate generation|frequent pattern mining|pattern mining,
https://openalex.org/W2113242816,The random subspace method for constructing decision forests,"The random subspace method for constructing decision forests

Much of previous attention on decision trees focuses the splitting criteria and optimization tree sizes. The dilemma between overfitting achieving maximum accuracy is seldom resolved. A method to construct a based classifier proposed that maintains highest training data improves generalization as it grows in complexity. consists multiple constructed systematically by pseudorandomly selecting subsets components feature vector, is, randomly chosen subspaces. subspace compared single-tree classifiers other forest construction methods experiments publicly available datasets, where method's superiority demonstrated. We also discuss independence relate combined classification accuracy.

random subspace method, decision theory, computer science, decision forests, decision tree learning, decision tree",1998,6120,random subspace method|decision theory|computer science|decision forests|decision tree learning|decision tree,
https://openalex.org/W1834627138,Deep Learning Face Attributes in the Wild,"Deep Learning Face Attributes in the Wild

Predicting face attributes in the wild is challenging due to complex variations. We propose a novel deep learning framework for attribute prediction wild. It cascades two CNNs, LNet and ANet, which are fine-tuned jointly with tags, but pre-trained differently. by massive general object categories localization, while ANet identities prediction. This not only outperforms state-of-the-art large margin, also reveals valuable facts on representation. (1) shows how performances of localization (LNet) (ANet) can be improved different pre-training strategies. (2) that although filters image-level their response maps over entire images have strong indication locations. fact enables training annotations, without bounding boxes or landmarks, required all recognition works. (3) demonstrates high-level hidden neurons automatically discover semantic concepts after identities, such significantly enriched fine-tuning tags. Each well explained sparse linear combination these concepts.

image analysis, pattern recognition, computer science, computational imaging, scene interpretation, computer vision, machine learning, face attributes, data science, computational intelligence, deep learning, human image synthesis, style transfer, facial recognition system, machine vision, face detection",2015,6114,image analysis|pattern recognition|computer science|computational imaging|scene interpretation|computer vision|machine learning|face attributes|data science|computational intelligence|deep learning|human image synthesis|style transfer|facial recognition system|machine vision|face detection,
https://openalex.org/W2145482038,Computing Machinery and Intelligence (1950),"Computing Machinery and Intelligence (1950)

Abstract Together with ‘On Computable Numbers’, ‘Computing Machinery and Intelligence’ forms Turing’s best-known work. This elegant sometimes amusing essay was originally published in 1950 the leading philosophy journal Mind. friend Robin Gandy (like Turing a mathematical logician) said that Intelligence’… intended not so much as penetrating contribution to but propaganda. thought time had come for philosophers mathematicians scientists take seriously fact computers were merely calculating engines capable of behaviour which must be accounted intelligent; he sought persuade people this so. He wrote paper—unlike his papers—quickly enjoyment. I can remember him reading aloud me some passages— always smile, giggle. The quality originality have earned it place among classics mind. contains principal exposition famous ‘imitation game’ or test. test first appeared, restricted form, closing paragraphs ‘Intelligent Machinery’ (Chapter 10). Chapters 13 14, dating from 1951 1952 respectively, contain further discussion amplification; unpublished until 1999, important additional material throws new light on how is understood. imitation game involves three participants: computer, human interrogator, ‘foil’. interrogator attempts determine, by asking questions other two participants, them computer. All communication via keyboard screen, an equivalent arrangement (Turing suggested teleprinter link). may ask wide-ranging she likes, computer permitted do everything possible force wrong identification. (So might answer ‘No’ response ‘Are you computer?’ follow request multiply one large number another long pause plausibly incorrect answer.) foil help make correct

intelligent processing, computer science, artificial intelligence, human-computer interaction, intelligent computing, intelligent systems, theory of computation, cognitive computing, automated reasoning, systems engineering, computational intelligence, human computation, human-like intelligence, scientific computing, machine intelligence, cognitive technology, computational science, computer engineering",2004,6084,intelligent processing|computer science|artificial intelligence|human-computer interaction|intelligent computing|intelligent systems|theory of computation|cognitive computing|automated reasoning|systems engineering|computational intelligence|human computation|human-like intelligence|scientific computing|machine intelligence|cognitive technology|computational science|computer engineering,
https://openalex.org/W1996021349,"The wavelet transform, time-frequency localization and signal analysis","The wavelet transform, time-frequency localization and signal analysis

Two different procedures for effecting a frequency analysis of time-dependent signal locally in time are studied. The first procedure is the short-time or windowed Fourier transform; second wavelet transform, which high-frequency components studied with sharper resolution than low-frequency components. similarities and differences between these two methods discussed. For both schemes detailed study made reconstruction method its stability as function chosen time-frequency density. Finally, notion localization precise, within this framework, by theorems.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>

computer science, signal processing, digital signal processing, wavelet, wavelet theory, time-frequency localization, wavelet transform, signal analysis",1990,6080,computer science|signal processing|digital signal processing|wavelet|wavelet theory|time-frequency localization|wavelet transform|signal analysis,https://openalex.org/W2034139177|https://openalex.org/W2151693816
https://openalex.org/W3096831136,Generative adversarial networks,"Generative adversarial networks

Generative adversarial networks are a kind of artificial intelligence algorithm designed to solve the generative modeling problem. The goal model is study collection training examples and learn probability distribution that generated them. Adversarial Networks (GANs) then able generate more from estimated distribution. models based on deep learning common, but GANs among most successful (especially in terms their ability realistic high-resolution images). have been successfully applied wide variety tasks (mostly research settings) continue present unique challenges opportunities because they game theory while other approaches optimization.

computer science, generative adversarial network, machine learning",2020,6076,computer science|generative adversarial network|machine learning,
https://openalex.org/W2110999179,"The automated computation of tree-level and next-to-leading order differential cross sections, and their matching to parton shower simulations","The automated computation of tree-level and next-to-leading order differential cross sections, and their matching to parton shower simulations

We discuss the theoretical bases that underpin automation of computations tree-level and next-to-leading order cross sections, their matching to parton shower simulations, merging matched samples differ by light-parton multiplicities. present a computer program, MadGraph5_aMC@NLO, capable handling all these -- parton-level fixed order, shower-matched, merged in unified framework whose defining features are flexibility, high level parallelisation, human intervention limited input physics quantities. demonstrate potential program presenting selected phenomenological applications relevant LHC 1-TeV $e^+e^-$ collider. While results restricted QCD corrections SM processes first public version, we show from user viewpoint no changes have be expected case due any given renormalisable Lagrangian, implementation well under way.

finite element method, reduced order modeling, computer science, differential geometry, structure from motion, thermal engineering, numerical method for partial differential equation, systems biology, applied mathematics, numerical algorithm, shower simulations, computational mechanics, numerical analysis, computational electromagnetics, order theory, numerical simulation, automated computation, computational geometry",2014,6062,finite element method|reduced order modeling|computer science|differential geometry|structure from motion|thermal engineering|numerical method for partial differential equation|systems biology|applied mathematics|numerical algorithm|shower simulations|computational mechanics|numerical analysis|computational electromagnetics|order theory|numerical simulation|automated computation|computational geometry,
https://openalex.org/W2963857521,Towards Evaluating the Robustness of Neural Networks,"Towards Evaluating the Robustness of Neural Networks

Neural networks provide state-of-the-art results for most machine learning tasks. Unfortunately, neural are vulnerable to adversarial examples: given an input x and any target classification t, it is possible find a new x' that similar but classified as t. This makes difficult apply in security-critical areas. Defensive distillation recently proposed approach can take arbitrary network, increase its robustness, reducing the success rate of current attacks' ability examples from 95% 0.5%. In this paper, we demonstrate defensive does not significantly robustness by introducing three attack algorithms successful on both distilled undistilled with 100% probability. Our attacks tailored distance metrics used previously literature, when compared previous example generation algorithms, our often much more effective (and never worse). Furthermore, propose using high-confidence simple transferability test show also be break distillation. We hope will benchmark future defense attempts create resist examples.

computer science, robustness (computer science), machine learning, network robustness, neural networks, neural computation, neural network (machine learning), robustness testing",2017,6058,computer science|robustness (computer science)|machine learning|network robustness|neural networks|neural computation|neural network (machine learning)|robustness testing,
https://openalex.org/W1901616594,"Machine learning: Trends, perspectives, and prospects","Machine learning: Trends, perspectives, and prospects

Machine learning addresses the question of how to build computers that improve automatically through experience. It is one today’s most rapidly growing technical fields, lying at intersection computer science and statistics, core artificial intelligence data science. Recent progress in machine has been driven both by development new algorithms theory ongoing explosion availability online low-cost computation. The adoption data-intensive machine-learning methods can be found throughout science, technology commerce, leading more evidence-based decision-making across many walks life, including health care, manufacturing, education, financial modeling, policing, marketing.

computer science, computational learning theory, supervised learning, statistical learning theory, unsupervised machine learning, machine learning, data science, knowledge discovery, deep learning, machine learning research, neural network (machine learning), automated machine learning",2015,6055,computer science|computational learning theory|supervised learning|statistical learning theory|unsupervised machine learning|machine learning|data science|knowledge discovery|deep learning|machine learning research|neural network (machine learning)|automated machine learning,
https://openalex.org/W2131726714,Xen and the art of virtualization,"Xen and the art of virtualization

Numerous systems have been designed which use virtualization to subdivide the ample resources of a modern computer. Some require specialized hardware, or cannot support commodity operating systems. target 100% binary compatibility at expense performance. Others sacrifice security functionality for speed. Few offer resource isolation performance guarantees; most provide only best-effort provisioning, risking denial service.This paper presents Xen, an x86 virtual machine monitor allows multiple share conventional hardware in safe and managed fashion, but without sacrificing either functionality. This is achieved by providing idealized abstraction such as Linux, BSD Windows XP, can be ported with minimal effort.Our design targeted hosting up 100 instances simultaneously on server. The approach taken Xen extremely efficient: we allow Linux XP hosted negligible overhead --- few percent compared unvirtualized case. We considerably outperform competing commercial freely available solutions range microbenchmarks system-wide tests.

technology, human-computer interaction, data virtualization, network virtualization, virtual reality, distributed system, virtualization security, extended reality, computer science, virtualization support, virtualized infrastructure, communication",2003,6042,technology|human-computer interaction|data virtualization|network virtualization|virtual reality|distributed system|virtualization security|extended reality|computer science|virtualization support|virtualized infrastructure|communication,
https://openalex.org/W2130660124,Content-based image retrieval at the end of the early years,"Content-based image retrieval at the end of the early years

Presents a review of 200 references in content-based image retrieval. The paper starts with discussing the working conditions retrieval: patterns use, types pictures, role semantics, and sensory gap. Subsequent sections discuss computational steps for retrieval systems. Step one is processing sorted by color, texture, local geometry. Features are discussed next, by: accumulative global features, salient points, object shape signs, structural combinations thereof. Similarity pictures objects reviewed each feature types, close connection to means feedback user systems capable giving interaction. We briefly aspects system engineering: databases, architecture, evaluation. In concluding section, we present our view on: driving force field, heritage from computer vision, influence on similarity interaction, need problem evaluation, semantic

image analysis, content-based image retrieval, computer science, image search, early years, image retrieval, image representation, information retrieval, digital image processing",2000,6037,image analysis|content-based image retrieval|computer science|image search|early years|image retrieval|image representation|information retrieval|digital image processing,
https://openalex.org/W1831050183,Building Predictive Models in<i>R</i>Using the<b>caret</b>Package,"Building Predictive Models in<i>R</i>Using the<b>caret</b>Package

The caret package, short for classification and regression training, contains numerous tools developing predictive models using the rich set of available in R. package focuses on simplifying model training tuning across a wide variety modeling techniques. It also includes methods pre-processing data, calculating variable importance, visualizations. An example from computational chemistry is used to illustrate functionality real data benchmark benefits parallel processing with several types models.

prediction modelling, computer science, predictive learning, structured prediction, systems biology, machine learning, systems modeling, predictive analytics, predictive modeling, data science, modeling and simulation, machine learning research, predictive models, data modeling, computational model",2008,6036,prediction modelling|computer science|predictive learning|structured prediction|systems biology|machine learning|systems modeling|predictive analytics|predictive modeling|data science|modeling and simulation|machine learning research|predictive models|data modeling|computational model,
https://openalex.org/W2003370853,Theory of edge detection,"Theory of edge detection

A theory of edge detection is presented. The analysis proceeds in two parts. (1) Intensity changes, which occur a natural image over wide range scales, are detected separately at different scales. An appropriate filter for this purpose given scale found to be the second derivative Gaussian, and it shown that, provided some simple conditions satisfied, these primary filters need not orientation-dependent. Thus, intensity changes best by finding zero values ∇ 2 G(x, y) * I(x, I, where two-dimen­sional Gaussian distribution Laplacian. thus discovered each channels then represented oriented primitives called zero-crossing segments, evidence that representation complete. (2) images arise from surface discontinuities or reflectance illumination bound­aries, all have property they spatially localized. Because this, segments independent, rules deduced combining them into description image. This raw primal sketch. explains several basic psychophysical findings, opera­tion forming output centre-surround G acting on forms basis physiological model cells (see Marr &amp; Ullman 1979).

image analysis, pattern recognition, computer science, machine vision, graph theory, edge detection, theoretical computer science, computer vision, applied mathematics, feature detection, object detection, localization, systems engineering, image representation, spectral theory, detection technique, image segmentation, convex analysis",1980,6016,image analysis|pattern recognition|computer science|machine vision|graph theory|edge detection|theoretical computer science|computer vision|applied mathematics|feature detection|object detection|localization|systems engineering|image representation|spectral theory|detection technique|image segmentation|convex analysis,https://openalex.org/W2145023731
https://openalex.org/W2402144811,TensorFlow: a system for large-scale machine learning,"TensorFlow: a system for large-scale machine learning

TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. Tensor-Flow uses dataflow graphs to represent computation, shared state, the operations mutate state. It maps nodes of graph across many machines cluster, within multiple computational devices, including multicore CPUs, general-purpose GPUs, custom-designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility application developer: whereas previous parameter server designs management state built into system, enables developers experiment with novel optimizations training algorithms. supports variety applications, focus on inference deep neural networks. Several Google services use production, we have released it an open-source project, has become widely used for research. In this paper, describe model demonstrate compelling performance achieves several real-world applications.

massive data processing, machine learning, computer science, systems engineering, large ai model, machine learning research, large-scale datasets, data science, algorithmic learning, automated machine learning, large-scale machine learning",2016,6009,massive data processing|machine learning|computer science|systems engineering|large ai model|machine learning research|large-scale datasets|data science|algorithmic learning|automated machine learning|large-scale machine learning,https://openalex.org/W2954996726
https://openalex.org/W2168676717,Algorithms for quantum computation: discrete logarithms and factoring,"Algorithms for quantum computation: discrete logarithms and factoring

A computer is generally considered to be a universal computational device; i.e., it believed able simulate any physical device with cost in computation time of at most polynomial factor: It not clear whether this still true when quantum mechanics taken into consideration. Several researchers, starting David Deutsch, have developed models for mechanical computers and investigated their properties. This paper gives Las Vegas algorithms finding discrete logarithms factoring integers on that take number steps which the input size, e.g., digits integer factored. These two problems are hard classical been used as basis several proposed cryptosystems. We thus give first examples cryptanalysis.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>

computer science, quantum algorithm, quantum computing, quantum computation, discrete logarithms",2002,6004,computer science|quantum algorithm|quantum computing|quantum computation|discrete logarithms,https://openalex.org/W2084652510
https://openalex.org/W2116341502,The Graph Neural Network Model,"The Graph Neural Network Model

Many underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, biology, pattern recognition, mining, can be represented terms graphs. In this paper, we propose a new neural network model, called graph (GNN) that extends existing methods for processing the domains. This GNN which directly process most practically useful types graphs, acyclic, cyclic, directed, undirected, implements function tau(G,n) isin IR <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">m</sup> maps G one its nodes <i xmlns:xlink=""http://www.w3.org/1999/xlink"">n</i> into an xmlns:xlink=""http://www.w3.org/1999/xlink"">m</i> -dimensional Euclidean space. A supervised learning algorithm is derived to estimate parameters proposed model. The computational cost also considered. Some experimental results are shown validate algorithm, demonstrate generalization capabilities.

computer science, graph theory, machine learning, neural network (machine learning), graph neural network",2009,5998,computer science|graph theory|machine learning|neural network (machine learning)|graph neural network,https://openalex.org/W2963091558
https://openalex.org/W2036265926,The complexity of theorem-proving procedures,"The complexity of theorem-proving procedures

It is shown that any recognition problem solved by a polynomial time-bounded nondeterministic Turing machine can be “reduced” to the of determining whether given propositional formula tautology. Here means, roughly speaking, first deterministically in time provided an oracle available for solving second. From this notion reducible, degrees difficulty are defined, and it tautologyhood has same degree as two graphs isomorphic subgraph Other examples discussed. A method measuring complexity proof procedures predicate calculus introduced

mathematics, computational complexity, computer science, computational complexity theory, proof theory, proof complexity, theorem-proving procedures, logic in computer science",1971,5996,mathematics|computational complexity|computer science|computational complexity theory|proof theory|proof complexity|theorem-proving procedures|logic in computer science,
https://openalex.org/W2174661749,"Radiomics: Images Are More than Pictures, They Are Data","Radiomics: Images Are More than Pictures, They Are Data

In the past decade, field of medical image analysis has grown exponentially, with an increased number pattern recognition tools and increase in data set sizes. These advances have facilitated development processes for high-throughput extraction quantitative features that result conversion images into mineable subsequent these decision support; this practice is termed radiomics. This contrast to traditional treating as pictures intended solely visual interpretation. Radiomic contain first-, second-, higher-order statistics. are combined other patient mined sophisticated bioinformatics develop models may potentially improve diagnostic, prognostic, predictive accuracy. Because radiomics analyses be conducted standard care images, it conceivable digital will eventually become routine practice. report describes process radiomics, its challenges, potential power facilitate better clinical making, particularly patients cancer.

image analysis, pattern recognition, computer science, computational imaging, content-based image retrieval, radiomics, image communication, computer vision, data and information visualization, image sequence analysis, data science, image representation, radiographic imaging, machine learning research, machine vision, digital image processing, image database",2016,5990,image analysis|pattern recognition|computer science|computational imaging|content-based image retrieval|radiomics|image communication|computer vision|data and information visualization|image sequence analysis|data science|image representation|radiographic imaging|machine learning research|machine vision|digital image processing|image database,
https://openalex.org/W4288089799,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer,"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer

Transfer learning, where a model is first pre-trained on data-rich task before being fine-tuned downstream task, has emerged as powerful technique in natural language processing (NLP). The effectiveness of transfer learning given rise to diversity approaches, methodology, and practice. In this paper, we explore the landscape techniques for NLP by introducing unified framework that converts all text-based problems into text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled data sets, other factors dozens understanding tasks. By combining insights from our exploration with scale new ``Colossal Clean Crawled Corpus'', achieve state-of-the-art results many benchmarks covering summarization, question answering, text classification, more. To facilitate future work NLP, release set, models, code.

machine learning, computer science, unified text-to-text transformer, natural language processing, text processing, transfer learning",2019,5988,machine learning|computer science|unified text-to-text transformer|natural language processing|text processing|transfer learning,https://openalex.org/W3138516171
https://openalex.org/W2095905764,Use of the Hough transformation to detect lines and curves in pictures,"Use of the Hough transformation to detect lines and curves in pictures

Hough has proposed an interesting and computationally efficient procedure for detecting lines in pictures. This paper points out that the use of angle-radius rather than slope-intercept parameters simplifies computation further. It also shows how method can be used more general curve fitting, gives alternative interpretations explain source its efficiency.

pattern recognition, computer science, visual science, image analysis, neuroscience, object detection, image representation, hough transformation, computational imaging, computational geometry, localization, shift detection, machine vision, digital image processing, curve fitting, object recognition, computer vision, curve modeling, applied mathematics",1972,5979,pattern recognition|computer science|visual science|image analysis|neuroscience|object detection|image representation|hough transformation|computational imaging|computational geometry|localization|shift detection|machine vision|digital image processing|curve fitting|object recognition|computer vision|curve modeling|applied mathematics,
https://openalex.org/W2060108852,A Method for the Construction of Minimum-Redundancy Codes,"A Method for the Construction of Minimum-Redundancy Codes

An optimum method of coding an ensemble messages consisting a finite number members is developed. A minimum-redundancy code one constructed in such way that the average digits per message minimized.

default logic, computer science, algebraic coding theory, code reuse, error correction code, minimum-redundancy codes, formal methods",1952,5948,default logic|computer science|algebraic coding theory|code reuse|error correction code|minimum-redundancy codes|formal methods,
https://openalex.org/W1493688518,Extreme Programming Explained: Embrace Change,"Extreme Programming Explained: Embrace Change

Software development projects can be fun, productive, and even daring. Yet they consistently deliver value to a business remain under control.Extreme Programming (XP) was conceived developed address the specific needs of software conducted by small teams in face vague changing requirements. This new lightweight methodology challenges many conventional tenets, including long-held assumption that cost piece necessarily rises dramatically over course time. XP recognizes have work achieve this reduction exploit savings once been earned.Fundamentals include: Distinguishing between decisions made interests those project stakeholders. Writing unit tests before programming keeping all running at times. Integrating testing whole system--several times day. Producing pairs, two programmers one screen. Starting with simple design constantly evolves add needed flexibility remove unneeded complexity. Putting minimal system into production quickly growing it whatever directions prove most valuable.Why is so controversial? Some sacred cows don't make cut XP: Don't force team members specialize become analysts, architects, programmers, testers, integrators--every programmer participates these critical activities every conduct complete up-front analysis design--an starts quick entire system, continue throughout development. Develop infrastructure frameworks as you develop your application, not up-front--delivering heartbeat drives projects. write maintain implementation documentation--communication occurs face-to-face, or through efficient carefully written code.You may love XP, hate it, but Extreme Explained will take fresh look how software. 0201616416B04062001

extreme programming, computer science, embrace change",1999,5943,extreme programming|computer science|embrace change,
https://openalex.org/W2118585731,LIBLINEAR: A Library for Large Linear Classification,"LIBLINEAR: A Library for Large Linear Classification

LIBLINEAR is an open source library for large-scale linear classification. It supports logistic regression and support vector machines. We provide easy-to-use command-line tools calls users developers. Comprehensive documents are available both beginners advanced users. Experiments demonstrate that very efficient on large sparse data sets.

algorithmic library, automatic classification, large linear classification, statistics, data classification, computer science, machine learning, machine learning research, data science",2008,5943,algorithmic library|automatic classification|large linear classification|statistics|data classification|computer science|machine learning|machine learning research|data science,https://openalex.org/W2101234009|https://openalex.org/W2133990480|https://openalex.org/W2295107390|https://openalex.org/W1834627138
https://openalex.org/W2141224535,Fast and robust fixed-point algorithms for independent component analysis,"Fast and robust fixed-point algorithms for independent component analysis

Independent component analysis (ICA) is a statistical method for transforming an observed multidimensional random vector into components that are statistically as independent from each other possible. We use combination of two different approaches linear ICA: Comon's information theoretic approach and the projection pursuit approach. Using maximum entropy approximations differential entropy, we introduce family new contrast functions ICA. These enable both estimation whole decomposition by minimizing mutual information, individual directions. The properties estimators based on such analyzed under assumption mixture model, it shown how to choose robust and/or minimum variance. Finally, simple fixed-point algorithms practical optimization functions.

computer science, independent component analysis, machine learning, robust optimization, computational optimization, robust routing, robust fixed-point algorithms",1999,5936,computer science|independent component analysis|machine learning|robust optimization|computational optimization|robust routing|robust fixed-point algorithms,
https://openalex.org/W4298872162,Bootstrap Methods and their Application,"Bootstrap Methods and their Application

Bootstrap methods are computer-intensive of statistical analysis, which use simulation to calculate standard errors, confidence intervals, and significance tests. The apply for any level modelling, so can be used fully parametric, semiparametric, completely nonparametric analysis. This 1997 book gives a broad up-to-date coverage bootstrap methods, with numerous applied examples, developed in coherent way the necessary theoretical basis. Applications include stratified data; finite populations; censored missing linear, nonlinear, smooth regression models; classification; time series spatial problems. Special features include: extensive discussion tests intervals; material on various diagnostic methods; efficient computation, including improved Monte Carlo simulation. Each chapter includes both practical exercises. S-Plus programs implementing described text available from supporting website.

computer science, bootstrap resampling, methodology comparison, bootstrap methods, applied mathematics, systems engineering",1997,5926,computer science|bootstrap resampling|methodology comparison|bootstrap methods|applied mathematics|systems engineering,
https://openalex.org/W2963121255,PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space,"PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space

Few prior works study deep learning on point sets. PointNet by Qi et al. is a pioneer in this direction. However, design does not capture local structures induced the metric space points live in, limiting its ability to recognize fine-grained patterns and generalizability complex scenes. In work, we introduce hierarchical neural network that applies recursively nested partitioning of input set. By exploiting distances, our able learn features with increasing contextual scales. With further observation sets are usually sampled varying densities, which results greatly decreased performance for networks trained uniform propose novel set layers adaptively combine from multiple Experiments show called PointNet++ efficiently robustly. particular, significantly better than state-of-the-art have been obtained challenging benchmarks 3D clouds.

computer science, hierarchical classification, point sets, feature learning, manifold learning, data science, deep learning, pattern recognition, neural network (machine learning), machine learning, computational imaging, machine learning research, feature (computer vision), deep hierarchical feature, machine vision, metric space, image analysis, computational intelligence, geometric learning, applied mathematics",2017,5922,computer science|hierarchical classification|point sets|feature learning|manifold learning|data science|deep learning|pattern recognition|neural network (machine learning)|machine learning|computational imaging|machine learning research|feature (computer vision)|deep hierarchical feature|machine vision|metric space|image analysis|computational intelligence|geometric learning|applied mathematics,
https://openalex.org/W2339500526,Tabu Search,"Tabu Search

From the Publisher:
This book explores meta-heuristics approach called tabu search, which is dramatically changing our ability to solve a hostof problems that stretch over realms of resource planning,telecommunications, VLSI design, financial analysis, scheduling, spaceplanning, energy distribution, molecular engineering, logistics,pattern classification, flexible manufacturing, waste management,mineral exploration, biomedical environmental conservationand scores other problems. The major ideas search arepresented with examples show their relevance multipleapplications. Numerous illustrations and diagrams are used clarifyprinciples deserve emphasis, have not always been wellunderstood or applied. book's goal provide ''hands-on' knowledge insight alike, rather than focus exclusively eitheron computational recipes on abstract themes. This designedto be useful accessible researchers practitioners inmanagement science, industrial economics, computerscience. It can appropriately as textbook in masterscourse doctoral seminar. Because its emphasis presentingideas through diagrams, identifyingassociated practical applications, it also asupplementary text upper division undergraduate courses. 

Finally, there many more applications canpossibly covered single book, new ones emerging everyday. grounding essential ideasof will allow readers create successfulapplications own. Along essentialideas,understanding advanced issues provided, enabling togo beyond today's developments methods tomorrow.

interactive information retrieval, information retrieval, web search, clustering, knowledge discovery, information fusion, data mining, knowledge representation and reasoning, semantic search, tabu search, search technology, computer science, machine learning, linguistics, machine learning research, data science, combinatorial optimization, exploratory search",1997,5917,interactive information retrieval|information retrieval|web search|clustering|knowledge discovery|information fusion|data mining|knowledge representation and reasoning|semantic search|tabu search|search technology|computer science|machine learning|linguistics|machine learning research|data science|combinatorial optimization|exploratory search,
https://openalex.org/W2103504761,The Laplacian Pyramid as a Compact Image Code,"The Laplacian Pyramid as a Compact Image Code

We describe a technique for image encoding in which local operators of many scales but identical shape serve as the basis functions. The representation differs from established techniques that code elements are localized spatial frequency well space. Pixel-to-pixel correlations first removed by subtracting lowpass filtered copy itself. result is net data compression since difference, or error, has low variance and entropy, low-pass may represented at reduced sample density. Further achieved quantizing difference image. These steps then repeated to compress Iteration process appropriately expanded generates pyramid structure. equivalent sampling with Laplacian scales. Thus, tends enhance salient features. A further advantage present it suited analysis tasks compression. Fast algorithms described coding decoding.

computational imaging, computer science, image coding, compact image code, computer vision, laplacian pyramid",1983,5870,computational imaging|computer science|image coding|compact image code|computer vision|laplacian pyramid,https://openalex.org/W2132984323|https://openalex.org/W2395611524|https://openalex.org/W2142276208
https://openalex.org/W1504694836,Programs for Machine Learning,"Programs for Machine Learning

Algorithms for constructing decision trees are among the most well known and widely used of all machine learning methods. Among tree algorithms, J. Ross Quinlan's ID3 its successor, C4.5, probably popular in community. These algorithms variations on them have been subject numerous research papers since Quinlan introduced ID3. Until recently, researchers looking an introduction to turned seminal 1986 Machine Learning journal article [Quinlan, 1986]. In his new book, C4.5: Programs Learning, has put together a definitive, much needed description complete system, including latest developments. As such, this book will be welcome addition library many students.

computer science, supervised learning, machine learning tool, unsupervised machine learning, machine learning, data science, reinforcement learning, knowledge discovery, machine learning model, machine learning research, neural network (machine learning), statistical software, automated machine learning",1994,5865,computer science|supervised learning|machine learning tool|unsupervised machine learning|machine learning|data science|reinforcement learning|knowledge discovery|machine learning model|machine learning research|neural network (machine learning)|statistical software|automated machine learning,https://openalex.org/W1484413656|https://openalex.org/W2112076978
https://openalex.org/W3175752499,clusterProfiler 4.0: A universal enrichment tool for interpreting omics data,"clusterProfiler 4.0: A universal enrichment tool for interpreting omics data

Public summary•clusterProfiler supports exploring functional characteristics of both coding and non-coding genomics data for thousands species with up-to-date gene annotation•It provides a universal interface annotation from variety sources thus can be applied in diverse scenarios•It tidy to access, manipulate, visualize enrichment results help users achieve efficient interpretation•Datasets obtained multiple treatments time points analyzed compared single run, easily revealing consensus differences among distinct conditionsSummaryFunctional analysis is pivotal interpreting high-throughput omics life science. It crucial this type tool use the latest databases as many organisms possible. To meet these requirements, we present here an updated version our popular Bioconductor package, clusterProfiler 4.0. This package has been enhanced considerably its original published 9 years ago. The new based on internally supported ontologies pathways well provided by or derived online databases. also extends dplyr ggplot2 packages offer interfaces operation visualization. Other features include set comparison lists. We anticipate that 4.0 will wide range scenarios across organisms.Graphical abstract

computer science, omics technology, cluster computing, omics, large-scale datasets, clustering, machine learning, omics datasets, omics data, data science, omics integration, deep learning, statistics, benchmark datasets, universal enrichment tool, biomedical informatics, bioinformatics",2021,5864,computer science|omics technology|cluster computing|omics|large-scale datasets|clustering|machine learning|omics datasets|omics data|data science|omics integration|deep learning|statistics|benchmark datasets|universal enrichment tool|biomedical informatics|bioinformatics,
https://openalex.org/W2242218935,Accurate Image Super-Resolution Using Very Deep Convolutional Networks,"Accurate Image Super-Resolution Using Very Deep Convolutional Networks

We present a highly accurate single-image superresolution (SR) method. Our method uses very deep convolutional network inspired by VGG-net used for ImageNet classification [19]. find increasing our depth shows significant improvement in accuracy. final model 20 weight layers. By cascading small filters many times structure, contextual information over large image regions is exploited an efficient way. With networks, however, convergence speed becomes critical issue during training. propose simple yet effective training procedure. learn residuals only and use extremely high learning rates (104 higher than SRCNN [6]) enabled adjustable gradient clipping. proposed performs better existing methods accuracy visual improvements results are easily noticeable.

image analysis, computational imaging, computer science, convolutional neural network, deep convolutional networks, super-resolution imaging, biomedical imaging, computer vision, machine learning, high resolution, single-image super-resolution, data science, deep learning, image representation, image resolution, machine vision, digital image processing, accurate image super-resolution",2016,5855,image analysis|computational imaging|computer science|convolutional neural network|deep convolutional networks|super-resolution imaging|biomedical imaging|computer vision|machine learning|high resolution|single-image super-resolution|data science|deep learning|image representation|image resolution|machine vision|digital image processing|accurate image super-resolution,https://openalex.org/W2508457857|https://openalex.org/W2962785568
https://openalex.org/W2962785568,The Unreasonable Effectiveness of Deep Features as a Perceptual Metric,"The Unreasonable Effectiveness of Deep Features as a Perceptual Metric

While it is nearly effortless for humans to quickly assess the perceptual similarity between two images, underlying processes are thought be quite complex. Despite this, most widely used metrics today, such as PSNR and SSIM, simple, shallow functions, fail account many nuances of human perception. Recently, deep learning community has found that features VGG network trained on ImageNet classification been remarkably useful a training loss image synthesis. But how these so-called ""perceptual losses""? What elements critical their success? To answer questions, we introduce new dataset judgments. We systematically evaluate across different architectures tasks compare them with classic metrics. find outperform all previous by large margins our dataset. More surprisingly, this result not restricted ImageNet-trained features, but holds levels supervision (supervised, self-supervised, or even unsupervised). Our results suggest an emergent property shared visual representations.

visual science, unreasonable effectiveness, principal component analysis, computer science, feature learning, machine learning research, deep learning, feature construction, pattern recognition, machine vision, neuroscience, image representation, feature (computer vision), computational imaging, machine learning, deep features, computer vision, cognitive science, feature detection, image analysis",2018,5839,visual science|unreasonable effectiveness|principal component analysis|computer science|feature learning|machine learning research|deep learning|feature construction|pattern recognition|machine vision|neuroscience|image representation|feature (computer vision)|computational imaging|machine learning|deep features|computer vision|cognitive science|feature detection|image analysis,https://openalex.org/W2962770929
https://openalex.org/W2131629857,Above the Clouds: A Berkeley View of Cloud Computing,"Above the Clouds: A Berkeley View of Cloud Computing

Cloud Computing, the long-held dream of computing as a utility, has potential to transform large part IT industry, making software even more attractive service and shaping way hardware is designed purchased. Developers with innovative ideas for new Internet services no longer require capital outlays in deploy their or human expense operate it. They need not be concerned about overprovisioning whose popularity does meet predictions, thus wasting costly resources, underprovisioning one that becomes wildly popular, missing customers revenue. Moreover, companies batch-oriented tasks can get results quickly programs scale, since using 1000 servers hour costs than server hours. This elasticity without paying premium unprecedented history IT. Computing refers both applications delivered over systems datacenters provide those services. The themselves have long been referred Software Service (SaaS). datacenter what we will call Cloud. When made available pay-as-you-go manner general public, it Public Cloud; being sold Utility Computing. We use term Private refer internal business other organization, public. Thus, sum SaaS but include Clouds. People users providers SaaS, focus on Providers (Cloud Users) Providers, which received less attention Users. From point view, three aspects are

computer science, cloud computing architecture, cloud computing, cloud resource management, cloud-based integration, berkeley view",2009,5837,computer science|cloud computing architecture|cloud computing|cloud resource management|cloud-based integration|berkeley view,https://openalex.org/W2114296561
https://openalex.org/W2251939518,Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank,"Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank

Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality tasks such as sentiment detection requires richer supervised training and evaluation resources more powerful models composition. To remedy this, we introduce Sentiment Treebank. It includes fine grained labels for 215,154 parse trees 11,855 sentences presents new challenges compositionality. address them, Recursive Neural Tensor Network. When trained on treebank, this model outperforms all previous methods several metrics. pushes state art single sentence positive/negative classification from 80% up to 85.4%. The accuracy predicting fine-grained reaches 80.7%, an improvement 9.7% over bag features baselines. Lastly, it is only that can accurately capture effects negation its scope at various tree levels both positive negative phrases.

computer science, text mining, language model, natural language processing, treebanks, machine learning, semantic evaluation, vector space model, cognitive science, computational linguistics, data science, knowledge discovery, recursive deep models, semantic compositionality, machine learning research, sentiment treebank, semantic parsing",2013,5832,computer science|text mining|language model|natural language processing|treebanks|machine learning|semantic evaluation|vector space model|cognitive science|computational linguistics|data science|knowledge discovery|recursive deep models|semantic compositionality|machine learning research|sentiment treebank|semantic parsing,https://openalex.org/W2896457183|https://openalex.org/W2965373594|https://openalex.org/W1832693441|https://openalex.org/W2123442489|https://openalex.org/W2970641574
https://openalex.org/W2416799949,Edge Computing: Vision and Challenges,"Edge Computing: Vision and Challenges

The proliferation of Internet Things (IoT) and the success rich cloud services have pushed horizon a new computing paradigm, edge computing, which calls for processing data at network. Edge has potential to address concerns response time requirement, battery life constraint, bandwidth cost saving, as well safety privacy. In this paper, we introduce definition followed by several case studies, ranging from offloading smart home city, collaborative materialize concept computing. Finally, present challenges opportunities in field hope paper will gain attention community inspire more research direction.

multi-access edge computing, computer science, edge computing",2016,5815,multi-access edge computing|computer science|edge computing,
https://openalex.org/W2145287260,DeepFace: Closing the Gap to Human-Level Performance in Face Verification,"DeepFace: Closing the Gap to Human-Level Performance in Face Verification

In modern face recognition, the conventional pipeline consists of four stages: detect => align represent classify. We revisit both alignment step and representation by employing explicit 3D modeling in order to apply a piecewise affine transformation, derive from nine-layer deep neural network. This network involves more than 120 million parameters using several locally connected layers without weight sharing, rather standard convolutional layers. Thus we trained it on largest facial dataset to-date, an identity labeled images belonging 4, 000 identities. The learned representations coupling accurate model-based with large database generalize remarkably well faces unconstrained environments, even simple classifier. Our method reaches accuracy 97.35% Labeled Faces Wild (LFW) dataset, reducing error current state art 27%, closely approaching human-level performance.

image analysis, pattern recognition, computer science, information fusion, adversarial machine learning, face verification, human-level performance, computer vision, biometrics, cognitive science, data science, computational intelligence, deep learning, deepfakes, human image synthesis, facial recognition system, machine vision, face detection",2014,5810,image analysis|pattern recognition|computer science|information fusion|adversarial machine learning|face verification|human-level performance|computer vision|biometrics|cognitive science|data science|computational intelligence|deep learning|deepfakes|human image synthesis|facial recognition system|machine vision|face detection,https://openalex.org/W1677182931|https://openalex.org/W2109255472|https://openalex.org/W2954996726|https://openalex.org/W3099206234|https://openalex.org/W1834627138
https://openalex.org/W4297733535,Graph Attention Networks,"Graph Attention Networks

We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based convolutions or their approximations. By stacking in which nodes are able attend over neighborhoods' features, we enable (implicitly) specifying different weights a neighborhood, without requiring any kind costly matrix operation (such as inversion) depending knowing structure upfront. In this way, several key challenges spectral-based simultaneously, and make our model readily applicable inductive well transductive problems. Our GAT models have achieved matched state-of-the-art results across four established benchmarks: Cora, Citeseer Pubmed citation datasets, protein-protein interaction dataset (wherein test graphs remain unseen during training).

graph theory, transfer learning, network science, graph neural network, computer science, machine learning, graph attention networks, graph analysis, deep learning",2017,5809,graph theory|transfer learning|network science|graph neural network|computer science|machine learning|graph attention networks|graph analysis|deep learning,
https://openalex.org/W2950354111,Canu: scalable and accurate long-read assembly via adaptive <i>k</i>-mer weighting and repeat separation,"Canu: scalable and accurate long-read assembly via adaptive <i>k</i>-mer weighting and repeat separation

Long-read single-molecule sequencing has revolutionized de novo genome assembly and enabled the automated reconstruction of reference-quality genomes. However, given relatively high error rates such technologies, efficient accurate large repeats closely related haplotypes remains challenging. We address these issues with Canu, a successor Celera Assembler that is specifically designed for noisy sequences. Canu introduces support nanopore sequencing, halves depth-of-coverage requirements, improves continuity while simultaneously reducing runtime by an order magnitude on genomes versus 8.2. These advances result from new overlapping algorithms, including adaptive strategy based tf-idf weighted MinHash sparse graph construction avoids collapsing diverged haplotypes. demonstrate can reliably assemble complete microbial near-complete eukaryotic chromosomes using either Pacific Biosciences (PacBio) or Oxford Nanopore technologies achieves contig NG50 >21 Mbp both human Drosophila melanogaster PacBio data sets. For structures cannot be linearly represented, provides graph-based outputs in graphical fragment (GFA) format analysis integration complementary phasing scaffolding techniques. The combination highly resolved graphs long-range information promises complex

computer science, precision engineering, long-read sequencing, machine learning, accurate long-read assembly, biomedical engineering, repeat separation, early detection, sequence assembly",2017,5798,computer science|precision engineering|long-read sequencing|machine learning|accurate long-read assembly|biomedical engineering|repeat separation|early detection|sequence assembly,
https://openalex.org/W1968020664,Security: A New Framework for Analysis,"Security: A New Framework for Analysis

Security Analysis: Conceptual Apparatus The Military Sector Environmental Economic Societal Political How Sectors are Synthesized by Actors.

computer science, security studies, security theory, security evaluation, software analysis, program analysis, analytics, security modelling, security measurement",1998,5791,computer science|security studies|security theory|security evaluation|software analysis|program analysis|analytics|security modelling|security measurement,
https://openalex.org/W2014767176,An improved algorithm for reaction path following,"An improved algorithm for reaction path following

A new algorithm is presented for obtaining points on a steepest descent path from the transition state of reactants and products. In mass-weighted coordinates, this corresponds to intrinsic reaction coordinate. Points are found by constrained optimizations involving all internal degrees freedom molecule. The optimized so that segment between any two adjacent given an arc circle, gradient at each point tangent path. Only vector energy gradients needed construct resulting continuous, differentiable piecewise quadratic. limit small step size, present shown take with correct curvature vector; hence, it second order algorithm. method has been tested following reactions: HCN→CNH, SiH2+H2→SiH4, CH4+H→CH3+H2, F−+CH3F→FCH3+F−, C2H5F→C2H4+HF. Reaction paths calculated size 0.4 a.u. almost identical those computed 0.1 or smaller.

image analysis, improved algorithm, computer science, reaction path, chemical engineering, algorithmic efficiency, machine learning, numerical algorithm, computational chemistry, machine vision",1989,5774,image analysis|improved algorithm|computer science|reaction path|chemical engineering|algorithmic efficiency|machine learning|numerical algorithm|computational chemistry|machine vision,
https://openalex.org/W2577537660,<i>Stan</i>: A Probabilistic Programming Language,"<i>Stan</i>: A Probabilistic Programming Language

Stan is a probabilistic programming language for specifying statistical models. A program imperatively defines log probability function over parameters conditioned on specified data and constants. As of version 2.14.0, provides full Bayesian inference continuous-variable models through Markov chain Monte Carlo methods such as the No-U-Turn sampler, an adaptive form Hamiltonian sampling. Penalized maximum likelihood estimates are calculated using optimization limited memory Broyden-Fletcher-Goldfarb-Shanno algorithm. also platform computing densities their gradients Hessians, which can be used in alternative algorithms variational Bayes, expectation propagation, marginal approximate integration. To this end, set up so that densities, gradients, along with intermediate quantities algorithm acceptance probabilities, easily accessible. called from command line cmdstan package, R rstan Python pystan package. All three interfaces support sampling optimization-based diagnostics posterior analysis. provide access to parameter transforms, specialized plotting.

computer science, probabilistic programming, probability theory, programming language, probabilistic programming language",2017,5765,computer science|probabilistic programming|probability theory|programming language|probabilistic programming language,https://openalex.org/W2577537660
https://openalex.org/W1747388711,Sisvar: a computer statistical analysis system,"Sisvar: a computer statistical analysis system

Sisvar is a statistical analysis system, first released in 1996 although its development began 1994. The version was done the programming language Pascal and compiled with Borland Turbo 3. developed to achieve some specific goals. objective obtain software that could be used directly on experimental course of Department Exact Science at Federal University Lavras. second initiate genuinely Brazilian free program met demands peculiarities research conducted country. third goal present for scientific community would allow results analyzed efficiently reliably. All initial goals were achieved. gained acceptance by because it provides reliable, accurate, precise, simple robust results, allows users greater degree interactivity.

computer science, statistical analysis",2011,5749,computer science|statistical analysis,
https://openalex.org/W1604938182,Advances in kernel methods: support vector learning,"Advances in kernel methods: support vector learning

Introduction to support vector learning roadmap. Part 1 Theory: three remarks on the method of function estimation, Vladimir Vapnik generalization performance machines and other pattern classifiers, Peter Bartlett John Shawe-Taylor Bayesian voting schemes large margin Nello Cristianini machines, reproducing kernel Hilbert spaces, randomized GACV, Grace Wahba geometry invariance in based methods, Christopher J.C. Burges annealed VC entropy for classifiers - a statistical mechanics study, Manfred Opper numbers, operators kernels, Robert C. Williamson et al. 2 Implementations: solving quadratic programming problem arising classification, Linda Kaufman making large-scale machine practical, Thorsten Joachims fast training using sequential minimal optimization, Platt. 3 Applications: dynamic reconstruction chaotic system, Davide Mattera Simon Haykin time series prediction, Klaus-Robert Muller al pairwise classification Ulrich Kressel. 4 Extensions algorithm: reducing run-time complexity Edgar E. Osuna Federico Girosi regression with ANOVA decomposition Mark O. Stitson density Jason Weston combining mathematical methods Bernhard Scholkopf

kernel method, support vector learning, computer science, machine learning",1999,5730,kernel method|support vector learning|computer science|machine learning,https://openalex.org/W2168356304
https://openalex.org/W2097879961,Bootstrap Methods and Their Application,"Bootstrap Methods and Their Application

This book gives a broad and up-to-date coverage of bootstrap methods, with numerous applied examples, developed in coherent way the necessary theoretical basis. Applications include stratified data; finite populations; censored missing linear, nonlinear, smooth regression models; classification; time series spatial problems. Special features include: extensive discussion significance tests confidence intervals; material on various diagnostic methods; methods for efficient computation, including improved Monte Carlo simulation. Each chapter includes both practical exercises. Included is disk purpose-written S-Plus programs implementing described text. Computer algorithms are clearly described, computer code included 3-inch, 1.4M use IBM computers compatible machines. Users must have application. Author resource page: http://statwww.epfl.ch/davison/BMA/

computer science, bootstrap resampling, methodology comparison, bootstrap methods, applied mathematics, systems engineering",1999,5718,computer science|bootstrap resampling|methodology comparison|bootstrap methods|applied mathematics|systems engineering,https://openalex.org/W2154652894
https://openalex.org/W166315768,Simulacra and Simulation,"Simulacra and Simulation

The transition from signs which dissimulate something to that there is nothing, marks the decisive turning point. first implies a theology of truth and secrecy. second inaugurates an age simulacra simulation, in no longer any God recognize his own, nor last judgement separate false, real its artificial resurrection, since everything already dead risen advance. Disneyland perfect model all entangled orders simulation. objective profile United States, then, may be traced throughout Disneyland, even down morphology individuals crowd. imaginary neither true false: it deterrence machine Set up order rejuvenate reverse fiction real.

computer science, simulation methodology, modeling and simulation, simulation modelling, social simulation, simulation framework, numerical simulation, discrete-event simulation, simulation infrastructure",1995,5701,computer science|simulation methodology|modeling and simulation|simulation modelling|social simulation|simulation framework|numerical simulation|discrete-event simulation|simulation infrastructure,
https://openalex.org/W1815090327,"Mindstorms: Children, Computers, And Powerful Ideas","Mindstorms: Children, Computers, And Powerful Ideas

The Gears of My Childhood

Before I was two years old had developed an intense involvement with automobiles. names car parts made up a very substantial portion my vocabulary: particularly proud knowing about the transmission system, gearbox, and most especially differential. It was, course, many later before understood how gears work; but once did, playing became favorite pastime. loved rotating circular objects against one another in gearlike motions and, naturally, first erector set project crude gear system.

I adept at turning wheels head making chains cause effect: This turns this way so that must turn .  found particular pleasure such systems as differential gear, which does not follow simple linear chain causality since motion shaft can be distributed different ways to depending on what resistance they encounter. remember quite vividly excitement discovering system could lawful completely comprehensible without being rigidly deterministic.

I believe working differentials did more for mathematical development than anything taught elementary school. Gears, serving models, carried otherwise abstract ideas into head. clearly examples from school math. saw multiplication tables gears, brush equations variables (e.g., 3x + 4y = 10) immediately evoked By time mental model relation between x y, figuring teeth each needed, equation become comfortable friend.

Many when read Piaget incident served me his notion assimilation, except struck by fact discussion do full justice own idea. He talks almost entirely cognitive aspects assimilation. But there is also affective component. Assimilating certainly powerful bring knowledge bear new object. it well. am sure assimilations helped endow mathematics, me, positive tone traced back infantile experiences cars. really agrees. As came know him personally neglect comes modest sense little known arrogant its irrelevance. let return childhood.

One day surprised discover some adults---even adults---did understand or even care magic gears. no longer think much have never turned away questions started discovery: How incomprehensible other people? father suggested clever explanation. painfully aware people who easily things difficult. Slowly began formulate still consider fundamental learning: Anything easy if you assimilate your collection models. If can't, Here too developing thinking would resonant Piaget's. understanding learning genetic. refer genesis knowledge. What individual learn, he learns it, depends models has available. raises, recursively, question learned these Thus laws intellectual structures grow out how, process, acquire both logical emotional form.

This book exercise applied genetic epistemology expanded beyond Piaget's emphasis include concern affective. develops perspective education research focused creating conditions under will take root. For last decades been trying do. And doing find myself frequently reminded several encounter gear. First, told learn Second, feeling, love, well relationship Third, them second year. any scientific educational psychologist tried measure effects encounter, probably failed. profound consequences but, conjecture, only later. A pre- post- test age missed them.

Piaget's work gave framework looking childhood. used illustrate advanced ideas, groups relative motion. this. connecting formal connects body knowledge, sensorimotor schemata child. You projecting yourself place it. double relationship---both sensory---that gives power carry mathematics mind. In terminology shall develop chapters, acts here transitional object.

A modern-day Montessori might propose, convinced story, create children. every child experience had. hope miss essence story. fell love something cannot reduced purely terms. Something personal happened, assume repeated children exactly same form.

My thesis summarized as: computer might. Proteus machines. Its universality, simulate. Because thousand forms serve functions, appeal tastes. result attempts over past decade computers instruments flexible enough themselves like were me.

computer science, child psychology, human-computer interaction, technology, creative computing, powerful ideas, child-computer interaction, computing education, computational thinking, cognitive development, human-centered computing, education",1980,5695,computer science|child psychology|human-computer interaction|technology|creative computing|powerful ideas|child-computer interaction|computing education|computational thinking|cognitive development|human-centered computing|education,
https://openalex.org/W1672666614,Computer Simulation Using Particles,"Computer Simulation Using Particles

Computer experiments using particle models A one-dimensional plasma model The simulation program Time integration schemes particle-mesh force calculation solution of field equations Collisionless Particle-particle/particle-mesh algorithms Plasma Semiconductor device Astrophysics Solids, liquids and phase changes Fourier transforms series finite Bibliography Index

simulation methodology, numerical simulation, computer science, particle technology, modeling and simulation, simulation modelling, computer engineering, scientific computing, interacting particle system, particle method, computer simulation",1988,5691,simulation methodology|numerical simulation|computer science|particle technology|modeling and simulation|simulation modelling|computer engineering|scientific computing|interacting particle system|particle method|computer simulation,https://openalex.org/W2041902442
https://openalex.org/W2128160875,Dynamic programming algorithm optimization for spoken word recognition,"Dynamic programming algorithm optimization for spoken word recognition

This paper reports on an optimum dynamic progxamming (DP) based time-normalization algorithm for spoken word recognition. First, a general principle of is given using time-warping function. Then, two time-normalized distance definitions, called symmetric and asymmetric forms, are derived from the principle. These forms compared with each other through theoretical discussions experimental studies. The form superiority established. A new technique, slope constraint, successfully introduced, in which warping function restricted so as to improve discrimination between words different categories. effective constraint characteristic qualitatively analyzed, condition determined experiments. optimized then extensively subjected comparison various DP-algorithms, previously applied recognition by research groups. experiment shows that present gives no more than about two-thirds errors, even best conventional algorithm.

computer science, speech recognition, dynamic programming, natural language processing, speech processing, spoken word recognition, spoken language processing, language recognition, speech technology, spoken language technology, computational optimization",1978,5680,computer science|speech recognition|dynamic programming|natural language processing|speech processing|spoken word recognition|spoken language processing|language recognition|speech technology|spoken language technology|computational optimization,
https://openalex.org/W4210727445,Introduction to algorithms,"Introduction to algorithms

Emphasizing practical understanding over the technicalities of specific algorithms, this elegant textbook is an accessible introduction to field optimization, focusing on powerful and reliable convex optimization techniques. Students practitioners will learn how recognize, simplify, model solve problems - apply these principles their own projects. A clear self-contained linear algebra demonstrates core mathematical concepts in a way that easy follow, helps students understand relevance. Requiring only basic geometry, calculus, probability statistics, striking careful balance between accessibility rigor, it enables quickly material, without being overwhelmed by complex mathematics. Accompanied numerous end-of-chapter problems, online solutions manual for instructors, relevant examples from diverse fields including engineering, data science, economics, finance, management, perfect undergraduate graduate students.

computer science, algorithmic library, algorithmic mechanism design, algorithmic game theory, analysis of algorithm, computational optimization, algorithmic information theory, discrete algorithm, mathematical optimization, theoretical computer science, mathematical programming, numerical algorithm, computational science, theory of computation, computational mathematics, applied mathematics",2018,5655,computer science|algorithmic library|algorithmic mechanism design|algorithmic game theory|analysis of algorithm|computational optimization|algorithmic information theory|discrete algorithm|mathematical optimization|theoretical computer science|mathematical programming|numerical algorithm|computational science|theory of computation|computational mathematics|applied mathematics,
https://openalex.org/W2104670598,Tabu Search—Part II,"Tabu Search—Part II

This is the second half of a two part series devoted to tabu search metastrategy for optimization problems. Part I introduced fundamental ideas as an approach guiding other heuristics overcome limitations local optimality, both in deterministic and probabilistic framework. also reported successful applications from wide range settings, which frequently made it possible obtain higher quality solutions than previously obtained with competing strategies, generally less computational effort. II, this issue, examines refinements more advanced aspects search. Following brief review notation, II introduces new dynamic strategies managing lists, allowing fuller exploitation underlying evaluation functions. In turn, elements staged structured move sets are characterized, bear on issue finiteness. Three ways applying solution integer programming problems then described, providing connections certain nonlinear applications. Finally, paper concludes survey that have occurred since developments I. Together additional comparisons methods body problems, these include results parallel processing implementations use settings ranging telecommunications neural networks. INFORMS Journal Computing, ISSN 1091-9856, was published ORSA Computing 1989 1995 under 0899-1499.

computer science, graph theory, web search, interactive search, tabu search, clustering, communication, search technology, data science, knowledge discovery, similarity search, machine learning research, combinatorial optimization, interactive information retrieval, information retrieval, data mining, part ii",1990,5639,computer science|graph theory|web search|interactive search|tabu search|clustering|communication|search technology|data science|knowledge discovery|similarity search|machine learning research|combinatorial optimization|interactive information retrieval|information retrieval|data mining|part ii,https://openalex.org/W2153233077
https://openalex.org/W2279098554,SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size,"SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size

Recent research on deep neural networks has focused primarily improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve level. With equivalent accuracy, smaller offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) bandwidth export new model from the cloud an autonomous car. (3) are more feasible deploy FPGAs and other hardware with limited memory. To provide all of these advantages, we propose small architecture called SqueezeNet. SqueezeNet achieves AlexNet-level ImageNet 50x fewer parameters. Additionally, compression techniques able compress than 0.5MB (510x AlexNet). 
The available for download here: this https URL

model comparison, electrical engineering, alexnet-level accuracy, fewer parameters, computer science, large language model, machine learning, model compression, machine learning research, time series, data science, model size",2016,5638,model comparison|electrical engineering|alexnet-level accuracy|fewer parameters|computer science|large language model|machine learning|model compression|machine learning research|time series|data science|model size,https://openalex.org/W2612445135|https://openalex.org/W3018757597|https://openalex.org/W2963125010|https://openalex.org/W2962785568
https://openalex.org/W2016053056,Large-Scale Video Classification with Convolutional Neural Networks,"Large-Scale Video Classification with Convolutional Neural Networks

Convolutional Neural Networks (CNNs) have been established as a powerful class of models for image recognition problems. Encouraged by these results, we provide an extensive empirical evaluation CNNs on large-scale video classification using new dataset 1 million YouTube videos belonging to 487 classes. We study multiple approaches extending the connectivity CNN in time domain take advantage local spatio-temporal information and suggest multiresolution, foveated architecture promising way speeding up training. Our best networks display significant performance improvements compared strong feature-based baselines (55.3% 63.9%), but only surprisingly modest improvement single-frame (59.3% 60.9%). further generalization our model retraining top layers UCF-101 Action Recognition observe baseline (63.3% from 43.9%).

neural network (machine learning), computer science, machine learning research, deep learning, pattern recognition, machine vision, multimedia information processing, multimedia retrieval, scene understanding, computational imaging, machine learning, data science, video interpretation, video retrieval, computer vision, video understanding, cognitive science, large-scale video classification, convolutional neural network",2014,5630,neural network (machine learning)|computer science|machine learning research|deep learning|pattern recognition|machine vision|multimedia information processing|multimedia retrieval|scene understanding|computational imaging|machine learning|data science|video interpretation|video retrieval|computer vision|video understanding|cognitive science|large-scale video classification|convolutional neural network,https://openalex.org/W2183341477|https://openalex.org/W2271840356|https://openalex.org/W1522734439|https://openalex.org/W2963524571|https://openalex.org/W2402144811
https://openalex.org/W1993885071,A New Heuristic Optimization Algorithm: Harmony Search,"A New Heuristic Optimization Algorithm: Harmony Search

Many optimization problems in various fields have been solved using diverse al gorithms. Traditional techniques such as linear programming (LP), non-linear (NLP), and dynamic program ming (DP) had major roles solving these problems. However, their drawbacks generate demand for other types of algorithms, heuristic approaches (simulated annealing, tabu search, evolutionary algo rithms). there are still some possibili ties devising new algorithms based on analogies with natural or artificial phenom ena. A algorithm, mimicking the improvisation music players, has devel oped named Harmony Search (HS). The performance algorithm is illustrated a traveling salesman problem (TSP), specific academic problem, least-cost pipe network design problem.

heuristic search, computer science, harmony search, control optimization, mathematical optimization, tabu search, applied mathematics, heuristic (computer science), optimization problem, design optimization, computational optimization",2001,5626,heuristic search|computer science|harmony search|control optimization|mathematical optimization|tabu search|applied mathematics|heuristic (computer science)|optimization problem|design optimization|computational optimization,
https://openalex.org/W2118382442,Depth-First Search and Linear Graph Algorithms,"Depth-First Search and Linear Graph Algorithms

The value of depth-first search or “backtracking” as a technique for solving problems is illustrated by two examples. An improved version an algorithm finding the strongly connected components directed graph and at biconnected undirect are presented. space time requirements both algorithms bounded $k_1 V + k_2 E k_3 $ some constants ,k_2 $, $k_3 where number vertices edges being examined.

computer science, graph theory, graph algorithm, linear graph algorithms, depth-first search",1972,5624,computer science|graph theory|graph algorithm|linear graph algorithms|depth-first search,
https://openalex.org/W2559085405,Realtime Multi-person 2D Pose Estimation Using Part Affinity Fields,"Realtime Multi-person 2D Pose Estimation Using Part Affinity Fields

We present an approach to efficiently detect the 2D pose of multiple people in image. The uses a nonparametric representation, which we refer as Part Affinity Fields (PAFs), learn associate body parts with individuals architecture encodes global context, allowing greedy bottom-up parsing step that maintains high accuracy while achieving realtime performance, irrespective number is designed jointly part locations and their association via two branches same sequential prediction process. Our method placed first inaugural COCO 2016 keypoints challenge, significantly exceeds previous state-of-the-art result on MPII Multi-Person benchmark, both performance efficiency.

image analysis, pattern recognition, computer science, human pose estimation, multi-view geometry, computer vision, machine learning, motion capture, pose estimation, deep learning, 3d pose estimation, machine vision, part affinity fields",2017,5622,image analysis|pattern recognition|computer science|human pose estimation|multi-view geometry|computer vision|machine learning|motion capture|pose estimation|deep learning|3d pose estimation|machine vision|part affinity fields,https://openalex.org/W2963150697
https://openalex.org/W1980569376,Extrinsic and Intrinsic Motivation to Use Computers in the Workplace<sup>1</sup>,"Extrinsic and Intrinsic Motivation to Use Computers in the Workplace<sup>1</sup>

Previous research indicates that perceived usefulness is a major determinant and predictor of intentions to use computers in the workplace. In contrast, impact enjoyment on usage has not been examined. Two studies are reported concerning relative effects use, of, Usefulness had strong effect both Study 1, regarding word processing software (β=.68), 2, business graphics programs (β=.79). As hypothesized, also significant studies, controlling for (β=.16 0.15 Studies 1 respectively). found correlated 0.63 with system influenced behavior entirely indirectly through their intentions. positive interaction between was observed. Together, explained 62% (Study 1) 75% 2) variance Moreover, were mediate fully output quality ease use. measure task importance moderated but enjoyment. Several implications drawn how design computer be more useful enjoyable order increase acceptability among potential users.

computer science, human-computer interaction, motivation, psychology, task performance, intrinsic motivation, behavioral sciences",1992,5608,computer science|human-computer interaction|motivation|psychology|task performance|intrinsic motivation|behavioral sciences,
https://openalex.org/W2099040451,RTP: A Transport Protocol for Real-Time Applications,"RTP: A Transport Protocol for Real-Time Applications

This memorandum describes RTP, the real-time transport protocol. RTP provides end-to-end network functions suitable for applications transmitting data, such as audio, video or simulation over multicast unicast services. does not address resource reservation and guarantee quality-of-service The data is augmented by a control protocol (RTCP) to allow monitoring of delivery in manner scalable large networks, provide minimal identification functionality. RTCP are designed be independent underlying layers. supports use RTP-level translators mixers.

computer science, wireless communication, real-time protocol, real-time system, systems engineering, real-time application, real-time communication, real-time computing, wireless sensor network, transport protocol",2003,5594,computer science|wireless communication|real-time protocol|real-time system|systems engineering|real-time application|real-time communication|real-time computing|wireless sensor network|transport protocol,
https://openalex.org/W2126512988,Computer Self-Efficacy: Development of a Measure and Initial Test,"Computer Self-Efficacy: Development of a Measure and Initial Test

This paper discusses the role of individuals' beliefs about their abilities to competently use computers (computer self-efficacy) in determination computer use. A survey Canadian managers and professionals was conducted develop validate a measure self-efficacy assess both its impacts antecedents. Computer self- efficacy found exert significant influence on expectations outcomes using computers, emotional reactions (affect anxiety), as well actual An individual's outcome expecta- tions were be positively influenced by encouragement others work group, others' computers. Thus, represents an important individual trait, which moderates organizational influences (such support) decision Understanding self-efficacy, then, is successful implementation systems organizations. The existence reliable valid makes assessment possible should have implications for support, training, implementation.

computer science, initial test, computing education, computer self-efficacy, self-efficacy theory",1995,5588,computer science|initial test|computing education|computer self-efficacy|self-efficacy theory,
https://openalex.org/W2889326414,UMAP: Uniform Manifold Approximation and Projection,"UMAP: Uniform Manifold Approximation and Projection

Uniform Manifold Approximation and Projection (UMAP) is a dimension reduction technique that can be used for visualisation similarly to t-SNE, but also general non-linear reduction.UMAP has rigorous mathematical foundation, simple use, with scikit-learn compatible API.UMAP among the fastest manifold learning implementations available -significantly faster than most t-SNE implementations.UMAP supports number of useful features, including ability use labels (or partial labels) supervised semi-supervised) reduction, transform new unseen data into pretrained embedding space.

applied mathematics, differential geometry, manifold modeling, computational geometry, manifold learning, pade approximant, projection system, sparse representation, uniform manifold approximation, numerical simulation, approximation theory, computer science, geometric modeling, machine learning research",2018,5566,applied mathematics|differential geometry|manifold modeling|computational geometry|manifold learning|pade approximant|projection system|sparse representation|uniform manifold approximation|numerical simulation|approximation theory|computer science|geometric modeling|machine learning research,
https://openalex.org/W1969353942,REVIGO Summarizes and Visualizes Long Lists of Gene Ontology Terms,"REVIGO Summarizes and Visualizes Long Lists of Gene Ontology Terms

Outcomes of high-throughput biological experiments are typically interpreted by statistical testing for enriched gene functional categories defined the Gene Ontology (GO). The resulting lists GO terms may be large and highly redundant, thus difficult to interpret. REVIGO is a Web server that summarizes long, unintelligible finding representative subset using simple clustering algorithm relies on semantic similarity measures. Furthermore, visualizes this non-redundant term set in multiple ways assist interpretation: multidimensional scaling graph-based visualizations accurately render subdivisions relationships data, while treemaps tag clouds also offered as alternative views. freely available at http://revigo.irb.hr/.

computer science, data and information visualization, bioinformatics database, molecular biology, revigo summarizes, bioinformatics, gene ontology terms, visualizes long lists, hierarchical classification, systems biology, biological network visualization, biomedical ontology, omics datasets, computational biology, genomics, genome biology, clustering, knowledge discovery, semantic web, molecular informatics, biomedical informatics",2011,5560,computer science|data and information visualization|bioinformatics database|molecular biology|revigo summarizes|bioinformatics|gene ontology terms|visualizes long lists|hierarchical classification|systems biology|biological network visualization|biomedical ontology|omics datasets|computational biology|genomics|genome biology|clustering|knowledge discovery|semantic web|molecular informatics|biomedical informatics,
https://openalex.org/W2153233077,Survey of Clustering Algorithms,"Survey of Clustering Algorithms

Data analysis plays an indispensable role for understanding various phenomena. Cluster analysis, primitive exploration with little or no prior knowledge, consists of research developed across a wide variety communities. The diversity, on one hand, equips us many tools. On the other profusion options causes confusion. We survey clustering algorithms data sets appearing in statistics, computer science, and machine learning, illustrate their applications some benchmark sets, traveling salesman problem, bioinformatics, new field attracting intensive efforts. Several tightly related topics, proximity measure, cluster validation, are also discussed.

computer science, community mining, unsupervised machine learning, clustering, machine learning, data science, knowledge discovery, fuzzy clustering, statistics, machine learning research, document clustering, data mining",2005,5531,computer science|community mining|unsupervised machine learning|clustering|machine learning|data science|knowledge discovery|fuzzy clustering|statistics|machine learning research|document clustering|data mining,
https://openalex.org/W2142384583,The viterbi algorithm,"The viterbi algorithm

The Viterbi algorithm (VA) is a recursive optimal solution to the problem of estimating state sequence discrete-time finite-state Markov process observed in memoryless noise. Many problems areas such as digital communications can be cast this form. This paper gives tutorial exposition and how it implemented analyzed. Applications date are reviewed. Increasing use widening variety foreseen.

viterbi algorithm, computer science",1973,5525,viterbi algorithm|computer science,https://openalex.org/W2160337655
https://openalex.org/W2037521346,Principles of Computerized Tomographic Imaging,"Principles of Computerized Tomographic Imaging

Tomography refers to the cross-sectional imaging of an object from either transmission or reflection data collected by illuminating many different directions. The impact tomography in diagnostic medicine has been revolutionary, since it enabled doctors view internal organs with unprecedented precision and safety patient. There are also numerous nonmedical applications which lend themselves methods computerized tomography, such as mapping underground resources...cross-sectional for nondestructive testing...the determination brightness distribution over a celestial sphere...three-dimensional electron microscopy. Principles Computerized Tomographic Imaging provides tutorial overview topics tomographic covering mathematical principles theory...how apply theory problems medical other fields...several variations that currently being researched.

computational imaging, medical image computing, computer science, advanced imaging, medical imaging, biomedical imaging, digital image processing, computerized tomographic imaging",2001,5524,computational imaging|medical image computing|computer science|advanced imaging|medical imaging|biomedical imaging|digital image processing|computerized tomographic imaging,
https://openalex.org/W2158864412,A metrics suite for object oriented design,"A metrics suite for object oriented design

Given the central role that software development plays in delivery and application of information technology, managers are increasingly focusing on process improvement area. This demand has spurred provision a number new and/or improved approaches to development, with perhaps most prominent being object-orientation (OO). In addition, focus increased for measures, or metrics which manage process. The need such is particularly acute when an organization adopting technology established practices have yet be developed. research addresses these needs through implementation suite OO design. Metrics developed previous research, while contributing field's understanding processes, generally been subject serious criticisms, including lack theoretical base. Following Wand Weber (1989), base chosen was ontology Bunge (1977). Six design developed, then analytically evaluated against Weyuker's (1988) proposed set measurement principles. An automated data collection tool implemented collect empirical sample at two field sites order demonstrate their feasibility suggest ways may use improvement.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>

computer science, system software, program evaluation, design research, software design, software engineering, system metric, object orientation, object-oriented modeling, systems engineering, computer-aided design, metrics suite, software maintenance, design optimization, design automation, object-oriented programming, software analysis, object-oriented design, design",1994,5519,computer science|system software|program evaluation|design research|software design|software engineering|system metric|object orientation|object-oriented modeling|systems engineering|computer-aided design|metrics suite|software maintenance|design optimization|design automation|object-oriented programming|software analysis|object-oriented design|design,
https://openalex.org/W2970641574,Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks,"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks

Nils Reimers, Iryna Gurevych. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint (EMNLP-IJCNLP). 2019.

link prediction, word embeddings, nlp task, natural language processing, siamese bert-networks, sentence embeddings, computer science, linguistics, language engineering, deep learning, computational linguistics",2019,5492,link prediction|word embeddings|nlp task|natural language processing|siamese bert-networks|sentence embeddings|computer science|linguistics|language engineering|deep learning|computational linguistics,
https://openalex.org/W1597739853,Vision: A Computational Investigation into the Human Representation and Processing of Visual Information,"Vision: A Computational Investigation into the Human Representation and Processing of Visual Information

David Marr's posthumously published Vision (1982) influenced a generation of brain and cognitive scientists, inspiring many to enter the field. In Vision, Marr describes general framework for understanding visual perception touches on broader questions about how its functions can be studied understood. Researchers from range sciences have long valued creativity, intellectual power, ability integrate insights data neuroscience, psychology, computation. This MIT Press edition makes influential work available new students scientists. framework, process vision constructs set representations, starting description input image culminating with three-dimensional objects in surrounding environment. A central theme, one that has had far-reaching influence both neuroscience science, is notion different levels analysis--in computational level, algorithmic hardware implementation level. Now, thirty years later, main problems occupied remain fundamental open study perception. provides inspiration continuing efforts knowledge cognition computation understand brain.--MIT CogNet.

computer science, computational investigation, human representation, visual science, image analysis, information visualization, neuroscience, visualization, cognitive science, visual system, image representation, vision recognition, computational imaging, early vision, machine vision, visual processing, visual computing, vision research, computer vision, visual perception, visual information",1982,5483,computer science|computational investigation|human representation|visual science|image analysis|information visualization|neuroscience|visualization|cognitive science|visual system|image representation|vision recognition|computational imaging|early vision|machine vision|visual processing|visual computing|vision research|computer vision|visual perception|visual information,
https://openalex.org/W3083406432,"<scp>UCSF ChimeraX</scp>: Structure visualization for researchers, educators, and developers","<scp>UCSF ChimeraX</scp>: Structure visualization for researchers, educators, and developers

Abstract UCSF ChimeraX is the next‐generation interactive visualization program from Resource for Biocomputing, Visualization, and Informatics (RBVI), following Chimera. brings (a) significant performance graphics enhancements; (b) new implementations of Chimera's most highly used tools, many with further improvements; (c) several entirely analysis features; (d) support areas such as virtual reality, light‐sheet microscopy, medical imaging data; (e) major ease‐of‐use advances, including toolbars icons to perform actions a single click, basic “undo” capabilities, more logical consistent commands; (f) an app store researchers contribute tools. includes full user documentation free noncommercial use, downloads available Windows, Linux, macOS https://www.rbvi.ucsf.edu/chimerax .

image analysis, computer science, knowledge representation and reasoning, information visualization, interactive visualization, linked data visualization, computational visualization, systems biology, protein structure, visualization, data and information visualization, data science, knowledge discovery, software visualization, statistical software, scientific visualization, structure visualization",2020,5482,image analysis|computer science|knowledge representation and reasoning|information visualization|interactive visualization|linked data visualization|computational visualization|systems biology|protein structure|visualization|data and information visualization|data science|knowledge discovery|software visualization|statistical software|scientific visualization|structure visualization,https://openalex.org/W3083406432
https://openalex.org/W1971040550,Evaluating collaborative filtering recommender systems,"Evaluating collaborative filtering recommender systems

Recommender systems have been evaluated in many, often incomparable, ways. In this article, we review the key decisions evaluating collaborative filtering recommender systems: user tasks being evaluated, types of analysis and datasets used, ways which prediction quality is measured, evaluation attributes other than quality, user-based system as a whole. addition to reviewing strategies used by prior researchers, present empirical results from various accuracy metrics on one content domain where all tested collapsed roughly into three equivalence classes. Metrics within each equivalency class were strongly correlated, while different classes uncorrelated.

computer science, human-computer interaction, recommender system, information filtering system, data science, collaborative filtering, analytics, user evaluation, user-centric evaluation",2004,5469,computer science|human-computer interaction|recommender system|information filtering system|data science|collaborative filtering|analytics|user evaluation|user-centric evaluation,https://openalex.org/W2171960770
https://openalex.org/W2257024953,Aplikasi Analisis Multivariate Dengan Program IBM SPSS 25,"Aplikasi Analisis Multivariate Dengan Program IBM SPSS 25

Bab 1 : Skala Pengukuran dan Metode Analisis Data
Bab 2 Pengnalan Program SPSS, Aplikasi Statistik Deskriptif
dan Crosstab.
Bab 3 Data Screening Transformasi data
Bab 4 Uji Validitas Reliabilitas Suatu Konstruk
Bab 5 Beda, ANOVA, ANCOVA MANOVA
Bab 6 Regresi
Bab 7 Asumsi Klasik
Bab 8 Regresi dengan Klasik, Variabel Dummy dan
Chow test
Bab 9 Model Bentuk Fungsional
Bab 10 Moderasi
Bab 11 Mediator
Bab 12 Moderator
Bab 13 Diskriminan

Bab 14 Logistic Regression
Bab 15 Korelasi Kanonikal
Bab 16 Conjoint
Bab 17 Faktor
Bab 18 Kluster
Bab 19 Multidimensional Scaling
Bab 20 Loglinear

computer science, software engineering, multivariate calibration, machine learning, applied mathematics, multivariate analysis, software analysis, deep learning, statistics, program analysis, multivariate approximation, statistical software, computational science",2018,5468,computer science|software engineering|multivariate calibration|machine learning|applied mathematics|multivariate analysis|software analysis|deep learning|statistics|program analysis|multivariate approximation|statistical software|computational science,
https://openalex.org/W1983364832,3D Convolutional Neural Networks for Human Action Recognition,"3D Convolutional Neural Networks for Human Action Recognition

We consider the automated recognition of human actions in surveillance videos. Most current methods build classifiers based on complex handcrafted features computed from raw inputs. Convolutional neural networks (CNNs) are a type deep model that can act directly However, such models currently limited to handling 2D In this paper, we develop novel 3D CNN for action recognition. This extracts both spatial and temporal dimensions by performing convolutions, thereby capturing motion information encoded multiple adjacent frames. The developed generates channels input frames, final feature representation combines all channels. To further boost performance, propose regularizing outputs with high-level combining predictions variety different models. apply recognize real-world environment airport videos, they achieve superior performance comparison baseline methods.

image analysis, computational imaging, computer science, mobile computing, convolutional neural network, human pose estimation, neuroscience, computer vision, machine learning, cognitive science, 3d pose estimation, deep learning, human action recognition, activity recognition, neural network (machine learning), machine vision, 3d computer vision",2013,5467,image analysis|computational imaging|computer science|mobile computing|convolutional neural network|human pose estimation|neuroscience|computer vision|machine learning|cognitive science|3d pose estimation|deep learning|human action recognition|activity recognition|neural network (machine learning)|machine vision|3d computer vision,https://openalex.org/W1522734439|https://openalex.org/W2963524571|https://openalex.org/W2016053056
https://openalex.org/W1895577753,Show and tell: A neural image caption generator,"Show and tell: A neural image caption generator

Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present generative model based on deep recurrent architecture combines recent advances machine translation can be used to generate sentences image. The trained maximize likelihood target description sentence given training Experiments several datasets show accuracy fluency it learns solely from descriptions. Our often quite accurate, which verify both qualitatively quantitatively. For instance, while current state-of-the-art BLEU-1 score (the higher better) Pascal dataset 25, our approach yields 59, compared human performance around 69. We also improvements Flickr30k, 56 66, SBU, 19 28. Lastly, newly released COCO dataset, achieve BLEU-4 27.7, state-of-the-art.

image analysis, computational imaging, computer science, vision language model, generative adversarial network, machine learning, recurrent neural network, generative ai, cognitive science, data science, computational intelligence, deep learning, image representation, machine learning research, automatic annotation, neural network (machine learning), machine vision, digital image processing",2015,5465,image analysis|computational imaging|computer science|vision language model|generative adversarial network|machine learning|recurrent neural network|generative ai|cognitive science|data science|computational intelligence|deep learning|image representation|machine learning research|automatic annotation|neural network (machine learning)|machine vision|digital image processing,https://openalex.org/W2962858109|https://openalex.org/W2963125010
https://openalex.org/W1575923498,"Topology Optimization: Theory, Methods, and Applications","Topology Optimization: Theory, Methods, and Applications

1 Topology optimization by distribution of isotropic material.- 2 Extensions and applications.- 3 Design with anisotropic materials.- 4 design truss structures.- 5 Appendices.- 6 Bibliographical notes.- References.- Author Index.

computer science, engineering optimization, topology, global optimization, mathematical optimization, applied mathematics, topology optimization, systems engineering, intelligent optimization, combinatorial optimization, optimization problem, design optimization, computational optimization, topology control, continuous optimization",2011,5457,computer science|engineering optimization|topology|global optimization|mathematical optimization|applied mathematics|topology optimization|systems engineering|intelligent optimization|combinatorial optimization|optimization problem|design optimization|computational optimization|topology control|continuous optimization,
https://openalex.org/W2138122982,Accelerated Profile HMM Searches,"Accelerated Profile HMM Searches

Profile hidden Markov models (profile HMMs) and probabilistic inference methods have made important contributions to the theory of sequence database homology search. However, practical use profile HMM has been hindered by computational expense existing software implementations. Here I describe an acceleration heuristic for HMMs, ""multiple segment Viterbi"" (MSV) algorithm. The MSV algorithm computes optimal sum multiple ungapped local alignment segments using a striped vector-parallel approach previously described fast Smith/Waterman alignment. scores follow same statistical distribution as gapped scores, allowing rapid evaluation significance score thus facilitating its filter. also 20-fold standard Forward/Backward algorithms method call ""sparse rescaling"". These are assembled in pipeline which high-scoring hits passed on reanalysis with full This accelerated is implemented freely available HMMER3 package. Performance benchmarks show that filter sacrifices negligible sensitivity compared unaccelerated searches. substantially more sensitive 100- 1000-fold faster than HMMER2. now about BLAST protein

pattern recognition, computer science, profiling tool, clustering, machine learning, big data search, profiling technique, relevance feedback, data science, knowledge discovery, machine learning research, profile hmm searches, information retrieval, hidden markov model, data mining",2011,5454,pattern recognition|computer science|profiling tool|clustering|machine learning|big data search|profiling technique|relevance feedback|data science|knowledge discovery|machine learning research|profile hmm searches|information retrieval|hidden markov model|data mining,
https://openalex.org/W2000982976,Variational Mode Decomposition,"Variational Mode Decomposition

During the late 1990s, Huang introduced algorithm called Empirical Mode Decomposition, which is widely used today to recursively decompose a signal into different modes of unknown but separate spectral bands. EMD known for limitations like sensitivity noise and sampling. These could only partially be addressed by more mathematical attempts this decomposition problem, synchrosqueezing, empirical wavelets or recursive variational decomposition. Here, we propose an entirely non-recursive mode model, where are extracted concurrently. The model looks ensemble their respective center frequencies, such that collectively reproduce input signal, while each being smooth after demodulation baseband. In Fourier domain, corresponds narrow-band prior. We show important relations Wiener filter denoising. Indeed, proposed method generalization classic multiple, adaptive Our provides solution problem theoretically well founded still easy understand. efficiently optimized using alternating direction multipliers approach. Preliminary results attractive performance with respect existing models. particular, our much robust sampling noise. Finally, promising practical on series artificial real data.

computer science, variational analysis, modal analysis, vector processing, applied mathematics, variational mode decomposition, numerical analysis, nonlinear dimensionality reduction, functional analysis",2014,5439,computer science|variational analysis|modal analysis|vector processing|applied mathematics|variational mode decomposition|numerical analysis|nonlinear dimensionality reduction|functional analysis,
https://openalex.org/W2142276208,"A new, fast, and efficient image codec based on set partitioning in hierarchical trees","A new, fast, and efficient image codec based on set partitioning in hierarchical trees

Embedded zerotree wavelet (EZW) coding, introduced by Shapiro (see IEEE Trans. Signal Processing, vol.41, no.12, p.3445, 1993), is a very effective and computationally simple technique for image compression. We offer an alternative explanation of the principles its operation, so that reasons excellent performance can be better understood. These are partial ordering magnitude with set partitioning sorting algorithm, ordered bit plane transmission, exploitation self-similarity across different scales transform. Moreover, we present new implementation based on in hierarchical trees (SPIHT), which provides even than our previously reported extension EZW surpassed original EZW. The coding results, calculated from actual file sizes images reconstructed decoding either comparable to or surpass previous results obtained through much more sophisticated complex methods. In addition, procedures extremely fast, they made faster, only small loss performance, omitting entropy stream arithmetic code.

computational imaging, computer science, set partitioning, image coding, hierarchical trees, efficient image codec, digital image processing",1996,5414,computational imaging|computer science|set partitioning|image coding|hierarchical trees|efficient image codec|digital image processing,https://openalex.org/W2133665775
https://openalex.org/W2163808566,Face Description with Local Binary Patterns: Application to Face Recognition,"Face Description with Local Binary Patterns: Application to Face Recognition

This paper presents a novel and efficient facial image representation based on local binary pattern (LBP) texture features. The face is divided into several regions from which the LBP feature distributions are extracted concatenated an enhanced vector to be used as descriptor. performance of proposed method assessed in recognition problem under different challenges. Other applications extensions also discussed.

pattern recognition, computer science, face description, face recognition, image analysis, information fusion, cognitive science, data science, image representation, computational imaging, sparse representation, deep learning, machine learning research, machine vision, digital image processing, face detection, local binary patterns, computer vision, texture analysis, image similarity, image classification",2006,5406,pattern recognition|computer science|face description|face recognition|image analysis|information fusion|cognitive science|data science|image representation|computational imaging|sparse representation|deep learning|machine learning research|machine vision|digital image processing|face detection|local binary patterns|computer vision|texture analysis|image similarity|image classification,https://openalex.org/W2129812935|https://openalex.org/W2145287260
https://openalex.org/W6908809,ADADELTA: An Adaptive Learning Rate Method,"ADADELTA: An Adaptive Learning Rate Method

We present a novel per-dimension learning rate method for gradient descent called ADADELTA. The dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic descent. requires no manual tuning of appears robust to noisy information, different model architecture choices, various data modalities selection hyperparameters. show promising results compared other methods on the MNIST digit classification task single machine large scale voice dataset in distributed cluster environment.

computer science, sequential learning, machine learning",2012,5403,computer science|sequential learning|machine learning,https://openalex.org/W2157331557|https://openalex.org/W2964308564|https://openalex.org/W1832693441|https://openalex.org/W2950635152|https://openalex.org/W2508457857
https://openalex.org/W2152826865,Active appearance models,"Active appearance models

We describe a new method of matching statistical models appearance to images. A set model parameters control modes shape and gray-level variation learned from training set. construct an efficient iterative algorithm by learning the relationship between perturbations in induced image errors.

computer science, active appearance models, aesthetics",2001,5394,computer science|active appearance models|aesthetics,https://openalex.org/W2168356304|https://openalex.org/W1989702938
https://openalex.org/W2964043796,Asynchronous Methods for Deep Reinforcement Learning,"Asynchronous Methods for Deep Reinforcement Learning

We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent optimization of neural network controllers. present variants four standard algorithms show parallel actor-learners have stabilizing effect on training allowing all methods to successfully train The best performing method, an variant actor-critic, surpasses the current state-of-the-art Atari domain while half time single multi-core CPU instead GPU. Furthermore, we actor-critic succeeds wide variety continuous motor control problems as well new task navigating random 3D mazes using visual input.

machine learning, computer science, deep reinforcement learning, reinforcement learning, deep learning, asynchronous methods",2016,5388,machine learning|computer science|deep reinforcement learning|reinforcement learning|deep learning|asynchronous methods,
https://openalex.org/W2048679005,Combining labeled and unlabeled data with co-training,"Combining labeled and unlabeled data with co-training

Article Free Access Share on Combining labeled and unlabeled data with co-training Authors: Avrim Blum School of Computer Science, Carnegie Mellon University, Pittsburgh, PA PAView Profile , Tom Mitchell Authors Info & Claims COLT' 98: Proceedings the eleventh annual conference Computational learning theoryJuly 1998Pages 92–100https://doi.org/10.1145/279943.279962Published:24 July 1998Publication History 3,333citation12,128DownloadsMetricsTotal Citations3,333Total Downloads12,128Last 12 Months1,744Last 6 weeks220 Get Citation AlertsNew Alert added!This alert has been successfully added will be sent to:You notified whenever a record that you have chosen cited.To manage your preferences, click button below.Manage my Alert!Please log in to account Save BinderSave BinderCreate New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF

pattern recognition, computer science, information fusion, data integration, unsupervised machine learning, machine learning, data science, knowledge discovery, data annotation, classification method, data mining",1998,5386,pattern recognition|computer science|information fusion|data integration|unsupervised machine learning|machine learning|data science|knowledge discovery|data annotation|classification method|data mining,
https://openalex.org/W2167482691,Graph drawing by force‐directed placement,"Graph drawing by force‐directed placement

Abstract We present a modification of the spring‐embedder model Eades [Congressus Numerantium, 42, 149–160, (1984)] for drawing undirected graphs with straight edges. Our heuristic strives uniform edge lengths, and we develop it in analogy to forces natural systems, simple, elegant, conceptually‐intuitive, efficient algorithm.

computer science, graph theory, graph drawing, force-directed placement, graph processing",1991,5383,computer science|graph theory|graph drawing|force-directed placement|graph processing,https://openalex.org/W2150220236
https://openalex.org/W2031533839,Fully homomorphic encryption using ideal lattices,"Fully homomorphic encryption using ideal lattices

We propose a fully homomorphic encryption scheme -- i.e., that allows one to evaluate circuits over encrypted data without being able decrypt. Our solution comes in three steps. First, we provide general result that, construct an permits evaluation of arbitrary circuits, it suffices can (slightly augmented versions of) its own decryption circuit; call (augmented) circuit bootstrappable.

computer science, lattice theory, ideal lattices, homomorphic encryption, theoretical computer science, cryptography, applied mathematics, data security, algebraic number theory, lattice (order)",2009,5366,computer science|lattice theory|ideal lattices|homomorphic encryption|theoretical computer science|cryptography|applied mathematics|data security|algebraic number theory|lattice (order),
https://openalex.org/W2156406284,Recognition-by-components: A theory of human image understanding.,"Recognition-by-components: A theory of human image understanding.

The perceptual recognition of objects is conceptualized to be a process in which the image input segmented at regions deep concavity into an arrangement simple geometric components, such as blocks, cylinders, wedges, and cones. fundamental assumption proposed theory, recognition-by-components (RBC), that modest set generalized-cone called geons (N £ 36), can derived from contrasts five readily detectable properties edges two-dimensiona l image: curvature, collinearity, symmetry, parallelism, cotermination. detection these generally invariant over viewing position an$ quality consequently allows robust object perception when projected novel viewpoint or degraded. RBC thus provides principled account heretofore undecided relation between classic principles organization pattern recognition: constraints toward regularization (Pragnanz) characterize not complete but object's components. Representational power derives allowance free combinations geons. A Principle Componential Recovery for major phenomena If two three recovered input, quickly recognized even they are occluded, novel, rotated depth, extensively results experiments on briefly presented pictures by human observers provide empirical support theory. Any single project infinity configurations retina. orientation viewer vary continuously, each giving rise different two-dimensional projection. occluded other texture fields, viewed behind foliage. need full-colored textured instead simplified line drawing. Moreover, missing some its parts exemplar particular category. But it only with rare exceptions fails rapidly classified, either instance familiar category cannot so classified (itself form classification).

object categorization, computer science, human image understanding, human-computer interaction, pattern recognition, machine vision, visual processing, image representation, object recognition, computational imaging, scene interpretation, machine learning, visual perception, cognition, behavioral sciences, cognitive science, feature detection, image communication, image analysis",1987,5365,object categorization|computer science|human image understanding|human-computer interaction|pattern recognition|machine vision|visual processing|image representation|object recognition|computational imaging|scene interpretation|machine learning|visual perception|cognition|behavioral sciences|cognitive science|feature detection|image communication|image analysis,https://openalex.org/W1989702938
https://openalex.org/W2023808162,The temporal logic of programs,"The temporal logic of programs

A unified approach to program verification is suggested, which applies both sequential and parallel programs. The main proof method suggested that of temporal reasoning in the time dependence events basic concept. Two formal systems are presented for providing a basis reasoning. One forms formalization intermittent assertions, while other an adaptation tense logic system Kb, particularly suitable about concurrent

temporal logic, computer science, logic in computer science, program analysis, temporal complexity, logic programming",1977,5350,temporal logic|computer science|logic in computer science|program analysis|temporal complexity|logic programming,
https://openalex.org/W2119923823,Base-Calling of Automated Sequencer Traces Using <i>Phred.</i> II. Error Probabilities,"Base-Calling of Automated Sequencer Traces Using <i>Phred.</i> II. Error Probabilities

Elimination of the data processing bottleneck in high-throughput sequencing will require both improved accuracy software and reliable measures that accuracy. We have developed implemented our base-calling program phred ability to estimate a probability error for each base-call, as function certain parameters computed from trace data. These probabilities are shown here be valid (correspond actual rates) high power discriminate correct base-calls incorrect ones, read collected under several different chemistries electrophoretic conditions. They play critical role assembly phrap finishing consed.

automated sequencer traces, computer science, error probabilities, sequence analysis, outlier detection, clustering, automated deduction, biostatistics, data science, machine learning research, sequence alignment, error correction, sequence assembly",1998,5346,automated sequencer traces|computer science|error probabilities|sequence analysis|outlier detection|clustering|automated deduction|biostatistics|data science|machine learning research|sequence alignment|error correction|sequence assembly,https://openalex.org/W2121016876|https://openalex.org/W2950354111
https://openalex.org/W1512098439,Fast Training of Support Vector Machines Using Sequential Minimal Optimization,"Fast Training of Support Vector Machines Using Sequential Minimal Optimization

This chapter describes a new algorithm for training Support Vector Machines: Sequential Minimal Optimization, or SMO. Training Machine (SVM) requires the solution of very large quadratic programming (QP) optimization problem. SMO breaks this QP problem into series smallest possible problems. These small problems are solved analytically, which avoids using time-consuming numerical as an inner loop. The amount memory required is linear in set size, allows to handle sets. Because matrix computation avoided, scales somewhere between and size various test problems, while standard projected conjugate gradient (PCG) chunking cubic size. SMO's time dominated by SVM evaluation, hence fastest SVMs sparse data For MNIST database, fast PCG chunking; UCI Adult database SVMs, can be more than 1000 times faster algorithm.

support vector machine, sequential minimal optimization, computer science, machine learning",1998,5345,support vector machine|sequential minimal optimization|computer science|machine learning,https://openalex.org/W1746819321|https://openalex.org/W2172000360
https://openalex.org/W2000359198,A Limited Memory Algorithm for Bound Constrained Optimization,"A Limited Memory Algorithm for Bound Constrained Optimization

An algorithm for solving large nonlinear optimization problems with simple bounds is described. It based on the gradient projection method and uses a limited memory BFGS matrix to approximate Hessian of objective function. shown how take advantage form approximation implement efficiently. The results numerical tests set are reported.

computer science, mathematical optimization, limited memory algorithm, constrained optimization, optimization problem",1995,5342,computer science|mathematical optimization|limited memory algorithm|constrained optimization|optimization problem,https://openalex.org/W3103145119
https://openalex.org/W2339183141,Computational thinking,"Computational thinking

It represents a universally applicable attitude and skill set everyone, not just computer scientists, would be eager to learn use.

computer science, theory of computation, computing education, automated reasoning, computational thinking, scientific computing, computational science",2006,5340,computer science|theory of computation|computing education|automated reasoning|computational thinking|scientific computing|computational science,
https://openalex.org/W2963748441,"SQuAD: 100,000+ Questions for Machine Comprehension of Text","SQuAD: 100,000+ Questions for Machine Comprehension of Text

We present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on set Wikipedia articles, where answer to each question is segment text from corresponding passage. analyze understand types reasoning required questions, leaning heavily dependency and constituency trees. build strong logistic regression model, which achieves an F1 score 51.0%, significant improvement over simple baseline (20%). However, human performance (86.8%) much higher, indicating that presents good challenge problem for future research. The freely available at https://stanford-qa.com

automated reasoning, explainable ai, information retrieval, machine comprehension, knowledge discovery, nlp task, natural language processing, question answering, computer science, language model, machine learning, large language model, artificial intelligence, data science",2016,5338,automated reasoning|explainable ai|information retrieval|machine comprehension|knowledge discovery|nlp task|natural language processing|question answering|computer science|language model|machine learning|large language model|artificial intelligence|data science,https://openalex.org/W2896457183|https://openalex.org/W2965373594
https://openalex.org/W2158899491,Natural Language Processing (almost) from Scratch,"Natural Language Processing (almost) from Scratch

We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, semantic role labeling. This versatility is achieved by trying avoid task-specific engineering therefore disregarding lot of prior knowledge. Instead exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis vast amounts mostly unlabeled training data. work then used as building freely available tagging with good performance minimal computational requirements.

machine learning, computer science, natural language, nlp task, natural language processing, computational linguistics, language model",2011,5330,machine learning|computer science|natural language|nlp task|natural language processing|computational linguistics|language model,https://openalex.org/W2250539671|https://openalex.org/W1832693441
https://openalex.org/W3005680577,A Simple Framework for Contrastive Learning of Visual Representations,"A Simple Framework for Contrastive Learning of Visual Representations

This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed self-supervised algorithms without requiring specialized architectures or memory bank. In order to understand what enables the prediction tasks learn useful representations, we systematically study major components our framework. show that (1) composition data augmentations plays critical role in defining effective predictive tasks, (2) introducing learnable nonlinear transformation between representation and loss substantially improves quality learned (3) benefits from larger batch sizes more training steps compared supervised learning. By combining these findings, are able considerably outperform previous methods semi-supervised on ImageNet. A linear classifier trained representations by SimCLR achieves 76.5% top-1 accuracy, which is 7% relative improvement over state-of-the-art, matching performance ResNet-50. When fine-tuned only 1% labels, achieve 85.8% top-5 outperforming AlexNet with 100X fewer labels.

simple framework, visual modeling, computer vision, machine vision, contrastive learning, visual perception, visual reasoning, cognitive science, computer science, machine learning, image representation, deep learning, data science, visual representations, visual data mining, image analysis",2020,5329,simple framework|visual modeling|computer vision|machine vision|contrastive learning|visual perception|visual reasoning|cognitive science|computer science|machine learning|image representation|deep learning|data science|visual representations|visual data mining|image analysis,https://openalex.org/W3035524453
https://openalex.org/W1966382716,Modern factor analysis,"Modern factor analysis

This thoroughly revised third edition of Harry H. Harman's authoritative text incorporates the many new advances made in computer science and technology over last ten years. The author gives full coverage to both theoretical applied aspects factor analysis from its foundations through most advanced techniques. highly readable will be welcomed by researchers students working psychology, statistics, economics, related disciplines.

image analysis, computer science, latent modeling, modern factor analysis, micro-level evidence, abstract interpretation, applied mathematics, biometrics, causal inference, matrix factorization, statistics, time series, machine learning research, quantitative science study, principal component analysis, data mining",1960,5314,image analysis|computer science|latent modeling|modern factor analysis|micro-level evidence|abstract interpretation|applied mathematics|biometrics|causal inference|matrix factorization|statistics|time series|machine learning research|quantitative science study|principal component analysis|data mining,https://openalex.org/W2141224535
https://openalex.org/W2135505702,An energy-efficient MAC protocol for wireless sensor networks,"An energy-efficient MAC protocol for wireless sensor networks

This paper proposes S-MAC, a medium-access control (MAC) protocol designed for wireless sensor networks. Wireless networks use battery-operated computing and sensing devices. A network of these devices will collaborate common application such as environmental monitoring. We expect to be deployed in an ad hoc fashion, with individual nodes remaining largely inactive long periods time, but then becoming suddenly active when something is detected. These characteristics applications motivate MAC that different from traditional MACs IEEE 802.11 almost every way: energy conservation self-configuration are primary goals, while per-node fairness latency less important. S-MAC uses three novel techniques reduce consumption support self-configuration. To listening idle channel, periodically sleep. Neighboring form virtual clusters auto-synchronize on sleep schedules. Inspired by PAMAS, also sets the radio during transmissions other nodes. Unlike it only in-channel signaling. Finally, applies message passing contention sensor-network require store-and-forward processing data move through network. evaluate our implementation over sample node, Mote, developed at University California, Berkeley. The experiment results show that, source 802.11-like consumes 2-6 times more than traffic load messages sent 1-10 s.

computer science, mobile computing, energy-efficient networking, medium access control, routing protocol, energy-efficient mac protocol, energy efficiency, wireless sensor network, computer engineering",2003,5314,computer science|mobile computing|energy-efficient networking|medium access control|routing protocol|energy-efficient mac protocol|energy efficiency|wireless sensor network|computer engineering,
https://openalex.org/W2114623221,Fog computing and its role in the internet of things,"Fog computing and its role in the internet of things

Fog Computing extends the Cloud paradigm to edge of network, thus enabling a new breed applications and services. Defining characteristics are: a) Low latency location awareness; b) Wide-spread geographical distribution; c) Mobility; d) Very large number nodes, e) Predominant role wireless access, f) Strong presence streaming real time applications, g) Heterogeneity. In this paper we argue that above make appropriate platform for critical Internet Things (IoT) services namely, Connected Vehicle, Smart Grid, Cities, and, in general, Wireless Sensors Actuators Networks (WSANs).

fog computing, information technology, computer science, technology, fog computing security, internet computing, internet of things, ubiquitous computing, iot communication",2012,5310,fog computing|information technology|computer science|technology|fog computing security|internet computing|internet of things|ubiquitous computing|iot communication,https://openalex.org/W2134295053|https://openalex.org/W2416799949
https://openalex.org/W2024135760,Images of Organization,"Images of Organization

Preface Part I. An Overview Introduction II. Some Images of Organization 2. Mechanization Takes Command: Organizations as Machines Machines, Mechanical Thinking, and the Rise Bureaucratic The Origins Mechanistic Classical Management Theory: Designing bureaucratic organizations Scientific Strengths Limitations Machine Metaphor 3. Nature Intervenes: Organisms Discovering Organizational Needs Recognizing Importance Environment: Open Systems Contingency Adapting to Environment Variety Species Promoting Health Development Natural Selection: Population-Ecology View Ecology: Creation Shared Futures Organismic 4. Learning Self-Organization: Brains Brain Information Processing Creating Cybernetics, Learning, Learn Can Learn? Guidelines for Holographic Principles Design Metaphors 5. Social Realty: Cultures Culture a Cultural Phenomenon Context Corporate Subcultures Reality Culture: Rule Following or Enactment? Organization: enactment 6. Interests, Conflict, Power: Political Government Activity Analyzing Interests Understanding Conflict Exploring Power Managing Pluralist 7. Plato's Cave: Psychic Prisons Trap Favored Ways Thinking Unconscious Repressed Sexuality Patriarchal Family Organization, Death, Immortality Anxiety Dolls, Teddy Bears Shadow, Archetype Unconscious: A Creative Destructive Force Prison 8. Unfolding Logics Change: Flux Transformation Autopoiesis: Rethinking Relations With Enactment Form Narcissism: Interact Projections Themselves Identity Closure: Egocentrism Versus Systemic Wisdom Shifting Attractors: Logic Chaos Complexity in Midst Loops, Not Lines: Mutual Causality Contradiction Crisis: Dialectical Change Analysis: How Opposing Forces Drive Dialectics 9. Ugly Face: Instruments Domination Use Exploit Their Employees Class, Control Work Hazards, Occupational Disease, Industrial Accidents Workaholism Mental Stress Politics Radicalized Multinationals World Economy Powers Multinationals: Record Exploitation? III. Implications For Practice 10. Challenge Create Seeing Shaping Life Seeing, Acting New 11. Reading Multicom Case Interpreting Developing Detailed Storyline From Another Emergent Intelligence 12. Postscript Bibliographic Notes Bibliography

image analysis, computer science, organizational behavior, organization study, visual culture, image communication, organizational system, image representation, organization development, organizational theory, art history, organizational characteristic, organizational communication, organizational research, organizational structure",1986,5305,image analysis|computer science|organizational behavior|organization study|visual culture|image communication|organizational system|image representation|organization development|organizational theory|art history|organizational characteristic|organizational communication|organizational research|organizational structure,
https://openalex.org/W1825077972,Neural network design,"Neural network design

This book, by the authors of Neural Network Toolbox for MATLAB, provides a clear and detailed coverage fundamental neural network architectures learning rules. In it, emphasize coherent presentation principal networks, methods training them their applications to practical problems. Features Extensive both feedforward networks (including multilayer radial basis networks) recurrent networks. addition conjugate gradient Levenberg-Marquardt variations backpropagation algorithm, text also covers Bayesian regularization early stopping, which ensure generalization ability trained Associative competitive including feature maps vector quantization, are explained with simple building blocks. A chapter tips function approximation, pattern recognition, clustering prediction, along five chapters presenting real-world case studies. Detailed examples numerous solved Slides comprehensive demonstration software can be downloaded from hagan.okstate.edu/nnd.html.

computer science, artificial intelligence, convolutional neural network, neuroscience, machine learning, networked system design, neural architecture search, cognitive science, systems neuroscience, neural computation, recurrent neural network, evolving neural network, sparse neural network, machine learning research, neural network design, neural network (machine learning)",1995,5304,computer science|artificial intelligence|convolutional neural network|neuroscience|machine learning|networked system design|neural architecture search|cognitive science|systems neuroscience|neural computation|recurrent neural network|evolving neural network|sparse neural network|machine learning research|neural network design|neural network (machine learning),
https://openalex.org/W2098693229,Face recognition using eigenfaces,"Face recognition using eigenfaces

An approach to the detection and identification of human faces is presented, a working, near-real-time face recognition system which tracks subject's head then recognizes person by comparing characteristics those known individuals described. This treats as two-dimensional problem, taking advantage fact that are normally upright thus may be described small set 2-D characteristic views. Face images projected onto feature space ('face space') best encodes variation among images. The defined 'eigenfaces', eigenvectors faces; they do not necessarily correspond isolated features such eyes, ears, noses. framework provides ability learn recognize new in an unsupervised manner.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>

pattern recognition, computer science, face recognition, image analysis, information fusion, feature detection, data science, computational imaging, localization, deep learning, machine learning research, machine vision, digital image processing, face detection, object recognition, feature extraction, computer vision, applied mathematics, image classification",2002,5301,pattern recognition|computer science|face recognition|image analysis|information fusion|feature detection|data science|computational imaging|localization|deep learning|machine learning research|machine vision|digital image processing|face detection|object recognition|feature extraction|computer vision|applied mathematics|image classification,https://openalex.org/W2121647436|https://openalex.org/W2129812935
