{
  "metadata": {
    "domain_name": "deep_learning",
    "analysis_date": "2025-06-22T22:59:58.878327",
    "analysis_type": "period_signal_detection",
    "description": "Period characterization using temporal network stability analysis",
    "methodology": {
      "data_sources": "Papers, semantic citations, breakthrough papers",
      "network_construction": "Citation network with temporal filtering",
      "analysis_metrics": "Stability, persistence, flow, centrality consensus",
      "theme_detection": "TF-IDF with network structure enhancement",
      "paper_selection": "Network centrality-based selection",
      "labeling": "LLM-enhanced period labeling"
    }
  },
  "input_segments": {
    "count": 1,
    "description": "Time segments from shift signal detection",
    "segments": [
      {
        "start_year": 1995,
        "end_year": 2020,
        "duration": 26
      }
    ]
  },
  "period_characterizations": {
    "count": 1,
    "description": "Final period characterizations with network analysis",
    "characterizations": [
      {
        "period": [
          1995,
          2020
        ],
        "topic_label": "Empirical Optimization of Deep Architectures",
        "topic_description": "This paradigm centers on the empirical refinement of deep neural network architectures through systematic experimentation, as evidenced by the development of residual networks (2016), Inception modules (2015), and fully convolutional networks (2015). It emphasizes architectural innovations like depth increase, efficient computation, and feature hierarchy learning, supported by large-scale benchmarks such as ImageNet and PASCAL VOC, to achieve state-of-the-art performance through iterative model improvements.",
        "network_stability": 0.35879950361769325,
        "community_persistence": 0.4237082889942988,
        "flow_stability": 0.6237961297137447,
        "centrality_consensus": 0.9949943037493145,
        "representative_papers": [
          {
            "id": "https://openalex.org/W2194775991",
            "title": "Deep Residual Learning for Image Recognition",
            "year": 2016,
            "citation_count": 159317,
            "score": 0.26971970102383525,
            "is_breakthrough": true,
            "abstract": "The article presents a residual learning framework that simplifies the training of significantly deeper neural networks, demonstrating that these networks can achieve higher accuracy with lower complexity. It highlights empirical results from the ImageNet dataset, where a deep residual network achieved a 3.57% error rate, winning first place in the ILSVRC 2015 classification task, and shows improvements in object detection on the COCO dataset due to enhanced deep representations.\n\nTopic: image analysis, pattern recognition, computer science, computational imaging, convolutional neural network, object recognition, unsupervised machine learning, machine learning, deep residual learning, deep learning, image representation, image recognition, principal component analysis, image classification, digital image processing",
            "keywords": [
              "image analysis",
              "pattern recognition",
              "computer science",
              "computational imaging",
              "convolutional neural network",
              "object recognition",
              "unsupervised machine learning",
              "machine learning",
              "deep residual learning",
              "deep learning",
              "image representation",
              "image recognition",
              "principal component analysis",
              "image classification",
              "digital image processing"
            ]
          },
          {
            "id": "https://openalex.org/W2962835968",
            "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
            "year": 2014,
            "citation_count": 49225,
            "score": 0.2659107761808289,
            "is_breakthrough": true,
            "abstract": "The article explores the impact of increasing the depth of convolutional networks on accuracy in large-scale image recognition, demonstrating that using very small (3x3) convolution filters can significantly enhance performance with networks of 16-19 weight layers. The findings contributed to a successful submission in the ImageNet Challenge 2014, securing top placements, and the authors have made their best-performing models publicly available to support further research in deep learning and computer vision.\n\nTopic: digital image processing, automatic classification, deep convolutional networks, computer science, machine learning research, deep learning, pattern recognition, machine vision, image representation, large-scale image recognition, large-scale datasets, computational imaging, machine learning, data science, cognitive science, computational intelligence, convolutional neural network, feature detection, unsupervised machine learning, image analysis",
            "keywords": [
              "digital image processing",
              "automatic classification",
              "deep convolutional networks",
              "computer science",
              "machine learning research",
              "deep learning",
              "pattern recognition",
              "machine vision",
              "image representation",
              "large-scale image recognition",
              "large-scale datasets",
              "computational imaging",
              "machine learning",
              "data science",
              "cognitive science",
              "computational intelligence",
              "convolutional neural network",
              "feature detection",
              "unsupervised machine learning",
              "image analysis"
            ]
          },
          {
            "id": "https://openalex.org/W2102605133",
            "title": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation",
            "year": 2014,
            "citation_count": 24628,
            "score": 0.264372525934776,
            "is_breakthrough": true,
            "abstract": "The article presents a novel algorithm, R-CNN, that significantly enhances object detection and semantic segmentation performance on the PASCAL VOC dataset by over 30% compared to previous methods. It leverages high-capacity convolutional neural networks for region proposals and emphasizes the benefits of supervised pre-training with limited labeled data, providing insights into the learned feature hierarchies.\n\nTopic: pattern recognition, computer science, machine learning, fuzzy set, image analysis, information fusion, accurate object detection, feature detection, cognitive science, object detection, data science, object categorization, computational imaging, localization, deep learning, machine vision, rich feature hierarchies, semantic segmentation, object recognition, computer vision, scene analysis",
            "keywords": [
              "pattern recognition",
              "computer science",
              "machine learning",
              "fuzzy set",
              "image analysis",
              "information fusion",
              "accurate object detection",
              "feature detection",
              "cognitive science",
              "object detection",
              "data science",
              "object categorization",
              "computational imaging",
              "localization",
              "deep learning",
              "machine vision",
              "rich feature hierarchies",
              "semantic segmentation",
              "object recognition",
              "computer vision",
              "scene analysis"
            ]
          },
          {
            "id": "https://openalex.org/W2097117768",
            "title": "Going deeper with convolutions",
            "year": 2015,
            "citation_count": 40093,
            "score": 0.263268278724901,
            "is_breakthrough": true,
            "abstract": "The article introduces a deep convolutional neural network architecture called Inception, which achieved state-of-the-art results in the ImageNet Large-Scale Visual Recognition Challenge 2014. It emphasizes the efficient use of computational resources through a carefully designed network structure, exemplified by GoogLeNet, a 22-layer model that enhances classification and detection capabilities while maintaining a constant computational budget.\n\nTopic: image analysis, computational imaging, computer science, information fusion, convolutional neural network, large language model, deep reinforcement learning, machine learning, applied mathematics, sparse neural network, data science, neural computation, deep learning, computational intelligence, machine learning research, deepfakes, neural network (machine learning), machine vision",
            "keywords": [
              "image analysis",
              "computational imaging",
              "computer science",
              "information fusion",
              "convolutional neural network",
              "large language model",
              "deep reinforcement learning",
              "machine learning",
              "applied mathematics",
              "sparse neural network",
              "data science",
              "neural computation",
              "deep learning",
              "computational intelligence",
              "machine learning research",
              "deepfakes",
              "neural network (machine learning)",
              "machine vision"
            ]
          },
          {
            "id": "https://openalex.org/W1903029394",
            "title": "Fully convolutional networks for semantic segmentation",
            "year": 2015,
            "citation_count": 28292,
            "score": 0.26129795522731303,
            "is_breakthrough": true,
            "abstract": "The article discusses the development and application of fully convolutional networks (FCNs) for semantic segmentation, demonstrating that these networks can outperform state-of-the-art methods by processing images of arbitrary sizes and producing correspondingly-sized outputs. It highlights the architecture's ability to combine features from different layers for improved segmentation accuracy and reports significant performance improvements on benchmark datasets like PASCAL VOC and NYUDv2.\n\nTopic: pattern recognition, computer science, machine learning, image segmentation, image analysis, information fusion, convolutional neural network, convolutional networks, cognitive science, data science, computational imaging, scene understanding, deep learning, machine learning research, machine vision, semantic segmentation, medical image computing, feature extraction, computer vision, scene analysis",
            "keywords": [
              "pattern recognition",
              "computer science",
              "machine learning",
              "image segmentation",
              "image analysis",
              "information fusion",
              "convolutional neural network",
              "convolutional networks",
              "cognitive science",
              "data science",
              "computational imaging",
              "scene understanding",
              "deep learning",
              "machine learning research",
              "machine vision",
              "semantic segmentation",
              "medical image computing",
              "feature extraction",
              "computer vision",
              "scene analysis"
            ]
          },
          {
            "id": "https://openalex.org/W2163605009",
            "title": "ImageNet Classification with Deep Convolutional Neural Networks",
            "year": 2012,
            "citation_count": 63969,
            "score": 0.2594184002763554,
            "is_breakthrough": false,
            "abstract": "The article discusses the development and training of a deep convolutional neural network that achieved significant improvements in image classification accuracy on the ImageNet dataset, achieving top-1 and top-5 error rates of 37.5% and 17.0%, respectively. It highlights the network's architecture, including its use of non-saturating neurons and dropout regularization, and notes its success in the ILSVRC-2012 competition, where it outperformed other entries with a winning rate of 15.3%.\n\nTopic: digital image processing, biomedical imaging, automatic classification, intelligent classification, neural network (machine learning), imagenet classification, computer science, health science, machine learning research, deep learning, image representation, medical image computing, computational imaging, data classification, machine learning, image classification, data science, convolutional neural network, image analysis",
            "keywords": [
              "digital image processing",
              "biomedical imaging",
              "automatic classification",
              "intelligent classification",
              "neural network (machine learning)",
              "imagenet classification",
              "computer science",
              "health science",
              "machine learning research",
              "deep learning",
              "image representation",
              "medical image computing",
              "computational imaging",
              "data classification",
              "machine learning",
              "image classification",
              "data science",
              "convolutional neural network",
              "image analysis"
            ]
          },
          {
            "id": "https://openalex.org/W3118608800",
            "title": "Learning Multiple Layers of Features from Tiny Images",
            "year": 2009,
            "citation_count": 21388,
            "score": 0.2474696724459328,
            "is_breakthrough": true,
            "abstract": "The article discusses the training of a multi-layer generative model for natural images using a dataset of millions of tiny color images, specifically focusing on Restricted Boltzmann Machines (RBMs) and Deep Belief Networks (DBNs) to learn effective image features and improve classification performance compared to raw pixel data. It highlights the challenges faced by previous attempts and emphasizes the use of the CIFAR-10 dataset for labeled image analysis.\n\nTopic: image analysis, computational imaging, computer science, feature learning, computer vision, machine learning, tiny images, feature fusion, multiple layers, data science, knowledge discovery, deep learning, image representation, few-shot learning, machine vision, digital image processing, multiple instance learning",
            "keywords": [
              "image analysis",
              "computational imaging",
              "computer science",
              "feature learning",
              "computer vision",
              "machine learning",
              "tiny images",
              "feature fusion",
              "multiple layers",
              "data science",
              "knowledge discovery",
              "deep learning",
              "image representation",
              "few-shot learning",
              "machine vision",
              "digital image processing",
              "multiple instance learning"
            ]
          },
          {
            "id": "https://openalex.org/W1836465849",
            "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift",
            "year": 2015,
            "citation_count": 19668,
            "score": 0.24655352674458347,
            "is_breakthrough": true,
            "abstract": "The article discusses Batch Normalization, a technique designed to address the issue of internal covariate shift in deep neural networks, which complicates training by altering the distribution of layer inputs. By normalizing inputs within mini-batches, this method accelerates training, allows for higher learning rates, and can reduce the need for other regularization techniques, ultimately achieving significant improvements in model accuracy on tasks like image classification.\n\nTopic: neural network (machine learning), internal covariate shift, batch normalization, computer science, machine learning, deep learning, data science",
            "keywords": [
              "neural network (machine learning)",
              "internal covariate shift",
              "batch normalization",
              "computer science",
              "machine learning",
              "deep learning",
              "data science"
            ]
          }
        ],
        "network_metrics": {
          "density": 0.012473123121432833,
          "number_of_nodes": 422,
          "number_of_edges": 2216,
          "average_clustering": 0.21681858490060552,
          "number_of_components": 62,
          "degree_centralization": 0.237461825585341
        },
        "confidence": 0.962690172125927
      }
    ],
    "confidence_statistics": {
      "mean_confidence": 0.962690172125927,
      "min_confidence": 0,
      "max_confidence": 1
    }
  },
  "detailed_analysis": {
    "count": 1,
    "description": "Detailed analysis data for each period including intermediate metrics",
    "analysis_data": [
      {
        "period": [
          1995,
          2020
        ],
        "num_papers": 422,
        "num_breakthrough_papers": 100,
        "network_stability": 0.35879950361769325,
        "community_persistence": 0.4237082889942988,
        "flow_stability": 0.6237961297137447,
        "centrality_consensus": 0.9949943037493145,
        "dominant_themes": [
          "neural",
          "image",
          "learning"
        ],
        "representative_papers": [
          {
            "id": "https://openalex.org/W2194775991",
            "title": "Deep Residual Learning for Image Recognition",
            "year": 2016,
            "citation_count": 159317,
            "score": 0.26971970102383525,
            "is_breakthrough": true,
            "abstract": "The article presents a residual learning framework that simplifies the training of significantly deeper neural networks, demonstrating that these networks can achieve higher accuracy with lower complexity. It highlights empirical results from the ImageNet dataset, where a deep residual network achieved a 3.57% error rate, winning first place in the ILSVRC 2015 classification task, and shows improvements in object detection on the COCO dataset due to enhanced deep representations.\n\nTopic: image analysis, pattern recognition, computer science, computational imaging, convolutional neural network, object recognition, unsupervised machine learning, machine learning, deep residual learning, deep learning, image representation, image recognition, principal component analysis, image classification, digital image processing",
            "keywords": [
              "image analysis",
              "pattern recognition",
              "computer science",
              "computational imaging",
              "convolutional neural network",
              "object recognition",
              "unsupervised machine learning",
              "machine learning",
              "deep residual learning",
              "deep learning",
              "image representation",
              "image recognition",
              "principal component analysis",
              "image classification",
              "digital image processing"
            ]
          },
          {
            "id": "https://openalex.org/W2962835968",
            "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
            "year": 2014,
            "citation_count": 49225,
            "score": 0.2659107761808289,
            "is_breakthrough": true,
            "abstract": "The article explores the impact of increasing the depth of convolutional networks on accuracy in large-scale image recognition, demonstrating that using very small (3x3) convolution filters can significantly enhance performance with networks of 16-19 weight layers. The findings contributed to a successful submission in the ImageNet Challenge 2014, securing top placements, and the authors have made their best-performing models publicly available to support further research in deep learning and computer vision.\n\nTopic: digital image processing, automatic classification, deep convolutional networks, computer science, machine learning research, deep learning, pattern recognition, machine vision, image representation, large-scale image recognition, large-scale datasets, computational imaging, machine learning, data science, cognitive science, computational intelligence, convolutional neural network, feature detection, unsupervised machine learning, image analysis",
            "keywords": [
              "digital image processing",
              "automatic classification",
              "deep convolutional networks",
              "computer science",
              "machine learning research",
              "deep learning",
              "pattern recognition",
              "machine vision",
              "image representation",
              "large-scale image recognition",
              "large-scale datasets",
              "computational imaging",
              "machine learning",
              "data science",
              "cognitive science",
              "computational intelligence",
              "convolutional neural network",
              "feature detection",
              "unsupervised machine learning",
              "image analysis"
            ]
          },
          {
            "id": "https://openalex.org/W2102605133",
            "title": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation",
            "year": 2014,
            "citation_count": 24628,
            "score": 0.264372525934776,
            "is_breakthrough": true,
            "abstract": "The article presents a novel algorithm, R-CNN, that significantly enhances object detection and semantic segmentation performance on the PASCAL VOC dataset by over 30% compared to previous methods. It leverages high-capacity convolutional neural networks for region proposals and emphasizes the benefits of supervised pre-training with limited labeled data, providing insights into the learned feature hierarchies.\n\nTopic: pattern recognition, computer science, machine learning, fuzzy set, image analysis, information fusion, accurate object detection, feature detection, cognitive science, object detection, data science, object categorization, computational imaging, localization, deep learning, machine vision, rich feature hierarchies, semantic segmentation, object recognition, computer vision, scene analysis",
            "keywords": [
              "pattern recognition",
              "computer science",
              "machine learning",
              "fuzzy set",
              "image analysis",
              "information fusion",
              "accurate object detection",
              "feature detection",
              "cognitive science",
              "object detection",
              "data science",
              "object categorization",
              "computational imaging",
              "localization",
              "deep learning",
              "machine vision",
              "rich feature hierarchies",
              "semantic segmentation",
              "object recognition",
              "computer vision",
              "scene analysis"
            ]
          },
          {
            "id": "https://openalex.org/W2097117768",
            "title": "Going deeper with convolutions",
            "year": 2015,
            "citation_count": 40093,
            "score": 0.263268278724901,
            "is_breakthrough": true,
            "abstract": "The article introduces a deep convolutional neural network architecture called Inception, which achieved state-of-the-art results in the ImageNet Large-Scale Visual Recognition Challenge 2014. It emphasizes the efficient use of computational resources through a carefully designed network structure, exemplified by GoogLeNet, a 22-layer model that enhances classification and detection capabilities while maintaining a constant computational budget.\n\nTopic: image analysis, computational imaging, computer science, information fusion, convolutional neural network, large language model, deep reinforcement learning, machine learning, applied mathematics, sparse neural network, data science, neural computation, deep learning, computational intelligence, machine learning research, deepfakes, neural network (machine learning), machine vision",
            "keywords": [
              "image analysis",
              "computational imaging",
              "computer science",
              "information fusion",
              "convolutional neural network",
              "large language model",
              "deep reinforcement learning",
              "machine learning",
              "applied mathematics",
              "sparse neural network",
              "data science",
              "neural computation",
              "deep learning",
              "computational intelligence",
              "machine learning research",
              "deepfakes",
              "neural network (machine learning)",
              "machine vision"
            ]
          },
          {
            "id": "https://openalex.org/W1903029394",
            "title": "Fully convolutional networks for semantic segmentation",
            "year": 2015,
            "citation_count": 28292,
            "score": 0.26129795522731303,
            "is_breakthrough": true,
            "abstract": "The article discusses the development and application of fully convolutional networks (FCNs) for semantic segmentation, demonstrating that these networks can outperform state-of-the-art methods by processing images of arbitrary sizes and producing correspondingly-sized outputs. It highlights the architecture's ability to combine features from different layers for improved segmentation accuracy and reports significant performance improvements on benchmark datasets like PASCAL VOC and NYUDv2.\n\nTopic: pattern recognition, computer science, machine learning, image segmentation, image analysis, information fusion, convolutional neural network, convolutional networks, cognitive science, data science, computational imaging, scene understanding, deep learning, machine learning research, machine vision, semantic segmentation, medical image computing, feature extraction, computer vision, scene analysis",
            "keywords": [
              "pattern recognition",
              "computer science",
              "machine learning",
              "image segmentation",
              "image analysis",
              "information fusion",
              "convolutional neural network",
              "convolutional networks",
              "cognitive science",
              "data science",
              "computational imaging",
              "scene understanding",
              "deep learning",
              "machine learning research",
              "machine vision",
              "semantic segmentation",
              "medical image computing",
              "feature extraction",
              "computer vision",
              "scene analysis"
            ]
          },
          {
            "id": "https://openalex.org/W2163605009",
            "title": "ImageNet Classification with Deep Convolutional Neural Networks",
            "year": 2012,
            "citation_count": 63969,
            "score": 0.2594184002763554,
            "is_breakthrough": false,
            "abstract": "The article discusses the development and training of a deep convolutional neural network that achieved significant improvements in image classification accuracy on the ImageNet dataset, achieving top-1 and top-5 error rates of 37.5% and 17.0%, respectively. It highlights the network's architecture, including its use of non-saturating neurons and dropout regularization, and notes its success in the ILSVRC-2012 competition, where it outperformed other entries with a winning rate of 15.3%.\n\nTopic: digital image processing, biomedical imaging, automatic classification, intelligent classification, neural network (machine learning), imagenet classification, computer science, health science, machine learning research, deep learning, image representation, medical image computing, computational imaging, data classification, machine learning, image classification, data science, convolutional neural network, image analysis",
            "keywords": [
              "digital image processing",
              "biomedical imaging",
              "automatic classification",
              "intelligent classification",
              "neural network (machine learning)",
              "imagenet classification",
              "computer science",
              "health science",
              "machine learning research",
              "deep learning",
              "image representation",
              "medical image computing",
              "computational imaging",
              "data classification",
              "machine learning",
              "image classification",
              "data science",
              "convolutional neural network",
              "image analysis"
            ]
          },
          {
            "id": "https://openalex.org/W3118608800",
            "title": "Learning Multiple Layers of Features from Tiny Images",
            "year": 2009,
            "citation_count": 21388,
            "score": 0.2474696724459328,
            "is_breakthrough": true,
            "abstract": "The article discusses the training of a multi-layer generative model for natural images using a dataset of millions of tiny color images, specifically focusing on Restricted Boltzmann Machines (RBMs) and Deep Belief Networks (DBNs) to learn effective image features and improve classification performance compared to raw pixel data. It highlights the challenges faced by previous attempts and emphasizes the use of the CIFAR-10 dataset for labeled image analysis.\n\nTopic: image analysis, computational imaging, computer science, feature learning, computer vision, machine learning, tiny images, feature fusion, multiple layers, data science, knowledge discovery, deep learning, image representation, few-shot learning, machine vision, digital image processing, multiple instance learning",
            "keywords": [
              "image analysis",
              "computational imaging",
              "computer science",
              "feature learning",
              "computer vision",
              "machine learning",
              "tiny images",
              "feature fusion",
              "multiple layers",
              "data science",
              "knowledge discovery",
              "deep learning",
              "image representation",
              "few-shot learning",
              "machine vision",
              "digital image processing",
              "multiple instance learning"
            ]
          },
          {
            "id": "https://openalex.org/W1836465849",
            "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift",
            "year": 2015,
            "citation_count": 19668,
            "score": 0.24655352674458347,
            "is_breakthrough": true,
            "abstract": "The article discusses Batch Normalization, a technique designed to address the issue of internal covariate shift in deep neural networks, which complicates training by altering the distribution of layer inputs. By normalizing inputs within mini-batches, this method accelerates training, allows for higher learning rates, and can reduce the need for other regularization techniques, ultimately achieving significant improvements in model accuracy on tasks like image classification.\n\nTopic: neural network (machine learning), internal covariate shift, batch normalization, computer science, machine learning, deep learning, data science",
            "keywords": [
              "neural network (machine learning)",
              "internal covariate shift",
              "batch normalization",
              "computer science",
              "machine learning",
              "deep learning",
              "data science"
            ]
          }
        ],
        "network_metrics": {
          "density": 0.012473123121432833,
          "number_of_nodes": 422,
          "number_of_edges": 2216,
          "average_clustering": 0.21681858490060552,
          "number_of_components": 62,
          "degree_centralization": 0.237461825585341
        },
        "confidence": 0.962690172125927,
        "period_label": "Empirical Optimization of Deep Architectures",
        "period_description": "This paradigm centers on the empirical refinement of deep neural network architectures through systematic experimentation, as evidenced by the development of residual networks (2016), Inception modules (2015), and fully convolutional networks (2015). It emphasizes architectural innovations like depth increase, efficient computation, and feature hierarchy learning, supported by large-scale benchmarks such as ImageNet and PASCAL VOC, to achieve state-of-the-art performance through iterative model improvements."
      }
    ],
    "network_statistics": {
      "total_papers_analyzed": 422,
      "total_breakthrough_papers": 100,
      "average_network_stability": 0.35879950361769325
    }
  },
  "visualization_metadata": {
    "timeline_data": {
      "period_boundaries": [
        [
          1995,
          2020
        ]
      ],
      "period_labels": [
        "Empirical Optimization of Deep Architectures"
      ],
      "confidence_timeline": [
        [
          1995,
          0.962690172125927
        ]
      ]
    },
    "network_metrics_timeline": {
      "stability_timeline": [
        [
          1995,
          0.35879950361769325
        ]
      ],
      "persistence_timeline": [
        [
          1995,
          0.4237082889942988
        ]
      ],
      "flow_timeline": [
        [
          1995,
          0.6237961297137447
        ]
      ],
      "consensus_timeline": [
        [
          1995,
          0.9949943037493145
        ]
      ]
    },
    "thematic_evolution": {
      "themes_by_period": [
        [
          [
            1995,
            2020
          ],
          [
            "neural",
            "image",
            "learning"
          ]
        ]
      ],
      "representative_papers_by_period": [
        [
          [
            1995,
            2020
          ],
          [
            {
              "id": "https://openalex.org/W2194775991",
              "title": "Deep Residual Learning for Image Recognition",
              "year": 2016,
              "citation_count": 159317,
              "score": 0.26971970102383525,
              "is_breakthrough": true,
              "abstract": "The article presents a residual learning framework that simplifies the training of significantly deeper neural networks, demonstrating that these networks can achieve higher accuracy with lower complexity. It highlights empirical results from the ImageNet dataset, where a deep residual network achieved a 3.57% error rate, winning first place in the ILSVRC 2015 classification task, and shows improvements in object detection on the COCO dataset due to enhanced deep representations.\n\nTopic: image analysis, pattern recognition, computer science, computational imaging, convolutional neural network, object recognition, unsupervised machine learning, machine learning, deep residual learning, deep learning, image representation, image recognition, principal component analysis, image classification, digital image processing",
              "keywords": [
                "image analysis",
                "pattern recognition",
                "computer science",
                "computational imaging",
                "convolutional neural network",
                "object recognition",
                "unsupervised machine learning",
                "machine learning",
                "deep residual learning",
                "deep learning",
                "image representation",
                "image recognition",
                "principal component analysis",
                "image classification",
                "digital image processing"
              ]
            },
            {
              "id": "https://openalex.org/W2962835968",
              "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
              "year": 2014,
              "citation_count": 49225,
              "score": 0.2659107761808289,
              "is_breakthrough": true,
              "abstract": "The article explores the impact of increasing the depth of convolutional networks on accuracy in large-scale image recognition, demonstrating that using very small (3x3) convolution filters can significantly enhance performance with networks of 16-19 weight layers. The findings contributed to a successful submission in the ImageNet Challenge 2014, securing top placements, and the authors have made their best-performing models publicly available to support further research in deep learning and computer vision.\n\nTopic: digital image processing, automatic classification, deep convolutional networks, computer science, machine learning research, deep learning, pattern recognition, machine vision, image representation, large-scale image recognition, large-scale datasets, computational imaging, machine learning, data science, cognitive science, computational intelligence, convolutional neural network, feature detection, unsupervised machine learning, image analysis",
              "keywords": [
                "digital image processing",
                "automatic classification",
                "deep convolutional networks",
                "computer science",
                "machine learning research",
                "deep learning",
                "pattern recognition",
                "machine vision",
                "image representation",
                "large-scale image recognition",
                "large-scale datasets",
                "computational imaging",
                "machine learning",
                "data science",
                "cognitive science",
                "computational intelligence",
                "convolutional neural network",
                "feature detection",
                "unsupervised machine learning",
                "image analysis"
              ]
            },
            {
              "id": "https://openalex.org/W2102605133",
              "title": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation",
              "year": 2014,
              "citation_count": 24628,
              "score": 0.264372525934776,
              "is_breakthrough": true,
              "abstract": "The article presents a novel algorithm, R-CNN, that significantly enhances object detection and semantic segmentation performance on the PASCAL VOC dataset by over 30% compared to previous methods. It leverages high-capacity convolutional neural networks for region proposals and emphasizes the benefits of supervised pre-training with limited labeled data, providing insights into the learned feature hierarchies.\n\nTopic: pattern recognition, computer science, machine learning, fuzzy set, image analysis, information fusion, accurate object detection, feature detection, cognitive science, object detection, data science, object categorization, computational imaging, localization, deep learning, machine vision, rich feature hierarchies, semantic segmentation, object recognition, computer vision, scene analysis",
              "keywords": [
                "pattern recognition",
                "computer science",
                "machine learning",
                "fuzzy set",
                "image analysis",
                "information fusion",
                "accurate object detection",
                "feature detection",
                "cognitive science",
                "object detection",
                "data science",
                "object categorization",
                "computational imaging",
                "localization",
                "deep learning",
                "machine vision",
                "rich feature hierarchies",
                "semantic segmentation",
                "object recognition",
                "computer vision",
                "scene analysis"
              ]
            },
            {
              "id": "https://openalex.org/W2097117768",
              "title": "Going deeper with convolutions",
              "year": 2015,
              "citation_count": 40093,
              "score": 0.263268278724901,
              "is_breakthrough": true,
              "abstract": "The article introduces a deep convolutional neural network architecture called Inception, which achieved state-of-the-art results in the ImageNet Large-Scale Visual Recognition Challenge 2014. It emphasizes the efficient use of computational resources through a carefully designed network structure, exemplified by GoogLeNet, a 22-layer model that enhances classification and detection capabilities while maintaining a constant computational budget.\n\nTopic: image analysis, computational imaging, computer science, information fusion, convolutional neural network, large language model, deep reinforcement learning, machine learning, applied mathematics, sparse neural network, data science, neural computation, deep learning, computational intelligence, machine learning research, deepfakes, neural network (machine learning), machine vision",
              "keywords": [
                "image analysis",
                "computational imaging",
                "computer science",
                "information fusion",
                "convolutional neural network",
                "large language model",
                "deep reinforcement learning",
                "machine learning",
                "applied mathematics",
                "sparse neural network",
                "data science",
                "neural computation",
                "deep learning",
                "computational intelligence",
                "machine learning research",
                "deepfakes",
                "neural network (machine learning)",
                "machine vision"
              ]
            },
            {
              "id": "https://openalex.org/W1903029394",
              "title": "Fully convolutional networks for semantic segmentation",
              "year": 2015,
              "citation_count": 28292,
              "score": 0.26129795522731303,
              "is_breakthrough": true,
              "abstract": "The article discusses the development and application of fully convolutional networks (FCNs) for semantic segmentation, demonstrating that these networks can outperform state-of-the-art methods by processing images of arbitrary sizes and producing correspondingly-sized outputs. It highlights the architecture's ability to combine features from different layers for improved segmentation accuracy and reports significant performance improvements on benchmark datasets like PASCAL VOC and NYUDv2.\n\nTopic: pattern recognition, computer science, machine learning, image segmentation, image analysis, information fusion, convolutional neural network, convolutional networks, cognitive science, data science, computational imaging, scene understanding, deep learning, machine learning research, machine vision, semantic segmentation, medical image computing, feature extraction, computer vision, scene analysis",
              "keywords": [
                "pattern recognition",
                "computer science",
                "machine learning",
                "image segmentation",
                "image analysis",
                "information fusion",
                "convolutional neural network",
                "convolutional networks",
                "cognitive science",
                "data science",
                "computational imaging",
                "scene understanding",
                "deep learning",
                "machine learning research",
                "machine vision",
                "semantic segmentation",
                "medical image computing",
                "feature extraction",
                "computer vision",
                "scene analysis"
              ]
            },
            {
              "id": "https://openalex.org/W2163605009",
              "title": "ImageNet Classification with Deep Convolutional Neural Networks",
              "year": 2012,
              "citation_count": 63969,
              "score": 0.2594184002763554,
              "is_breakthrough": false,
              "abstract": "The article discusses the development and training of a deep convolutional neural network that achieved significant improvements in image classification accuracy on the ImageNet dataset, achieving top-1 and top-5 error rates of 37.5% and 17.0%, respectively. It highlights the network's architecture, including its use of non-saturating neurons and dropout regularization, and notes its success in the ILSVRC-2012 competition, where it outperformed other entries with a winning rate of 15.3%.\n\nTopic: digital image processing, biomedical imaging, automatic classification, intelligent classification, neural network (machine learning), imagenet classification, computer science, health science, machine learning research, deep learning, image representation, medical image computing, computational imaging, data classification, machine learning, image classification, data science, convolutional neural network, image analysis",
              "keywords": [
                "digital image processing",
                "biomedical imaging",
                "automatic classification",
                "intelligent classification",
                "neural network (machine learning)",
                "imagenet classification",
                "computer science",
                "health science",
                "machine learning research",
                "deep learning",
                "image representation",
                "medical image computing",
                "computational imaging",
                "data classification",
                "machine learning",
                "image classification",
                "data science",
                "convolutional neural network",
                "image analysis"
              ]
            },
            {
              "id": "https://openalex.org/W3118608800",
              "title": "Learning Multiple Layers of Features from Tiny Images",
              "year": 2009,
              "citation_count": 21388,
              "score": 0.2474696724459328,
              "is_breakthrough": true,
              "abstract": "The article discusses the training of a multi-layer generative model for natural images using a dataset of millions of tiny color images, specifically focusing on Restricted Boltzmann Machines (RBMs) and Deep Belief Networks (DBNs) to learn effective image features and improve classification performance compared to raw pixel data. It highlights the challenges faced by previous attempts and emphasizes the use of the CIFAR-10 dataset for labeled image analysis.\n\nTopic: image analysis, computational imaging, computer science, feature learning, computer vision, machine learning, tiny images, feature fusion, multiple layers, data science, knowledge discovery, deep learning, image representation, few-shot learning, machine vision, digital image processing, multiple instance learning",
              "keywords": [
                "image analysis",
                "computational imaging",
                "computer science",
                "feature learning",
                "computer vision",
                "machine learning",
                "tiny images",
                "feature fusion",
                "multiple layers",
                "data science",
                "knowledge discovery",
                "deep learning",
                "image representation",
                "few-shot learning",
                "machine vision",
                "digital image processing",
                "multiple instance learning"
              ]
            },
            {
              "id": "https://openalex.org/W1836465849",
              "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift",
              "year": 2015,
              "citation_count": 19668,
              "score": 0.24655352674458347,
              "is_breakthrough": true,
              "abstract": "The article discusses Batch Normalization, a technique designed to address the issue of internal covariate shift in deep neural networks, which complicates training by altering the distribution of layer inputs. By normalizing inputs within mini-batches, this method accelerates training, allows for higher learning rates, and can reduce the need for other regularization techniques, ultimately achieving significant improvements in model accuracy on tasks like image classification.\n\nTopic: neural network (machine learning), internal covariate shift, batch normalization, computer science, machine learning, deep learning, data science",
              "keywords": [
                "neural network (machine learning)",
                "internal covariate shift",
                "batch normalization",
                "computer science",
                "machine learning",
                "deep learning",
                "data science"
              ]
            }
          ]
        ]
      ]
    },
    "period_statistics": {
      "average_period_duration": 26.0,
      "total_timespan": 26,
      "characterization_success_rate": 1.0
    }
  }
}